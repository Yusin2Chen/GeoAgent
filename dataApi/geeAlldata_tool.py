from typing import Protocol, TypeVar, Generic, Sequence, Dict, Optional, List, Tuple, Any, Set, Union, Callable
from .gee_utils import BBox, Collection
import iso8601
import json
import os
import requests
from datetime import datetime
from .data_registery import DataRegistry
geeData_registery = DataRegistry()

@geeData_registery.add()
class AAFC_ACI:
    def __init__(self,):
        self.sensor = 'AAFC_ACI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AAFC_ACI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AAFC_ACI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AAFC_ACI(example: str = ''):
        """
        Starting in 2009, the Earth Observation Team of the Science and Technology Branch (STB) at Agriculture and Agri-Food Canada (AAFC) began the process of generating annual crop type digital maps. Focusing on the Prairie Provinces in 2009 and 2010, a Decision Tree (DT) based methodology was applied using optical (Landsat-5, AWiFS, DMC) and radar (Radarsat-2) based satellite images. Beginning with the 2011 growing season, this activity has been extended to other provinces in support of a national crop inventory. To date this approach can consistently deliver a crop inventory that meets the overall target accuracy of at least 85% at a final spatial resolution of 30m (56m in 2009 and 2010). 
        :param example: var dataset = ee.ImageCollection('AAFC/ACI'); var crop2016 = dataset     .filter(ee.Filter.date('2016-01-01', '2016-12-31'))     .first(); Map.setCenter(-103.8881, 53.0372, 10); Map.addLayer(crop2016, {}, '2016 Canada AAFC Annual Crop Inventory'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ACA_reef_habitat_v1_0:
    def __init__(self,):
        self.sensor = 'ACA_reef_habitat_v1_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ACA_reef_habitat_v1_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ACA_reef_habitat_v1_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ACA_reef_habitat_v1_0(example: str = ''):
        """
        The [Allen Coral Atlas](https://allencoralatlas.org/) dataset maps the geomorphic zonation and benthic habitat for the world's shallow coral reefs at 5m pixel resolution. The underlying satellite image data are temporal composites of [PlanetScope satellite](https://www.planet.com/products/basemap/) imagery spanning 2018-2020. The habitat maps are created via a machine learning approach with contextual editing, using a range of imagery, bathymetry, and derived products as input data, trained via a globally consistent reference dataset. A global mask layer is also included for use when generating global reporting statistics. A full description of the methods and approaches can be found in the methods section of the [Allen Coral Atlas website](https://allencoralatlas.org/methods/).  The Allen Coral Atlas was funded by [Vulcan Inc.](https://vulcan.com/) and is managed by the [Arizona State University Center for Global Discovery and Conservation Science](https://gdcs.asu.edu/). Partners include [Planet](https://www.planet.com/), the [University of Queensland](https://www.uq.edu.au/), and the [National Geographic Society](https://www.nationalgeographic.org/).  Scientific background publications:  - Lyons, M. B., Roelfsema, C. M., Kennedy, E. V., Kovacs, E. M., Borrego-Acevedo, R., Markey, K., ... & Murray, N. J. (2020). Mapping the world's coral reefs using a global multiscale earth observation framework. Remote Sensing in Ecology and Conservation, 6(4), 557-568. [doi:10.1002/rse2.157](https://doi.org/10.1002/rse2.157)  - Kennedy, E. V., Roelfsema, C. M., Lyons, M. B., Kovacs, E. M., Borrego-Acevedo, R., Roe, M., ... & Tudman, P. (2021). Reef Cover, a coral reef classification for global habitat mapping from remote sensing. Scientific Data, 8(1), 1-20. [doi:10.1038/s41597-021-00958-z](https://doi.org/10.1038/s41597-021-00958-z)  - Roelfsema, C. M., Lyons, M., Murray, N., Kovacs, E. M., Kennedy, E., Markey, K., ... & Phinn, S. R. (2021). Workflow for the generation of expert-derived training and validation data: a view to global scale habitat mapping. Frontiers in Marine Science.  [doi:10.3389/fmars.2021.643381](https://doi.org/10.3389/fmars.2021.643381)  - Li, J., Knapp, D. E., Lyons, M., Roelfsema, C., Phinn, S., Schill, S. R., & Asner, G. P. (2021). Automated global shallow water bathymetry mapping using Google Earth Engine. Remote Sensing, 13(8), 1469. [doi:10.3390/rs13081469](https://doi.org/10.3390/rs13081469)  - Li, J., Knapp, D. E., Fabina, N. S., Kennedy, E. V., Larsen, K., Lyons, M. B., ... & Asner, G. P. (2020). A global coral reef probability map generated using convolutional neural networks. Coral Reefs, 39(6), 1805-1815. [doi:10.1007/s00338-020-02005-6](https://doi.org/10.1007/s00338-020-02005-6)  Allen Coral Atlas maps, bathymetry and map statistics are &copy; 2020 Allen Coral Atlas Partnership and Vulcan, Inc. 
        :param example: var dataset = ee.Image('ACA/reef_habitat/v1_0');  // Teti'aroa, an atoll in French Polynesia. Map.setCenter(-149.56194, -17.00872, 13); Map.setOptions('SATELLITE');  // The visualizations are baked into the image properties.  // Example mask application. var reefExtent = dataset.select('reef_mask').selfMask(); Map.addLayer(reefExtent, {}, 'Global reef extent');  // Geomorphic zonation classification. var geomorphicZonation = dataset.select('geomorphic').selfMask(); Map.addLayer(geomorphicZonation, {}, 'Geomorphic zonation');  // Benthic habitat classification. var benthicHabitat = dataset.select('benthic').selfMask(); Map.addLayer(benthicHabitat, {}, 'Benthic habitat'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ACA_reef_habitat_v2_0:
    def __init__(self,):
        self.sensor = 'ACA_reef_habitat_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ACA_reef_habitat_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ACA_reef_habitat_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ACA_reef_habitat_v2_0(example: str = ''):
        """
        The [Allen Coral Atlas](https://allencoralatlas.org/) dataset maps the geomorphic zonation and benthic habitat for the world's shallow coral reefs at 5 m pixel resolution. Also included is a global reef extent product that maps additional reef areas unable to be explicitly included in the geomorphic and benthic mapping. The underlying satellite image data are temporal composites of [PlanetScope satellite](https://www.planet.com/products/basemap/) imagery spanning 2018-2020. The habitat maps are created via a machine learning approach with contextual editing, using a range of imagery, bathymetry and derived products as input data, trained via a globally consistent reference data set. A full description of the methods and approaches can be found in the methods section of the [Allen Coral Atlas website](https://allencoralatlas.org/methods/).  The first version ([v1.0](https://developers.google.com/earth-engine/datasets/catalog/ACA_reef_habitat_v1_0)) of the Allen Coral Atlas was completed in Q4 2021, and this new version (v2.0) has a wide range of improvements across the globe that incorporated both user feedback on v1.0 and new technical developments in mapping methodology. A brief overview of the changes can be found [here](https://allencoralatlas.org/blog/geomorphic-and-benthic-maps-2022-update/) and a more comprehensive technical summary can be found [here](https://storage.googleapis.com/coral-atlas-static-files/resources-page-materials/Allen_Coral_Atlas_2022_habitat_map_revisions.pdf).  The Allen Coral Atlas was funded by [Vulcan Inc.](https://vulcan.com/) and is managed by the [Arizona State University Center for Global Discovery and Conservation Science](https://gdcs.asu.edu/). Partners include [Planet](https://www.planet.com/), the [University of Queensland](https://www.uq.edu.au/), and the [Coral Reef Alliance](https://coral.org/en/).  Scientific background publications:  - Lyons, M. B., Roelfsema, C. M., Kennedy, E. V., Kovacs, E. M., Borrego-Acevedo, R., Markey, K., ... & Murray, N. J. (2020). Mapping the world's coral reefs using a global multiscale earth observation framework. Remote Sensing in Ecology and Conservation, 6(4), 557-568. [doi:10.1002/rse2.157](https://doi.org/10.1002/rse2.157)  - Kennedy, E. V., Roelfsema, C. M., Lyons, M. B., Kovacs, E. M., Borrego-Acevedo, R., Roe, M., ... & Tudman, P. (2021). Reef Cover, a coral reef classification for global habitat mapping from remote sensing. Scientific Data, 8(1), 1-20. [doi:10.1038/s41597-021-00958-z](https://doi.org/10.1038/s41597-021-00958-z)  - Roelfsema, C. M., Lyons, M., Murray, N., Kovacs, E. M., Kennedy, E., Markey, K., ... & Phinn, S. R. (2021). Workflow for the generation of expert-derived training and validation data: a view to global scale habitat mapping. Frontiers in Marine Science.  [doi:10.3389/fmars.2021.643381](https://doi.org/10.3389/fmars.2021.643381)  - Li, J., Knapp, D. E., Lyons, M., Roelfsema, C., Phinn, S., Schill, S. R., & Asner, G. P. (2021). Automated global shallow water bathymetry mapping using Google Earth Engine. Remote Sensing, 13(8), 1469. [doi:10.3390/rs13081469](https://doi.org/10.3390/rs13081469)  - Li, J., Knapp, D. E., Fabina, N. S., Kennedy, E. V., Larsen, K., Lyons, M. B., ... & Asner, G. P. (2020). A global coral reef probability map generated using convolutional neural networks. Coral Reefs, 39(6), 1805-1815. [doi:10.1007/s00338-020-02005-6](https://doi.org/10.1007/s00338-020-02005-6)  Allen Coral Atlas maps, bathymetry and map statistics are &copy; 2023 Allen Coral Atlas Partnership and Vulcan, Inc. 
        :param example: var dataset = ee.Image('ACA/reef_habitat/v2_0');  // Teti'aroa, an atoll in French Polynesia. Map.setCenter(-149.56194, -17.00872, 13); Map.setOptions('SATELLITE');  // The visualizations are baked into the image properties.  // Example mask application. var reefExtent = dataset.select('reef_mask').selfMask(); Map.addLayer(reefExtent, {}, 'Global reef extent');  // Geomorphic zonation classification. var geomorphicZonation = dataset.select('geomorphic').selfMask(); Map.addLayer(geomorphicZonation, {}, 'Geomorphic zonation');  // Benthic habitat classification. var benthicHabitat = dataset.select('benthic').selfMask(); Map.addLayer(benthicHabitat, {}, 'Benthic habitat'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class AHN_AHN2_05M_INT:
    def __init__(self,):
        self.sensor = 'AHN_AHN2_05M_INT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AHN_AHN2_05M_INT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AHN_AHN2_05M_INT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AHN_AHN2_05M_INT(example: str = ''):
        """
        The AHN DEM is a 0.5m DEM covering the Netherlands. It was generated from LIDAR data taken in the spring between 2007 and 2012.  It contains ground level samples with all other items above ground (such as buildings, bridges, trees etc.) removed. This version is interpolated; the areas where objects have been removed are filled with interpolated values. The point cloud was converted to a 0.5m grid using a squared inverse distance weighting method.  Note: This dataset does not include a small number of tiles listed in the manifest that are only available at a lower resolution. 
        :param example: var dataset = ee.Image('AHN/AHN2_05M_INT'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -5.0,   max: 30.0, }; Map.setCenter(5.76583, 51.855276, 16); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class AHN_AHN2_05M_NON:
    def __init__(self,):
        self.sensor = 'AHN_AHN2_05M_NON'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AHN_AHN2_05M_NON.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AHN_AHN2_05M_NON.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AHN_AHN2_05M_NON(example: str = ''):
        """
        The AHN DEM is a 0.5m DEM covering the Netherlands. It was generated from LIDAR data taken in the spring between 2007 and 2012.  It contains ground level samples with all other items above ground (such as buildings, bridges, trees etc.) removed. This version is non-interpolated; the areas where objects have been removed are left blank and not filled with interpolated values. The point cloud was converted to a 0.5m grid using a squared inverse distance weighting method. 
        :param example: var dataset = ee.Image('AHN/AHN2_05M_NON'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -5.0,   max: 30.0, }; Map.setCenter(5.80258, 51.78547, 14); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class AHN_AHN2_05M_RUW:
    def __init__(self,):
        self.sensor = 'AHN_AHN2_05M_RUW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AHN_AHN2_05M_RUW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AHN_AHN2_05M_RUW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AHN_AHN2_05M_RUW(example: str = ''):
        """
        The AHN DEM is a 0.5m DEM covering the Netherlands. It was generated from LIDAR data taken in the spring between 2007 and 2012.  This version contains both ground level samples and items above ground level (such as buildings, bridges, trees etc). The point cloud was converted to a 0.5m grid using an squared inverse distance weighting method. 
        :param example: var dataset = ee.Image('AHN/AHN2_05M_RUW'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -5.0,   max: 30.0, }; Map.setCenter(5.76583, 51.855276, 16); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ASTER_AST_L1T_003:
    def __init__(self,):
        self.sensor = 'ASTER_AST_L1T_003'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ASTER_AST_L1T_003.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ASTER_AST_L1T_003.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ASTER_AST_L1T_003(example: str = ''):
        """
        The Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) is a multispectral imager that was launched on board NASA's Terra spacecraft in December, 1999. ASTER can collect data in 14 spectral bands from the visible to the thermal infrared. Each scene covers an area of 60 x 60 km. These scenes, produced by the USGS, contain calibrated at-sensor radiance, ortho-rectified and terrain corrected.  Not all 14 bands were collected in each scene. An asset property named ORIGINAL_BANDS_PRESENT contains the list of bands that are present in each scene.  To convert from Digital Numbers (DN) to radiance at the sensor, the unit conversion coefficients are available in the metadata. See [ASTER L1T Product Users' Guide](https://lpdaac.usgs.gov/documents/647/AST__L1T_User_Guide_V3.pdf) and [ASTER L1T Product Specification](https://lpdaac.usgs.gov/documents/300/ASTER_L1T_Product_Specification.pdf) for more information.  Documentation:  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/72/AST_L1T_ATBD.pdf)  * [User's Guide](https://lpdaac.usgs.gov/documents/647/AST__L1T_User_Guide_V3.pdf)  * [ASTER Level-1T Product Specification](https://lpdaac.usgs.gov/documents/300/ASTER_L1T_Product_Specification.pdf)  * [ASTER L1T Quick Reference Guide(ASTER L1T Quick Reference Guide)](https://lpdaac.usgs.gov/documents/174/AST_L1T_Quick_Reference_Guide.pdf) 
        :param example: var dataset = ee.ImageCollection('ASTER/AST_L1T_003')                   .filter(ee.Filter.date('2018-01-01', '2018-08-15')); var falseColor = dataset.select(['B3N', 'B02', 'B01']); var falseColorVis = {   min: 0.0,   max: 255.0, }; Map.setCenter(-122.0272, 39.6734, 11); Map.addLayer(falseColor.median(), falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class AU_GA_AUSTRALIA_5M_DEM:
    def __init__(self,):
        self.sensor = 'AU_GA_AUSTRALIA_5M_DEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AU_GA_AUSTRALIA_5M_DEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AU_GA_AUSTRALIA_5M_DEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AU_GA_AUSTRALIA_5M_DEM(example: str = ''):
        """
        The Digital Elevation Model (DEM) 5 meter Grid of Australia derived from LiDAR model represents a National 5 meter (bare earth) DEM which has been derived from some 236 individual LiDAR surveys between 2001 and 2015 covering an area in excess of 245,000 square kilometers. These surveys cover Australia's populated coastal zone; floodplain surveys within the Murray Darling Basin, and individual surveys of major and minor population centers. All available 1 meter resolution LiDAR-derived DEMs have been compiled and resampled using a neighborhood-mean method to 5 meter resolution datasets for each survey area, and then merged into a single dataset for each State. Each state's dataset is provided as a separate image within the image collection.  The acquisition of the individual LiDAR surveys and derivation of the 5m product has been part of a long-term collaboration between Geoscience Australia, the Cooperative Research Centre for Spatial Information (CRCSI), the Departments of Climate Change and Environment, State and Territory jurisdictions, Local Government and the Murray Darling Basin Authority under the auspices of the National Elevation Data Framework and Coastal and Urban DEM Program. The source datasets have been captured to standards that are generally consistent with the Australian ICSM LiDAR Acquisition Specifications with require a fundamental vertical accuracy of at least 0.30m (95% confidence) and horizontal accuracy of at least 0.80m (95% confidence).  There are several areas close to Perth with null (NaN) values around (115.85, -31.99), (115.72, -33.75), and (115.10, -33.43). 
        :param example: var dataset = ee.ImageCollection('AU/GA/AUSTRALIA_5M_DEM'); var elevation = dataset.select('elevation'); var elevationVis = {   min: 0.0,   max: 150.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(140.1883, -35.9113, 8); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class AU_GA_DEM_1SEC_v10_DEM_H:
    def __init__(self,):
        self.sensor = 'AU_GA_DEM_1SEC_v10_DEM_H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AU_GA_DEM_1SEC_v10_DEM-H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AU_GA_DEM_1SEC_v10_DEM-H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AU_GA_DEM_1SEC_v10_DEM_H(example: str = ''):
        """
        The Hydrologically Enforced Digital Elevation Model (DEM-H) was derived from the SRTM data acquired by NASA in February 2000. The model has been hydrologically conditioned and drainage enforced. The DEM-H captures flow paths based on SRTM elevations and mapped stream lines, and supports delineation of catchments and related hydrological attributes. The dataset was derived from the 1 second smoothed Digital Elevation Model (DEM-S; ANZCW0703014016) by enforcing hydrological connectivity with the ANUDEM software, using selected AusHydro V1.6 (February 2010) 1:250,000 scale watercourse lines (ANZCW0503900101) and lines derived from DEM-S to define the watercourses. The drainage enforcement has produced a consistent representation of hydrological connectivity with some elevation artifacts resulting from the drainage enforcement. A full description of the methods is in preparation (Dowling et al., in prep).  This product provides a DEM suitable for use in hydrological analysis such as catchment definition and flow routing.  There are several areas with unexpected negative values: close to Canberra around (150.443044, -35.355281) with values of -55 and in Western Australia around (124.84, -16.44) with -43. 
        :param example: var dataset = ee.Image('AU/GA/DEM_1SEC/v10/DEM-H'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -10.0,   max: 1300.0,   palette: [     '3ae237', 'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13',     'ff6e08', 'ff500d', 'ff0000', 'de0101', 'c21301', '0602ff', '235cb1',     '307ef3', '269db1', '30c8e2', '32d3ef', '3be285', '3ff38f', '86e26f'   ], }; Map.setCenter(133.95, -24.69, 5); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class AU_GA_DEM_1SEC_v10_DEM_S:
    def __init__(self,):
        self.sensor = 'AU_GA_DEM_1SEC_v10_DEM_S'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/AU_GA_DEM_1SEC_v10_DEM-S.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/AU_GA_DEM_1SEC_v10_DEM-S.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_AU_GA_DEM_1SEC_v10_DEM_S(example: str = ''):
        """
        The Smoothed Digital Elevation Model (DEM-S) was derived from the SRTM data acquired by NASA in February 2000. DEM-S represents ground surface topography (excluding vegetation features) and has been smoothed to reduce noise and improve the representation of surface shape. An adaptive process applied more smoothing in flatter areas than hilly areas, and more smoothing in noisier areas than in less noisy areas.  This DEM-S supports calculation of local terrain shape attributes such as slope, aspect, and curvature that could not be reliably derived from the unsmoothed 1 second DEM because of noise.  There are several areas with unexpected negative values: close to Canberra around (150.443044, -35.355281) with values of -55 and in Western Australia around (124.84, -16.44) with -43. 
        :param example: var dataset = ee.Image('AU/GA/DEM_1SEC/v10/DEM-S'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -10.0,   max: 1300.0,   palette: [     '3ae237', 'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13',     'ff6e08', 'ff500d', 'ff0000', 'de0101', 'c21301', '0602ff', '235cb1',     '307ef3', '269db1', '30c8e2', '32d3ef', '3be285', '3ff38f', '86e26f'   ], }; Map.setCenter(133.95, -24.69, 5); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class BIOPAMA_GlobalOilPalm_v1:
    def __init__(self,):
        self.sensor = 'BIOPAMA_GlobalOilPalm_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/BIOPAMA_GlobalOilPalm_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/BIOPAMA_GlobalOilPalm_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_BIOPAMA_GlobalOilPalm_v1(example: str = ''):
        """
        The dataset is a 10m global industrial and smallholder oil palm map for 2019. It covers areas where oil palm plantations were detected. The classified images are the output of a convolutional neural network based on Sentinel-1 and Sentinel-2 half-year composites.  See [article](https://essd.copernicus.org/articles/13/1211/2021/) for additional information. 
        :param example: // Import the dataset; a collection of composite granules from 2019. var dataset = ee.ImageCollection('BIOPAMA/GlobalOilPalm/v1');  // Select the classification band. var opClass = dataset.select('classification');  // Mosaic all of the granules into a single image. var mosaic = opClass.mosaic();  // Define visualization parameters. var classificationVis = {   min: 1,   max: 3,   palette: ['ff0000','ef00ff', '696969'] };  // Create a mask to add transparency to non-oil palm plantation class pixels. var mask = mosaic.neq(3); mask = mask.where(mask.eq(0), 0.6);  // Display the data on the map. Map.addLayer(mosaic.updateMask(mask),              classificationVis, 'Oil palm plantation type', true); Map.setCenter(-3.0175, 5.2745,12); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class BLM_AIM_v1_TerrADat_TerrestrialAIM:
    def __init__(self,):
        self.sensor = 'BLM_AIM_v1_TerrADat_TerrestrialAIM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/BLM_AIM_v1_TerrADat_TerrestrialAIM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/BLM_AIM_v1_TerrADat_TerrestrialAIM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_BLM_AIM_v1_TerrADat_TerrestrialAIM(example: str = ''):
        """
        Since 2011, the Bureau of Land Management (BLM) has collected field information to inform land health through its Assessment Inventory and Monitoring (AIM) strategy. To date, more than 6,000 terrestrial AIM field plots have been collected over BLM lands.  The BLM AIM data archive is updated annually. Standardized core indicators are collected at each plot that are known to be both ecologically relevant and clearly tied to rangeland health. These indicators inform biotic integrity, soil and site stability, and hydrologic function. The terrestrial plot measurements include fractional bare ground cover, vegetation composition and height, plants of management concern, Non-native invasive species, plant canopy gaps, species richness, and soil aggregate stability. AIM represents one of the most extensive, publicly available plot measurement datasets across Western US federal lands, which can be integrated with remotely sensed imagery and other geospatial information for a range of analysis, classification, and validation purposes.  This dataset was created to monitor the status, condition and trend of national BLM resources in accordance with BLM policies.  The methodology used for the collection of these data can be found on https://landscapetoolbox.org and the Monitoring Manual, 2nd Edition.  These data should not be used for statistical or spatial inferences without knowledge of how the sample design was drawn or without calculating spatial weights for the points based on the sample design.  This feature class includes monitoring data collected nationally to understand the status, condition, and trend of resources on BLM lands. Data are collected in accordance with the BLM Assessment, Inventory, and Monitoring (AIM) Strategy. The AIM Strategy specifies a probabilistic sampling design, standard core indicators and methods, electronic data capture and management, and integration with remote sensing. Attributes include the BLM terrestrial core indicators: bare ground, vegetation composition, plant species of management concern, non-native invasive species, and percent canopy gaps (see Entity/Attribute Section for exact details on attributes). Data were collected and managed by BLM Field Offices, BLM Districts, and/or affiliated field crews with support from the BLM National Operations Center. Data are stored in a centralized database (TerrADat) at the BLM National Operations Center.  Data were collected by trained data collectors with the BLM and partner organizations. They followed the BLM core terrestrial data [collection protocols](https://www.ntc.blm.gov/krc/viewresource.php?courseID=281&programAreaId=148). Data were captured electronically using the [Database for Inventory, Monitoring, and Assessment](https://jornada.nmsu.edu/tools/dima). They were managed by the data collectors, with oversight from BLM field offices, state offices, and the National Operations Center. This dataset has undergone rigorous QA/QC to ensure data quality. 
        :param example: var greens = ee.List([   '#00441B', '#00682A', '#37A055', '#5DB96B', '#AEDEA7', '#E7F6E2', '#F7FCF5' ]); var reds = ee.List([   '#67000D', '#9E0D14', '#E32F27', '#F6553D', '#FCA082', '#FEE2D5', '#FFF5F0' ]);  function normalize(value, min, max) {   return value.subtract(min).divide(ee.Number(max).subtract(min)); }  function setColor(feature, property, min, max, palette) {   var value = normalize(feature.getNumber(property), min, max)                   .multiply(palette.size())                   .min(palette.size().subtract(1))                   .max(0);   return feature.set({style: {color: palette.get(value.int())}}); }  var fc = ee.FeatureCollection('BLM/AIM/v1/TerrADat/TerrestrialAIM'); var woodyHeightStyle = function(f) {   return setColor(f, 'WoodyHgt_Avg', 0, 100, greens); }; var bareSoilStyle = function(f) {   return setColor(f, 'BareSoilCover_FH', 0, 100, reds); };  var treeHeight = fc.filter('WoodyHgt_Avg > 1').map(woodyHeightStyle); var bareSoil = fc.filter('BareSoilCover_FH > 1').map(bareSoilStyle);  Map.addLayer(bareSoil.style({styleProperty: 'style', pointSize: 3})); Map.addLayer(treeHeight.style({styleProperty: 'style', pointSize: 1}));  Map.setCenter(-110, 40, 6); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class BNU_FGS_CCNL_v1:
    def __init__(self,):
        self.sensor = 'BNU_FGS_CCNL_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/BNU_FGS_CCNL_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/BNU_FGS_CCNL_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_BNU_FGS_CCNL_v1(example: str = ''):
        """
        The Consistent and Corrected Nighttime Lights (CCNL) dataset is a reprocessed version of the [Defense Meteorological Program (DMSP) Operational Line-Scan System (OLS) Version 4](NOAA_DMSP-OLS_NIGHTTIME_LIGHTS). A series of methods was used to mitigate the impact of inter-annual inconsistency, saturation, and blooming effects and to improve data quality.  CCNL Version 1 spans the globe from 75N to 65S and has 1km pixel size. 
        :param example: var dataset = ee.ImageCollection('BNU/FGS/CCNL/v1')                   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var nighttimeLights = dataset.select('b1'); var nighttimeLightsVis = {   min: 3.0,   max: 60.0, }; Map.setCenter(31.4, 30, 6); Map.addLayer(nighttimeLights, nighttimeLightsVis, 'Nighttime Lights'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CAS_IGSNRR_PML_V2:
    def __init__(self,):
        self.sensor = 'CAS_IGSNRR_PML_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CAS_IGSNRR_PML_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CAS_IGSNRR_PML_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CAS_IGSNRR_PML_V2(example: str = ''):
        """
        Penman-Monteith-Leuning Evapotranspiration V2 (PML_V2) products include evapotranspiration (ET), its three components, and gross primary product (GPP) at 500m and 8-day resolution during 2002-2017 and with spatial range from -60°S to 90°N. The major advantages of the PML_V2 products are:    1. coupled estimates of transpiration and GPP via canopy   conductance (Gan et al., 2018; Zhang et al., 2019)   2. partitioning ET into three components: transpiration from vegetation,   direct evaporation from the soil and vaporization of intercepted    rainfall from vegetation (Zhang et al., 2016).  The PML_V2 products perform well against observations at 95 flux sites across globe, and are similar to or noticeably better than major state-of-the-art ET and GPP products widely used by water and ecology science communities (Zhang et al., 2019). 
        :param example: var dataset = ee.ImageCollection('CAS/IGSNRR/PML/V2');  var visualization = {   bands: ['GPP'],   min: 0.0,   max: 9.0,   palette: [     'a50026', 'd73027', 'f46d43', 'fdae61', 'fee08b', 'ffffbf',     'd9ef8b', 'a6d96a', '66bd63', '1a9850', '006837',   ] };  Map.setCenter(0.0, 15.0, 2);  Map.addLayer(     dataset, visualization, 'PML_V2 0.1.4 Gross Primary Product (GPP)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CAS_IGSNRR_PML_V2_v017:
    def __init__(self,):
        self.sensor = 'CAS_IGSNRR_PML_V2_v017'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CAS_IGSNRR_PML_V2_v017.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CAS_IGSNRR_PML_V2_v017.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CAS_IGSNRR_PML_V2_v017(example: str = ''):
        """
        Penman-Monteith-Leuning Evapotranspiration V2 (PML_V2) products include evapotranspiration (ET), its three components, and gross primary product (GPP) at 500m and 8-day resolution during 2000-2017 and with spatial range from -60°S to 90°N. The major advantages of the PML_V2 products are:    1. coupled estimates of transpiration and GPP via canopy   conductance (Gan et al., 2018; Zhang et al., 2019)   2. partitioning ET into three components: transpiration from vegetation,   direct evaporation from the soil and vaporization of intercepted    rainfall from vegetation (Zhang et al., 2016).  The PML_V2 products perform well against observations at 95 flux sites across globe, and are similar to or noticeably better than major state-of-the-art ET and GPP products widely used by water and ecology science communities (Zhang et al., 2019). 
        :param example: var dataset = ee.ImageCollection('CAS/IGSNRR/PML/V2_v017');  var visualization = {   bands: ['GPP'],   min: 0.0,   max: 9.0,   palette: [     'a50026', 'd73027', 'f46d43', 'fdae61', 'fee08b', 'ffffbf',     'd9ef8b', 'a6d96a', '66bd63', '1a9850', '006837',   ] };  Map.setCenter(0.0, 15.0, 2);  Map.addLayer(     dataset, visualization, 'PML_V2 0.1.7 Gross Primary Product (GPP)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CGIAR_SRTM90_V4:
    def __init__(self,):
        self.sensor = 'CGIAR_SRTM90_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CGIAR_SRTM90_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CGIAR_SRTM90_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CGIAR_SRTM90_V4(example: str = ''):
        """
        The Shuttle Radar Topography Mission (SRTM) digital elevation dataset was originally produced to provide consistent, high-quality elevation data at near global scope. This version of the SRTM digital elevation data has been processed to fill data voids, and to facilitate its ease of use. 
        :param example: var dataset = ee.Image('CGIAR/SRTM90_V4'); var elevation = dataset.select('elevation'); var slope = ee.Terrain.slope(elevation); Map.setCenter(-112.8598, 36.2841, 10); Map.addLayer(slope, {min: 0, max: 60}, 'slope'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Basic_Demographic_Characteristics:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Basic_Demographic_Characteristics'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Basic_Demographic_Characteristics.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Basic_Demographic_Characteristics.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Basic_Demographic_Characteristics(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population count grids contain population estimates, by age and sex, per 30 arc-second grid cell consistent with national censuses and population registers. There is one image for each modeled age and sex category based on the 2010 round of Census.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-basic-demographic-characteristics-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Basic_Demographic_Characteristics').first(); var raster = dataset.select('basic_demographic_characteristics'); var raster_vis = {   'max': 1000.0,   'palette': [     'ffffe7',     '86a192',     '509791',     '307296',     '2c4484',     '000066'   ],   'min': 0.0 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'basic_demographic_characteristics');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Data_Context:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Data_Context'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Data_Context.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Data_Context.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Data_Context(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  Categorizes pixels with estimated zero population based on information provided in the census documents.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-admin-unit-center-points-population-estimates-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Data_Context'); var raster = dataset.select('data_context'); var raster_vis = {   'min': 200.0,   'palette': [     'ffffff',     '099506',     'f04923',     'e62440',     '706984',     'a5a5a5',     'ffe152',     'd4cc11',     '000000'   ],   'max': 207.0 }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(raster, raster_vis, 'data_context');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Land_Area:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Land_Area'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Land_Area.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Land_Area.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Land_Area(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  This data grids contains per-pixel data containing land surface area estimates.  [General Documentation](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-quality-indicators/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Land_Area'); var raster = dataset.select('land_area'); var raster_vis = {   'min': 0.0,   'palette': [     'ecefb7',     '745638'   ],   'max': 0.86 }; Map.setCenter(26.4, 19.81, 1); Map.addLayer(raster, raster_vis, 'land_area');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Mean_Administrative_Unit_Area:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Mean_Administrative_Unit_Area'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Mean_Administrative_Unit_Area.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Mean_Administrative_Unit_Area.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Mean_Administrative_Unit_Area(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  The mean area of the input unit(s) from which population count and density grids are created.  [General documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-admin-unit-center-points-population-estimates-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Mean_Administrative_Unit_Area'); var raster = dataset.select('mean_administrative_unit_area'); var raster_vis = {   'min': 0.0,   'palette': [     'ffffff',     '747474',     '656565',     '3c3c3c',     '2f2f2f',     '000000'   ],   'max': 40000.0 }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(raster, raster_vis, 'mean_administrative_unit_area');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_National_Identifier_Grid:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_National_Identifier_Grid'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_National_Identifier_Grid.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_National_Identifier_Grid.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_National_Identifier_Grid(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  The National Identifier Grid Represents the Census Data Source Used to Produce the GPWv4 Populations estimates. Pixels that have the same value reflect the same data source, most often a country or territory.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-national-identifier-grid-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_National_Identifier_Grid'); var raster = dataset.select('national_identifier_grid'); var raster_vis = {   'min': 4.0,   'palette': [     '000000',     'ffffff'   ],   'max': 999.0 }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(raster, raster_vis, 'national_identifier_grid');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Population_Count:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Population_Count'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Population_Count.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Population_Count.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Population_Count(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population count grids contain estimates of the number of persons per 30 arc-second grid cell consistent with national censuses and population registers. There is one image for each modeled year.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-rev11/docs)  Note: Because this collection has a pyramid policy of MEAN, zooming out results in information loss. Calculations need to be performed at native resolution. 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Population_Count').first(); var raster = dataset.select('population_count'); var raster_vis = {   'max': 1000.0,   'palette': [     'ffffe7',     '86a192',     '509791',     '307296',     '2c4484',     '000066'   ],   'min': 0.0 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'population_count');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Population_Density:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Population_Density'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Population_Density.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Population_Density.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Population_Density(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population density grids contain estimates of the number of persons per square kilometer consistent with national censuses and population registers. There is one image for each modeled year.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Population_Density').first(); var raster = dataset.select('population_density'); var raster_vis = {   'max': 1000.0,   'palette': [     'ffffe7',     'FFc869',     'ffac1d',     'e17735',     'f2552c',     '9f0c21'   ],   'min': 200.0 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'population_density');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Count:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Count'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_UNWPP-Adjusted_Population_Count.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_UNWPP-Adjusted_Population_Count.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Count(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population count grids contain estimates of the number of persons per 30 arc-second grid cell, consistent with national censuses and population registers with respect to relative spatial distribution but adjusted to match the 2015 Revision of UN World Population Prospects country totals. There is one image for each modeled year.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/docs)  Note: Because this collection has a pyramid policy of MEAN, zooming out results in information loss. Calculations need to be performed at native resolution. 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_UNWPP-Adjusted_Population_Count').first(); var raster = dataset.select('unwpp-adjusted_population_count'); var raster_vis = {   'max': 1000.0,   'palette': [     'ffffe7',     '86a192',     '509791',     '307296',     '2c4484',     '000066'   ],   'min': 0.0 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'unwpp-adjusted_population_count');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Density:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Density'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_UNWPP-Adjusted_Population_Density.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_UNWPP-Adjusted_Population_Density.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_UNWPP_Adjusted_Population_Density(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population density grids contain estimates of the number of persons per 30 arc-second grid cell, consistent with national censuses and population registers with respect to relative spatial distribution but adjusted to match the 2015 Revision of UN World Population Prospects country totals. There is one image for each modeled year.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_UNWPP-Adjusted_Population_Density').first(); var raster = dataset.select('unwpp-adjusted_population_density'); var raster_vis = {   'max': 1000.0,   'palette': [     'ffffe7',     'FFc869',     'ffac1d',     'e17735',     'f2552c',     '9f0c21'   ],   'min': 0.0 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'unwpp-adjusted_population_density');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Water_Area:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Water_Area'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Water_Area.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Water_Area.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Water_Area(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  This data grids contains per-pixel data containing water surface area estimates.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-land-water-area-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Water_Area'); var raster = dataset.select('water_area'); var raster_vis = {   'min': 0.0,   'palette': [     'f5f6da',     '180d02'   ],   'max': 0.860558 }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(raster, raster_vis, 'water_area');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv411_GPW_Water_Mask:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv411_GPW_Water_Mask'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv411_GPW_Water_Mask.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv411_GPW_Water_Mask.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv411_GPW_Water_Mask(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4), Revision 11 models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  Identifies water pixels; non-water pixels are masked  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-basic-demographic-characteristics-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv411/GPW_Water_Mask'); var raster = dataset.select('water_mask'); var raster_vis = {   'min': 0.0,   'palette': [     '005ce6',     '00ffc5',     'bed2ff',     'aed0f1'   ],   'max': 3.0 }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(raster, raster_vis, 'water_mask');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv4_ancillary_data_grids:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv4_ancillary_data_grids'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv4_ancillary-data-grids.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv4_ancillary-data-grids.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv4_ancillary_data_grids(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4) models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These ancillary data grids contain additional per-pixel data that can be used to assess the quality of the population estimates and how they were produced.  [General Documentation](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-land-water-area/docs) 
        :param example: var dataset = ee.Image('CIESIN/GPWv4/ancillary-data-grids'); var zeroPopulationAreas = dataset.select('data-context'); var zeroPopulationAreasVis = {   min: 201.0,   max: 205.0,   palette: ['099506', 'ff0b00', '060606', 'a5a5a5', 'ffe152'], }; Map.setCenter(-3.3, 36.03, 1); Map.addLayer(     zeroPopulationAreas, zeroPopulationAreasVis, 'Zero Population Areas'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv4_population_count:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv4_population_count'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv4_population-count.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv4_population-count.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv4_population_count(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4) models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population count grids contain estimates of the number of persons per 30 arc-second grid cell consistent with national censuses and population registers. There is one image for each modeled year.  [General Documentation](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv4/population-count'); var populationCount = dataset.select('population-count')   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var populationCountVis = {   min: 200.0,   max: 1000.0,   palette: ['ffffff', 'ffcdc6', 'ff0000', '950000'], }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(populationCount, populationCountVis, 'Population Count'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv4_population_density:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv4_population_density'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv4_population-density.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv4_population-density.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv4_population_density(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4) models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population density grids contain estimates of the number of persons per square kilometer consistent with national censuses and population registers. There is one image for each modeled year.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-rev11/docs) 
        :param example: var dataset = ee.ImageCollection('CIESIN/GPWv4/population-density'); var populationDensity = dataset.select('population-density')   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var populationDensityVis = {   min: 200.0,   max: 1500.0,   palette: ['ffffff', 'ffcdc6', 'ff0000', '950000'], }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(populationDensity, populationDensityVis, 'Population Density'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv4_unwpp_adjusted_population_count:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv4_unwpp_adjusted_population_count'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv4_unwpp-adjusted-population-count.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv4_unwpp-adjusted-population-count.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv4_unwpp_adjusted_population_count(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4) models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population count grids contain estimates of the number of persons per 30 arc-second grid cell, consistent with national censuses and population registers with respect to relative spatial distribution but adjusted to match the 2015 Revision of UN World Population Prospects country totals. There is one image for each modeled year.  [General Documentation](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals/docs) 
        :param example: var dataset =     ee.ImageCollection('CIESIN/GPWv4/unwpp-adjusted-population-count'); var populationCount = dataset.select('population-count')   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var populationCountVis = {   min: 200.0,   max: 1000.0,   palette: ['ffffff', 'ffcdc6', 'ff0000', '950000'], }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(populationCount, populationCountVis, 'Population Count'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CIESIN_GPWv4_unwpp_adjusted_population_density:
    def __init__(self,):
        self.sensor = 'CIESIN_GPWv4_unwpp_adjusted_population_density'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CIESIN_GPWv4_unwpp-adjusted-population-density.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CIESIN_GPWv4_unwpp-adjusted-population-density.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CIESIN_GPWv4_unwpp_adjusted_population_density(example: str = ''):
        """
        The Gridded Population of World Version 4 (GPWv4) models the distribution of global human population for the years 2000, 2005, 2010, 2015, and 2020 on 30 arc-second (approximately 1km) grid cells. Population is distributed to cells using proportional allocation of population from census and administrative units. Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of censuses, which occurred between 2005 and 2014. The input data are extrapolated to produce population estimates for each modeled year.  These population density grids contain estimates of the number of persons per 30 arc-second grid cell, consistent with national censuses and population registers with respect to relative spatial distribution but adjusted to match the 2015 Revision of UN World Population Prospects country totals. There is one image for each modeled year.  [General Documentation](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals/docs) 
        :param example: var dataset =     ee.ImageCollection('CIESIN/GPWv4/unwpp-adjusted-population-density'); var populationDensity = dataset.select('population-density')   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var populationDensityVis = {   min: 200.0,   max: 1500.0,   palette: ['ffffff', 'ffcdc6', 'ff0000', '950000'], }; Map.setCenter(79.1, 19.81, 3); Map.addLayer(populationDensity, populationDensityVis, 'Population Density'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_CORINE_V18_5_1_100m:
    def __init__(self,):
        self.sensor = 'COPERNICUS_CORINE_V18_5_1_100m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_CORINE_V18_5_1_100m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_CORINE_V18_5_1_100m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_CORINE_V18_5_1_100m(example: str = ''):
        """
        The CORINE (coordination of information on the environment) Land Cover (CLC) inventory was initiated in 1985 to standardize data collection on land in Europe to support environmental policy development. The project is coordinated by the European Environment Agency (EEA) in the frame of the EU Copernicus programme and implemented by national teams. The number of participating countries has increased over time currently including 33 (EEA) member countries and six cooperating countries (EEA39) with a total area of over 5.8 Mkm2.  The reference year of the first CLC inventory was 1990 and the first update created in 2000. Later, the update cycle has become 6 years. Satellite imagery provides the geometrical and thematic basis for mapping with in-situ data as essential ancillary information. The basic technical parameters of CLC (i.e. 44 classes in nomenclature, 25 hectares minimum mapping unit (MMU), and 100 meters minimum mapping width) have not changed since the beginning, therefore the results of the different inventories are comparable. 
        :param example: var dataset = ee.Image('COPERNICUS/CORINE/V18_5_1/100m/2012'); var landCover = dataset.select('landcover'); Map.setCenter(16.436, 39.825, 6); Map.addLayer(landCover, {}, 'Land Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_CORINE_V20_100m:
    def __init__(self,):
        self.sensor = 'COPERNICUS_CORINE_V20_100m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_CORINE_V20_100m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_CORINE_V20_100m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_CORINE_V20_100m(example: str = ''):
        """
        The CORINE (coordination of information on the environment) Land Cover (CLC) inventory was initiated in 1985 to standardize data collection on land in Europe to support environmental policy development. The project is coordinated by the European Environment Agency (EEA) in the frame of the EU Copernicus programme and implemented by national teams. The number of participating countries has increased over time currently including 33 (EEA) member countries and six cooperating countries (EEA39) with a total area of over 5.8 Mkm2.  CLC2018 is one of the datasets produced within the frame the Corine Land Cover programme referring to land cover / land use status of year 2018. The reference year of the first CLC inventory was 1990 and the first update created in 2000. Later, the update cycle has become 6 years. Satellite imagery provides the geometrical and thematic basis for mapping with in-situ data as essential ancillary information. The basic technical parameters of CLC (i.e. 44 classes in nomenclature, 25 hectares minimum mapping unit (MMU), and 100 meters minimum mapping width) have not changed since the beginning, therefore the results of the different inventories are comparable.  The time period covered by each asset is:  * 1990 asset: 1989 to 1998 * 2000 asset: 1999 to 2001 * 2006 asset: 2005 to 2007 * 2012 asset: 2011 to 2012 * 2018 asset: 2017 to 2018 
        :param example: var dataset = ee.Image('COPERNICUS/CORINE/V20/100m/2012'); var landCover = dataset.select('landcover'); Map.setCenter(16.436, 39.825, 6); Map.addLayer(landCover, {}, 'Land Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_DEM_GLO30:
    def __init__(self,):
        self.sensor = 'COPERNICUS_DEM_GLO30'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_DEM_GLO30.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_DEM_GLO30.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_DEM_GLO30(example: str = ''):
        """
        The Copernicus DEM is a Digital Surface Model (DSM) which represents the surface of the Earth including buildings, infrastructure and vegetation. This DEM is derived from an edited DSM named WorldDEM&trade, i.e. flattening of water bodies and consistent flow of rivers has been included. Editing of shore- and coastlines, special features such as airports and implausible terrain structures has also been applied.  The WorldDEM product is based on the radar satellite data acquired during the TanDEM-X Mission, which is funded by a Public Private Partnership between the German State, represented by the German Aerospace Centre (DLR) and Airbus Defence and Space. More details are available in the dataset [documentation](https://spacedata.copernicus.eu/documents/20123/121239/GEO1988-CopernicusDEM-SPE-002_ProductHandbook_I4.0.pdf).  Earth Engine asset has been ingested from the DGED files.  Note: See the code example for the recommended way of computing slope. Unlike most DEMs in Earth Engine, this is an image collection due to multiple resolutions of source files that make it impossible to mosaic them into a single asset, so the slope computations need a reprojection. 
        :param example: var dataset = ee.ImageCollection('COPERNICUS/DEM/GLO30'); var elevation = dataset.select('DEM'); var elevationVis = {   min: 0.0,   max: 1000.0,   palette: ['0000ff','00ffff','ffff00','ff0000','ffffff'], }; Map.setCenter(-6.746, 46.529, 4); Map.addLayer(elevation, elevationVis, 'DEM'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_Landcover_100m_Proba_V_C3_Global:
    def __init__(self,):
        self.sensor = 'COPERNICUS_Landcover_100m_Proba_V_C3_Global'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_Landcover_100m_Proba-V-C3_Global.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_Landcover_100m_Proba-V-C3_Global.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_Landcover_100m_Proba_V_C3_Global(example: str = ''):
        """
        The Copernicus Global Land Service (CGLS) is earmarked as a component of the Land service to operate a multi-purpose service component that provides a series of bio-geophysical products on the status and evolution of land surface at global scale.  The Dynamic Land Cover map at 100 m resolution (CGLS-LC100) is a new product in the portfolio of the CGLS and delivers a global land cover map at 100 m spatial resolution. The CGLS Land Cover product provides a primary land cover scheme. Next to these discrete classes, the product also includes continuous field layers for all basic land cover classes that provide proportional estimates for vegetation/ground cover for the land cover types. This continuous classification scheme may depict areas of heterogeneous land cover better than the standard classification scheme and, as such, can be tailored for application use (e.g. forest monitoring, crop monitoring, biodiversity and conservation, monitoring environment and security in Africa, climate modelling, etc.).  These consistent Land Cover maps (v3.0.1) are provided for the period 2015-2019 over the entire Globe, derived from the PROBA-V 100 m time-series, a database of high quality land cover training sites and several ancillary datasets, reaching an accuracy of 80% at Level1 over al years.  It is planned to provide yearly updates from 2020 through the use of a Sentinel time-series.  See also:  * [Algorithm Theoretical Basis Document](https://doi.org/10.5281/zenodo.3938968)  * [Product User Manual](https://doi.org/10.5281/zenodo.3938963)  * [Validation Report](https://doi.org/10.5281/zenodo.3938974) 
        :param example: var dataset = ee.Image('COPERNICUS/Landcover/100m/Proba-V-C3/Global/2019') .select('discrete_classification');  Map.setCenter(-88.6, 26.4, 1);  Map.addLayer(dataset, {}, 'Land Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_Landcover_100m_Proba_V_Global:
    def __init__(self,):
        self.sensor = 'COPERNICUS_Landcover_100m_Proba_V_Global'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_Landcover_100m_Proba-V_Global.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_Landcover_100m_Proba-V_Global.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_Landcover_100m_Proba_V_Global(example: str = ''):
        """
        The Copernicus Global Land Service (CGLS) is earmarked as a component of the Land service to operate a multi-purpose service component that provides a series of bio-geophysical products on the status and evolution of land surface at global scale.  The Dynamic Land Cover map at 100 m resolution (CGLS-LC100) is a new product in the portfolio of the CGLS and delivers a global land cover map at 100 m spatial resolution. The CGLS Land Cover product provides a primary land cover scheme. Next to these discrete classes, the product also includes continuous field layers for all basic land cover classes that provide proportional estimates for vegetation/ground cover for the land cover types. This continuous classification scheme may depict areas of heterogeneous land cover better than the standard classification scheme and, as such, can be tailored for application use (e.g. forest monitoring, crop monitoring, biodiversity and conservation, monitoring environment and security in Africa, climate modelling, etc.).  This Land Cover map is provided for the 2015 reference year over the entire Globe, derived from the PROBA-V 100 m time-series, a database of high quality land cover training sites and several ancillary datasets, reaching an accuracy of 80 % at Level1. 
        :param example: var dataset = ee.ImageCollection('COPERNICUS/Landcover/100m/Proba-V/Global');  var visualization = {   bands: ['discrete_classification'] };  Map.setCenter(-88.6, 26.4, 1);  Map.addLayer(dataset, visualization, 'Land Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S1_GRD:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S1_GRD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S1_GRD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S1_GRD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S1_GRD(example: str = ''):
        """
        The Sentinel-1 mission provides data from a dual-polarization C-band Synthetic Aperture Radar (SAR) instrument at 5.405GHz (C band).  This collection includes the S1 Ground Range Detected (GRD) scenes, processed using the Sentinel-1 Toolbox to generate a calibrated, ortho-corrected product. The collection is updated daily. New assets are ingested within two days after they become available.  This collection contains all of the GRD scenes.  Each scene has one of 3 resolutions (10, 25 or 40 meters), 4 band combinations (corresponding to scene polarization) and 3 instrument modes.  Use of the collection in a mosaic context will likely require filtering down to a homogeneous set of bands and parameters.  See [this article](https://developers.google.com/earth-engine/sentinel1) for details of collection use and preprocessing. Each scene contains either 1 or 2 out of 4 possible polarization bands, depending on the instrument's polarization settings.  The possible combinations are single band VV or HH, and dual band VV+VH and HH+HV:    1. VV: single co-polarization, vertical transmit/vertical receive   2. HH: single co-polarization, horizontal transmit/horizontal receive   3. VV + VH: dual-band cross-polarization, vertical transmit/horizontal   receive   4. HH + HV: dual-band cross-polarization, horizontal transmit/vertical   receive  Each scene also includes an additional 'angle' band that contains the approximate incidence angle from ellipsoid in degrees at every point. This band is generated by interpolating the 'incidenceAngle' property of the 'geolocationGridPoint' gridded field provided with each asset.  Each scene was pre-processed with [Sentinel-1 Toolbox](https://sentinel.esa.int/web/sentinel/toolboxes/sentinel-1) using the following steps:    1. Thermal noise removal   2. Radiometric calibration   3. Terrain correction using SRTM 30 or ASTER DEM for areas greater than      60 degrees latitude, where SRTM is not available. The final terrain-corrected values are converted to decibels via log scaling (10*log10(x)).  For more information about these pre-processing steps, please refer to the [Sentinel-1 Pre-processing article](https://developers.google.com/earth-engine/sentinel1). For further advice on working with Sentinel-1 imagery, see [Guido Lemoine's tutorial on SAR basics](https://developers.google.com/earth-engine/tutorials/community/sar-basics) and [Mort Canty's tutorial on SAR change detection](https://developers.google.com/earth-engine/tutorials/community/detecting-changes-in-sentinel-1-imagery-pt-1).  This collection is computed on-the-fly. If you want to use the underlying collection with raw power values (which is updated faster), see COPERNICUS/S1_GRD_FLOAT. 
        :param example: var imgVV = ee.ImageCollection('COPERNICUS/S1_GRD')         .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))         .filter(ee.Filter.eq('instrumentMode', 'IW'))         .select('VV')         .map(function(image) {           var edge = image.lt(-30.0);           var maskedImage = image.mask().and(edge.not());           return image.updateMask(maskedImage);         });  var desc = imgVV.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')); var asc = imgVV.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'));  var spring = ee.Filter.date('2015-03-01', '2015-04-20'); var lateSpring = ee.Filter.date('2015-04-21', '2015-06-10'); var summer = ee.Filter.date('2015-06-11', '2015-08-31');  var descChange = ee.Image.cat(         desc.filter(spring).mean(),         desc.filter(lateSpring).mean(),         desc.filter(summer).mean());  var ascChange = ee.Image.cat(         asc.filter(spring).mean(),         asc.filter(lateSpring).mean(),         asc.filter(summer).mean());  Map.setCenter(5.2013, 47.3277, 12); Map.addLayer(ascChange, {min: -25, max: 5}, 'Multi-T Mean ASC', true); Map.addLayer(descChange, {min: -25, max: 5}, 'Multi-T Mean DESC', true); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S2:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S2(example: str = ''):
        """
        See also collection COPERNICUS/S2_HARMONIZED that shifts data with PROCESSING_BASELINE '04.00' or above (after 2022-01-25) to be in the same range as in older scenes.  Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.  The Sentinel-2 data contain 13 UINT16 spectral bands representing TOA reflectance scaled by 10000. See the [Sentinel-2 User Handbook](https://sentinel.esa.int/documents/247904/685211/Sentinel-2_User_Handbook) for details. In addition, three QA bands are present where one (QA60) is a bitmask band with cloud mask information. For more details, [see the full explanation of how cloud masks are computed.](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-1c/cloud-masks)  Each Sentinel-2 product (zip archive) may contain multiple granules. Each granule becomes a separate Earth Engine asset. EE asset ids for Sentinel-2 assets have the following format: COPERNICUS/S2/20151128T002653_20151128T102149_T56MNN. Here the first numeric part represents the sensing date and time, the second numeric part represents the product generation date and time, and the final 6-character string is a unique granule identifier indicating its UTM grid reference (see [MGRS](https://en.wikipedia.org/wiki/Military_Grid_Reference_System)).  The Level-2 data produced by ESA can be found in the collection [COPERNICUS/S2_SR](COPERNICUS_S2_SR).  For datasets to assist with cloud and/or cloud shadow detection, see [COPERNICUS/S2_CLOUD_PROBABILITY](COPERNICUS_S2_CLOUD_PROBABILITY) and [GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED](GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED).  For more details on Sentinel-2 radiometric resolution, [see this page](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric). 
        :param example: /**  * Function to mask clouds using the Sentinel-2 QA band  * @param {ee.Image} image Sentinel-2 image  * @return {ee.Image} cloud masked Sentinel-2 image  */ function maskS2clouds(image) {   var qa = image.select('QA60');    // Bits 10 and 11 are clouds and cirrus, respectively.   var cloudBitMask = 1 << 10;   var cirrusBitMask = 1 << 11;    // Both flags should be set to zero, indicating clear conditions.   var mask = qa.bitwiseAnd(cloudBitMask).eq(0)       .and(qa.bitwiseAnd(cirrusBitMask).eq(0));    return image.updateMask(mask).divide(10000); }  // Map the function over one month of data and take the median. // Load Sentinel-2 TOA reflectance data. var dataset = ee.ImageCollection('COPERNICUS/S2')                   .filterDate('2018-01-01', '2018-01-31')                   // Pre-filter to get less cloudy granules.                   .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))                   .map(maskS2clouds);  var rgbVis = {   min: 0.0,   max: 0.3,   bands: ['B4', 'B3', 'B2'], };  Map.setCenter(-9.1695, 38.6917, 12); Map.addLayer(dataset.median(), rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S2_CLOUD_PROBABILITY:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S2_CLOUD_PROBABILITY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S2_CLOUD_PROBABILITY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S2_CLOUD_PROBABILITY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S2_CLOUD_PROBABILITY(example: str = ''):
        """
        The S2 cloud probability is created with the [sentinel2-cloud-detector](https://github.com/sentinel-hub/sentinel2-cloud-detector) library (using [LightGBM](https://github.com/microsoft/LightGBM)). All bands are upsampled using bilinear interpolation to 10m resolution before the gradient boost base algorithm is applied.  The resulting `0..1` floating point probability is scaled to `0..100` and stored as a UINT8.  Areas missing any or all of the bands are masked out. Higher values are more likely to be clouds or highly reflective surfaces (e.g. roof tops or snow).  Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.  The Level-2 data can be found in the collection [COPERNICUS/S2_SR](COPERNICUS_S2_SR).  The Level-1B data can be found in the collection [COPERNICUS/S2](COPERNICUS_S2).  Additional metadata is available on assets in those collections.  See [this tutorial](https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless) explaining how to apply the cloud mask. 
        :param example: var s2Sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED'); var s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY');  var START_DATE = ee.Date('2019-01-01'); var END_DATE = ee.Date('2019-03-01'); var MAX_CLOUD_PROBABILITY = 65; var region =     ee.Geometry.Rectangle({coords: [-76.5, 2.0, -74, 4.0], geodesic: false}); Map.setCenter(-75, 3, 12);  function maskClouds(img) {   var clouds = ee.Image(img.get('cloud_mask')).select('probability');   var isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY);   return img.updateMask(isNotCloud); }  // The masks for the 10m bands sometimes do not exclude bad data at // scene edges, so we apply masks from the 20m and 60m bands as well. // Example asset that needs this operation: // COPERNICUS/S2_CLOUD_PROBABILITY/20190301T000239_20190301T000238_T55GDP function maskEdges(s2_img) {   return s2_img.updateMask(       s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask())); }  // Filter input collections by desired data range and region. var criteria = ee.Filter.and(     ee.Filter.bounds(region), ee.Filter.date(START_DATE, END_DATE)); s2Sr = s2Sr.filter(criteria).map(maskEdges); s2Clouds = s2Clouds.filter(criteria);  // Join S2 SR with cloud probability dataset to add cloud mask. var s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply({   primary: s2Sr,   secondary: s2Clouds,   condition:       ee.Filter.equals({leftField: 'system:index', rightField: 'system:index'}) });  var s2CloudMasked =     ee.ImageCollection(s2SrWithCloudMask).map(maskClouds).median(); var rgbVis = {min: 0, max: 3000, bands: ['B4', 'B3', 'B2']};  Map.addLayer(     s2CloudMasked, rgbVis, 'S2 SR masked at ' + MAX_CLOUD_PROBABILITY + '%',     true); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S2_HARMONIZED:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S2_HARMONIZED'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S2_HARMONIZED.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S2_HARMONIZED.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S2_HARMONIZED(example: str = ''):
        """
        After 2022-01-25, Sentinel-2 scenes with PROCESSING_BASELINE '04.00' or above have their DN (value) range shifted by 1000. The HARMONIZED collection shifts data in newer scenes to be in the same range as in older scenes.  Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.  The Sentinel-2 data contain 13 UINT16 spectral bands representing TOA reflectance scaled by 10000. See the [Sentinel-2 User Handbook](https://sentinel.esa.int/documents/247904/685211/Sentinel-2_User_Handbook) for details. In addition, three QA bands are present where one (QA60) is a bitmask band with cloud mask information. For more details, [see the full explanation of how cloud masks are computed.](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-1c/cloud-masks)  Each Sentinel-2 product (zip archive) may contain multiple granules. Each granule becomes a separate Earth Engine asset. EE asset ids for Sentinel-2 assets have the following format: COPERNICUS/S2/20151128T002653_20151128T102149_T56MNN. Here the first numeric part represents the sensing date and time, the second numeric part represents the product generation date and time, and the final 6-character string is a unique granule identifier indicating its UTM grid reference (see [MGRS](https://en.wikipedia.org/wiki/Military_Grid_Reference_System)).  The Level-2 data produced by ESA can be found in the collection [COPERNICUS/S2_SR](COPERNICUS_S2_SR).  For datasets to assist with cloud and/or cloud shadow detection, see [COPERNICUS/S2_CLOUD_PROBABILITY](COPERNICUS_S2_CLOUD_PROBABILITY) and [GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED](GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED).  For more details on Sentinel-2 radiometric resolution, [see this page](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric). 
        :param example: /**  * Function to mask clouds using the Sentinel-2 QA band  * @param {ee.Image} image Sentinel-2 image  * @return {ee.Image} cloud masked Sentinel-2 image  */ function maskS2clouds(image) {   var qa = image.select('QA60');    // Bits 10 and 11 are clouds and cirrus, respectively.   var cloudBitMask = 1 << 10;   var cirrusBitMask = 1 << 11;    // Both flags should be set to zero, indicating clear conditions.   var mask = qa.bitwiseAnd(cloudBitMask).eq(0)       .and(qa.bitwiseAnd(cirrusBitMask).eq(0));    return image.updateMask(mask).divide(10000); }  // Map the function over a month of data and take the median. // Load Sentinel-2 TOA reflectance data (adjusted for processing changes // that occurred after 2022-01-25). var dataset = ee.ImageCollection('COPERNICUS/S2_HARMONIZED')                   .filterDate('2022-01-01', '2022-01-31')                   // Pre-filter to get less cloudy granules.                   .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))                   .map(maskS2clouds);  var rgbVis = {   min: 0.0,   max: 0.3,   bands: ['B4', 'B3', 'B2'], };  Map.setCenter(-9.1695, 38.6917, 12); Map.addLayer(dataset.median(), rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S2_SR:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S2_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S2_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S2_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S2_SR(example: str = ''):
        """
        See also collection COPERNICUS/S2_SR_HARMONIZED that shifts data with PROCESSING_BASELINE '04.00' or above (after 2022-01-25) to be in the same range as in older scenes.  Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.  The Sentinel-2 L2 data are downloaded from scihub. They were computed by running sen2cor. WARNING: ESA did not produce L2 data for all L1 assets, and earlier L2 coverage is not global.  The assets contain 12 UINT16 spectral bands representing SR scaled by 10000 (unlike in L1 data, there is no B10). There are also several more L2-specific bands (see band list for details). See the [Sentinel-2 User Handbook](https://sentinel.esa.int/documents/247904/685211/Sentinel-2_User_Handbook) for details. In addition, three QA bands are present where one (QA60) is a bitmask band with cloud mask information. For more details, [see the full explanation of how cloud masks are computed.](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-1c/cloud-masks)  EE asset ids for Sentinel-2 L2 assets have the following format: COPERNICUS/S2_SR/20151128T002653_20151128T102149_T56MNN. Here the first numeric part represents the sensing date and time, the second numeric part represents the product generation date and time, and the final 6-character string is a unique granule identifier indicating its UTM grid reference (see [MGRS](https://en.wikipedia.org/wiki/Military_Grid_Reference_System)).  For datasets to assist with cloud and/or cloud shadow detection, see [COPERNICUS/S2_CLOUD_PROBABILITY](COPERNICUS_S2_CLOUD_PROBABILITY) and [GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED](GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED).  For more details on Sentinel-2 radiometric resolution, [see this page](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric). 
        :param example: /**  * Function to mask clouds using the Sentinel-2 QA band  * @param {ee.Image} image Sentinel-2 image  * @return {ee.Image} cloud masked Sentinel-2 image  */ function maskS2clouds(image) {   var qa = image.select('QA60');    // Bits 10 and 11 are clouds and cirrus, respectively.   var cloudBitMask = 1 << 10;   var cirrusBitMask = 1 << 11;    // Both flags should be set to zero, indicating clear conditions.   var mask = qa.bitwiseAnd(cloudBitMask).eq(0)       .and(qa.bitwiseAnd(cirrusBitMask).eq(0));    return image.updateMask(mask).divide(10000); }  var dataset = ee.ImageCollection('COPERNICUS/S2_SR')                   .filterDate('2020-01-01', '2020-01-30')                   // Pre-filter to get less cloudy granules.                   .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))                   .map(maskS2clouds);  var visualization = {   min: 0.0,   max: 0.3,   bands: ['B4', 'B3', 'B2'], };  Map.setCenter(83.277, 17.7009, 12);  Map.addLayer(dataset.mean(), visualization, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S2_SR_HARMONIZED:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S2_SR_HARMONIZED'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S2_SR_HARMONIZED.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S2_SR_HARMONIZED.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S2_SR_HARMONIZED(example: str = ''):
        """
        After 2022-01-25, Sentinel-2 scenes with PROCESSING_BASELINE '04.00' or above have their DN (value) range shifted by 1000. The HARMONIZED collection shifts data in newer scenes to be in the same range as in older scenes.  Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.  The Sentinel-2 L2 data are downloaded from scihub. They were computed by running sen2cor. WARNING: ESA did not produce L2 data for all L1 assets, and earlier L2 coverage is not global.  The assets contain 12 UINT16 spectral bands representing SR scaled by 10000 (unlike in L1 data, there is no B10). There are also several more L2-specific bands (see band list for details). See the [Sentinel-2 User Handbook](https://sentinel.esa.int/documents/247904/685211/Sentinel-2_User_Handbook) for details. In addition, three QA bands are present where one (QA60) is a bitmask band with cloud mask information. For more details, [see the full explanation of how cloud masks are computed.](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-1c/cloud-masks)  EE asset ids for Sentinel-2 L2 assets have the following format: COPERNICUS/S2_SR/20151128T002653_20151128T102149_T56MNN. Here the first numeric part represents the sensing date and time, the second numeric part represents the product generation date and time, and the final 6-character string is a unique granule identifier indicating its UTM grid reference (see [MGRS](https://en.wikipedia.org/wiki/Military_Grid_Reference_System)).  For datasets to assist with cloud and/or cloud shadow detection, see [COPERNICUS/S2_CLOUD_PROBABILITY](COPERNICUS_S2_CLOUD_PROBABILITY) and [GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED](GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED).  For more details on Sentinel-2 radiometric resolution, [see this page](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric). 
        :param example: /**  * Function to mask clouds using the Sentinel-2 QA band  * @param {ee.Image} image Sentinel-2 image  * @return {ee.Image} cloud masked Sentinel-2 image  */ function maskS2clouds(image) {   var qa = image.select('QA60');    // Bits 10 and 11 are clouds and cirrus, respectively.   var cloudBitMask = 1 << 10;   var cirrusBitMask = 1 << 11;    // Both flags should be set to zero, indicating clear conditions.   var mask = qa.bitwiseAnd(cloudBitMask).eq(0)       .and(qa.bitwiseAnd(cirrusBitMask).eq(0));    return image.updateMask(mask).divide(10000); }  var dataset = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')                   .filterDate('2020-01-01', '2020-01-30')                   // Pre-filter to get less cloudy granules.                   .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))                   .map(maskS2clouds);  var visualization = {   min: 0.0,   max: 0.3,   bands: ['B4', 'B3', 'B2'], };  Map.setCenter(83.277, 17.7009, 12);  Map.addLayer(dataset.mean(), visualization, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S3_OLCI:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S3_OLCI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S3_OLCI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S3_OLCI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S3_OLCI(example: str = ''):
        """
        The Ocean and Land Color Instrument (OLCI) Earth Observation Full Resolution (EFR) dataset contains top of atmosphere radiances at 21 spectral bands with center wavelengths ranging between 0.4&micro;m and 1.02&micro;m at spatial resolution of 300m with worldwide coverage every ~2 days.  OLCI is one of the instruments in the ESA/EUMETSAT Sentinel-3 mission for measuring sea-surface topography, sea- and land-surface temperature, ocean color and land color with high-end accuracy and reliability to support ocean forecasting systems, as well as environmental and climate monitoring.  The Sentinel-3 OLCI instrument is based on the optomechanical and imaging design of ENVISAT's MERIS. It is designed to retrieve the spectral distribution of upwelling radiance just above the sea surface (the water-leaving radiance).  OLCI observation is performed simultaneously in 21 spectral bands ranging from the visible to the near-infrared (400 to 1029nm). 
        :param example: var dataset = ee.ImageCollection('COPERNICUS/S3/OLCI')                   .filterDate('2018-04-01', '2018-04-04');  // Select bands for visualization and apply band-specific scale factors. var rgb = dataset.select(['Oa08_radiance', 'Oa06_radiance', 'Oa04_radiance'])               .median()               // Convert to radiance units.               .multiply(ee.Image([0.00876539, 0.0123538, 0.0115198]));  var visParams = {   min: 0,   max: 6,   gamma: 1.5, };  Map.setCenter(46.043, 1.45, 5); Map.addLayer(rgb, visParams, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_AER_AI:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_AER_AI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_AER_AI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_AER_AI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_AER_AI(example: str = ''):
        """
        ### NRTI/L3_AER_AI  This dataset provides near real-time high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Aerosol Index (AAI).  The AAI is based on wavelength-dependent changes in Rayleigh scattering in the UV spectral range for a pair of wavelengths.  The difference between observed and modelled reflectance results in the AAI.  When the AAI is positive, it indicates the presence of UV-absorbing aerosols like dust and smoke. It is useful for tracking the evolution of episodic aerosol plumes from dust outbreaks, volcanic ash, and biomass burning.  The wavelengths used have very low ozone absorption, so unlike aerosol optical thickness measurements, AAI can be calculated in the presence of clouds. Daily global coverage is therefore possible.  For this L3 AER_AI product, the absorbing_aerosol_index is calculated with a pair of measurements at the 354 nm and 388 nm wavelengths.  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'absorbing_aerosol_index_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(absorbing_aerosol_index,sensor_altitude,sensor_azimuth_angle,      sensor_zenith_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_NRTI_L2__AER_AI_20181113T080042_20181113T080542_05618_01_010200_20181113T083707.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_AER_AI')   .select('absorbing_aerosol_index')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: -1,   max: 2.0,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P Aerosol'); Map.setCenter(-118.82, 36.1, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_AER_LH:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_AER_LH'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_AER_LH.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_AER_LH.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_AER_LH(example: str = ''):
        """
        ### NRTI/L3_AER_LH  This dataset provides offline high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Layer Height (ALH).  The ALH is very sensitive to cloud contamination. However, aerosols and clouds can be difficult to distinguish, and ALH is computed for all FRESCO effective cloud fractions smaller than 0.05. Cloud masks are available from FRESCO and VIIRS, and are strongly recommended to filter for residual clouds. A sunglint mask is also available to screen sunglint regions, which are not filtered beforehand.  It is known that high surface albedos negatively influence the ALH, biasing the ALH towards the surface. In general, the ALH over (dark) oceans is considered reliable to within the requirement of 1000 m or 100 hPa. Over land, especially bright surfaces, the accuracy may be lower, and the use of the ALH product over bright surfaces like deserts is not advisable.  For this L3 AER_LH product, the aerosol_mid_pressure is calculated with a pair of measurements at the 354 nm and 388 nm wavelengths.  The [COPERNICUS/S5P/OFFL/L3_SO2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_SO2) product has the absorbing_aerosol_index calculated using the 340 nm and 380 nm wavelengths.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'aerosol_height_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(aerosol_height,aerosol_pressure,aerosol_optical_depth,      sensor_zenith_angle,sensor_azimuth_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_NRTI_L2__AER_LH_20191202T233055_20191202T233555_11074_01_010302_20191203T012120.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_AER_LH')   .select('aerosol_height')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: -81.17,   max: 67622.56,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P Aerosol Height'); Map.setCenter(44.09, 24.27, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_CLOUD:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_CLOUD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_CLOUD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_CLOUD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_CLOUD(example: str = ''):
        """
        ### NRTI/L3_CLOUD  This dataset provides near real-time high-resolution imagery of cloud parameters.  The TROPOMI/S5P cloud properties retrieval is based on the OCRA and ROCINN algorithms currently being used in the operational GOME and GOME-2 products. OCRA retrieves the cloud fraction using measurements in the UV/VIS spectral regions and ROCINN retrieves the cloud height (pressure) and optical thickness (albedo) using measurements in and around the oxygen A-band at 760 nm. Version 3.0 of the algorithms are used, which are based on a more realistic treatment of clouds as optically uniform layers of light-scattering particles. Additionally, the cloud parameters are also provided for a cloud model which assumes the cloud to be a Lambertian reflecting boundary. [More information.](http://www.tropomi.eu/data-products/cloud)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'cloud_fraction>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(cloud_fraction,cloud_top_pressure,cloud_top_height, cloud_base_pressure,cloud_base_height,cloud_optical_depth,surface_albedo, sensor_azimuth_angle,sensor_zenith_angle,solar_azimuth_angle, solar_zenith_angle)' S5P_NRTI_L2__CLOUD__20190208T230503_20190208T231003_06860_01_010105_20190209T005255.nc output.h5 ```  Assets between the dates 2018-07-10 and 2018-07-18 are missing due to non-standard structure of product files. 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_CLOUD')   .select('cloud_fraction')   .filterDate('2019-06-01', '2019-06-02');  var band_viz = {   min: 0,   max: 0.95,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P Cloud'); Map.setCenter(-58.14, -10.47, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_CO:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_CO'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_CO.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_CO.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_CO(example: str = ''):
        """
        ### NRTI/L3_CO  This dataset provides near real-time high-resolution imagery of CO concentrations.  Carbon monoxide (CO) is an important atmospheric trace gas for understanding tropospheric chemistry. In certain urban areas, it is a major atmospheric pollutant. Main sources of CO are combustion of fossil fuels, biomass burning, and atmospheric oxidation of methane and other hydrocarbons. Whereas fossil fuel combustion is the main source of CO at northern mid-latitudes, the oxidation of isoprene and biomass burning play an important role in the tropics. TROPOMI on the Sentinel 5 Precursor (S5P) satellite observes the CO global abundance exploiting clear-sky and cloudy-sky Earth radiance measurements in the 2.3 &mu;m spectral range of the shortwave infrared (SWIR) part of the solar spectrum. TROPOMI clear sky observations provide CO total columns with sensitivity to the tropospheric boundary layer. For cloudy atmospheres, the column sensitivity changes according to the light path. [More information.](http://www.tropomi.eu/data-products/carbon-monoxide)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'CO_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(CO_column_number_density,H2O_column_number_density,cloud_height, sensor_altitude,sensor_azimuth_angle, sensor_zenith_angle, solar_azimuth_angle,solar_zenith_angle)' S5P_NRTI_L2__CO_____20181122T000018_20181122T000518_05741_01_010200_20181122T004844.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_CO')   .select('CO_column_number_density')   .filterDate('2019-06-01', '2019-06-11');  var band_viz = {   min: 0,   max: 0.05,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P CO'); Map.setCenter(-25.01, -4.28, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_HCHO:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_HCHO'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_HCHO.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_HCHO.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_HCHO(example: str = ''):
        """
        ### NRTI/L3_HCHO  This dataset provides near real-time high-resolution imagery of atmospheric formaldehyde (HCHO) concentrations.  Formaldehyde is an intermediate gas in almost all oxidation chains of non-methane volatile organic compounds (NMVOC), leading eventually to CO<sub>2</sub>. Non-Methane Volatile Organic Compounds (NMVOCs) are, together with NO<sub>x</sub>, CO and CH<sub>4</sub>, among the most important precursors of tropospheric O<sub>3</sub>. The major HCHO source in the remote atmosphere is CH<sub>4</sub> oxidation. Over the continents, the oxidation of higher NMVOCs emitted from vegetation, fires, traffic and industrial sources results in important and localized enhancements of the HCHO levels. The seasonal and inter-annual variations of the formaldehyde distribution are principally related to temperature changes and fire events, but also to changes in anthropogenic activities. HCHO concentrations in the boundary layer can be directly related to the release of short-lived hydrocarbons, which mostly cannot be observed directly from space. [More information.](http://www.tropomi.eu/data-products/formaldehyde)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  Example harpconvert invocation for one tile:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_HCHO_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(tropospheric_HCHO_column_number_density,      tropospheric_HCHO_column_number_density_amf,      HCHO_slant_column_number_density,cloud_fraction,sensor_altitude,      sensor_azimuth_angle, sensor_zenith_angle,solar_azimuth_angle,      solar_zenith_angle)' S5P_NRTI_L2__HCHO___20181017T181013_20181017T181513_05241_01_010102_20181017T185718.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_HCHO')   .select('tropospheric_HCHO_column_number_density')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: 0.0,   max: 0.0003,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P HCHO'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_NO2:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_NO2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_NO2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_NO2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_NO2(example: str = ''):
        """
        ### NRTI/L3_NO2  This dataset provides near real-time high-resolution imagery of NO<sub>2</sub> concentrations.  Nitrogen oxides (NO<sub>2</sub> and NO) are important trace gases in the Earth's atmosphere, present in both the troposphere and the stratosphere. They enter the atmosphere as a result of anthropogenic activities (notably fossil fuel combustion and biomass burning) and natural processes (wildfires, lightning, and microbiological processes in soils). Here, NO<sub>2</sub> is used to represent concentrations of collective nitrogen oxides because during daytime, i.e. in the presence of sunlight, a photochemical cycle involving ozone (O<sub>3</sub>) converts NO into NO<sub>2</sub> and vice versa on a timescale of minutes. The TROPOMI NO<sub>2</sub> processing system is based on the algorithm developments for the DOMINO-2 product and for the EU QA4ECV NO<sub>2</sub> reprocessed dataset for OMI, and has been adapted for TROPOMI. This retrieval-assimilation-modelling system uses the 3-dimensional global TM5-MP chemistry transport model at a resolution of 1x1 degree as an essential element. [More information.](http://www.tropomi.eu/data-products/nitrogen-dioxide)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_NO2_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(NO2_column_number_density,tropospheric_NO2_column_number_density,      stratospheric_NO2_column_number_density,NO2_slant_column_number_density,      tropopause_pressure,absorbing_aerosol_index,cloud_fraction,      sensor_altitude,sensor_azimuth_angle,      sensor_zenith_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_NRTI_L2__NO2____20181107T013042_20181107T013542_05529_01_010200_20181107T021824.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_NO2')   .select('NO2_column_number_density')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: 0,   max: 0.0002,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P N02'); Map.setCenter(65.27, 24.11, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_O3:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_O3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_O3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_O3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_O3(example: str = ''):
        """
        ### NRTI/L3_O3  This dataset provides near-real-time high-resolution imagery of total column ozone concentrations. See also `COPERNICUS/S5P/OFFL/L3_O3_TCL` for the tropospheric column data.  In the stratosphere, the ozone layer shields the biosphere from dangerous solar ultraviolet radiation. In the troposphere, it acts as an efficient cleansing agent, but at high concentration it also becomes harmful to the health of humans, animals, and vegetation. Ozone is also an important greenhouse-gas contributor to ongoing climate change. Since the discovery of the Antarctic ozone hole in the 1980s and the subsequent Montreal Protocol regulating the production of chlorine-containing ozone-depleting substances, ozone has been routinely monitored from the ground and from space.  For this product, there are two algorithms that deliver total ozone: GDP for the near real-time and GODFIT for the offline products. GDP is currently being used for generating the operational total ozone products from GOME, SCIAMACHY and GOME-2; while GODFIT is being used in the ESA CCI and the Copernicus C3S projects. [More information.](http://www.tropomi.eu/data-products/total-ozone-column) [Product user manual.](https://sentinel.esa.int/documents/247904/2474726/Sentinel-5P-Level-2-Product-User-Manual-Ozone-Total-Column)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  The qa value is adjusted before running harpconvert to satisfy all of the following criteria:  * ozone_total_vertical_column in [0, 0.45] * ozone_effective_temperature in [180, 260] * fitted_root_mean_square > 0.01  Example harpconvert invocation: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'O3_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(O3_column_number_density,O3_column_number_density_amf, O3_slant_column_number_density,O3_effective_temperature,cloud_fraction, sensor_azimuth_angle,sensor_zenith_angle,solar_azimuth_angle, solar_zenith_angle)' S5P_NRTI_L2__O3_____20180710T230038_20180710T230538_03840_01_010000_20180711T005227.nc output.h5 ```  - Assets between the dates 2018-07-10 and 2018-07-18 are missing due to non-standard structure of product files. 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_O3')   .select('O3_column_number_density')   .filterDate('2019-06-01', '2019-06-05');  var band_viz = {   min: 0.12,   max: 0.15,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P O3'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_NRTI_L3_SO2:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_NRTI_L3_SO2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_NRTI_L3_SO2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_NRTI_L3_SO2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_NRTI_L3_SO2(example: str = ''):
        """
        ### NRTI/L3_SO2  This dataset provides near real-time high-resolution imagery of atmospheric sulfur dioxide (SO<sub>2</sub>) concentrations.  Sulfur dioxide (SO<sub>2</sub>) enters the Earth's atmosphere through both natural and anthropogenic processes. It plays a role in chemistry on a local and global scale and its impact ranges from short-term pollution to effects on climate. Only about 30% of the emitted SO<sub>2</sub> comes from natural sources; the majority is of anthropogenic origin. SO<sub>2</sub> emissions adversely affect human health and air quality. SO<sub>2</sub> has an effect on climate through radiative forcing, via the formation of sulfate aerosols. Volcanic SO<sub>2</sub> emissions can also pose a threat to aviation, along with volcanic ash. S5P/TROPOMI samples the Earth's surface with a revisit time of one day with unprecedented spatial resolution of 3.5 x 7 km which allows the resolution of fine details including the detection of much smaller SO<sub>2</sub> plumes. [More information.](http://www.tropomi.eu/data-products/sulphur-dioxide)  ### NRTI L3 Product  To make our NRTI L3 products, we use [harpconvert](https://stcorp.github.io/harp/doc/html/harpconvert.html) to grid the data.  The qa value is adjusted before running harpconvert to satisfy all of the following criteria:  * snow_ice < 0.5 * sulfurdioxide_total_air_mass_factor_polluted > 0.1 * sulfurdioxide_total_vertical_column > -0.001 * qa_value > 0.5 * cloud_fraction_crb < 0.3 * solar_zenith_angle < 60  The 15km SO2 band is ingested only when solar_zenith_angle < 70.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'SO2_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(SO2_column_number_density,SO2_column_number_density_amf,      SO2_slant_column_number_density,cloud_fraction, sensor_altitude,      sensor_azimuth_angle, sensor_zenith_angle,solar_azimuth_angle,      solar_zenith_angle)' S5P_NRTI_L2__SO2____20190129T101503_20190129T102003_06711_01_010105_20190129T111328.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/NRTI/L3_SO2')   .select('SO2_column_number_density')   .filterDate('2019-06-01', '2019-06-11');  var band_viz = {   min: 0.0,   max: 0.0005,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P SO2'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_AER_AI:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_AER_AI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_AER_AI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_AER_AI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_AER_AI(example: str = ''):
        """
        ### OFFL/L3_AER_AI  This dataset provides offline high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Aerosol Index (AAI).  The AAI is based on wavelength-dependent changes in Rayleigh scattering in the UV spectral range for a pair of wavelengths.  The difference between observed and modelled reflectance results in the AAI.  When the AAI is positive, it indicates the presence of UV-absorbing aerosols like dust and smoke. It is useful for tracking the evolution of episodic aerosol plumes from dust outbreaks, volcanic ash, and biomass burning.  The wavelengths used have very low ozone absorption, so unlike aerosol optical thickness measurements, AAI can be calculated in the presence of clouds. Daily global coverage is therefore possible.  For this L3 AER_AI product, the absorbing_aerosol_index is calculated with a pair of measurements at the 354 nm and 388 nm wavelengths.  The [COPERNICUS/S5P/OFFL/L3_SO2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_SO2) product has the absorbing_aerosol_index calculated using the 340 nm and 380 nm wavelengths.  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'absorbing_aerosol_index_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__AER_AI_20181030T213916_20181030T232046_05427_01_010200_20181105T210529.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'absorbing_aerosol_index_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(absorbing_aerosol_index,sensor_altitude,sensor_azimuth_angle,      sensor_zenith_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_OFFL_L2__AER_AI_20181030T213916_20181030T232046_05427_01_010200_20181105T210529.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_AER_AI')   .select('absorbing_aerosol_index')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: -1,   max: 2.0,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P Aerosol'); Map.setCenter(-118.82, 36.1, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_AER_LH:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_AER_LH'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_AER_LH.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_AER_LH.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_AER_LH(example: str = ''):
        """
        ### OFFL/L3_AER_LH  This dataset provides offline high-resolution imagery of the UV Aerosol Index (UVAI), also called the Absorbing Layer Height (ALH).  The ALH is very sensitive to cloud contamination. However, aerosols and clouds can be difficult to distinguish, and ALH is computed for all FRESCO effective cloud fractions smaller than 0.05. Cloud masks are available from FRESCO and VIIRS, and are strongly recommended to filter for residual clouds. A sunglint mask is also available to screen sunglint regions, which are not filtered beforehand.  It is known that high surface albedos negatively influence the ALH, biasing the ALH towards the surface. In general, the ALH over (dark) oceans is considered reliable to within the requirement of 1000 m or 100 hPa. Over land, especially bright surfaces, the accuracy may be lower, and the use of the ALH product over bright surfaces like deserts is not advisable.  For this L3 AER_LH product, the aerosol_mid_pressure is calculated with a pair of measurements at the 354 nm and 388 nm wavelengths.  The [COPERNICUS/S5P/OFFL/L3_SO2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_SO2) product has the absorbing_aerosol_index calculated using the 340 nm and 380 nm wavelengths.  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'aerosol_height_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__AER_LH_20190404T042423_20190404T060554_07630_01_010300_20190410T062552.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'aerosol_height_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(aerosol_height,aerosol_pressure,aerosol_optical_depth,      sensor_zenith_angle,sensor_azimuth_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_OFFL_L2__AER_LH_20190404T042423_20190404T060554_07630_01_010300_20190410T062552.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_AER_LH')                     .select('aerosol_height')                     .filterDate('2019-06-01', '2019-06-05');  var visualization = {   min: 0,   max: 6000,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.setCenter(44.09, 24.27, 4);  Map.addLayer(collection.mean(), visualization, 'S5P Aerosol Height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_CH4:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_CH4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_CH4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_CH4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_CH4(example: str = ''):
        """
        ### OFFL/L3_CH4  This dataset provides offline high-resolution imagery of methane concentrations.  Methane (CH<sub>4</sub>) is, after carbon dioxide (CO<sub>2</sub>), the most important contributor to the anthropogenically enhanced greenhouse effect. Roughly three-quarters of methane emissions are anthropogenic and as such it is important to continue the record of satellite based measurements. TROPOMI aims at providing CH<sub>4</sub> column concentrations with high sensitivity to the Earth's surface, good spatiotemporal coverage, and sufficient accuracy to facilitate inverse modeling of sources and sinks. TROPOMI uses absorption information from the Oxygen-A Band (760nm) and the SWIR spectral range to monitor CH<sub>4</sub> abundances in the Earth's atmosphere. [More information.](http://www.tropomi.eu/data-products/methane)  Currently, the following data quality issues are known, are not covered by the quality flags, and should be kept in mind when looking at the methane product and also at preliminary validation results. For more details, see the [MPC VDAF website](http://mpc-vdaf.tropomi.eu).  Filtering on qa_value &lt; 0.5 does not remove all pixels considered bad. Some pixels with too low methane concentrations are still present:   - Single TROPOMI overpasses show stripes of erroneous CH<sub>4</sub> values    in the flight direction.   - Not all pixels above inland water are filtered.   - Uncertainties for the XCH<sub>4</sub> is only based on the single    sounding precision due to measurement noise. For applications requiring    an overall uncertainty estimate, we propose to multiply the provided    error by a factor 2, which reflects the scatter of single sounding errors    in the TCCON validation.   - Data prior to November 2021 only provides XCH<sub>4</sub> over land,    after which glint ocean observations were added.   - No data are present between 2022-07-26 and 2022-08-31 due to a    [provider outage](https://scihub.copernicus.eu/news/News01082).  ### OFFL L3 Product  To make our OFFL L3 products, we find which areas within the product's bounding box contain data by using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'CH4_column_volume_mixing_ratio_dry_air_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__CH4____20190223T202409_20190223T220540_07072_01_010202_20190301T221106.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'CH4_column_volume_mixing_ratio_dry_air_validity>50; derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(CH4_column_volume_mixing_ratio_dry_air, aerosol_height, aerosol_optical_depth, sensor_azimuth_angle, sensor_zenith_angle, solar_azimuth_angle, solar_zenith_angle)' S5P_OFFL_L2__CH4____20190223T202409_20190223T220540_07072_01_010202_20190301T221106.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_CH4')   .select('CH4_column_volume_mixing_ratio_dry_air')   .filterDate('2019-06-01', '2019-07-16');  var band_viz = {   min: 1750,   max: 1900,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P CH4'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_CLOUD:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_CLOUD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_CLOUD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_CLOUD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_CLOUD(example: str = ''):
        """
        ### OFFL/L3_CLOUD  This dataset provides offline high-resolution imagery of cloud parameters.  The TROPOMI/S5P cloud properties retrieval is based on the OCRA and ROCINN algorithms currently being used in the operational GOME and GOME-2 products. OCRA retrieves the cloud fraction using measurements in the UV/VIS spectral regions and ROCINN retrieves the cloud height (pressure) and optical thickness (albedo) using measurements in and around the oxygen A-band at 760 nm. Version 3.0 of the algorithms are used, which are based on a more realistic treatment of clouds as optically uniform layers of light-scattering particles. Additionally, the cloud parameters are also provided for a cloud model which assumes the cloud to be a Lambertian reflecting boundary. [More information.](http://www.tropomi.eu/data-products/cloud)  ### OFFL L3 Product  To make our OFFL L3 products, we find which areas within the product's bounding box contain data by using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'cloud_fraction>50;derive(datetime_stop {time})' S5P_OFFL_L2__CLOUD__20180705T095218_20180705T113348_03760_01_010000_20180712T082510.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'cloud_fraction>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(cloud_fraction,cloud_top_pressure,cloud_top_height, cloud_base_pressure,cloud_base_height,cloud_optical_depth,surface_albedo, sensor_azimuth_angle,sensor_zenith_angle,solar_azimuth_angle, solar_zenith_angle)' S5P_OFFL_L2__CLOUD__20180705T095218_20180705T113348_03760_01_010000_20180712T082510.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_CLOUD')   .select('cloud_fraction')   .filterDate('2019-06-01', '2019-06-02');  var band_viz = {   min: 0,   max: 0.95,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P Cloud'); Map.setCenter(-58.14, -10.47, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_CO:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_CO'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_CO.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_CO.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_CO(example: str = ''):
        """
        ### OFFL/L3_CO  This dataset provides offline high-resolution imagery of CO concentrations.  Carbon monoxide (CO) is an important atmospheric trace gas for understanding tropospheric chemistry. In certain urban areas, it is a major atmospheric pollutant. Main sources of CO are combustion of fossil fuels, biomass burning, and atmospheric oxidation of methane and other hydrocarbons. Whereas fossil fuel combustion is the main source of CO at northern mid-latitudes, the oxidation of isoprene and biomass burning play an important role in the tropics. TROPOMI on the Sentinel 5 Precursor (S5P) satellite observes the CO global abundance exploiting clear-sky and cloudy-sky Earth radiance measurements in the 2.3 &mu;m spectral range of the shortwave infrared (SWIR) part of the solar spectrum. TROPOMI clear sky observations provide CO total columns with sensitivity to the tropospheric boundary layer. For cloudy atmospheres, the column sensitivity changes according to the light path. [More information.](http://www.tropomi.eu/data-products/carbon-monoxide)  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'CO_column_number_density_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__CO_____20181031T060643_20181031T074813_05432_01_010200_20181106T052542.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'CO_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(CO_column_number_density,H2O_column_number_density,cloud_height, sensor_altitude,sensor_azimuth_angle, sensor_zenith_angle, solar_azimuth_angle,solar_zenith_angle)' S5P_OFFL_L2__CO_____20181031T060643_20181031T074813_05432_01_010200_20181106T052542.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_CO')   .select('CO_column_number_density')   .filterDate('2019-06-01', '2019-06-11');  var band_viz = {   min: 0,   max: 0.05,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P CO'); Map.setCenter(-25.01, -4.28, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_HCHO:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_HCHO'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_HCHO.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_HCHO.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_HCHO(example: str = ''):
        """
        ### OFFL/L3_HCHO  This dataset provides offline high-resolution imagery of atmospheric formaldehyde (HCHO) concentrations.  Formaldehyde is an intermediate gas in almost all oxidation chains of non-methane volatile organic compounds (NMVOC), leading eventually to CO<sub>2</sub>. Non-Methane Volatile Organic Compounds (NMVOCs) are, together with NO<sub>x</sub>, CO and CH<sub>4</sub>, among the most important precursors of tropospheric O<sub>3</sub>. The major HCHO source in the remote atmosphere is CH<sub>4</sub> oxidation. Over the continents, the oxidation of higher NMVOCs emitted from vegetation, fires, traffic and industrial sources results in important and localized enhancements of the HCHO levels. The seasonal and inter-annual variations of the formaldehyde distribution are principally related to temperature changes and fire events, but also to changes in anthropogenic activities. HCHO concentrations in the boundary layer can be directly related to the release of short-lived hydrocarbons, which mostly cannot be observed directly from space. [More information.](http://www.tropomi.eu/data-products/formaldehyde)  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_HCHO_column_number_density_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__HCHO___20190116T171037_20190116T185207_06531_01_010105_20190123T104749.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_HCHO_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(tropospheric_HCHO_column_number_density,      tropospheric_HCHO_column_number_density_amf,      HCHO_slant_column_number_density,cloud_fraction,sensor_altitude,      sensor_azimuth_angle, sensor_zenith_angle,solar_azimuth_angle,      solar_zenith_angle)' S5P_OFFL_L2__HCHO___20190116T171037_20190116T185207_06531_01_010105_20190123T104749.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_HCHO')   .select('tropospheric_HCHO_column_number_density')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: 0.0,   max: 0.0003,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P HCHO'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_NO2:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_NO2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_NO2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_NO2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_NO2(example: str = ''):
        """
        ### OFFL/L3_NO2  This dataset provides offline high-resolution imagery of NO<sub>2</sub> concentrations.  Nitrogen oxides (NO<sub>2</sub> and NO) are important trace gases in the Earth's atmosphere, present in both the troposphere and the stratosphere. They enter the atmosphere as a result of anthropogenic activities (notably fossil fuel combustion and biomass burning) and natural processes (wildfires, lightning, and microbiological processes in soils). Here, NO<sub>2</sub> is used to represent concentrations of collective nitrogen oxides because during daytime, i.e. in the presence of sunlight, a photochemical cycle involving ozone (O<sub>3</sub>) converts NO into NO<sub>2</sub> and vice versa on a timescale of minutes. The TROPOMI NO<sub>2</sub> processing system is based on the algorithm developments for the DOMINO-2 product and for the EU QA4ECV NO<sub>2</sub> reprocessed dataset for OMI, and has been adapted for TROPOMI. This retrieval-assimilation-modelling system uses the 3-dimensional global TM5-MP chemistry transport model at a resolution of 1x1 degree as an essential element. [More information.](http://www.tropomi.eu/data-products/nitrogen-dioxide)  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_NO2_column_number_density_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__NO2____20181010T074409_20181010T092539_05135_01_010100_20181016T092316.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'tropospheric_NO2_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(NO2_column_number_density,tropospheric_NO2_column_number_density,      stratospheric_NO2_column_number_density,NO2_slant_column_number_density,      tropopause_pressure,absorbing_aerosol_index,cloud_fraction,      sensor_altitude,sensor_azimuth_angle,      sensor_zenith_angle,solar_azimuth_angle,solar_zenith_angle)' S5P_OFFL_L2__NO2____20181010T074409_20181010T092539_05135_01_010100_20181016T092316.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_NO2')   .select('tropospheric_NO2_column_number_density')   .filterDate('2019-06-01', '2019-06-06');  var band_viz = {   min: 0,   max: 0.0002,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P N02'); Map.setCenter(65.27, 24.11, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_O3:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_O3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_O3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_O3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_O3(example: str = ''):
        """
        ### OFFL/L3_O3  This dataset provides offline high-resolution imagery of total column ozone concentrations. See also `COPERNICUS/S5P/OFFL/L3_O3_TCL` for the tropospheric column data.  In the stratosphere, the ozone layer shields the biosphere from dangerous solar ultraviolet radiation. In the troposphere, it acts as an efficient cleansing agent, but at high concentration it also becomes harmful to the health of humans, animals, and vegetation. Ozone is also an important greenhouse-gas contributor to ongoing climate change. Since the discovery of the Antarctic ozone hole in the 1980s and the subsequent Montreal Protocol regulating the production of chlorine-containing ozone-depleting substances, ozone has been routinely monitored from the ground and from space.  For this product, there are two algorithms that deliver total ozone: GDP for the near real-time and GODFIT for the offline products. GDP is currently being used for generating the operational total ozone products from GOME, SCIAMACHY and GOME-2; while GODFIT is being used in the ESA CCI and the Copernicus C3S projects. [More information.](http://www.tropomi.eu/data-products/total-ozone-column) [Product user manual](https://sentinel.esa.int/documents/247904/2474726/Sentinel-5P-Level-2-Product-User-Manual-Ozone-Total-Column)  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'O3_column_number_density_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__O3_____20181005T225147_20181006T003317_05073_01_010102_20181012T001415.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  The qa value is adjusted before running harpconvert to satisfy all of the following criteria:  * ozone_total_vertical_column in [0, 0.45] * ozone_effective_temperature in [180, 260] * ring_scale_factor in [0, 0.15] * effective_albedo in [-0.5, 1.5]  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'O3_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(O3_column_number_density,O3_effective_temperature,cloud_fraction, sensor_altitude,sensor_azimuth_angle, sensor_zenith_angle, solar_azimuth_angle,solar_zenith_angle)' S5P_OFFL_L2__O3_____20181005T225147_20181006T003317_05073_01_010102_20181012T001415.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_O3')   .select('O3_column_number_density')   .filterDate('2019-06-01', '2019-06-05');  var band_viz = {   min: 0.12,   max: 0.15,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P O3'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_O3_TCL:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_O3_TCL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_O3_TCL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_O3_TCL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_O3_TCL(example: str = ''):
        """
        ### OFFL/L3_O3_TCL  This dataset provides offline tropospheric high-resolution imagery of ozone concentrations between 20N and 20S. See also `COPERNICUS/S5P/OFFL/L3_O3` and `COPERNICUS/S5P/NRTI/L3_O3` for the total column data.  In the stratosphere, the ozone layer shields the biosphere from dangerous solar ultraviolet radiation. In the troposphere, it acts as an efficient cleansing agent, but at high concentration it also becomes harmful to the health of humans, animals, and vegetation. Ozone is also an important greenhouse-gas contributor to ongoing climate change. Since the discovery of the Antarctic ozone hole in the 1980s and the subsequent Montreal Protocol regulating the production of chlorine-containing ozone-depleting substances, ozone has been routinely monitored from the ground and from space.  For this product, the convective cloud differential (ccd) and cloud slicing (csa) algorithm were used. [Product user manual.](https://sentinel.esa.int/documents/247904/2474726/Sentinel-5P-Level-2-Product-User-Manual-Ozone-Tropospheric-Column). [More information.](http://www.tropomi.eu/data-products/tropospheric-ozone-column).  Unlike all other S5P products, this product was ingested directly without using `harpconvert`, as it is already a gridded product. Pixels with qa_value<70 are masked out.  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_O3_TCL')   .select('ozone_tropospheric_vertical_column')   .filterDate('2019-06-01', '2019-07-01');  var band_viz = {   min: 0,   max: 0.02,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P O3'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class COPERNICUS_S5P_OFFL_L3_SO2:
    def __init__(self,):
        self.sensor = 'COPERNICUS_S5P_OFFL_L3_SO2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/COPERNICUS_S5P_OFFL_L3_SO2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/COPERNICUS_S5P_OFFL_L3_SO2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_COPERNICUS_S5P_OFFL_L3_SO2(example: str = ''):
        """
        ### OFFL/L3_SO2  This dataset provides offline high-resolution imagery of atmospheric sulfur dioxide (SO<sub>2</sub>) concentrations.  Sulfur dioxide (SO<sub>2</sub>) enters the Earth's atmosphere through both natural and anthropogenic processes. It plays a role in chemistry on a local and global scale and its impact ranges from short-term pollution to effects on climate. Only about 30% of the emitted SO<sub>2</sub> comes from natural sources; the majority is of anthropogenic origin. SO<sub>2</sub> emissions adversely affect human health and air quality. SO<sub>2</sub> has an effect on climate through radiative forcing, via the formation of sulfate aerosols. Volcanic SO<sub>2</sub> emissions can also pose a threat to aviation, along with volcanic ash. S5P/TROPOMI samples the Earth's surface with a revisit time of one day with unprecedented spatial resolution of 3.5 x 7 km which allows the resolution of fine details including the detection of much smaller SO<sub>2</sub> plumes. [More information.](http://www.tropomi.eu/data-products/sulphur-dioxide)  For this L3 SO<sub>2</sub> product, the absorbing_aerosol_index is calculated with a pair of measurements at the 340 nm and 380 wavelengths.  The [COPERNICUS/S5P/OFFL/L3_AER_AI](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_AER_AI) product has the absorbing_aerosol_index calculated using the 354 nm and 388 nm wavelengths.  ### OFFL L3 Product  To make our OFFL L3 products, we find areas within the product's bounding box with data using a command like this:  ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'SO2_column_number_density_validity>50;derive(datetime_stop {time})' S5P_OFFL_L2__SO2____20181228T231131_20181229T005301_06265_01_010105_20190104T083244.nc grid_info.h5 ```  We then merge all the data into one large mosaic (area-averaging values for pixels that may have different values for different times).  From the mosaic, we create a set of tiles containing orthorectified raster data.  The qa value is adjusted before running harpconvert to satisfy all of the following criteria:  * snow_ice < 0.5 * sulfurdioxide_total_air_mass_factor_polluted > 0.1 * sulfurdioxide_total_vertical_column > -0.001 * qa_value > 0.5 * cloud_fraction_crb < 0.3 * solar_zenith_angle < 60  The 15km SO2 band is ingested only when solar_zenith_angle < 70.  Example harpconvert invocation for one tile: ``` harpconvert --format hdf5 --hdf5-compression 9 -a 'SO2_column_number_density_validity>50;derive(datetime_stop {time}); bin_spatial(2001, 50.000000, 0.01, 2001, -120.000000, 0.01); keep(SO2_column_number_density,SO2_column_number_density_amf,      SO2_slant_column_number_density,absorbing_aerosol_index,cloud_fraction, sensor_altitude,      sensor_azimuth_angle, sensor_zenith_angle,solar_azimuth_angle,      solar_zenith_angle)' S5P_OFFL_L2__SO2____20181228T231131_20181229T005301_06265_01_010105_20190104T083244.nc output.h5 ```  ### Sentinel-5 Precursor  Sentinel-5 Precursor is a satellite launched on 13 October 2017 by the European Space Agency to monitor air pollution.  The onboard sensor is frequently referred to as Tropomi (TROPOspheric Monitoring Instrument).  All of the S5P datasets, except CH<sub>4</sub>, have two versions: Near  Real-Time (NRTI) and Offline (OFFL). CH<sub>4</sub> is available as OFFL only.  The NRTI assets cover a smaller area than the OFFL assets, but appear more  quickly after acquisition.  The OFFL assets contain data from a single orbit  (which, due to half the earth being dark, contains data only for a single  hemisphere).  Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.  The original Sentinel 5P Level 2 (L2) data is binned by time, not by latitude/longitude.  To make it possible to ingest the data into Earth Engine, each Sentinel 5P L2 product is converted to L3, keeping a single grid per orbit (that is, no aggregation across products is performed).  Source products spanning the antimeridian are ingested as two Earth Engine assets, with suffixes _1 and _2.  The conversion to L3 is done by the [harpconvert](https://cdn.rawgit.com/stcorp/harp/master/doc/html/harpconvert.html) tool using the `bin_spatial` operation.  The source data is filtered to remove pixels with QA values less than:  *  80% for AER_AI *  75% for the tropospheric_NO2_column_number_density band of NO2 *  50% for all other datasets except for O3 and SO2  The O3_TCL product is ingested directly (without running harpconvert). 
        :param example: var collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_SO2')   .select('SO2_column_number_density')   .filterDate('2019-06-01', '2019-06-11');  var band_viz = {   min: 0.0,   max: 0.0005,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'S5P SO2'); Map.setCenter(0.0, 0.0, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CPOM_CryoSat2_ANTARCTICA_DEM:
    def __init__(self,):
        self.sensor = 'CPOM_CryoSat2_ANTARCTICA_DEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CPOM_CryoSat2_ANTARCTICA_DEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CPOM_CryoSat2_ANTARCTICA_DEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CPOM_CryoSat2_ANTARCTICA_DEM(example: str = ''):
        """
        This dataset is a digital elevation model (DEM) of the Antarctic ice sheet and ice shelves based on observations recorded by the CryoSat-2 satellite radar altimeter between July 2010 and July 2016.  The DEM is formed from spatio-temporal fits to elevation measurements accumulated within 1, 2, and 5 km grid cells, and is posted at the modal resolution of 1 km. The median and root mean square difference between the DEM and 2.3*10&#8311; airborne laser altimeter measurements acquired during NASA Operation IceBridge campaigns are -0.30 and 13.50 m, respectively.  The DEM uncertainty rises in regions of high slope, especially where elevation measurements were acquired in low-resolution mode; taking this into account, we estimate the average accuracy to be 9.5 m. 
        :param example: var dataset = ee.Image('CPOM/CryoSat2/ANTARCTICA_DEM');  var visualization = {   bands: ['elevation'],   min: 0.0,   max: 4000.0,   palette: ['001fff', '00ffff', 'fbff00', 'ff0000'] };  Map.setCenter(17.0, -76.0, 3);  Map.addLayer(dataset, visualization, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSIC_SPEI_2_8:
    def __init__(self,):
        self.sensor = 'CSIC_SPEI_2_8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSIC_SPEI_2_8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSIC_SPEI_2_8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSIC_SPEI_2_8(example: str = ''):
        """
        The Global SPEI database (SPEIbase) offers long-time robust information about drought conditions at the global scale, with a 0.5 degree pixel size and monthly cadence. It provides SPEI time scales from 1 to 48 months.  The Standardized Precipitatin-Evapotranspiration Index (SPEI) expresses, as a standardized variate (mean zero and unit variance), the deviations of the current climatic balance (precipitation minus evapotranspiration potential) with respect to the long-term balance. The reference period for the calculation in the SPEIbase corresponds to the whole study period. Being a standardized variate means that the SPEI condition can be compared across space and time.  The SPEIbase is based on the [FAO-56 Penman-Monteith estimation](https://www.fao.org/3/x0490e/x0490e06.htm) estimation of potential evapotranspiration. This is a major difference with respect to the SPEI Global Drought Monitor, that uses the Thornthwaite PET estimation. The Penman-Montheith method is considered a superior method, so the SPEIbase is recommended for most uses including long-term climatological analysis. 
        :param example: // Retrieve the last date from the SPEI dataset. var dataset = ee.ImageCollection("CSIC/SPEI/2_8").   filterDate('2021-12-01', '2022-01-01');  // Select the 24-month analysis. var spei24 = dataset.select('SPEI_24_month');  // Set the visualization ranges and color palette. var visParams = {   min: -2.33,   max:  2.33,   palette: [     '8b1a1a', 'de2929', 'f3641d',     'fdc404', '9afa94', '03f2fd',     '12adf3', '1771de', '00008b',   ] };  // Set the map center to Spain's location. Map.setCenter(-3.75, 40.47, 4);  // Display the SPEI 24-month layer. Map.addLayer(spei24, visParams, 'SPEI 24 month'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSIC_SPEI_2_9:
    def __init__(self,):
        self.sensor = 'CSIC_SPEI_2_9'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSIC_SPEI_2_9.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSIC_SPEI_2_9.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSIC_SPEI_2_9(example: str = ''):
        """
        The Global SPEI database (SPEIbase) offers long-time robust information about drought conditions at the global scale, with a 0.5 degree pixel size and monthly cadence. It provides SPEI time scales from 1 to 48 months.  The Standardized Precipitatin-Evapotranspiration Index (SPEI) expresses, as a standardized variate (mean zero and unit variance), the deviations of the current climatic balance (precipitation minus evapotranspiration potential) with respect to the long-term balance. The reference period for the calculation in the SPEIbase corresponds to the whole study period. Being a standardized variate means that the SPEI condition can be compared across space and time.  The SPEIbase is based on the [FAO-56 Penman-Monteith estimation](https://www.fao.org/3/x0490e/x0490e06.htm) estimation of potential evapotranspiration. This is a major difference with respect to the SPEI Global Drought Monitor, that uses the Thornthwaite PET estimation. The Penman-Montheith method is considered a superior method, so the SPEIbase is recommended for most uses including long-term climatological analysis. 
        :param example: // Retrieve the last date from the SPEI dataset. var dataset = ee.ImageCollection("CSIC/SPEI/2_9").   filterDate('2022-12-01', '2023-01-01');  // Select the 24-month analysis. var spei24 = dataset.select('SPEI_24_month');  // Set the visualization ranges and color palette. var visParams = {   min: -2.33,   max:  2.33,   palette: [     '8b1a1a', 'de2929', 'f3641d',     'fdc404', '9afa94', '03f2fd',     '12adf3', '1771de', '00008b',   ] };  // Set the map center to Spain's location. Map.setCenter(-3.75, 40.47, 4);  // Display the SPEI 24-month layer. Map.addLayer(spei24, visParams, 'SPEI 24 month'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSIRO_SLGA:
    def __init__(self,):
        self.sensor = 'CSIRO_SLGA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSIRO_SLGA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSIRO_SLGA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSIRO_SLGA(example: str = ''):
        """
        The Soil and Landscape Grid of Australia (SLGA) is a comprehensive dataset of soil attributes across Australia at 3 arc-second resolution (~90m pixels). The surfaces are the outcomes from modelling that describe the spatial distribution of the soil attributes using existing soil data and environmental covariates. See [Viscarra Rossel et al (2015)](https://www.publish.csiro.au/sr/SR14366) for further details. The SLGA can be used in studies of vadose zone processes, including solute transport, groundwater and nutrient fluxes beyond the root zone, as well as a wide spectrum of ecological, hydrological, and broader environmental applications.  Each product contains six digital soil attribute maps and their upper and lower confidence limits, representing the soil attribute at six depths: 0-5cm, 5-15cm, 15-30cm, 30-60cm, 60-100cm, and 100-200cm. These depths and soil attributes are consistent with the specifications of [GlobalSoilMap](https://www.isric.org/projects/globalsoilmapnet).  This collection has 12 images. Ten of them contain data for GSM primary soil attributes; the other two contain regolith depth and soil depth GSM attributes.  | Attribute                              | Description                                                                                                                   | Code | # of Bands | |----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|------|------------| | Bulk Density (whole earth)             | Bulk density of the whole soil (including coarse fragments) in mass per unit volume by a method equivalent to the core method | BDW  | 18         | | Organic Carbon                         | Mass fraction of carbon by weight in the < 2mm soil material as determined by dry combustion at 900 Celsius                   | SOC  | 18         | | Clay                                   | < 2&micro;m mass fraction of the <2mm soil material determined using the pipette method                                       | CLY  | 18         | | Silt                                   | 2-20&micro;m mass fraction of the < 2mm soil material determined using the pipette method                                     | SLT  | 18         | | Sand                                   | 20&micro;m - 2mm mass fraction of the < 2mm soil material determined using the pipette method                                 | SND  | 18         | | pH (CaCl2)                             | pH of 1:5 soil/0.01M calcium chloride extract                                                                                 | pHc  | 18         | | Available Water Capacity               | Available water capacity computed for each of the specified depth increments                                                  | AWC  | 18         | | Total Nitrogen                         | Mass fraction of total nitrogen in the soil by weight                                                                         | NTO  | 18         | | Total Phosphorus                       | Mass fraction of total phosphorus in the soil by weight                                                                       | PTO  | 18         | | Effective Cation Exchange Capacity     | Cations extracted using barium chloride (BaCl2) plus exchangeable H + Al                                                      | ECE  | 18         | | Depth of Regolith                      | Depth to hard rock. Depth is inclusive of all regolith.                                                                       | DER  | 3          | | Depth of Soil                          | Depth of soil profile (A & B horizons)                                                                                        | DES  | 3          | 
        :param example: var dataset = ee.ImageCollection('CSIRO/SLGA')                   .filter(ee.Filter.eq('attribute_code', 'DES')); var soilDepth = dataset.select('DES_000_200_EV'); var soilDepthVis = {   min: 0.1,   max: 1.84,   palette: ['8d6738', '252525'], }; Map.setCenter(132.495, -21.984, 5); Map.addLayer(soilDepth, soilDepthVis, 'Soil Depth');
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_ALOS_CHILI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_ALOS_CHILI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_ALOS_CHILI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_ALOS_CHILI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_ALOS_CHILI(example: str = ''):
        """
        CHILI is a surrogate for effects of insolation and topographic shading on evapotranspiration represented by calculating insolation at early afternoon, sun altitude equivalent to equinox. It is based on the 30m \"AVE\" band of JAXA's ALOS DEM (available in EE as JAXA/ALOS/AW3D30_V1_1).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/ALOS_CHILI'); var alosChili = dataset.select('constant'); var alosChiliVis = {   min: 0.0,   max: 255.0, }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(alosChili, alosChiliVis, 'ALOS CHILI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_ALOS_landforms:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_ALOS_landforms'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_ALOS_landforms.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_ALOS_landforms.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_ALOS_landforms(example: str = ''):
        """
        The ALOS Landform dataset provides landform classes created by combining the Continuous Heat-Insolation Load Index (ALOS CHILI) and the multi-scale Topographic Position Index (ALOS mTPI) datasets. It is based on the 30m \"AVE\" band of JAXA's ALOS DEM (available in EE as JAXA/ALOS/AW3D30_V1_1).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/ALOS_landforms'); var landforms = dataset.select('constant'); var landformsVis = {   min: 11.0,   max: 42.0,   palette: [     '141414', '383838', '808080', 'ebeb8f', 'f7d311', 'aa0000', 'd89382',     'ddc9c9', 'dccdce', '1c6330', '68aa63', 'b5c98e', 'e1f0e5', 'a975ba',     '6f198c'   ], }; Map.setCenter(-105.58, 40.5498, 11); Map.addLayer(landforms, landformsVis, 'Landforms'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_ALOS_mTPI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_ALOS_mTPI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_ALOS_mTPI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_ALOS_mTPI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_ALOS_mTPI(example: str = ''):
        """
        The mTPI distinguishes ridge from valley forms. It is calculated using elevation data for each location subtracted by the mean elevation within a neighborhood. mTPI uses moving windows of radius (km): 115.8, 89.9, 35.5, 13.1, 5.6, 2.8, and 1.2. It is based on the 30m \"AVE\" band of JAXA's ALOS DEM (available in EE as JAXA/ALOS/AW3D30_V1_1).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/ALOS_mTPI'); var alosMtpi = dataset.select('AVE'); var alosMtpiVis = {   min: -200.0,   max: 200.0,   palette: ['0b1eff', '4be450', 'fffca4', 'ffa011', 'ff0000'], }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(alosMtpi, alosMtpiVis, 'ALOS mTPI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_ALOS_topoDiversity:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_ALOS_topoDiversity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_ALOS_topoDiversity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_ALOS_topoDiversity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_ALOS_topoDiversity(example: str = ''):
        """
        Topographic diversity (D) is a surrogate variable that represents the variety of temperature and moisture conditions available to species as local habitats. It expresses the logic that a higher variety of topo-climate niches should support higher diversity (especially plant) and support species persistence given climatic change.  To calculate D, the multi-scale Topographic Position Index (mTPI), being a dominant control of soil moisture (T), was used for measuring hillslope position. The mTPI was combined with the square-root transform for mTPI>0 (T') and with the standard deviation of the Continuous Heat-Insolation Load Index (CHILI), calculated at multiple scales (C') as: D = 1 - ((1-T') * (1-C'). It is based on the 30m \"AVE\" band of JAXA's ALOS DEM (available in EE as JAXA/ALOS/AW3D30_V1_1).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/ALOS_topoDiversity'); var alosTopographicDiversity = dataset.select('constant'); var alosTopographicDiversityVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(-111.313, 39.724, 6); Map.addLayer(     alosTopographicDiversity, alosTopographicDiversityVis,     'ALOS Topographic Diversity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_SRTM_CHILI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_SRTM_CHILI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_SRTM_CHILI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_SRTM_CHILI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_SRTM_CHILI(example: str = ''):
        """
        CHILI is a surrogate for effects of insolation and topographic shading on evapotranspiration represented by calculating insolation at early afternoon, sun altitude equivalent to equinox. It is based on the 30m SRTM DEM (available in EE as USGS/SRTMGL1_003).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/SRTM_CHILI'); var srtmChili = dataset.select('constant'); var srtmChiliVis = {   min: 0.0,   max: 255.0, }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(srtmChili, srtmChiliVis, 'SRTM CHILI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_SRTM_landforms:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_SRTM_landforms'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_SRTM_landforms.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_SRTM_landforms.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_SRTM_landforms(example: str = ''):
        """
        The SRTM Landform dataset provides landform classes created by combining the Continuous Heat-Insolation Load Index (SRTM CHILI) and the multi-scale Topographic Position Index (SRTM mTPI) datasets. It is based on the 30m SRTM DEM (available in EE as USGS/SRTMGL1_003).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/SRTM_landforms'); var landforms = dataset.select('constant'); var landformsVis = {   min: 11.0,   max: 42.0,   palette: [     '141414', '383838', '808080', 'ebeb8f', 'f7d311', 'aa0000', 'd89382',     'ddc9c9', 'dccdce', '1c6330', '68aa63', 'b5c98e', 'e1f0e5', 'a975ba',     '6f198c'   ], }; Map.setCenter(-105.58, 40.5498, 11); Map.addLayer(landforms, landformsVis, 'Landforms'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_SRTM_mTPI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_SRTM_mTPI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_SRTM_mTPI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_SRTM_mTPI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_SRTM_mTPI(example: str = ''):
        """
        The mTPI distinguishes ridge from valley forms. It is calculated using elevation data for each location subtracted by the mean elevation within a neighborhood. mTPI uses moving windows of radius (km): 115.8, 89.9, 35.5, 13.1, 5.6, 2.8, and 1.2. It is based on the 30m SRTM DEM (available in EE as USGS/SRTMGL1_003).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/SRTM_mTPI'); var srtmMtpi = dataset.select('elevation'); var srtmMtpiVis = {   min: -200.0,   max: 200.0,   palette: ['0b1eff', '4be450', 'fffca4', 'ffa011', 'ff0000'], }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(srtmMtpi, srtmMtpiVis, 'SRTM mTPI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_Global_SRTM_topoDiversity:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_Global_SRTM_topoDiversity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_Global_SRTM_topoDiversity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_Global_SRTM_topoDiversity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_Global_SRTM_topoDiversity(example: str = ''):
        """
        Topographic diversity (D) is a surrogate variable that represents the variety of temperature and moisture conditions available to species as local habitats. It expresses the logic that a higher variety of topo-climate niches should support higher diversity (especially plant) and support species persistence given climatic change.  To calculate D, the multi-scale Topographic Position Index (mTPI), being a dominant control of soil moisture (T), was used for measuring hillslope position. The mTPI was combined with the square-root transform for mTPI>0 (T') and with the standard deviation of the Continuous Heat-Insolation Load Index (CHILI), calculated at multiple scales (C') as: D = 1 - ((1-T') * (1-C'). It is based on the 30m SRTM DEM (available in EE as USGS/SRTMGL1_003).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/Global/SRTM_topoDiversity'); var srtmTopographicDiversity = dataset.select('constant'); var srtmTopographicDiversityVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(-111.313, 39.724, 6); Map.addLayer(     srtmTopographicDiversity, srtmTopographicDiversityVis,     'SRTM Topographic Diversity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_CHILI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_CHILI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_CHILI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_CHILI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_CHILI(example: str = ''):
        """
        CHILI is a surrogate for effects of insolation and topographic shading on evapotranspiration represented by calculating insolation at early afternoon, sun altitude equivalent to equinox. It is based on the USGS's 10m NED DEM (available in EE as USGS/NED).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/CHILI'); var usChili = dataset.select('constant'); var usChiliVis = {   min: 0.0,   max: 255.0, }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(usChili, usChiliVis, 'US CHILI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_landforms:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_landforms'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_landforms.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_landforms.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_landforms(example: str = ''):
        """
        The ALOS Landform dataset provides landform classes created by combining the Continuous Heat-Insolation Load Index (CHILI) and the multi-scale Topographic Position Index (mTPI) datasets. It is based on the USGS's 10m NED DEM (available in EE as USGS/NED).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/landforms'); var landforms = dataset.select('constant'); var landformsVis = {   min: 11.0,   max: 42.0,   palette: [     '141414', '383838', '808080', 'ebeb8f', 'f7d311', 'aa0000', 'd89382',     'ddc9c9', 'dccdce', '1c6330', '68aa63', 'b5c98e', 'e1f0e5', 'a975ba',     '6f198c'   ], }; Map.setCenter(-105.58, 40.5498, 11); Map.addLayer(landforms, landformsVis, 'Landforms'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_lithology:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_lithology'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_lithology.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_lithology.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_lithology(example: str = ''):
        """
        The Lithology dataset provides classes of the general types of parent material of soil on the surface. It is not derived from any DEM.  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/lithology'); var lithology = dataset.select('b1'); var lithologyVis = {   min: 0.0,   max: 20.0,   palette: [     '356eff', 'acb6da', 'd6b879', '313131', 'eda800', '616161', 'd6d6d6',     'd0ddae', 'b8d279', 'd5d378', '141414', '6db155', '9b6d55', 'feeec9',     'd6b879', '00b7ec', 'ffda90', 'f8b28c'   ], }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(lithology, lithologyVis, 'Lithology'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_mTPI:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_mTPI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_mTPI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_mTPI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_mTPI(example: str = ''):
        """
        The mTPI distinguishes ridge from valley forms. It is calculated using elevation data for each location subtracted by the mean elevation within a neighborhood. mTPI uses moving windows of radius (km): 115.8, 89.9, 35.5, 13.1, 5.6, 2.8, and 1.2. It is based on the USGS's 10m NED DEM (available in EE as USGS/NED).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/mTPI'); var usMtpi = dataset.select('elevation'); var usMtpiVis = {   min: -200.0,   max: 200.0,   palette: ['0b1eff', '4be450', 'fffca4', 'ffa011', 'ff0000'], }; Map.setCenter(-105.8636, 40.3439, 11); Map.addLayer(usMtpi, usMtpiVis, 'US mTPI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_physioDiversity:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_physioDiversity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_physioDiversity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_physioDiversity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_physioDiversity(example: str = ''):
        """
        The Physiographic Diversity dataset provides an index of the diversity of physiographic types. It was calculated using the Shannon diversity index at multiple-scales (km): 115.8, 89.9, 35.5, 13.1, 5.6, 2.8, and 1.2. It is based on the USGS's 10m NED DEM (available in EE as USGS/NED).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/physioDiversity'); var physiographicDiversity = dataset.select('b1'); var physiographicDiversityVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(-94.625, 39.825, 7); Map.addLayer(     physiographicDiversity, physiographicDiversityVis,     'Physiographic Diversity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_physiography:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_physiography'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_physiography.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_physiography.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_physiography(example: str = ''):
        """
        The Physiography dataset represents the spatial intersection of landforms (available in EE as ERGo/1_0/US/landforms) and lithology (available in EE as ERGo/1_0/US/lithology) data layers. It provides 247 unique combinations out of a possible 270. The values for each type are formed by concatenating the landform and lithology types (e.g., 1101 is \"Peak/ridge\" landform on \"carbonate\" lithology). This data layer is sometimes referred to as characterizing \"land facets\".  The landforms layer is based on the USGS's 10m NED DEM (available in EE as USGS/NED). The lithology layer is not basen on any DEM.  This dataset is provided just for the US, because of the availability of the lithology data layer, though these data are likely available for other countries. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/physiography'); var physiography = dataset.select('constant'); var physiographyVis = {   min: 1100.0,   max: 4220.0, }; Map.setCenter(-105.4248, 40.5242, 8); Map.addLayer(physiography, physiographyVis, 'Physiography'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_ERGo_1_0_US_topoDiversity:
    def __init__(self,):
        self.sensor = 'CSP_ERGo_1_0_US_topoDiversity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_ERGo_1_0_US_topoDiversity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_ERGo_1_0_US_topoDiversity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_ERGo_1_0_US_topoDiversity(example: str = ''):
        """
        Topographic diversity (D) is a surrogate variable that represents the variety of temperature and moisture conditions available to species as local habitats. It expresses the logic that a higher variety of topo-climate niches should support higher diversity (especially plant) and support species persistence given climatic change.  To calculate D, the multi-scale Topographic Position Index (mTPI), being a dominant control of soil moisture (T), was used for measuring hillslope position. The mTPI was combined with the square-root transform for mTPI>0 (T') and with the standard deviation of the Continuous Heat-Insolation Load Index (CHILI), calculated at multiple scales (C') as: D = 1 - ((1-T') * (1-C'). It is based on the USGS's 10m NED DEM (available in EE as USGS/NED).  The Conservation Science Partners (CSP) Ecologically Relevant Geomorphology (ERGo) Datasets, Landforms and Physiography contain detailed, multi-scale data on landforms and physiographic (aka land facet) patterns. Although there are many potential uses of these data, the original purpose for these data was to develop an ecologically relevant classification and map of landforms and physiographic classes that are suitable for climate adaptation planning. Because there is large uncertainty associated with future climate conditions and even more uncertainty around ecological responses, providing information about what is unlikely to change offers a strong foundation for managers to build robust climate adaptation plans. The quantification of these features of the landscape is sensitive to the resolution, so we provide the highest resolution possible given the extent and characteristics of a given index. 
        :param example: var dataset = ee.Image('CSP/ERGo/1_0/US/topoDiversity'); var usTopographicDiversity = dataset.select('constant'); var usTopographicDiversityVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(-111.313, 39.724, 6); Map.addLayer(     usTopographicDiversity, usTopographicDiversityVis,     'US Topographic Diversity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class CSP_HM_GlobalHumanModification:
    def __init__(self,):
        self.sensor = 'CSP_HM_GlobalHumanModification'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/CSP_HM_GlobalHumanModification.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/CSP_HM_GlobalHumanModification.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_CSP_HM_GlobalHumanModification(example: str = ''):
        """
        The global Human Modification dataset (gHM) provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or "stressor". 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets:  * human settlement (population density, built-up areas) * agriculture (cropland, livestock) * transportation (major, minor, and two-track roads; railroads) * mining and energy production * electrical infrastructure (power lines, nighttime lights)  Please see the paper for additional methodological details. This asset was re-projected to WGS84 for use in Earth Engine. 
        :param example: var dataset = ee.ImageCollection('CSP/HM/GlobalHumanModification');  var visualization = {   bands: ['gHM'],   min: 0.0,   max: 1.0,   palette: ['0c0c0c', '071aff', 'ff0000', 'ffbd03', 'fbff05', 'fffdfd'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Human modification'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class DLR_WSF_WSF2015_v1:
    def __init__(self,):
        self.sensor = 'DLR_WSF_WSF2015_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/DLR_WSF_WSF2015_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/DLR_WSF_WSF2015_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_DLR_WSF_WSF2015_v1(example: str = ''):
        """
        The World Settlement Footprint (WSF) 2015 is a 10m resolution binary mask outlining the extent of human settlements globally derived by means of 2014-2015 multitemporal Landsat-8 and Sentinel-1 imagery (of which ~217,000 and ~107,000 scenes have been processed, respectively).  The temporal dynamics of human settlements over time are sensibly different than those of all other non-settlement information classes. Hence, given all the multitemporal images available over a region of interest in the selected time interval, key temporal statistics (i.e., temporal mean, minimum, maximum, etc.) are extracted for:  * the original backscattering value in the case of radar data; and *  different spectral indices (e.g., vegetation index, built-up index, etc.) derived after performing cloud masking in the case of optical imagery.  Next, different classification schemes based on Support Vector Machines (SVMs) are separately applied to the optical and radar temporal features, respectively, and, finally, the two outputs are properly combined together.  To quantitatively assess the high accuracy and reliability of the layer, an extensive validation exercise has been carried out in collaboration with Google based on a huge amount of ground-truth samples (i.e., 900,000) labeled by crow-sourcing photo-interpretation. A statistically robust and transparent protocol has been defined following the state-of-the-art practices currently recommended in the literature.  For all technical details, please refer to [the publication](https://www.nature.com/articles/s41597-020-00580-5) 
        :param example: var dataset = ee.Image('DLR/WSF/WSF2015/v1');  var opacity = 0.75; var blackBackground = ee.Image(0); Map.addLayer(blackBackground, null, 'Black background', true, opacity);  var visualization = {   min: 0,   max: 255, }; Map.addLayer(dataset, visualization, 'Human settlement areas');  Map.setCenter(90.45, 23.7, 7); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class DOE_ORNL_LandScan_HD_Ukraine_202201:
    def __init__(self,):
        self.sensor = 'DOE_ORNL_LandScan_HD_Ukraine_202201'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/DOE_ORNL_LandScan_HD_Ukraine_202201.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/DOE_ORNL_LandScan_HD_Ukraine_202201.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_DOE_ORNL_LandScan_HD_Ukraine_202201(example: str = ''):
        """
        [LandScan High Definition (HD)](https://landscan.ornl.gov) provides gridded population estimates at 3 arc-second (~100m) resolution. Values for each LandScan HD cell represent an ambient (i.e. 24 hour average) population count estimate.  In this way, the data capture the full potential activity space of people throughout the course of the day and night rather than just a residential location. The LandScan HD model incorporates current land use and infrastructure data from a variety of sources, applies facility occupancy estimates from ORNL's Population Density Tables (PDT) project, and leverages novel image processing algorithms developed at ORNL to rapidly map building structures and neighborhood areas using high-performance computing environments.  The source for subnational population counts used in the development of this data comes from [State Statistics Service of Ukraine](https://ukrstat.org/en/operativ/operativ2021/ds/kn/arh_kn2021_e.html).  These subnational estimates were adjusted to the country total population provided by the [CIA World Factbook](https://www.cia.gov/the-world-factbook/countries/ukraine/#people-and-society). 
        :param example: var dataset = ee.Image('DOE/ORNL/LandScan_HD/Ukraine_202201'); var vis = {   min: 0.0,   max: 10.0,   palette: ['lemonchiffon', 'khaki', 'orange', 'orangered', 'red', 'maroon'], }; Map.centerObject(dataset); Map.addLayer(dataset, vis, 'Population Count'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_CAMS_NRT:
    def __init__(self,):
        self.sensor = 'ECMWF_CAMS_NRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_CAMS_NRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_CAMS_NRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_CAMS_NRT(example: str = ''):
        """
        The Copernicus Atmosphere Monitoring Service provides the capacity to continuously monitor the composition of the Earth's atmosphere at global and regional scales. The main global near-real-time production system is a data assimilation and forecasting suite providing two 5-day forecasts per day for aerosols and chemical compounds that are part of the chemical scheme.  Prior to 2021-07-01 only two parameters were available, 1. Total Aerosol Optical Depth at 550 nm surface 2. Particulate matter d < 25 um surface Note that system:time_start refers to forecast time. 
        :param example: // Get data generated from model hour 0 for January 1st, 2019. var dataset = ee.ImageCollection('ECMWF/CAMS/NRT')                   .filterDate('2019-01-01', '2019-01-02')                   .filter('model_initialization_hour == 0');  // Select first and last forecast hours. var hour00 = dataset.filter('model_forecast_hour == 0').first(); var hour21 = dataset.filter('model_forecast_hour == 21').first();  // Visualization parameters for specified aerosol band. var visParams = {   bands: ['total_aerosol_optical_depth_at_550nm_surface'],   min: 0.0,   max: 3.6,   palette: [     '5e4fa2', '3288bd', '66c2a5', 'abe0a4', 'e6f598', 'ffffbf',     'fee08b', 'fdae61', 'f46d43', 'd53e4f', '9e0142'   ] };  // Display forecasts on the map. Map.setCenter(70, 45, 3); Map.addLayer(hour00, visParams, 'Total Aerosal Optical Depth - H00', true, 0.8); Map.addLayer(hour21, visParams, 'Total Aerosal Optical Depth - H21', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_DAILY:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_DAILY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_DAILY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_DAILY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_DAILY(example: str = ''):
        """
        ERA5 is the fifth generation ECMWF atmospheric reanalysis of the global climate. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset. ERA5 replaces its predecessor, the ERA-Interim reanalysis.  ERA5 DAILY provides aggregated values for each day for seven ERA5 climate reanalysis parameters: 2m air temperature, 2m dewpoint temperature, total precipitation, mean sea level pressure, surface pressure, 10m u-component of wind and 10m v-component of wind. Additionally, daily minimum and maximum air temperature at 2m has been calculated based on the hourly 2m air temperature data. Daily total precipitation values are given as daily sums. All other parameters are provided as daily averages.  ERA5 data is available from 1979 to three months from real-time. More information and more ERA5 atmospheric parameters can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu).  Provider's Note: Daily aggregates have been calculated based on the ERA5 hourly values of each parameter. 
        :param example: // Example script to load and visualize ERA5 climate reanalysis parameters in // Google Earth Engine  // Daily mean 2m air temperature var era5_2mt = ee.ImageCollection('ECMWF/ERA5/DAILY')                    .select('mean_2m_air_temperature')                    .filter(ee.Filter.date('2019-07-01', '2019-07-31')); print(era5_2mt);  // Daily total precipitation sums var era5_tp = ee.ImageCollection('ECMWF/ERA5/DAILY')                   .select('total_precipitation')                   .filter(ee.Filter.date('2019-07-01', '2019-07-31'));  // Daily mean 2m dewpoint temperature var era5_2d = ee.ImageCollection('ECMWF/ERA5/DAILY')                   .select('dewpoint_2m_temperature')                   .filter(ee.Filter.date('2019-07-01', '2019-07-31'));  // Daily mean sea-level pressure var era5_mslp = ee.ImageCollection('ECMWF/ERA5/DAILY')                     .select('mean_sea_level_pressure')                     .filter(ee.Filter.date('2019-07-01', '2019-07-31'));  // Daily mean surface pressure var era5_sp = ee.ImageCollection('ECMWF/ERA5/DAILY')                   .select('surface_pressure')                   .filter(ee.Filter.date('2019-07-01', '2019-07-31'));  // Daily mean 10m u-component of wind var era5_u_wind_10m = ee.ImageCollection('ECMWF/ERA5/DAILY')                           .select('u_component_of_wind_10m')                           .filter(ee.Filter.date('2019-07-01', '2019-07-31'));  // Convert pressure levels from Pa to hPa - Example for surface pressure var era5_sp = era5_sp.map(function(image) {   return image.divide(100).set(       'system:time_start', image.get('system:time_start')); });  // Visualization palette for total precipitation var visTp = {   min: 0.0,   max: 0.1,   palette: ['ffffff', '00ffff', '0080ff', 'da00ff', 'ffa400', 'ff0000'] };  // Visualization palette for temperature (mean, min and max) and 2m dewpoint // temperature var vis2mt = {   min: 250,   max: 320,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff', '00ff80',     '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00', 'ffb000', 'ffa400',     'ff4f00', 'ff2500', 'ff0a00', 'ff00ff'   ] };  // Visualization palette for u- and v-component of 10m wind var visWind = {   min: 0,   max: 30,   palette: [     'ffffff', 'ffff71', 'deff00', '9eff00', '77b038', '007e55', '005f51',     '004b51', '013a7b', '023aad'   ] };  // Visualization palette for pressure (surface pressure, mean sea level // pressure) - adjust min and max values for mslp to min:990 and max:1050 var visPressure = {   min: 500,   max: 1150,   palette: [     '01ffff', '058bff', '0600ff', 'df00ff', 'ff00ff', 'ff8c00', 'ff8c00'   ] };   // Add layer to map Map.addLayer(     era5_tp.filter(ee.Filter.date('2019-07-15')), visTp,     'Daily total precipitation sums'); Map.addLayer(     era5_2d.filter(ee.Filter.date('2019-07-15')), vis2mt,     'Daily mean 2m dewpoint temperature'); Map.addLayer(     era5_2mt.filter(ee.Filter.date('2019-07-15')), vis2mt,     'Daily mean 2m air temperature'); Map.addLayer(     era5_u_wind_10m.filter(ee.Filter.date('2019-07-15')), visWind,     'Daily mean 10m u-component of wind'); Map.addLayer(     era5_sp.filter(ee.Filter.date('2019-07-15')), visPressure,     'Daily mean surface pressure');  Map.setCenter(21.2, 22.2, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_DAILY_AGGR:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_DAILY_AGGR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_DAILY_AGGR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_DAILY_AGGR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_DAILY_AGGR(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  The asset is a daily aggregate of ECMWF ERA5 Land hourly assets which includes both flow and non-flow bands. Flow bands are formed by collecting the first hour's data of the following day which holds aggregated sum of previous day and while the non-flow bands are created by averaging all hourly data of the day. The flow bands are labeled with the "_sum" identifier, which approach is different from the daily data produced by Copernicus Climate Data Store, where flow bands are averaged too.  Daily aggregates have been pre-calculated to facilitate many applications requiring easy and fast access to the data.  ERA5-Land daily aggregated data is available from 1950 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu).  Precipitation and other flow (accumulated) bands might occasionally have negative values, which doesn't make physical sense. At other times their values might be excessively high.  This problem is due to how the GRIB format saves data: it simplifies or "packs" the data into smaller, less precise numbers, which can introduce errors. These errors get worse when the data varies a lot.  Because of this, when we look at the data for a whole day to compute daily totals, sometimes the highest amount of rainfall recorded at one time can seem larger than the total rainfall measured for the entire day.  To learn more, Please see: ["Why are there sometimes small negative precipitation accumulations"](https://confluence.ecmwf.int/display/UDOC/Why+are+there+sometimes+small+negative+precipitation+accumulations+-+ecCodes+GRIB+FAQ)
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').first();  var visualization = {   bands: ['temperature_2m'],   min: 250,   max: 320,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] }; Map.setCenter(70, 45, 3); Map.addLayer(     dataset, visualization, 'Air temperature (K) at 2m height', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_DAILY_RAW:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_DAILY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_DAILY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_DAILY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_DAILY_RAW(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  The asset is a daily aggregate of ECMWF ERA5 Land hourly assets which includes both flow and non-flow bands. Flow bands are formed by collecting the first hour's data of the following day which holds aggregated sum of previous day and while the non-flow bands are created by averaging all hourly data of the day. The flow bands are labeled with the "_sum" identifier, which approach is different from the daily data produced by Copernicus Climate Data Store, where flow bands are averaged too.  Daily aggregates have been pre-calculated to facilitate many applications requiring easy and fast access to the data.  ERA5-Land daily aggregated data is available from july 1963 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_HOURLY:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_HOURLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_HOURLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_HOURLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_HOURLY(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  Please note that the convention for accumulations used in ERA5-Land differs with that for ERA5. The accumulations are treated the same as those in ERA-Interim or ERA-Interim/Land, i.e., they are accumulated from the beginning of the forecast to the end of the forecast step. This happens within every day and gets reset on midnight. The Earth Engine Data team added 19 additional bands, one for each of the accumulation bands, with the hourly values computed as the difference between two consecutive forecast steps.  ERA5-Land data is available from 1950 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview). 
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY')                 .filter(ee.Filter.date('2020-07-01', '2020-07-02'));  var visualization = {   bands: ['temperature_2m'],   min: 250.0,   max: 320.0,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(22.2, 21.2, 0);  Map.addLayer(dataset, visualization, 'Air temperature [K] at 2m height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_MONTHLY:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_MONTHLY(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  The data presented here is a subset of the full ERA5-Land dataset post-processed by ECMWF. Monthly-mean averages have been pre-calculated to facilitate many applications requiring easy and fast access to the data, when sub-monthly fields are not required.  ERA5-Land data is available from 1950 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=overview). 
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5_LAND/MONTHLY')                 .filter(ee.Filter.date('2020-07-01', '2020-08-01'));  var visualization = {   bands: ['temperature_2m'],   min: 250.0,   max: 320.0,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(22.2, 21.2, 0);  Map.addLayer(dataset, visualization, 'Air temperature [K] at 2m height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_MONTHLY_AGGR:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_MONTHLY_AGGR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_MONTHLY_AGGR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_MONTHLY_AGGR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_MONTHLY_AGGR(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  The asset is a monthly aggregate of ECMWF ERA5 Land hourly assets which includes both flow and non-flow bands. Flow bands are formed by collecting the first hour's data of the following day for each day of the month and then adding them together, while the non-flow bands are created by averaging all hourly data of the month. The flow bands are labeled with the "_sum" identifier, which approach is different from the monthly data produced by Copernicus Climate Data Store, where flow bands are averaged too.  Monthly aggregates have been pre-calculated to facilitate many applications requiring easy and fast access to the data, when sub-monthly fields are not required.  ERA5-Land monthly aggregated data is available from 1950 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu).  Precipitation and other flow (accumulated) bands might occasionally have negative values, which doesn't make physical sense. At other times their values might be excessively high.  This problem is due to how the GRIB format saves data: it simplifies or "packs" the data into smaller, less precise numbers, which can introduce errors. These errors get worse when the data varies a lot.  Because of this, when we look at the data for a whole day to compute daily totals, sometimes the highest amount of rainfall recorded at one time can seem larger than the total rainfall measured for the entire day.  To learn more, Please see: ["Why are there sometimes small negative precipitation accumulations"](https://confluence.ecmwf.int/display/UDOC/Why+are+there+sometimes+small+negative+precipitation+accumulations+-+ecCodes+GRIB+FAQ)
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5_LAND/MONTHLY_AGGR').first();  var visualization = {   bands: ['temperature_2m'],   min: 250,   max: 320,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(70, 45, 3); Map.addLayer(     dataset, visualization, 'Air temperature [K] at 2m height', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_LAND_MONTHLY_BY_HOUR:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_LAND_MONTHLY_BY_HOUR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_LAND_MONTHLY_BY_HOUR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_LAND_MONTHLY_BY_HOUR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_LAND_MONTHLY_BY_HOUR(example: str = ''):
        """
        ERA5-Land is a reanalysis dataset providing a consistent view of the evolution of land variables over several decades at an enhanced resolution compared to ERA5. ERA5-Land has been produced by replaying the land component of the ECMWF ERA5 climate reanalysis. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset using the laws of physics. Reanalysis produces data that goes several decades back in time, providing an accurate description of the climate of the past. This dataset includes all 50 variables as available on CDS.  The data presented here is a subset of the full ERA5-Land dataset post-processed by ECMWF. Monthly-mean averages have been pre-calculated to facilitate many applications requiring easy and fast access to the data, when sub-monthly fields are not required.  Please note that the convention for accumulations used in ERA5-Land differs with that for ERA5. The accumulations are treated the same as those in ERA-Interim or ERA-Interim/Land, i.e., they are accumulated from the beginning of the forecast to the end of the forecast step. This happens within every day and gets reset on midnight. The Earth Engine Data team added 19 additional bands, one for each of the accumulation bands, with the hourly values computed as the difference between two consecutive forecast steps.  ERA5-Land data is available from 1950 to three months from real-time. More information can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu). 
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5_LAND/MONTHLY_BY_HOUR')                 .filter(ee.Filter.date('2020-07-01', '2020-08-01'));  var visualization = {   bands: ['temperature_2m'],   min: 250.0,   max: 320.0,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(22.2, 21.2, 0);  Map.addLayer(dataset, visualization, 'Air temperature [K] at 2m height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ECMWF_ERA5_MONTHLY:
    def __init__(self,):
        self.sensor = 'ECMWF_ERA5_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ECMWF_ERA5_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ECMWF_ERA5_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ECMWF_ERA5_MONTHLY(example: str = ''):
        """
        ERA5 is the fifth generation ECMWF atmospheric reanalysis of the global climate. Reanalysis combines model data with observations from across the world into a globally complete and consistent dataset. ERA5 replaces its predecessor, the ERA-Interim reanalysis.  ERA5 MONTHLY provides aggregated values for each month for seven ERA5 climate reanalysis  parameters: 2m air temperature, 2m dewpoint temperature, total precipitation, mean sea level pressure, surface pressure, 10m u-component of wind and 10m v-component of wind. Additionally, monthly minimum and maximum air temperature at 2m has been calculated based on the hourly 2m air temperature data. Monthly total precipitation values are given as monthly sums. All other parameters are provided as monthly averages.  ERA5 data is available from 1940 to three months from real-time, the version in the EE Data Catalog is available from 1979. More information and more ERA5 atmospheric parameters can be found at the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means?tab=overview).  Provider's Note: Monthly aggregates have been calculated based on the ERA5 hourly values of each parameter. 
        :param example: var dataset = ee.ImageCollection('ECMWF/ERA5/MONTHLY');  var visualization = {   bands: ['mean_2m_air_temperature'],   min: 250.0,   max: 320.0,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(22.2, 21.2, 0);  Map.addLayer(dataset, visualization, 'Monthly average air temperature [K] at 2m height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class EDF_MethaneSAT_MethaneAIR_methaneair_L4area_2021:
    def __init__(self,):
        self.sensor = 'EDF_MethaneSAT_MethaneAIR_methaneair_L4area_2021'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EDF_MethaneSAT_MethaneAIR_methaneair-L4area-2021.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EDF_MethaneSAT_MethaneAIR_methaneair-L4area-2021.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EDF_MethaneSAT_MethaneAIR_methaneair_L4area_2021(example: str = ''):
        """
        **The area emissions model is still in development and not representative of a final product.**  This dataset provides high-resolution, spatially disaggregated methane emission fluxes (kg/hr) of the Permian Delaware sub-basin in southern New Mexico and western Texas as well as for the Uinta basin in Utah.  Methane is a potent greenhouse gas that has more than 80 times the warming power of carbon dioxide over the first 20 years after it reaches the atmosphere. At least 30% of today's global warming is driven by methane from human actions. Cutting methane emissions associated with human activities - including avoidable emissions from oil and gas operations, agriculture, and waste management - is the single fastest way to slow the rate of global warming.  This dataset was generated using MethaneAIR measurements taken on 8 August 2021 (research flight RF06) over the Permian and 11 August 2021 (RF08) over Uinta. MethaneAIR is an airborne precursor of the MethaneSAT satellite mission, managed by [MethaneSAT LLC](https://www.methanesat.org/), a wholly owned subsidiary of Environmental Defense Fund. The methane emission fluxes were produced using a geostatistical inverse modeling framework specialized to exploit the high spatial resolution, wide spatial coverage, and high precision of MethaneAIR data.  For additional information about the MethaneAIR instrument, instrument calibration and emission detections, please refer to recent publications by [Staebell et al. (2021)](https://doi.org/10.5194/amt-14-3737-2021), [Conway et al. (2023)](https://doi.org/10.5194/amt-2023-111), [Chulakadabba et al. (2023)](https://doi.org/10.5194/egusphere-2023-822), [Abbadi et al. (2023)](https://doi.org/10.31223/X51D4C), [Omara et al. (2023)](https://doi.org/10.5194/essd-15-3761-2023), and [Miller et al. (2023)](https://doi.org/10.5194/egusphere-2023-1962).  Contact the data provider for more information about the project at this link: [https://www.methanesat.org/contact/](https://www.methanesat.org/contact/) 
        :param example: var dataset = ee.Image("EDF/MethaneSAT/MethaneAIR/methaneair-L4area-2021");  var fluxVisParams = {   min: 0,   max: 24,   palette: ['#070088','#a3069b','#cc4e64','#ffa826','#edfb59'], };  // Center on one of the two available areas of interests. // Map.setCenter(-109.6, 40, 9) Map.setCenter(-103.71, 31.96, 9); Map.addLayer(dataset, fluxVisParams, 'Methane area sources flux');
        :return: None
        """
        return None
        

@geeData_registery.add()
class EDF_MethaneSAT_MethaneAIR_methaneair_L4point_2021:
    def __init__(self,):
        self.sensor = 'EDF_MethaneSAT_MethaneAIR_methaneair_L4point_2021'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EDF_MethaneSAT_MethaneAIR_methaneair-L4point-2021.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EDF_MethaneSAT_MethaneAIR_methaneair-L4point-2021.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EDF_MethaneSAT_MethaneAIR_methaneair_L4point_2021(example: str = ''):
        """
        This dataset provides high-emitting methane point source detections (kg/hr) over the Permian Delaware sub-basin in southern New Mexico and western Texas as well as for the Uinta basin in Utah.  Methane is a potent greenhouse gas that has more than 80 times the warming power of carbon dioxide over the first 20 years after it reaches the atmosphere. At least 30% of today's global warming is driven by methane from human actions. Cutting methane emissions associated with human activities - including avoidable emissions from oil and gas operations, agriculture, and waste management - is the single fastest way to slow the rate of global warming.  This dataset was generated using MethaneAIR measurements taken on 8 August 2021 (research flight RF06) over the Permian and 11 August 2021 (RF08) over Uinta. MethaneAIR is an airborne precursor of the MethaneSAT satellite mission, managed by [MethaneSAT LLC](https://www.methanesat.org/), a wholly owned subsidiary of Environmental Defense Fund.  For additional information about the MethaneAIR instrument, instrument calibration and emission detections, please refer to recent publications by [Staebell et al. (2021)](https://doi.org/10.5194/amt-14-3737-2021), [Conway et al. (2023)](https://doi.org/10.5194/amt-2023-111), [Chulakadabba et al. (2023)](https://doi.org/10.5194/egusphere-2023-822), [Abbadi et al. (2023)](https://doi.org/10.31223/X51D4C), [Omara et al. (2023)](https://doi.org/10.5194/essd-15-3761-2023), and [Miller et al. (2023)](https://doi.org/10.5194/egusphere-2023-1962).  Contact the data provider for more information about the project at this link: [https://www.methanesat.org/contact/](https://www.methanesat.org/contact/) 
        :param example: var dataset = ee.FeatureCollection("EDF/MethaneSAT/MethaneAIR/methaneair-L4point-2021");  // Add a `style` property with `pointSize` dependent on flux value. dataset = dataset.map(function(feature) {     var size = ee.Number(feature.get('Flux_kg_hr')).divide(150);     return feature.set('style', { pointSize: size, color: 'red'});   }); var datasetVis = dataset.style({styleProperty: 'style'});  // Center on one of the two available areas of interests. // Map.setCenter(-109.6, 40, 9) Map.setCenter(-103.71, 31.96, 9); Map.addLayer(datasetVis, null, 'Methane point sources flux in kg/h');
        :return: None
        """
        return None
        

@geeData_registery.add()
class EDF_OGIM_OGIM_v2_4_RF06_RF08:
    def __init__(self,):
        self.sensor = 'EDF_OGIM_OGIM_v2_4_RF06_RF08'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EDF_OGIM_OGIM_v2-4_RF06_RF08.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EDF_OGIM_OGIM_v2-4_RF06_RF08.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EDF_OGIM_OGIM_v2_4_RF06_RF08(example: str = ''):
        """
        This dataset provides the locations of oil and gas (O&G) related infrastructure within two key O&G producing regions in the United States: the Delaware sub-basin of the Permian Basin in western Texas and southern New Mexico, and the Uinta Basin in Utah.  The Oil and Gas Infrastructure Mapping (OGIM) database is a project developed by the Environmental Defense Fund (EDF) and [MethaneSAT LLC](https://www.methanesat.org/), a wholly-owned subsidiary of EDF. The primary objective of developing a standardized O&G infrastructure database such as OGIM is to support MethaneSAT's emission quantification, source characterization, and other scientific- or advocacy-relevant analyses of methane emissions from the oil and gas sector. The OGIM database is developed based on the acquisition, analysis, and quality assurance of publicly available geospatial data sources of O&G facilities, which are combined within one standard data schema and coordinate reference system.  This dataset contains the spatial locations of the following types of infrastructure assets:  * oil and gas wells, * natural gas compressor stations, * gathering and processing facilities, * petroleum terminals, * oil and gas pipelines, * satellite detections of oil and gas flares, * and "other" oil and gas related infrastructure, such as metering stations.  Records in the OGIM are consolidated from numerous publicly-available governmental and academic sources, including:  * [Homeland Infrastructure Foundation-Level Data (HIFLD)](https://hifld-geoplatform.hub.arcgis.com/pages/hifld-open) * [EPA Facility Level Information on Greenhouse Gases Tool (FLIGHT)](https://ghgdata.epa.gov/ghgp/main.do) * [Texas Railroad Commission (RRC)](https://www.rrc.texas.gov/resource-center/research/data-sets-available-for-download/) * [New Mexico Energy Minerals, and Natural Resources Department (EMNRD)](https://ocd-hub-nm-emnrd.hub.arcgis.com/datasets/dd971b8e25c54d1a8ab7c549244cf3cc_0/about) * [Utah Geospatial Resource Center (UGRC)](https://gis.utah.gov/data/energy/oil-gas/) * [Earth Observation Group (EOG) at the Colorado School of Mines](https://eogdata.mines.edu/products/vnf/global_gas_flare.html) * [Marchese et al, 2015](https://doi.org/10.1021/acs.est.5b02275)  The O&G facilities in this dataset are spatially coincident with the extent of MethaneAIR measurements taken on 8 August 2021 (research flight RF06) over the Permian Basin and 11 August 2021 (research flight RF08) over the Uinta Basin. MethaneAIR is an airborne precursor of the MethaneSAT satellite mission, managed by MethaneSAT LLC. Only O&G facilities found within the RF06 or RF08 region of interest are included in this data release.  Important notes about the attributes associated with these facility locations:  - Missing values (i.e., values missing or not reported by the original data source) are handled by assigning "N/A" to string attributes, -999 to numerical attributes, and a generic date of "1900-01-01" to date/datetime attributes.  - Facility operator names have not been altered in any way from the original source of data and are assumed to be accurate as of the original source's publication date.  For more information about the OGIM database, including methods used in its development and key applications of the database, please refer to the recent publication by [Omara et al, 2023](https://doi.org/10.5194/essd-15-3761-2023).  Contact the data provider for more information about the project at this link: [https://www.methanesat.org/contact/](https://www.methanesat.org/contact/) 
        :param example: var dataset = ee.FeatureCollection("EDF/OGIM/OGIM_v2-4_RF06_RF08");  var datasetVis = dataset.style({   color: 'black',   pointSize: 3, });  // Center on one of the two available areas of interests. // Map.setCenter(-109.6, 40, 9); Map.setCenter(-103.71, 31.96, 9); Map.setOptions("SATELLITE"); Map.addLayer(datasetVis, {}, 'oil and gas infrastructure') 
        :return: None
        """
        return None
        

@geeData_registery.add()
class EO1_HYPERION:
    def __init__(self,):
        self.sensor = 'EO1_HYPERION'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EO1_HYPERION.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EO1_HYPERION.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EO1_HYPERION(example: str = ''):
        """
        Hyperion is a high resolution hyperspectral imager producing 220 unique spectral channels ranging from 0.357 to 2.576 micrometers with a 10-nm bandwidth. The instrument operates in a pushbroom fashion, with a spatial resolution of 30 meters for all bands and a standard scene width of 7.7 kilometers.  This dataset contains level 1A radiance images, radiometrically calibrated and orthorectified. The SWIR bands have a scaling factor of 80 and the VNIR bands have a scaling factor of 40 applied.  - VNIR bands (B008-B057, 426.82nm - 925.41nm): L = Digital Number / 40  - SWIR bands (B077-B224, 912.45nm - 2395.50nm): L = Digital Number / 80  Note that bands B001-B007, B058-B076, and B225-242 are not calibrated, have no valid values and are not included into EE assets. See the [detailed spectral coverage information](https://doi.org/10.5066/P9JXHMO2).  This is a preview dataset; only a portion of the data from the original source have been downloaded. 
        :param example: var dataset = ee.ImageCollection('EO1/HYPERION')                   .filter(ee.Filter.date('2016-01-01', '2017-03-01')); var rgb = dataset.select(['B050', 'B023', 'B015']); var rgbVis = {   min: 1000.0,   max: 14000.0,   gamma: 2.5, }; Map.setCenter(162.0044, -77.3463, 9); Map.addLayer(rgb.median(), rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class EPA_Ecoregions_2013_L3:
    def __init__(self,):
        self.sensor = 'EPA_Ecoregions_2013_L3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EPA_Ecoregions_2013_L3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EPA_Ecoregions_2013_L3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EPA_Ecoregions_2013_L3(example: str = ''):
        """
        The U.S. Environmental Protection Agency (USEPA) provides the Ecoregions dataset to serve as a spatial framework for the research, assessment, management, and monitoring of ecosystems and ecosystem components. Ecoregions denote areas of general similarity in ecosystems and in the type, quality, and quantity of environmental resources. These general-purpose regions are critical for structuring and implementing ecosystem management strategies across federal agencies, state agencies, and nongovernmental organizations that are responsible for different types of resources within the same geographical areas.  The approach used to compile this map is based on the premise that ecological regions can be identified through the analysis of patterns of biotic and abiotic phenomena, including geology, physiography, vegetation, climate, soils, land use, wildlife, and hydrology. The relative importance of each characteristic varies from one ecological region to another.  This dataset includes the USEPA ecoregions classification scheme, as well as the scheme from the Commission for Environmental Cooperation (CEC). Ecoregions are hierarchical, with Level IV being the most detailed and Level I defining the broadest classifications. Because of this hierarchy, Level III features retain information from Levels I and II. The CEC divided all of North America in distinct ecoregions for Levels I, II, and III, while the USEPA did so only for the United States at Level III and Level IV. The columns starting with 'us_' belong to the USEPA scheme, and the columns starting with 'na_' belong to the CEC scheme. The ingested version of this dataset contains features for the conterminous United States only (that is, Alaska and Hawaii are not included). Methods used to define the ecoregions are explained in Omernik (1995, 2004), Omernik and others (2000), and Gallant and others (1989).  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('EPA/Ecoregions/2013/L3'); var visParams = {   palette: ['0a3b04', '1a9924', '15d812'],   min: 23.0,   max: 3.57e+11,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'shape_area'); Map.setCenter(-99.814, 40.166, 5); Map.addLayer(image, visParams, 'EPA/Ecoregions/2013/L3'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class EPA_Ecoregions_2013_L4:
    def __init__(self,):
        self.sensor = 'EPA_Ecoregions_2013_L4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/EPA_Ecoregions_2013_L4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/EPA_Ecoregions_2013_L4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_EPA_Ecoregions_2013_L4(example: str = ''):
        """
        The U.S. Environmental Protection Agency (USEPA) provides the Ecoregions dataset to serve as a spatial framework for the research, assessment, management, and monitoring of ecosystems and ecosystem components. Ecoregions denote areas of general similarity in ecosystems and in the type, quality, and quantity of environmental resources. These general-purpose regions are critical for structuring and implementing ecosystem management strategies across federal agencies, state agencies, and nongovernmental organizations that are responsible for different types of resources within the same geographical areas.  The approach used to compile this map is based on the premise that ecological regions can be identified through the analysis of patterns of biotic and abiotic phenomena, including geology, physiography, vegetation, climate, soils, land use, wildlife, and hydrology. The relative importance of each characteristic varies from one ecological region to another.  This dataset includes the USEPA ecoregions classification scheme, as well as the scheme from the Commission for Environmental Cooperation (CEC). Ecoregions are hierarchical, with Level IV being the most detailed and Level I defining the broadest classifications. Because of this hierarchy, Level III features retain information from Levels I and II. The CEC divided all of North America in distinct ecoregions for Levels I, II, and III, while the USEPA did so only for the United States at Level III and Level IV. The columns starting with 'us_' belong to the USEPA scheme, and the columns starting with 'na_' belong to the CEC scheme. The ingested version of this dataset contains features for the conterminous United States only (that is, Alaska and Hawaii are not included). Methods used to define the ecoregions are explained in Omernik (1995, 2004), Omernik and others (2000), and Gallant and others (1989).  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('EPA/Ecoregions/2013/L4'); var visParams = {   palette: ['0a3b04', '1a9924', '15d812'],   min: 0.0,   max: 67800000000.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'shape_area'); Map.setCenter(-99.814, 40.166, 5); Map.addLayer(image, visParams, 'EPA/Ecoregions/2013/L4'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_CCI_FireCCI_5_1:
    def __init__(self,):
        self.sensor = 'ESA_CCI_FireCCI_5_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_CCI_FireCCI_5_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_CCI_FireCCI_5_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_CCI_FireCCI_5_1(example: str = ''):
        """
        The MODIS Fire_cci Burned Area pixel product version 5.1 (FireCCI51) is a monthly global ~250m spatial resolution dataset containing information on burned area as well as ancillary data. It is based on surface reflectance in the Near Infrared (NIR) band from the MODIS instrument onboard the Terra satellite, as well as active fire information from the same sensor of the Terra and Aqua satellites.  The burned area algorithm uses a two-phase hybrid approach. In a first step pixels with a high probability of being burned (called "seeds") are detected based on the active fires. In a second one, a contextual growing is applied to completely detect the fire patch. This growing phase is controlled by an adaptive thresholding, where thresholds are computed based on the specific characteristics of the area surrounding each seed. The variable used to guide the whole detection process is the NIR drop between pre- and post-fire images.  The dataset includes for each pixel the estimated day of the first detection of the fire, the confidence level of that detection, and the land cover that has been burned (extracted from the ESA CCI Land Cover dataset v2.0.7). In addition, an observation flag is provided to identify the pixels that were not processed due to the lack of valid observations or because they belong to a non-burnable land cover.  FireCCI51 was developed as part of the ESA Climate Change Initiative (CCI) Programme, and it is also part of the Copernicus Climate Change Service (C3S). 
        :param example: // Visualize FireCCI51 for one year var dataset = ee.ImageCollection('ESA/CCI/FireCCI/5_1')                   .filterDate('2020-01-01', '2020-12-31'); var burnedArea = dataset.select('BurnDate');  // Use a circular palette to assign colors to date of first detection var baVis = {   min: 1,   max: 366,   palette: [     'ff0000', 'fd4100', 'fb8200', 'f9c400', 'f2ff00', 'b6ff05',     '7aff0a', '3eff0f', '02ff15', '00ff55', '00ff99', '00ffdd',     '00ddff', '0098ff', '0052ff', '0210ff', '3a0dfb', '7209f6',     'a905f1', 'e102ed', 'ff00cc', 'ff0089', 'ff0047', 'ff0004'   ] }; var maxBA = burnedArea.max();  Map.setCenter(0, 18, 2.1); Map.addLayer(maxBA, baVis, 'Burned Area'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_GLOBCOVER_L4_200901_200912_V2_3:
    def __init__(self,):
        self.sensor = 'ESA_GLOBCOVER_L4_200901_200912_V2_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_GLOBCOVER_L4_200901_200912_V2_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_GLOBCOVER_L4_200901_200912_V2_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_GLOBCOVER_L4_200901_200912_V2_3(example: str = ''):
        """
        GlobCover 2009 is a global land cover map based on ENVISAT's Medium Resolution Imaging Spectrometer (MERIS) Level 1B data acquired in full resolution mode with a spatial resolution of approximately 300 meters. 
        :param example: var dataset = ee.Image('ESA/GLOBCOVER_L4_200901_200912_V2_3'); var landcover = dataset.select('landcover'); Map.setCenter(-88.6, 26.4, 3); Map.addLayer(landcover, {}, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_WorldCereal_2021_MARKERS_v100:
    def __init__(self,):
        self.sensor = 'ESA_WorldCereal_2021_MARKERS_v100'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_WorldCereal_2021_MARKERS_v100.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_WorldCereal_2021_MARKERS_v100.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_WorldCereal_2021_MARKERS_v100(example: str = ''):
        """
        The European Space Agency (ESA) WorldCereal Active Cropland 10 m 2021 product suite contains global-scale seasonal active cropland markers. They were generated as part of the [ESA-WorldCereal project](https://esa-worldcereal.org/). The active cropland products indicate whether or not a pixel identified as temporary crops has been actively cultivated during a specific growing season. In order for a pixel to be labeled as “active” during a particular growing season, a full crop growth cycle (sowing, growing, senescence and harvesting) needs to take place within the designated time period. Note that this active marker is not crop-type specific. Any crop grown (slightly) outside the predefined growing seasons will not be flagged as active cropland in any of the seasons covered by the WorldCereal system. The active marker results from running a growing season detection algorithm [1] on the Sentinel-2 derived enhanced vegetation index (EVI). More information on the methodology used to generate these products is described in [2].  This collection contains up to 106 agro-ecological zone (AEZ) images per crop season, where each AEZ has its own seasonality. The seasons for which the active cropland marker is available are described in the list below and were developed in [3] as part of the project.  WorldCereal seasons description:  - tc-wintercereals: the main cereals season defined in an AEZ - tc-springcereals: optional springcereals season, only defined in certain AEZ - tc-maize-main: the main maize season defined in an AEZ - tc-maize-second: optional second maize season, only defined in certain AEZ  Each product (image) has a binary classification band where value 0 corresponds to inactive cropland and value 100 corresponds to active cropland.  The collection should be filtered using one or more of the following image properties:  - aez_id, holding the ID of the AEZ to which the image belongs - season, describing the season for which the image is valid.  References:  - [1] Bolton, D. K., Gray, J. M., Melaas, E. K., Moon, M., Eklundh, L., and Friedl, M. A.: Continental-scale land surface phenology from harmonized Landsat 8 and Sentinel-2 imagery, Remote Sens. Environ., 240, 111685, https://doi.org/10.1016/j.rse.2020.111685, 2020. - [2] [WorldCereal methodology and products paper](https://doi.org/10.5194/essd-2023-184) - [3] [WorldCereal global seasonality paper](https://doi.org/10.1080/15481603.2022.2079273)  WorldCereal datasets:  -  Version 100 for year 2021    -  [ESA/WorldCereal/AEZ/v100](ESA_WorldCereal_AEZ_v100)    -  [ESA/WorldCereal/2021/MODELS/v100](ESA_WorldCereal_2021_MODELS_v100)    -  [ESA/WorldCereal/2021/MARKERS/v100](ESA_WorldCereal_2021_MARKERS_v100) 
        :param example: var dataset = ee.ImageCollection('ESA/WorldCereal/2021/MARKERS/v100')  // Filter on AEZ var aez_46173 = dataset.filter('aez_id == 46173');  // Get the active cropland marker for the different seasons var activemarker_summerseason = aez_46173.filter('season == "tc-maize-main"'); var activemarker_winterseason = aez_46173.filter('season == "tc-wintercereals"');  // Visualization specifics: red is inactive, green is active cropland var visualization = {   bands: ['classification'],   max: 100,   palette: ['eb0000', '37e622'] };  // Show active cropland in two major growing seasons in US. Map.addLayer(activemarker_summerseason, visualization, 'Active cropland tc-maize-main'); Map.addLayer(activemarker_winterseason, visualization, 'Active cropland tc-wintercereals');  Map.setCenter(-98.987, 38.0454, 11) 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_WorldCereal_2021_MODELS_v100:
    def __init__(self,):
        self.sensor = 'ESA_WorldCereal_2021_MODELS_v100'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_WorldCereal_2021_MODELS_v100.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_WorldCereal_2021_MODELS_v100.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_WorldCereal_2021_MODELS_v100(example: str = ''):
        """
        The European Space Agency (ESA) WorldCereal 10 m 2021 product suite consists of global-scale annual and seasonal crop maps and their related confidence. They were generated as part of the [ESA-WorldCereal project](https://esa-worldcereal.org/). More information on the content of these products and the methodology used to generate them is described in [1].  This collection contains up to 106 agro-ecological zone (AEZ) images for each product which were all processed with respect to their own regional seasonality and should be considered as independent products. These seasons are described in the list below and were developed in [2] as part of the project. Note that cereals as described by WorldCereal include wheat, barley, and rye, which belong to the *Triticeae* tribe.  WorldCereal seasons description:  - tc-annual: a one-year cycle being defined in an AEZ by the end of the last considered growing season - tc-wintercereals: the main cereals season defined in an AEZ - tc-springcereals: optional springcereals season, only defined in certain AEZ - tc-maize-main: the main maize season defined in an AEZ - tc-maize-second: optional second maize season, only defined in certain AEZ  The available products in this collection are:  - temporarycrops - maize - wintercereals - springcereals - irrigation  Each product (image) has a binary classification (0 or 100) and a confidence (0-100) band. Note that AEZs for which no irrigation product is available were not processed because of the unavailability of thermal Landsat data.  The collection should be filtered using one or more of the following image properties:  - aez_id, holding the ID of the AEZ to which the image belongs - product, describing the WorldCereal product name of the image - season, describing the season for which the image is valid.  References:  - [1] [WorldCereal methodology and products paper](https://doi.org/10.5194/essd-2023-184) - [2] [WorldCereal global seasonality paper](https://doi.org/10.1080/15481603.2022.2079273)  WorldCereal datasets:  -  Version 100 for year 2021    -  [ESA/WorldCereal/AEZ/v100](ESA_WorldCereal_AEZ_v100)    -  [ESA/WorldCereal/2021/MODELS/v100](ESA_WorldCereal_2021_MODELS_v100)    -  [ESA/WorldCereal/2021/MARKERS/v100](ESA_WorldCereal_2021_MARKERS_v100) 
        :param example: var dataset = ee.ImageCollection('ESA/WorldCereal/2021/MODELS/v100')  // Set satellite background Map.setOptions('SATELLITE');  // Typically we'd want to mask the "other" class (value 0) // in the images function mask_other(img) {   return img.updateMask(img.neq(0)) }  // Apply the mask_other function to the collection dataset = dataset.map(mask_other);  /*-------------------------------------------------- Basic example for a global mosaic of temporary crops --------------------------------------------------*/  // Get a global mosaic for all agro-ecological zone (AEZ) of temporary crops var temporarycrops = dataset.filter('product == "temporarycrops"').mosaic();  // Visualization specifics var visualization_class = {   bands: ["classification"],   max: 100,   palette: ["ff0000"] };  var visualization_conf = {   bands: ['confidence'],   min: [0],   max: [100],   palette: ['be0000','fff816','069711'], };  // Show global classification mosaic Map.centerObject(temporarycrops); Map.addLayer(temporarycrops, visualization_class, 'Temporary crops');  // By default don't show confidence layer Map.addLayer(     temporarycrops, visualization_conf, 'Temporary crops confidence', false);  /*-------------------------------------------------- Advanced example for tc-maize-main season products in a specific AEZ --------------------------------------------------*/  // Filter on AEZ and season var tc_maize_main_46172 = dataset.filter(   ee.Filter.eq('season', 'tc-maize-main')   ).filter(ee.Filter.eq('aez_id', 46172));  // Get the different products var maize = tc_maize_main_46172.filter('product == "maize"'); var irrigation = tc_maize_main_46172.filter('product == "irrigation"');  // Visualization specifics var visualization_maize = {   bands: ["classification"],   max: 100,   palette: ["#ebc334"] };  var visualization_irrigation = {   bands: ["classification"],   max: 100,   palette: ["#2d79eb"] };  // Show maize and irrigation classification Map.addLayer(maize, visualization_maize, 'Maize'); Map.addLayer(irrigation, visualization_irrigation, 'Active irrigation');  // Uncomment the line below to zoom to a region // where maize, other crops and active irrigation are visible // Map.setCenter(-0.9911, 43.5017, 12) 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_WorldCereal_AEZ_v100:
    def __init__(self,):
        self.sensor = 'ESA_WorldCereal_AEZ_v100'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_WorldCereal_AEZ_v100.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_WorldCereal_AEZ_v100.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_WorldCereal_AEZ_v100(example: str = ''):
        """
        The [European Space Agency (ESA) WorldCereal](https://esa-worldcereal.org/) classification system aims for product generation within one month after the end of a particular growing season. Due to the dynamic nature of these growing seasons across the globe, a global stratification into Agro-Ecological Zones (AEZ) was performed based on the global crop calendars created within the project [1]. The feature collection in this dataset contains the 106 AEZ for which WorldCereal products were generated. Each AEZ has unique crop calendars, described based on their start of season (SOS) and end of season (EOS). SOS and EOS are given in day of year (DOY). More information on the AEZ stratification and the subsequent WorldCereal product generation is described in [2].  AEZ properties:  - aez_id: the unique ID of each AEZ. WorldCereal products can be filtered based on this ID - aez_groupid: the group ID combines several unique AEZ into a group based on crop calendar similarity. - tc-annual_sos: SOS of the tc-annual season (DOY) - tc-annual_eos: EOS of the tc-annual season (DOY) - tc-wintercereals_sos: SOS of the tc-wintercereals season (DOY) - tc-wintercereals_eos: EOS of the tc-wintercereals season (DOY) - tc-springcereals_sos: SOS of the tc-springcereals season (DOY) - tc-springcereals_eos: EOS of the tc-springcereals season (DOY) - tc-maize-main_sos: SOS of the tc-maize-main season (DOY) - tc-maize-main_eos: EOS of the tc-maize-main season (DOY) - tc-maize-second_sos: SOS of the tc-maize-second season (DOY) - tc-maize-second_eos: EOS of the tc-maize-second season (DOY)  Missing values of SOS and EOS indicate the absence of the respective growing season in a particular AEZ.  References:  - [1] [WorldCereal global seasonality paper](https://doi.org/10.1080/15481603.2022.2079273) - [2] [WorldCereal methodology and products paper](https://doi.org/10.5194/essd-2023-184)  WorldCereal datasets:  -  Version 100 for year 2021    -  [ESA/WorldCereal/AEZ/v100](ESA_WorldCereal_AEZ_v100)    -  [ESA/WorldCereal/2021/MODELS/v100](ESA_WorldCereal_2021_MODELS_v100)    -  [ESA/WorldCereal/2021/MARKERS/v100](ESA_WorldCereal_2021_MARKERS_v100) 
        :param example: var aez = ee.FeatureCollection('ESA/WorldCereal/AEZ/v100');  // Find the AEZs with multiple growing seasons for maize and cereal. var twoMaizeAez =     aez.filter(ee.Filter.notNull(['tc-maize-main_eos', 'tc-maize-second_eos'])); var twoCerealAez = aez.filter(     ee.Filter.notNull(['tc-wintercereals_eos', 'tc-springcereals_eos']));  Map.addLayer(     twoMaizeAez.draw('ff0000', 1, 2), {}, 'AEZ with two maize seasons'); Map.addLayer(     twoCerealAez.draw('0000ff', 1, 2), {}, 'AEZ with two cereal seasons'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_WorldCover_v100:
    def __init__(self,):
        self.sensor = 'ESA_WorldCover_v100'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_WorldCover_v100.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_WorldCover_v100.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_WorldCover_v100(example: str = ''):
        """
        The European Space Agency (ESA) WorldCover 10 m 2020 product provides a global land cover map for 2020 at 10 m resolution based on Sentinel-1 and Sentinel-2 data.  The WorldCover product comes with 11 land cover classes and has been generated in the framework of the ESA WorldCover project, part of the 5th Earth Observation Envelope Programme (EOEP-5) of the European Space Agency.  See also:  * [ESA WorldCover website](https://esa-worldcover.org) * [User Manual and Validation Report](https://esa-worldcover.org/en/data-access) 
        :param example: var dataset = ee.ImageCollection('ESA/WorldCover/v100').first();  var visualization = {   bands: ['Map'], };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ESA_WorldCover_v200:
    def __init__(self,):
        self.sensor = 'ESA_WorldCover_v200'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ESA_WorldCover_v200.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ESA_WorldCover_v200.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ESA_WorldCover_v200(example: str = ''):
        """
        The European Space Agency (ESA) WorldCover 10 m 2021 product provides a global land cover map for 2021 at 10 m resolution based on Sentinel-1 and Sentinel-2 data.  The WorldCover product comes with 11 land cover classes and has been generated in the framework of the ESA WorldCover project, part of the 5th Earth Observation Envelope Programme (EOEP-5) of the European Space Agency.  See also:  * [ESA WorldCover website](https://esa-worldcover.org) * [User Manual and Validation Report](https://esa-worldcover.org/en/data-access) 
        :param example: var dataset = ee.ImageCollection('ESA/WorldCover/v200').first();  var visualization = {   bands: ['Map'], };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Estonia_Maamet_orthos_mono:
    def __init__(self,):
        self.sensor = 'Estonia_Maamet_orthos_mono'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Estonia_Maamet_orthos_mono.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Estonia_Maamet_orthos_mono.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Estonia_Maamet_orthos_mono(example: str = ''):
        """
        Orthophotos are an aerial photo dataset covering Estonia.  An orthophoto is a processed aerial photo from which distortions caused by terrain relief, camera tilt relative to the ground at the moment of exposure and camera central projection are removed. A digital orthophoto has a certain pixel size or resolution which shows the smallest indivisible exposed area on the ground (Ground Sampling Distance, GSD).  Orthophotos have a nationwide coverage and correspond to the scale of 1:5000-1:10000 (pixel size 20-40 cm). Orthophotos for densely populated areas are produced with the pixel size of 10-16 cm.  The mono dataset has a single grayscale band.  For more information, please see the [Estonia orthophotos documentation](https://geoportaal.maaamet.ee/eng/Spatial-Data/Orthophotos-p309.html) 
        :param example: var dataset = ee.ImageCollection('Estonia/Maamet/orthos/mono'); Map.setCenter(26.61312, 58.5879, 15); Map.addLayer(dataset, null, 'Estonia Maamet mono'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Estonia_Maamet_orthos_rgb:
    def __init__(self,):
        self.sensor = 'Estonia_Maamet_orthos_rgb'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Estonia_Maamet_orthos_rgb.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Estonia_Maamet_orthos_rgb.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Estonia_Maamet_orthos_rgb(example: str = ''):
        """
        Orthophotos are an aerial photo dataset covering Estonia.  An orthophoto is a processed aerial photo from which distortions caused by terrain relief, camera tilt relative to the ground at the moment of exposure and camera central projection are removed. A digital orthophoto has a certain pixel size or resolution which shows the smallest indivisible exposed area on the ground (Ground Sampling Distance, GSD).  Orthophotos have a nationwide coverage and correspond to the scale of 1:5000-1:10000 (pixel size 20-40 cm). Orthophotos for densely populated areas are produced with the pixel size of 10-16 cm.  The RGB dataset has three bands: red, green, and blue.  For more information, please see the [Estonia orthophotos documentation](https://geoportaal.maaamet.ee/eng/Spatial-Data/Orthophotos-p309.html) 
        :param example: var dataset = ee.ImageCollection('Estonia/Maamet/orthos/rgb'); Map.setCenter(24.959, 58.148, 18); Map.addLayer(dataset, null, 'Estonia Maamet rgb'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_2015_level0:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_2015_level0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_2015_level0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_2015_level0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_2015_level0(example: str = ''):
        """
        The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](   https://data.apps.fao.org:/map/catalog/srv/api/records/9c35ba10-5649-41c8-bdfc-eb78e9e65654/attachments/GAUL2015_Documentation.zip). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL/2015/level0');  Map.setCenter(7.82, 49.1, 4);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'Country Boundaries'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_2015_level1:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_2015_level1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_2015_level1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_2015_level1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_2015_level1(example: str = ''):
        """
        The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](   https://data.apps.fao.org:/map/catalog/srv/api/records/9c35ba10-5649-41c8-bdfc-eb78e9e65654/attachments/GAUL2015_Documentation.zip). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL/2015/level1');  Map.setCenter(7.82, 49.1, 4);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'First Level Administrative Units'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_2015_level2:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_2015_level2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_2015_level2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_2015_level2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_2015_level2(example: str = ''):
        """
        The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](   https://data.apps.fao.org:/map/catalog/srv/api/records/9c35ba10-5649-41c8-bdfc-eb78e9e65654/attachments/GAUL2015_Documentation.zip). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL/2015/level2');  Map.setCenter(12.876, 42.682, 5);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'Second Level Administrative Units'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_SIMPLIFIED_500m_2015_level0:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_SIMPLIFIED_500m_2015_level0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_SIMPLIFIED_500m_2015_level0(example: str = ''):
        """
        This version of GAUL dataset is simplified at 500m.  The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](https://sgst.wr.usgs.gov/gfsad30/FAO_GUAL/TechnicalAspectsGAUL2015_Doc1.pdf)). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level0');  Map.setCenter(7.82, 49.1, 4);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'Country Boundaries'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_SIMPLIFIED_500m_2015_level1:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_SIMPLIFIED_500m_2015_level1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_SIMPLIFIED_500m_2015_level1(example: str = ''):
        """
        This version of GAUL dataset is simplified at 500m.  The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](   https://sgst.wr.usgs.gov/gfsad30/FAO_GUAL/TechnicalAspectsGAUL2015_Doc1.pdf)). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level1');  Map.setCenter(7.82, 49.1, 4);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'First Level Administrative Units'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GAUL_SIMPLIFIED_500m_2015_level2:
    def __init__(self,):
        self.sensor = 'FAO_GAUL_SIMPLIFIED_500m_2015_level2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GAUL_SIMPLIFIED_500m_2015_level2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GAUL_SIMPLIFIED_500m_2015_level2(example: str = ''):
        """
        This version of GAUL dataset is simplified at 500m.  The Global Administrative Unit Layers (GAUL) compiles and disseminates the best available information on administrative units for all the countries in the world, providing a contribution to the standardization of the spatial dataset representing administrative units. The GAUL always maintains global layers with a unified coding system at country, first (e.g. departments), and second administrative levels (e.g. districts). Where data is available, it provides layers on a country by country basis down to third, fourth, and lowers levels. The overall methodology consists in a) collecting the best available data from most reliable sources, b) establishing validation periods of the geographic features (when possible), c) adding selected data to the global layer based on the last country boundaries map provided by the UN Cartographic Unit (UNCS), d) generating codes using GAUL Coding System, and e) distribute data to the users (see [Technical Aspects of the GAUL Distribution Set](   https://sgst.wr.usgs.gov/gfsad30/FAO_GUAL/TechnicalAspectsGAUL2015_Doc1.pdf)). Note that some administrative units are multipolygon features. 
        :param example: var dataset = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level2');  Map.setCenter(12.876, 42.682, 5);  var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 1.0, };  dataset = dataset.style(styleParams);  Map.addLayer(dataset, {}, 'Second Level Administrative Units'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GHG_1_DROSA_A:
    def __init__(self,):
        self.sensor = 'FAO_GHG_1_DROSA_A'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GHG_1_DROSA_A.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GHG_1_DROSA_A.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GHG_1_DROSA_A(example: str = ''):
        """
         The two related FAO datasets on Drained Organic Soils provide estimates of:  1. DROSA-A: area of Organic Soils (in hectares) drained for agricultural activities (cropland and grazed grassland)  2. DROSE-A: carbon (C) and nitrous oxide (N2O) estimates (in gigagrams) from the agricultural drainage of organic soils under these land uses.  Annual data are available at 0.0083333 X 0.0083333 resolution (~1 km at the equator), with global coverage for the period 1992 - 2018.  FAOSTAT estimates follow the Intergovernmental Panel on Climate Change Guidelines (IPCC) and use histosols as proxy for the presence of organic soils and annual land cover maps as time- dependent component. Additionally, soils characteristics, land use, and climate information are applied in the analysis. The carbon emissions can be converted to CO2, multiplying pixel values by the ratio of the molecular weight of carbon dioxide (CO2) to that of C (44/12).  Organic soils develop in wet soil ecosystems. They include tropical and boreal peatlands, high-latitude bogs, ferns, and mires. Organic soils cover globally a mere 3 percent of the terrestrial land area but represent up to 30 percent of the total soil carbon, thus playing an important role in maintaining the earth's carbon balance. Agriculture is a major cause of drainage of organic soils around the world.  Drainage exposes to aerobic conditions the organic matter of organic soils that oxidizes releasing large amounts of harmful greenhouse gases (GHG) to the atmosphere.  DROSA-A and DROSE-A are the basis for country and regional statistics on drained organic soils disseminated in three FAOSTAT datasets (Cultivation of Organic Soils; Cropland; and Grassland). 
        :param example: var dataset = ee.ImageCollection('FAO/GHG/1/DROSA_A');  var visualization = {   bands: ['cropland'],   min: 1.0,   max: 60.0,   palette: ['white', 'red'] };  Map.setCenter(108.0, -0.4, 6);  Map.addLayer(dataset, visualization, 'Cropland area drained (Annual)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_GHG_1_DROSE_A:
    def __init__(self,):
        self.sensor = 'FAO_GHG_1_DROSE_A'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_GHG_1_DROSE_A.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_GHG_1_DROSE_A.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_GHG_1_DROSE_A(example: str = ''):
        """
        The two related FAO datasets on Drained Organic Soils provide estimates of:  1. DROSA-A: area of Organic Soils (in hectares) drained for agricultural activities (cropland and grazed grassland)  2. DROSE-A: carbon (C) and nitrous oxide (N2O) estimates (in gigagrams) from the agricultural drainage of organic soils under these land uses.  Annual data are available at 0.0083333 X 0.0083333 resolution (~1 km at the equator), with global coverage for the period 1992 - 2018.  FAOSTAT estimates follow the Intergovernmental Panel on Climate Change Guidelines (IPCC) and use histosols as proxy for the presence of organic soils and annual land cover maps as time- dependent component. Additionally, soils characteristics, land use, and climate information are applied in the analysis. The carbon emissions can be converted to CO2, multiplying pixel values by the ratio of the molecular weight of carbon dioxide (CO2) to that of C (44/12).  Organic soils develop in wet soil ecosystems. They include tropical and boreal peatlands, high-latitude bogs, ferns, and mires. Organic soils cover globally a mere 3 percent of the terrestrial land area but represent up to 30 percent of the total soil carbon, thus playing an important role in maintaining the earth's carbon balance. Agriculture is a major cause of drainage of organic soils around the world.  Drainage exposes to aerobic conditions the organic matter of organic soils that oxidizes releasing large amounts of harmful greenhouse gases (GHG) to the atmosphere.  DROSA-A and DROSE-A are the basis for country and regional statistics on drained organic soils disseminated in three FAOSTAT datasets (Cultivation of Organic Soils; Cropland; and Grassland). 
        :param example: var dataset = ee.ImageCollection('FAO/GHG/1/DROSE_A');  var visualization = {   bands: ['croplandc'],   min: 0,   max: 1,   palette: ['yellow', 'red'] };  Map.setCenter(108.0, -0.4, 6);  Map.addLayer(dataset, visualization, 'Cropland C emissions (Annual)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_SOFO_1_FPP:
    def __init__(self,):
        self.sensor = 'FAO_SOFO_1_FPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_SOFO_1_FPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_SOFO_1_FPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_SOFO_1_FPP(example: str = ''):
        """
        The "Forest Proximate People" (FPP) dataset is one of the data layers contributing to the development of indicator #13, "number of forest-dependent people in extreme poverty," of the Collaborative Partnership on Forests (CPF) Global Core Set of forest-related indicators (GCS). The FPP dataset provides an estimate of the number of people living in or within 1 kilometer of forests (forest-proximate people) for the year 2019 with a pixel size of 100 meters at a global level. [Find out more about the dataset.](   https://data.apps.fao.org/catalog/dcat/forest-proximate-people) 
        :param example: var coll = ee.ImageCollection('FAO/SOFO/1/FPP'); var image = coll.first().select('FPP_1km'); Map.setCenter(17.5, 20, 3); Map.addLayer(     image, {min: 0, max: 12, palette: ['blue', 'yellow', 'red']},     'Forest proximate people – 1km cutoff distance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_SOFO_1_TPP:
    def __init__(self,):
        self.sensor = 'FAO_SOFO_1_TPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_SOFO_1_TPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_SOFO_1_TPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_SOFO_1_TPP(example: str = ''):
        """
        The "Tree Proximate People" (TPP) is one of the datasets contributing to the development of indicator #13, number of forest-dependent people in extreme poverty, of the Collaborative Partnership on Forests (CPF) Global Core Set of forest-related indicators (GCS). The TPP dataset provides 4 different estimates of tree proximate people (trees outside forests), all of them for the year 2019 with a pixel size of 100 meters at a global level. [Find out more about the dataset.](   https://data.apps.fao.org/catalog/dcat/tree-proximate-people) 
        :param example: var coll = ee.ImageCollection('FAO/SOFO/1/TPP'); var image = coll.first().select('TPP_1km'); Map.setCenter(17.5, 20, 3); Map.addLayer(     image, {min: 0, max: 12, palette: ['blue', 'yellow', 'red']},     'Tree proximate people – 1km cutoff distance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_AETI_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_AETI_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_AETI_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_AETI_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_AETI_D(example: str = ''):
        """
        The actual evapotranspiration and interception (ETIa) (dekadal, in mm/day) is the sum of the soil evaporation (E), canopy transpiration (T), and evaporation from rainfall intercepted by leaves (I). The value of each pixel represents the average daily ETIa in a given dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_AETI_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 50}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_E_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_E_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_E_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_E_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_E_D(example: str = ''):
        """
        The evaporation (E) data component (dekadal, in mm/day) is the actual evaporation of the soil surface. The value of each pixel represents the average daily actual evaporation for that specific dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_E_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 10}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_I_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_I_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_I_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_I_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_I_D(example: str = ''):
        """
        The interception (I) data component (dekadal, in mm/day) represents the evaporation of intercepted rainfall from the vegetation canopy. Interception is the process where rainfall is captured by the leaves. Part of this captured rainfall will evaporate again. The value of each pixel represents the average daily evaporated interception for that specific dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_I_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 50}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_NPP_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_NPP_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_NPP_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_NPP_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_NPP_D(example: str = ''):
        """
        Net primary production (NPP) is a fundamental characteristic of an ecosystem, expressing the conversion of carbon dioxide into biomass driven by photosynthesis. The pixel value represents the mean daily NPP for that specific dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_NPP_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 5000}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_RET_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_RET_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_RET_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_RET_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_RET_D(example: str = ''):
        """
        Reference evapotranspiration (RET) is defined as the evapotranspiration from a hypothetical reference crop and it simulates the behaviour of a well-watered grass surface. The value of each pixel represents the average of the daily reference evapotranspiration for that specific dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_RET_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 100}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_RET_E:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_RET_E'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_RET_E.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_RET_E.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_RET_E(example: str = ''):
        """
        Reference evapotranspiration (RET) is defined as the evapotranspiration from a hypothetical reference crop and it simulates the behaviour of a well-watered grass surface. Each pixel represents the daily reference evapotranspiration in mm. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_RET_E'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 100}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FAO_WAPOR_2_L1_T_D:
    def __init__(self,):
        self.sensor = 'FAO_WAPOR_2_L1_T_D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FAO_WAPOR_2_L1_T_D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FAO_WAPOR_2_L1_T_D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FAO_WAPOR_2_L1_T_D(example: str = ''):
        """
        The transpiration (T) data component (dekadal, in mm/day) is the actual transpiration of the vegetation canopy. The value of each pixel represents the average daily actual transpiration for that specific dekad. 
        :param example: var coll = ee.ImageCollection('FAO/WAPOR/2/L1_T_D'); var image = coll.first(); Map.setCenter(17.5, 20, 3); Map.addLayer(image, {min: 0, max: 50}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Finland_MAVI_VV_50cm:
    def __init__(self,):
        self.sensor = 'Finland_MAVI_VV_50cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Finland_MAVI_VV_50cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Finland_MAVI_VV_50cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Finland_MAVI_VV_50cm(example: str = ''):
        """
        NLS Orthophotos are an aerial photo dataset covering the whole of Finland. This data is provided by [Mavi(Agency for Rural Affairs)](https://maaseutuverkosto.fi/en/). An orthophoto is a combination of several individual aerial photos. The aerial photo dataset in orthophoto format is available as the most recent dataset consisting of the most recent aerial photos available. The most recent data is usually 1-3 years old. NLS Orthophotos are updated every 3 years (in Northern Lapland 12 years).  In these images, the bands are near-infrared, red, and green.  (In Dataset id, VV stands for "v&auml;&auml;r&auml;v&auml;ri", false color) For more information, please see the [NLS orthophotos documentation](https://www.maanmittauslaitos.fi/en/maps-and-spatial-data/expert-users/product-descriptions/orthophotos) 
        :param example: var dataset = ee.ImageCollection('Finland/MAVI/VV/50cm');  Map.setCenter(25.7416, 62.2446, 16); Map.addLayer(dataset, null, 'Finland 50 cm(false color)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Finland_SMK_VV_50cm:
    def __init__(self,):
        self.sensor = 'Finland_SMK_VV_50cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Finland_SMK_VV_50cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Finland_SMK_VV_50cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Finland_SMK_VV_50cm(example: str = ''):
        """
        NLS Orthophotos are an aerial photo dataset covering the whole of Finland. This data is provided by SMK([The Energy Agency](https://energiavirasto.fi/etusivu), formerly abbreviated SMK). An orthophoto is a combination of several individual aerial photos. The aerial photo dataset in orthophoto format is available as the most recent dataset consisting of the most recent aerial photos available. The most recent data is usually 1-3 years old. NLS Orthophotos are updated every 3 years (in Northern Lapland 12 years).  In these images, the bands are near-infrared, red, and green.  (In Dataset id, VV stands for "v&auml;&auml;r&auml;v&auml;ri", false color)  For more information, please see the [NLS orthophotos documentation](https://www.maanmittauslaitos.fi/en/maps-and-spatial-data/expert-users/product-descriptions/orthophotos) 
        :param example: var dataset = ee.ImageCollection('Finland/SMK/VV/50cm');  Map.setCenter(25.7416, 62.2446, 16); Map.addLayer(dataset, null, 'Finland 50 cm(false color)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Finland_SMK_V_50cm:
    def __init__(self,):
        self.sensor = 'Finland_SMK_V_50cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Finland_SMK_V_50cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Finland_SMK_V_50cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Finland_SMK_V_50cm(example: str = ''):
        """
        NLS Orthophotos are an aerial photo dataset covering the whole of Finland. This data is provided by SMK([The Energy Agency](https://energiavirasto.fi/etusivu), formerly abbreviated SMK). An orthophoto is a combination of several individual aerial photos. The aerial photo data set in orthophoto format is available as the most recent data set consisting of the most recent aerial photos available. The most recent data is usually 1-3 years old. NLS Orthophotos are updated every 3 years (in Northern Lapland 12 years).  (In Dataset id, V stands for "v&auml;ri", which means "color" as opposed to "false color") For more information, please see the [NLS orthophotos documentation](https://www.maanmittauslaitos.fi/en/maps-and-spatial-data/expert-users/product-descriptions/orthophotos) 
        :param example: var dataset = ee.ImageCollection('Finland/SMK/V/50cm');  Map.setCenter(24.9, 60.2, 17); Map.addLayer(dataset, null, 'Finland 50 cm(color)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FIRMS:
    def __init__(self,):
        self.sensor = 'FIRMS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FIRMS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FIRMS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FIRMS(example: str = ''):
        """
        The Earth Engine version of the Fire Information for Resource Management System (FIRMS) dataset contains the LANCE fire detection product in rasterized form. The near real-time (NRT) active fire locations are processed by LANCE using the standard MODIS MOD14/MYD14 Fire and Thermal Anomalies product. Each active fire location represents the centroid of a 1km pixel that is flagged by the algorithm as containing one or more fires within the pixel. The data are rasterized as follows: for each FIRMS active fire point, a 1km bounding box (BB) is defined; pixels in the MODIS sinusoidal projection that intersect the FIRMS BB are identified; if multiple FIRMS BBs intersect the same pixel, the one with higher confidence is retained; in case of a tie, the brighter one is retained.  The data in the near-real-time dataset are not considered to be of science quality.  Additional information can be found [here](https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms/about-firms).  NOTE: VIIRS FIRMS datasets from NOAA20 and SUOMI are also available:  * [NASA/LANCE/NOAA20_VIIRS/C2](NASA_LANCE_NOAA20_VIIRS_C2) * [NASA/LANCE/SNPP_VIIRS/C2](NASA_LANCE_SNPP_VIIRS_C2) 
        :param example: var dataset = ee.ImageCollection('FIRMS').filter(     ee.Filter.date('2018-08-01', '2018-08-10')); var fires = dataset.select('T21'); var firesVis = {   min: 325.0,   max: 400.0,   palette: ['red', 'orange', 'yellow'], }; Map.setCenter(-119.086, 47.295, 6); Map.addLayer(fires, firesVis, 'Fires'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class FORMA_FORMA_500m:
    def __init__(self,):
        self.sensor = 'FORMA_FORMA_500m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/FORMA_FORMA_500m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/FORMA_FORMA_500m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_FORMA_FORMA_500m(example: str = ''):
        """
        FORMA is a MODIS-based deforestation alerting system for the humid tropical forests. FORMA is designed for quick identification of new areas of tree cover loss. The system analyzes data gathered daily by the MODIS sensor, which operates on NASA's Terra and Aqua satellites. The FORMA alerts system then detects pronounced changes in vegetation cover over time, as measured by the Normalized Difference Vegetation Index (NDVI), a measure of vegetation greenness. These pronounced changes in vegetation cover are likely to indicate forest being cleared, burned, or defoliated. An alert is added to the dataset by setting the pixel value to the date at which a change was detected. FORMA alerts only appear in areas where the probability of tree cover loss is greater than or equal to 50%. FORMA data has 500-meter spatial resolution and twice-monthly update interval. FORMA alerts start in January 2006. 
        :param example: var dataset = ee.Image('FORMA/FORMA_500m');  var visualization = {   bands: ['constant'],   min: 1134979200.0,   max: 1433919600.0,   palette: ['ff0000'] };  Map.setCenter(-51.482, -0.835, 6);  Map.addLayer(dataset, visualization, 'Alert Areas'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Germany_Brandenburg_20cm:
    def __init__(self,):
        self.sensor = 'Germany_Brandenburg_20cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Germany_Brandenburg_20cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Germany_Brandenburg_20cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Germany_Brandenburg_20cm(example: str = ''):
        """
        Orthophotos are an aerial photo dataset covering the Brandenburg state of Germany. This data is provided by State government of Brandenburg ([LGB](https://geobasis-bb.de/lgb/de/)). Digital orthophotos are digitally corrected aerial photos and show all objects that are visible from the air at the time of recording in a parallel perspective. They have a high density of information on ecological, phenological, geographical and other topics.  For more information, please see the [Brandenburg orthophotos documentation] (https://geobasis-bb.de/lgb/de/geodaten/luftbilder/luftbilder-aktuell/) 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Germany_Brandenburg_orthos_20cm:
    def __init__(self,):
        self.sensor = 'Germany_Brandenburg_orthos_20cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Germany_Brandenburg_orthos_20cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Germany_Brandenburg_orthos_20cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Germany_Brandenburg_orthos_20cm(example: str = ''):
        """
        Orthophotos are an aerial photo dataset covering the Brandenburg state of Germany. This data is provided by State government of Brandenburg ([LGB](https://geobasis-bb.de/lgb/de/)). Digital orthophotos are digitally corrected aerial photos and show all objects that are visible from the air at the time of recording in a parallel perspective. They have a high density of information on ecological, phenological, geographical and other topics.  For more information, please see the [Brandenburg orthophotos documentation](https://geobasis-bb.de/lgb/de/geodaten/luftbilder/luftbilder-aktuell/) 
        :param example: var dataset = ee.Image('Germany/Brandenburg/orthos/20cm'); Map.setCenter(13.386091, 52.507899, 18); Map.addLayer(dataset, null, 'Brandenburg 20cm'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GFW_GFF_V1_fishing_hours:
    def __init__(self,):
        self.sensor = 'GFW_GFF_V1_fishing_hours'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GFW_GFF_V1_fishing_hours.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GFW_GFF_V1_fishing_hours.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GFW_GFF_V1_fishing_hours(example: str = ''):
        """
        Fishing effort, measured in hours of inferred fishing activity. Each asset is the effort for a given flag state and day, with one band for the fishing activity of each gear type.  See [sample Earth Engine scripts](https://globalfishingwatch.org/research/global-footprint-of-fisheries/). Also see [the main GFW site](https://GlobalFishingWatch.org) for program information, fully interactive visualization maps, and impacts. 
        :param example: var dataset = ee.ImageCollection('GFW/GFF/V1/fishing_hours')                   .filter(ee.Filter.date('2016-12-01', '2017-01-01')); var trawlers = dataset.select('trawlers'); var trawlersVis = {   min: 0.0,   max: 5.0, }; Map.setCenter(16.201, 36.316, 7); Map.addLayer(trawlers.max(), trawlersVis, 'Trawlers'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GFW_GFF_V1_vessel_hours:
    def __init__(self,):
        self.sensor = 'GFW_GFF_V1_vessel_hours'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GFW_GFF_V1_vessel_hours.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GFW_GFF_V1_vessel_hours.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GFW_GFF_V1_vessel_hours(example: str = ''):
        """
        Fishing vessel presence, measured in hours per square km. Each asset is the vessel presence for a given flag state and day, with one band for the presence of each gear type.  See [sample Earth Engine scripts](https://globalfishingwatch.org/research/global-footprint-of-fisheries/). Also see [the main GFW site](https://GlobalFishingWatch.org) for program information, fully interactive visualization maps, and impacts. 
        :param example: var dataset = ee.ImageCollection('GFW/GFF/V1/vessel_hours')                   .filter(ee.Filter.date('2016-12-01', '2017-01-01')); var trawlers = dataset.select('trawlers'); var trawlersVis = {   min: 0.0,   max: 5.0, }; Map.setCenter(130.61, 34.287, 8); Map.addLayer(trawlers.max(), trawlersVis, 'Trawlers'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLCF_GLS_TCC:
    def __init__(self,):
        self.sensor = 'GLCF_GLS_TCC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLCF_GLS_TCC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLCF_GLS_TCC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLCF_GLS_TCC(example: str = ''):
        """
        The Landsat Vegetation Continuous Fields (VCF) tree cover layers contain estimates of the percentage of horizontal ground in each 30-m pixel covered by woody vegetation greater than 5 meters in height. The data represent three nominal epochs, 2000, 2005 and 2010, compiled from the NASA/USGS Global Land Survey (GLS) collection of Landsat data. The product is derived from all seven bands of Landsat-5 Thematic Mapper (TM) and/or Landsat-7 Enhanced Thematic Mapper Plus (ETM+), depending on the GLS image selection.  Tree cover, the proportional, vertically projected area of vegetation (including leaves, stems, branches, etc.) of woody plants above a given height, affects terrestrial energy and water exchanges, photosynthesis and transpiration, net primary production, and carbon and nutrient fluxes. Tree cover also affects habitat quality and movements of wildlife, residential property value for humans, and other ecosystem services. The continuous classification scheme of the VCF product enables better depiction of land cover gradients than traditional discrete classification schemes. Importantly for detection and monitoring of forest changes (e.g., deforestation and degradation), tree cover provides a measurable attribute upon which to define forest cover and its changes. Changes in tree cover over time can be used to monitor and retrieve site-specific histories of forest change.  The dataset has been produced for three year epochs: 2000, 2005, 2010, with an image in the collection for each available WRS2 path/row. 
        :param example: var dataset = ee.ImageCollection('GLCF/GLS_TCC')                   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var treeCanopyCover = dataset.select('tree_canopy_cover'); var treeCanopyCoverVis = {   min: 0.0,   max: 100.0,   palette: ['ffffff', 'afce56', '5f9c00', '0e6a00', '003800'], }; Map.setCenter(-88.6, 26.4, 3); Map.addLayer(treeCanopyCover, treeCanopyCoverVis, 'Tree Canopy Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLCF_GLS_WATER:
    def __init__(self,):
        self.sensor = 'GLCF_GLS_WATER'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLCF_GLS_WATER.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLCF_GLS_WATER.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLCF_GLS_WATER(example: str = ''):
        """
        The Global Inland Water dataset shows inland surface water bodies, including fresh and saline lakes, rivers, and reservoirs.  From the GLS 2000 epoch, 3,650,723 km2 of inland water were identified, around three quarters of which were in North America and Asia. Boreal forests and tundra hold the largest portion of inland water, about 40% of the global total. The data exhibits strong linear correlation with both the MODIS dataset as well as 30-m resolution datasets over the United States and Canada. Residual errors were due primarily to the seasonality of water cover, snow and ice, and residual clouds.  The dataset contains one or more image for each available Landsat WRS2 path/row.  Documentation:  * [User's guide](https://lpdaac.usgs.gov/documents/1371/GFCC_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1370/GFCC_ATBD.pdf) 
        :param example: var dataset = ee.ImageCollection('GLCF/GLS_WATER'); var water = dataset.select('water'); var waterVis = {   min: 1.0,   max: 4.0,   palette: ['fafafa', '00c5ff', 'df73ff', '828282', 'cccccc'], }; Map.setCenter(-79.3094, 44.5693, 8); Map.addLayer(water, waterVis, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLIMS_2016:
    def __init__(self,):
        self.sensor = 'GLIMS_2016'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLIMS_2016.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLIMS_2016.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLIMS_2016(example: str = ''):
        """
        Global Land Ice Measurements from Space (GLIMS) is an international initiative with the goal of repeatedly surveying the world's estimated 200,000 glaciers.  The project seeks to create a globally comprehensive inventory of land ice, including measurements of glacier area, geometry, surface velocity, and snow line elevation. To perform these analyses, the GLIMS project uses satellite data, primarily from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) and the Landsat Enhanced Thematic Mapper Plus (ETM+), as well as historical information derived from maps and aerial photographs.  Each feature in this dataset is a polygonal boundary of a glacier at the time of analysis.  A few glacier IDs have hundreds of distinct rows over time.  This dataset is a snapshot of the inventory of glacier boundaries as of June 15, 2016, providing over 307,000 rows. 
        :param example: var dataset = ee.FeatureCollection('GLIMS/2016'); var visParams = {   palette: ['gray', 'cyan', 'blue'],   min: 0.0,   max: 10.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.setCenter(-26.763, 73.214, 6); Map.addLayer(image, visParams, 'GLIMS/2016'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLIMS_20171027:
    def __init__(self,):
        self.sensor = 'GLIMS_20171027'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLIMS_20171027.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLIMS_20171027.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLIMS_20171027(example: str = ''):
        """
        Global Land Ice Measurements from Space (GLIMS) is an international initiative with the goal of repeatedly surveying the world's estimated 200,000 glaciers.  The project seeks to create a globally comprehensive inventory of land ice, including measurements of glacier area, geometry, surface velocity, and snow line elevation. To perform these analyses, the GLIMS project uses satellite data, primarily from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) and the Landsat Enhanced Thematic Mapper Plus (ETM+), as well as historical information derived from maps and aerial photographs.  Each feature in this dataset is a polygonal boundary of a glacier at the time of analysis.  A few glacier IDs have hundreds of distinct rows over time.  This dataset is a snapshot of the inventory of glacier boundaries as of October 27, 2017, providing over 690,000 rows. 
        :param example: var dataset = ee.FeatureCollection('GLIMS/20171027'); var visParams = {   palette: ['gray', 'cyan', 'blue'],   min: 0.0,   max: 10.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.setCenter(-35.618, 66.743, 7); Map.addLayer(image, visParams, 'GLIMS/20171027'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLIMS_20210914:
    def __init__(self,):
        self.sensor = 'GLIMS_20210914'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLIMS_20210914.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLIMS_20210914.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLIMS_20210914(example: str = ''):
        """
        Global Land Ice Measurements from Space (GLIMS) is an international initiative with the goal of repeatedly surveying the world's estimated 200,000 glaciers.  The project seeks to create a globally comprehensive inventory of land ice, including measurements of glacier area, geometry, surface velocity, and snow line elevation. To perform these analyses, the GLIMS project uses satellite data, primarily from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) and the Landsat Enhanced Thematic Mapper Plus (ETM+), as well as historical information derived from maps and aerial photographs.  Each feature in this dataset is a polygonal boundary of a glacier at the time of analysis.  A few glacier IDs have hundreds of distinct rows over time.  This dataset is a snapshot of the inventory of glacier boundaries as of September 14, 2021, providing over 690,000 rows. 
        :param example: var dataset = ee.FeatureCollection('GLIMS/20210914'); var visParams = {   palette: ['gray', 'cyan', 'blue'],   min: 0.0,   max: 10.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.setCenter(-35.618, 66.743, 7); Map.addLayer(image, visParams, 'GLIMS/20210914'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLIMS_20230607:
    def __init__(self,):
        self.sensor = 'GLIMS_20230607'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLIMS_20230607.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLIMS_20230607.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLIMS_20230607(example: str = ''):
        """
        Global Land Ice Measurements from Space (GLIMS) is an international initiative with the goal of repeatedly surveying the world's estimated 200,000 glaciers.  The project seeks to create a globally comprehensive inventory of land ice, including measurements of glacier area, geometry, surface velocity, and snow line elevation. To perform these analyses, the GLIMS project uses satellite data, primarily from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) and the Landsat Enhanced Thematic Mapper Plus (ETM+), as well as historical information derived from maps and aerial photographs.  Each feature in this dataset is a polygonal boundary of a glacier at the time of analysis.  A few glacier IDs have hundreds of distinct rows over time.  This dataset is a snapshot of the inventory of glacier boundaries as of June 7, 2023, providing over 1,100,000 rows. 
        :param example: var dataset = ee.FeatureCollection('GLIMS/20230607'); var visParams = {   palette: ['gray', 'cyan', 'blue'],   min: 0.0,   max: 10.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.setCenter(-35.618, 66.743, 7); Map.addLayer(image, visParams, 'GLIMS/20230607'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLIMS_current:
    def __init__(self,):
        self.sensor = 'GLIMS_current'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLIMS_current.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLIMS_current.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLIMS_current(example: str = ''):
        """
        Global Land Ice Measurements from Space (GLIMS) is an international initiative with the goal of repeatedly surveying the world's estimated 200,000 glaciers.  The project seeks to create a globally comprehensive inventory of land ice, including measurements of glacier area, geometry, surface velocity, and snow line elevation. To perform these analyses, the GLIMS project uses satellite data, primarily from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) and the Landsat Enhanced Thematic Mapper Plus (ETM+), as well as historical information derived from maps and aerial photographs.  Each feature in this dataset is a polygonal boundary of a glacier at the time of analysis.  A few glacier IDs have hundreds of distinct rows over time.  This dataset is a snapshot of the inventory of glacier boundaries as of June 7, 2023, providing over 1,100,000 rows. 
        :param example: var dataset = ee.FeatureCollection('GLIMS/current'); var visParams = {   palette: ['gray', 'cyan', 'blue'],   min: 0.0,   max: 10.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.setCenter(-35.618, 66.743, 7); Map.addLayer(image, visParams, 'GLIMS/current'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GLOBAL_FLOOD_DB_MODIS_EVENTS_V1:
    def __init__(self,):
        self.sensor = 'GLOBAL_FLOOD_DB_MODIS_EVENTS_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GLOBAL_FLOOD_DB_MODIS_EVENTS_V1(example: str = ''):
        """
        The Global Flood Database contains maps of the extent and temporal distribution of 913 flood events occurring between 2000-2018. For more information, see [the associated journal article](https://doi.org/10.1038/s41586-021-03695-w).  Flood events were collected from the [Dartmouth Flood Observatory](https://floodobservatory.colorado.edu/) and used to collect MODIS imagery. The selected 913 events are those that were successfully mapped (passed quality control as having significant inundation beyond permanent water) using 12,719 scenes from Terra and Aqua MODIS sensors. Each pixel was classified as water or non-water at 250-meter resolution during the full date range of each flood event and subsequent data products were generated including maximum flood extent ("flooded" band) and the duration of inundation in days ("duration" band). Water and non-water classifications during a flood event include permanent water (here resampling the 30-meter [JRC Global Surface Water dataset](https://global-surface-water.appspot.com/) representing permanent water to 250-meter resolution), which can be masked out to isolate flood water using the "jrc_perm_water" band. Extra data quality bands were added representing cloud conditions during the flood event (e.g., "clear_views" representing the number of clear days the flood was observed between its start and end dates and "clear_perc" representing the percentage of clear day observation of the total event duration in days).  Each image in the ImageCollection represents the map of an individual flood. The collection can be filtered by date, country, or Dartmouth Flood Observatory original ID. 
        :param example: var gfd = ee.ImageCollection('GLOBAL_FLOOD_DB/MODIS_EVENTS/V1');  // An individual flood event - flooding due to Hurricane Isaac in the USA. var hurricaneIsaacDartmouthId = 3977; var hurricaneIsaacUsa = ee.Image(     gfd.filterMetadata('id', 'equals', hurricaneIsaacDartmouthId).first()); Map.setOptions('SATELLITE'); Map.setCenter(-90.2922, 29.4064, 9); Map.addLayer(   hurricaneIsaacUsa.select('flooded').selfMask(),   {min: 0, max: 1, palette: '001133'},   'Hurricane Isaac - Inundation Extent');  // The duration (number of days a flood event lasted). var durationPalette = ['c3effe', '1341e8', '051cb0', '001133']; Map.addLayer(   hurricaneIsaacUsa.select('duration').selfMask(),   {min: 0, max: 4, palette: durationPalette},   'Hurricane Isaac - Duration');  // Map all floods to generate the satellite-observed historical flood plain. var gfdFloodedSum = gfd.select('flooded').sum(); Map.addLayer(   gfdFloodedSum.selfMask(),   {min: 0, max: 10, palette: durationPalette},   'GFD Satellite Observed Flood Plain');  // Overlay permanent water to distinguish flood water. var jrc = gfd.select('jrc_perm_water').sum().gte(1); Map.addLayer(   jrc.selfMask(),   {min: 0, max: 1, palette: 'C3EFFE'},   'JRC Permanent Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_AirView_California_Unified_2015_2019:
    def __init__(self,):
        self.sensor = 'GOOGLE_AirView_California_Unified_2015_2019'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_AirView_California_Unified_2015_2019.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_AirView_California_Unified_2015_2019.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_AirView_California_Unified_2015_2019(example: str = ''):
        """
        This large vector dataset contains high resolution air pollution mapping of NO, NO2, O3, CH4, CO2, BC, PN2.5, and UFP concentrations in California between June 2015 and June 2019.  The dataset consists of measurements collected using four Google Street View vehicles equipped with the Aclima mobile measurement and data integration platform from 2015-05-28 to 2019-06-07.  Not all four cars were actively mapping over the entire time frame.  Note that there may be gaps in the data when an individual car was not mapping due to operational, mechanical, or system difficulties.  Dates of operation for each of the four cars:  * Car A: 2016-05-03 - 2019-04-30 * Car B: 2016-05-03 - 2018-06-08 * Car C: 2015-05-28 - 2019-06-07 * Car D: 2015-06-24 - 2018-11-05  Data was collected in several geographic regions of California including the San Francisco Bay Area, Los Angeles, and the northern San Joaquin Valley. Mapping occurred in targeted neighborhoods or cities within these regions.  The data set contains a table titled "California_Unified_2015_2019" which consists of the concentration of the pollutants Ozone (O3), Nitrogen Dioxide (NO2), Nitrogen Monoxide (NO), Methane (CH4), Carbon Dioxide (CO2), Black Carbon (BC), particle number less than 2.5 micrometers in size (PN2.5), and Ultrafine Particles (UFP)  measured using four Google Street View cars equipped with fast time-response, laboratory-grade instruments. The data was collected at 1-Hz time resolution from 20150528 to 20190607 for roads in three regions of California - the San Francisco Bay area, Los Angeles, and the northern San Joaquin Valley.  Specific areas mapped varied by region based on desired spatial data coverage and science questions.  Each data point is geolocated with latitude and longitude as well as the identity and speed of the car.  For details including methodologies, standards, data providers, metadata field definitions and descriptions, refer to the [metadata](https://docs.google.com/document/d/1If15JccoJcN01Jg3ljN3V-qUFS0HywKAd4OsQ-_JXJo/view). 
        :param example:  var fc = ee.FeatureCollection('GOOGLE/AirView/California_Unified_2015_2019');  var normal = fc.filter('NO2 >= 0 && NO2 < 1'); var mild = fc.filter('NO2 >= 1 && NO2 < 2'); var strong = fc.filter('NO2 >= 2');  Map.addLayer(normal, {color: 'green'}, 'NO2 [0; 1)'); Map.addLayer(mild, {color: 'yellow'}, 'NO2 [1; 2)'); Map.addLayer(strong, {color: 'red'}, 'NO2 >= 2'); Map.setCenter(-122.827746, 38.4001353, 20); Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED:
    def __init__(self,):
        self.sensor = 'GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_CLOUD_SCORE_PLUS_V1_S2_HARMONIZED(example: str = ''):
        """
        Cloud Score+ is a quality assessment (QA) processor for medium-to-high resolution optical satellite imagery. The Cloud Score+ S2_HARMONIZED dataset is being operationally produced from the [harmonized Sentinel-2 L1C collection](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_HARMONIZED), and Cloud Score+ outputs can be used to identify relatively clear pixels and effectively remove clouds and cloud shadows from [L1C (Top-of-Atmosphere)](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_HARMONIZED) or [L2A (Surface Reflectance)](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED) imagery.  The Cloud Score+ S2_HARMONIZED dataset includes two QA bands, `cs` and `cs_cdf`, that both grade the usability of individual pixels with respect to surface visibility on a continuous scale between 0 and 1, where 0 represents "not clear" (occluded), while 1 represents "clear" (unoccluded) observations. The `cs` band scores QA based on a spectral distance between the observed pixel and a (theoretical) clear reference observation, while the `cs_cdf` band represents the likelihood an observed pixel is clear based on an estimated cumulative distribution of scores for a given location through time. In other words, `cs` can be thought of as a more instantaneous atmospheric similarity score (i.e., how similar is this pixel to what we'd expect to see in a perfectly a clear reference), while `cs_cdf` captures an expectation of the estimated score through time (i.e., if we had all the scores for this pixel through time, how would this score rank?).  Images in the Cloud Score+ S2_HARMONIZED collection have the same id and `system:index` properties as the individual [Sentinel-2 L1C](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_HARMONIZED) assets from which they were produced such that Cloud Score+ bands can be linked to source images based on their shared `system:index`.  Cloud Score+ backfill for the entire Sentinel-2 archive is currently in progress and Dataset Availability dates will be updated periodically as new results are added to the Cloud Score+ collection.  For more information about the Cloud Score+ dataset and modelling approach, see [this Medium post](https://medium.com/google-earth/all-clear-with-cloud-score-bd6ee2e2235e). 
        :param example: // Harmonized Sentinel-2 Level 2A collection. var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');  // Cloud Score+ image collection. Note Cloud Score+ is produced from Sentinel-2 // Level 1C data and can be applied to either L1C or L2A collections. var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');  // Region of interest. var ROI = ee.Geometry.Point(-119.9087, 37.4159);  // Use 'cs' or 'cs_cdf', depending on your use case; see docs for guidance. var QA_BAND = 'cs_cdf';  // The threshold for masking; values between 0.50 and 0.65 generally work well. // Higher values will remove thin clouds, haze & cirrus shadows. var CLEAR_THRESHOLD = 0.60;  // Make a clear median composite. var composite = s2     .filterBounds(ROI)     .filterDate('2023-01-01', '2023-02-01')     .linkCollection(csPlus, [QA_BAND])     .map(function(img) {       return img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD));     })     .median();  // Sentinel-2 visualization parameters. var s2Viz = {bands: ['B4', 'B3', 'B2'], min: 0, max: 2500};  Map.addLayer(composite, s2Viz, 'median composite'); Map.centerObject(ROI, 11);
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_DYNAMICWORLD_V1:
    def __init__(self,):
        self.sensor = 'GOOGLE_DYNAMICWORLD_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_DYNAMICWORLD_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_DYNAMICWORLD_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_DYNAMICWORLD_V1(example: str = ''):
        """
        Dynamic World is a 10m near-real-time (NRT) Land Use/Land Cover (LULC) dataset that includes class probabilities and label information for nine classes.  Dynamic World predictions are available for the Sentinel-2 L1C collection from 2015-06-27 to present. The revisit frequency of Sentinel-2 is between 2-5 days depending on latitude. Dynamic World predictions are generated for Sentinel-2 L1C images with CLOUDY_PIXEL_PERCENTAGE <= 35%. Predictions are masked to remove clouds and cloud shadows using a combination of S2 Cloud Probability, Cloud Displacement Index, and Directional Distance Transform.  Images in the Dynamic World collection have names matching the individual Sentinel-2 L1C asset names from which they were derived, e.g:    ee.Image('COPERNICUS/S2/20160711T084022_20160711T084751_T35PKT')  has a matching Dynamic World image named:   ee.Image('GOOGLE/DYNAMICWORLD/V1/20160711T084022_20160711T084751_T35PKT').  All probability bands except the "label" band collectively sum to 1.  To learn more about the Dynamic World dataset and see examples for generating composites, calculating regional statistics, and working with the time series, see the [Introduction to Dynamic World](https://developers.google.com/earth-engine/tutorials/community/introduction-to-dynamic-world-pt-1) tutorial series.  Given Dynamic World class estimations are derived from single images using a spatial context from a small moving window, top-1 "probabilities" for predicted land covers that are in-part defined by cover over time, like crops, can be comparatively low in the absence of obvious distinguishing features. High-return surfaces in arid climates, sand, sunglint, etc may also exhibit this phenomenon.  To select only pixels that confidently belong to a Dynamic World class, it is recommended to mask Dynamic World outputs by thresholding the estimated "probability" of the top-1 prediction. 
        :param example: // Construct a collection of corresponding Dynamic World and Sentinel-2 for // inspection. Filter by region and date. var START = ee.Date('2021-04-02'); var END = START.advance(1, 'day');  var colFilter = ee.Filter.and(     ee.Filter.bounds(ee.Geometry.Point(20.6729, 52.4305)),     ee.Filter.date(START, END));  var dwCol = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1').filter(colFilter); var s2Col = ee.ImageCollection('COPERNICUS/S2_HARMONIZED');  // Link DW and S2 source images. var linkedCol = dwCol.linkCollection(s2Col, s2Col.first().bandNames());  // Get example DW image with linked S2 image. var linkedImg = ee.Image(linkedCol.first());  // Create a visualization that blends DW class label with probability. // Define list pairs of DW LULC label and color. var CLASS_NAMES = [     'water', 'trees', 'grass', 'flooded_vegetation', 'crops',     'shrub_and_scrub', 'built', 'bare', 'snow_and_ice'];  var VIS_PALETTE = [     '419bdf', '397d49', '88b053', '7a87c6', 'e49635', 'dfc35a', 'c4281b',     'a59b8f', 'b39fe1'];  // Create an RGB image of the label (most likely class) on [0, 1]. var dwRgb = linkedImg     .select('label')     .visualize({min: 0, max: 8, palette: VIS_PALETTE})     .divide(255);  // Get the most likely class probability. var top1Prob = linkedImg.select(CLASS_NAMES).reduce(ee.Reducer.max());  // Create a hillshade of the most likely class probability on [0, 1]; var top1ProbHillshade =     ee.Terrain.hillshade(top1Prob.multiply(100))     .divide(255);  // Combine the RGB image with the hillshade. var dwRgbHillshade = dwRgb.multiply(top1ProbHillshade);  // Display the Dynamic World visualization with the source Sentinel-2 image. Map.setCenter(20.6729, 52.4305, 12); Map.addLayer(     linkedImg, {min: 0, max: 3000, bands: ['B4', 'B3', 'B2']}, 'Sentinel-2 L1C'); Map.addLayer(     dwRgbHillshade, {min: 0, max: 0.65}, 'Dynamic World V1 - label hillshade');
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_Research_open_buildings_v1_polygons:
    def __init__(self,):
        self.sensor = 'GOOGLE_Research_open_buildings_v1_polygons'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_Research_open-buildings_v1_polygons.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_Research_open-buildings_v1_polygons.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_Research_open_buildings_v1_polygons(example: str = ''):
        """
        This large-scale open dataset consists of outlines of buildings derived from high-resolution 50 cm satellite imagery. It contains 516M building detections across an area of 19.4M km2 (64% of the African continent).  For each building in this dataset we include the polygon describing its footprint on the ground, a confidence score indicating how sure we are that this is a building, and a [Plus Code](https://plus.codes/) corresponding to the center of the building. There is no information about the type of building, its street address, or any details other than its geometry.  Building footprints are useful for a range of important applications: from population estimation, urban planning and humanitarian response to environmental and climate science. The project being based in Ghana, the current focus is on the continent of Africa.  Inference was carried out during April 2021.  For more details see the official [website](https://sites.research.google/open-buildings/) of the Open Buildings dataset.  Note that updated versions of this data are available. The newest version, Version 3.0 (with inference carried out on May 2023), is available as [GOOGLE/Research/open-buildings/v3/polygons](GOOGLE_Research_open-buildings_v3_polygons). 
        :param example: // Visualization of GOOGLE/Research/open-buildings/v1/polygons.  var t = ee.FeatureCollection('GOOGLE/Research/open-buildings/v1/polygons');  var t_060_065 = t.filter('confidence >= 0.60 && confidence < 0.65'); var t_065_070 = t.filter('confidence >= 0.65 && confidence < 0.70'); var t_gte_070 = t.filter('confidence >= 0.70');  Map.addLayer(t_060_065, {color: 'FF0000'}, 'Buildings confidence [0.60; 0.65)'); Map.addLayer(t_065_070, {color: 'FFFF00'}, 'Buildings confidence [0.65; 0.70)'); Map.addLayer(t_gte_070, {color: '00FF00'}, 'Buildings confidence >= 0.70'); Map.setCenter(3.389, 6.492, 17);  // Lagos, Nigeria Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_Research_open_buildings_v2_polygons:
    def __init__(self,):
        self.sensor = 'GOOGLE_Research_open_buildings_v2_polygons'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_Research_open-buildings_v2_polygons.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_Research_open-buildings_v2_polygons.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_Research_open_buildings_v2_polygons(example: str = ''):
        """
        This large-scale open dataset consists of outlines of buildings derived from high-resolution 50 cm satellite imagery. It contains 816M building detections in Africa, South Asia and Southeast Asia. The inference spanned an area of 39.1M km&#178;.  For each building in this dataset we include the polygon describing its footprint on the ground, a confidence score indicating how sure we are that this is a building, and a [Plus Code](https://plus.codes/) corresponding to the center of the building. There is no information about the type of building, its street address, or any details other than its geometry.  Building footprints are useful for a range of important applications: from population estimation, urban planning and humanitarian response to environmental and climate science. The project being based in Ghana, the current focus is on the continent of Africa.  Inference was carried out during Aug 2022.  For more details see the official [website](https://sites.research.google/open-buildings/) of the Open Buildings dataset.  Note that updated versions of this data are available. The newest version, Version 3.0 (with inference carried out on May 2023), is available as [GOOGLE/Research/open-buildings/v3/polygons](GOOGLE_Research_open-buildings_v3_polygons). 
        :param example: // Visualization of GOOGLE/Research/open-buildings/v2/polygons.  var t = ee.FeatureCollection('GOOGLE/Research/open-buildings/v2/polygons');  var t_060_065 = t.filter('confidence >= 0.60 && confidence < 0.65'); var t_065_070 = t.filter('confidence >= 0.65 && confidence < 0.70'); var t_gte_070 = t.filter('confidence >= 0.70');  Map.addLayer(t_060_065, {color: 'FF0000'}, 'Buildings confidence [0.60; 0.65)'); Map.addLayer(t_065_070, {color: 'FFFF00'}, 'Buildings confidence [0.65; 0.70)'); Map.addLayer(t_gte_070, {color: '00FF00'}, 'Buildings confidence >= 0.70'); Map.setCenter(3.389, 6.492, 17);  // Lagos, Nigeria Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GOOGLE_Research_open_buildings_v3_polygons:
    def __init__(self,):
        self.sensor = 'GOOGLE_Research_open_buildings_v3_polygons'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GOOGLE_Research_open-buildings_v3_polygons.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GOOGLE_Research_open-buildings_v3_polygons.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GOOGLE_Research_open_buildings_v3_polygons(example: str = ''):
        """
        This large-scale open dataset consists of outlines of buildings derived from high-resolution 50 cm satellite imagery. It contains 1.8B building detections in Africa, Latin America, Caribbean, South Asia and Southeast Asia. The inference spanned an area of 58M km&#178;.  For each building in this dataset we include the polygon describing its footprint on the ground, a confidence score indicating how sure we are that this is a building, and a [Plus Code](https://plus.codes/) corresponding to the center of the building. There is no information about the type of building, its street address, or any details other than its geometry.  Building footprints are useful for a range of important applications: from population estimation, urban planning and humanitarian response to environmental and climate science. The project is based in Ghana, with an initial focus on the continent of Africa and new updates on South Asia, South-East Asia, Latin America and the Caribbean.  Inference was carried out during May 2023.  For more details see the official [website](https://sites.research.google/open-buildings/) of the Open Buildings dataset. 
        :param example: // Visualization of GOOGLE/Research/open-buildings/v3/polygons.  var t = ee.FeatureCollection('GOOGLE/Research/open-buildings/v3/polygons');  var t_065_070 = t.filter('confidence >= 0.65 && confidence < 0.7'); var t_070_075 = t.filter('confidence >= 0.7 && confidence < 0.75'); var t_gte_075 = t.filter('confidence >= 0.75');  Map.addLayer(t_065_070, {color: 'FF0000'}, 'Buildings confidence [0.65; 0.7)'); Map.addLayer(t_070_075, {color: 'FFFF00'}, 'Buildings confidence [0.7; 0.75)'); Map.addLayer(t_gte_075, {color: '00FF00'}, 'Buildings confidence >= 0.75'); Map.setCenter(3.389, 6.492, 17);  // Lagos, Nigeria Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class GRIDMET_DROUGHT:
    def __init__(self,):
        self.sensor = 'GRIDMET_DROUGHT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/GRIDMET_DROUGHT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/GRIDMET_DROUGHT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_GRIDMET_DROUGHT(example: str = ''):
        """
        This dataset contains drought indices derived from the 4-km daily Gridded Surface Meteorological (GRIDMET) dataset. The drought indices provided include the standardized precipitation index (SPI), the evaporative drought demand index (EDDI), the standardized precipitation evapotranspiration index (SPEI), the Palmer Drought Severity Index (PDSI) and Palmer Z Index (Z).  SPI, EDDI, and SPEI are supplied on different time scales corresponding to the time aggregation of precipitation, reference evapotranspiration, and precipitation minus reference evapotranspiration, respectively. The time scales include 14 day, 30 day, 90 day, 180 day, 270 day, 1 year, 2 years and 5 years. The standardization is done by using a non-parametric standardized probability based method where plotting positions are used to obtain probabilities which are transformed to indices assuming an inverse-normal distribution. All data are standardized over a common time period of 1981-2016.  PDSI and Z are calculated using a modified version of the Palmer formula which uses reference evapotranspiration and precipitation from GRIDMET, and a static soil water holding capacity layer (top 1500mm) from STATSGO. Modifications to the coefficients of the original Palmer formula are applied to calculate PDSI. The baseline period for PDSI and Z calculations is 1979-2018.  Interpretation of the drought indices in this dataset is different for PDSI and Z than for SPI, SPEI and EDDI. Utilizing the interpretation from the US Drought monitor, values of these drought indices have the following meaning:  PDSI and z:    * 5.0 or more (extremely wet)   * 4.0 to 4.99 (very wet)   * 3.0 to 3.99 (moderately wet),   * 2.0 to 2.99 (slightly wet)   * 1.0 to 1.99 (incipient wet spell)   * -0.99 to 0.99(near normal)   * -1.99 to -1.00 (incipient dry spell)   * -2.99 to -2.00 (mild drought)   * -3.99 to -3.00 (moderate drought)   * -4.99 to -4.00 (severe drought)   * -5.0 or less (extreme drought)  SPI/SPEI/EDDI:    * 2.0 or more (extremely wet)   * 1.6 to 1.99 (very wet)   * 1.3 to 1.59 (moderately wet),   * 0.8 to 1.29 (slightly wet)   * 0.5 to 0.79 (incipient wet spell)   * -0.49 to 0.49(near normal),   * -0.79 to -0.5 (incipient dry spell)   * -1.29 to -0.8 (mild drought)   * -1.59 to -1.3 (moderate drought)   * -1.99 to -1.6 (severe drought)   * -2.0 or less (extreme drought).  This dataset contains provisional products that are replaced with updated versions when the complete source data become available. Products can be distinguished by the value of the 'status' property. At first, assets are ingested with status='early'. After several days, they are replaced by assets with status='provisional'. After about 2 months, they are replaced by the final assets with status='permanent'. 
        :param example: var collection = ee.ImageCollection('GRIDMET/DROUGHT'); print(collection);  // Filter by date var dS = '2020-03-30'; var dE = '2020-03-30'; var dSUTC = ee.Date(dS, 'GMT'); var dEUTC = ee.Date(dE, 'GMT'); var filtered = collection.filterDate(dSUTC, dEUTC.advance(1, 'day')); print(collection.aggregate_array('system:index'));  // Select variables pdsi and z var PDSI = filtered.select('pdsi'); var Z = filtered.select('z');  // Select variables for SPI/SPEI/EDDI // Note that possible timescales for SPI/SPEI/EDDI are: // 14d (14 day), 30d (30 day), 90d (90 day), 180d (180 day), // 1y (1 year), 2y (2 year), 5y (5 year) // Here we choose 2years = 48 months var SPI2y = filtered.select('spi2y'); var SPEI2y = filtered.select('spei2y'); var EDDI2y = filtered.select('spei2y');  // Make a color palette that is similar to USDM drought classification var usdmColors = '0000aa,0000ff,00aaff,00ffff,aaff55,ffffff,ffff00,fcd37f,ffaa00,e60000,730000';  // Make color options for standardized variables spi/spei/eddi var minColorbar= -2.5; var maxColorbar= 2.5; var colorbarOptions1 = {   'min':minColorbar,   'max':maxColorbar,   'palette': usdmColors };  // Make color options for Palmer variables psdi/z var minColorbar= -6; var maxColorbar= 6; var colorbarOptions2 = {   'min':minColorbar,   'max':maxColorbar,   'palette': usdmColors };  // Add map layers to Google Map Map.addLayer(ee.Image(PDSI.first()), colorbarOptions2, 'PDSI'); Map.addLayer(ee.Image(Z.first()), colorbarOptions2, 'Palmer-Z'); Map.addLayer(ee.Image(SPI2y.first()), colorbarOptions1, 'SPI-48months'); Map.addLayer(ee.Image(SPEI2y.first()), colorbarOptions1, 'SPEI-48months'); Map.addLayer(ee.Image(EDDI2y.first()), colorbarOptions1, 'EDDI-48months'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_GLBu0_08_sea_surface_elevation:
    def __init__(self,):
        self.sensor = 'HYCOM_GLBu0_08_sea_surface_elevation'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_GLBu0_08_sea_surface_elevation.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_GLBu0_08_sea_surface_elevation.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_GLBu0_08_sea_surface_elevation(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: var dataset = ee.ImageCollection('HYCOM/GLBu0_08/sea_surface_elevation')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var surfaceElevation = dataset.select('surface_elevation'); var surfaceElevationVis = {   min: -2000.0,   max: 2000.0,   palette: ['blue', 'cyan', 'yellow', 'red'], }; Map.setCenter(-28.1, 28.3, 1); Map.addLayer(surfaceElevation, surfaceElevationVis, 'Surface Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_GLBu0_08_sea_temp_salinity:
    def __init__(self,):
        self.sensor = 'HYCOM_GLBu0_08_sea_temp_salinity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_GLBu0_08_sea_temp_salinity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_GLBu0_08_sea_temp_salinity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_GLBu0_08_sea_temp_salinity(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: var dataset = ee.ImageCollection('HYCOM/GLBu0_08/sea_temp_salinity')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var seaWaterTemperature = dataset.select('sst_0'); var visParams = {   min: -20000.0,   max: 15000.0,   palette: ['000000', '005aff', '43c8c8', 'fff700', 'ff0000'], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(seaWaterTemperature, visParams, 'Sea Water Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_GLBu0_08_sea_water_velocity:
    def __init__(self,):
        self.sensor = 'HYCOM_GLBu0_08_sea_water_velocity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_GLBu0_08_sea_water_velocity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_GLBu0_08_sea_water_velocity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_GLBu0_08_sea_water_velocity(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: var dataset = ee.ImageCollection('HYCOM/GLBu0_08/sea_water_velocity')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var waterVelocityVis = {   min: -1000.0,   max: 4000.0,   bands: ['velocity_u_0', 'velocity_v_0', 'velocity_v_0'], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(dataset, waterVelocityVis, 'Water Velocity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_sea_surface_elevation:
    def __init__(self,):
        self.sensor = 'HYCOM_sea_surface_elevation'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_sea_surface_elevation.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_sea_surface_elevation.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_sea_surface_elevation(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: var dataset = ee.ImageCollection('HYCOM/sea_surface_elevation')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var surfaceElevation = dataset.select('surface_elevation'); var surfaceElevationVis = {   min: -2000.0,   max: 2000.0,   palette: ['blue', 'cyan', 'yellow', 'red'], }; Map.setCenter(-28.1, 28.3, 1); Map.addLayer(surfaceElevation, surfaceElevationVis, 'Surface Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_sea_temp_salinity:
    def __init__(self,):
        self.sensor = 'HYCOM_sea_temp_salinity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_sea_temp_salinity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_sea_temp_salinity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_sea_temp_salinity(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: // Import the time series of global images, filter 15 days in August, 2018. var dataset = ee.ImageCollection('HYCOM/sea_temp_salinity')     .filter(ee.Filter.date('2018-08-01', '2018-08-15'));  // Select water temperature at 0 meters and scale to degrees C. var seaWaterTemperature = dataset.select('water_temp_0')     .map(function scaleAndOffset(image) {       return ee.Image(image).multiply(0.001).add(20);     });  // Define visualization parameters. var visParams = {   min: -2.0,  // Degrees C   max: 34.0,   palette: ['000000', '005aff', '43c8c8', 'fff700', 'ff0000'], };  // Display mean 15-day temperature on the map. Map.setCenter(-88.6, 26.4, 1); Map.addLayer(seaWaterTemperature.mean(), visParams, 'Sea Water Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class HYCOM_sea_water_velocity:
    def __init__(self,):
        self.sensor = 'HYCOM_sea_water_velocity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/HYCOM_sea_water_velocity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/HYCOM_sea_water_velocity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_HYCOM_sea_water_velocity(example: str = ''):
        """
        The Hybrid Coordinate Ocean Model (HYCOM) is a data-assimilative hybrid isopycnal-sigma-pressure (generalized) coordinate ocean model. The subset of HYCOM data hosted in EE contains the variables salinity, temperature, velocity, and elevation. They have been interpolated to a uniform 0.08 degree lat/long grid between 80.48°S and 80.48°N. The salinity, temperature, and velocity variables have been interpolated to 40 standard z-levels.  The HYCOM Consortium, which includes the National Ocean Partnership Program (NOPP), is part of the U.S. Global Ocean Data Assimilation Experiment (GODAE).  Funded by the National Ocean Partnership Program, the Office of Naval Research (ONR), and DoD High Performance Computing Modernization Program.  For more information, see:  - [hycom.org](https://www.hycom.org/) - [GIS StackExchange hycom](https://gis.stackexchange.com/questions/tagged/hycom) - Wikipedia [HyCOM](https://en.wikipedia.org/wiki/HyCOM) - Wikipedia [List of ocean circulation models](https://en.wikipedia.org/wiki/List_of_ocean_circulation_models) - Wikipedia [Ocean general circulation model (OGCM)](https://en.wikipedia.org/wiki/Ocean_general_circulation_model) 
        :param example: var velocity = ee.Image('HYCOM/sea_water_velocity/2014040700').divide(1000);  // Compute speed from velocity. Map.addLayer(     velocity.select('velocity_u_0').hypot(velocity.select('velocity_v_0')));  Map.setCenter(-60, 33, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IDAHO_EPSCOR_GRIDMET:
    def __init__(self,):
        self.sensor = 'IDAHO_EPSCOR_GRIDMET'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IDAHO_EPSCOR_GRIDMET.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IDAHO_EPSCOR_GRIDMET.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IDAHO_EPSCOR_GRIDMET(example: str = ''):
        """
        The Gridded Surface Meteorological dataset provides high spatial resolution (~4-km) daily surface fields of temperature, precipitation, winds, humidity and radiation across the contiguous United States from 1979. The dataset blends the high resolution spatial data from PRISM with the high temporal resolution data from the National Land Data Assimilation System (NLDAS) to produce spatially and temporally continuous fields that lend themselves to additional land surface modeling.  This dataset contains provisional products that are replaced with updated versions when the complete source data become available. Products can be distinguished by the value of the 'status' property. At first, assets are ingested with status='early'. After several days, they are replaced by assets with status='provisional'. After about 2 months, they are replaced by the final assets with status='permanent'. 
        :param example: var dataset = ee.ImageCollection('IDAHO_EPSCOR/GRIDMET')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var maximumTemperature = dataset.select('tmmx'); var maximumTemperatureVis = {   min: 290.0,   max: 314.0,   palette: ['d8d8d8', '4addff', '5affa3', 'f2ff89', 'ff725c'], }; Map.setCenter(-115.356, 38.686, 5); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IDAHO_EPSCOR_MACAv2_METDATA:
    def __init__(self,):
        self.sensor = 'IDAHO_EPSCOR_MACAv2_METDATA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IDAHO_EPSCOR_MACAv2_METDATA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IDAHO_EPSCOR_MACAv2_METDATA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IDAHO_EPSCOR_MACAv2_METDATA(example: str = ''):
        """
        The MACAv2-METDATA dataset is a collection of 20 global climate models covering the conterminous USA. The Multivariate Adaptive Constructed Analogs (MACA) method is a statistical downscaling method which utilizes a training dataset (i.e. a meteorological observation dataset) to remove historical biases and match spatial patterns in climate model output.  The MACA method was used to downscale the model output from 20 global climate models (GCMs) of the Coupled Model Inter-Comparison Project 5 (CMIP5) for the historical GCM forcings (1950-2005) and the future Representative Concentration Pathways (RCPs) RCP 4.5 and RCP 8.5 scenarios (2006-2100) from the native resolution of the GCMS to 4km.  The full list of models can be found at: [https://climate.northwestknowledge.net/MACA/GCMs.php](https://climate.northwestknowledge.net/MACA/GCMs.php) 
        :param example: var dataset = ee.ImageCollection('IDAHO_EPSCOR/MACAv2_METDATA')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var maximumTemperature = dataset.select('tasmax'); var maximumTemperatureVis = {   min: 290.0,   max: 314.0,   palette: ['d8d8d8', '4addff', '5affa3', 'f2ff89', 'ff725c'], }; Map.setCenter(-84.37, 33.5, 5); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IDAHO_EPSCOR_MACAv2_METDATA_MONTHLY:
    def __init__(self,):
        self.sensor = 'IDAHO_EPSCOR_MACAv2_METDATA_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IDAHO_EPSCOR_MACAv2_METDATA_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IDAHO_EPSCOR_MACAv2_METDATA_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IDAHO_EPSCOR_MACAv2_METDATA_MONTHLY(example: str = ''):
        """
        The MACAv2-METDATA dataset is a collection of 20 global climate models covering the conterminous USA. The Multivariate Adaptive Constructed Analogs (MACA) method is a statistical downscaling method which utilizes a training dataset (i.e. a meteorological observation dataset) to remove historical biases and match spatial patterns in climate model output.  The MACA method was used to downscale the model output from 20 global climate models (GCMs) of the Coupled Model Inter-Comparison Project 5 (CMIP5) for the historical GCM forcings (1950-2005) and the future Representative Concentration Pathways (RCPs) RCP 4.5 and RCP 8.5 scenarios (2006-2100) from the native resolution of the GCMS to 4km.  This version contains monthly summaries.  The full list of models can be found at: [https://climate.northwestknowledge.net/MACA/GCMs.php](https://climate.northwestknowledge.net/MACA/GCMs.php) 
        :param example: var dataset = ee.ImageCollection('IDAHO_EPSCOR/MACAv2_METDATA_MONTHLY')                   .filter(ee.Filter.date('2018-07-01', '2018-08-01')); var maximumTemperature = dataset.select('tasmax'); var maximumTemperatureVis = {   min: 290.0,   max: 314.0,   palette: ['d8d8d8', '4addff', '5affa3', 'f2ff89', 'ff725c'], }; Map.setCenter(-115.356, 38.686, 5); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IDAHO_EPSCOR_PDSI:
    def __init__(self,):
        self.sensor = 'IDAHO_EPSCOR_PDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IDAHO_EPSCOR_PDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IDAHO_EPSCOR_PDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IDAHO_EPSCOR_PDSI(example: str = ''):
        """
        The Palmer Drought Severity Index dataset provides high spatial resolution (~4-km) thrice-monthly estimates of this widely used measure of integrated water supply and demand anomalies across the contiguous United States from 1979-present. The PDSI is calculated using precipitation and potential evapotranspiration derived from the gridded meteorological dataset of Abatzoglou (2013).  Potential evapotranspiration is computed using the Penman-Montieth equation for a reference grass surface. Available soil water holding capacity in the top 2.5m of the soil was derived from the STATSGO soils database and used in the computations. Whereas PDSI has typically been computed on monthly timescales, we compute these data three-times a month to provide more timely updates. Due to the spin-up of PDSI calculations, data for the first year of record should be used sparingly.  This dataset contains provisional products that are replaced with updated versions when the complete source data become available. Products can be distinguished by the value of the 'status' property. At first, assets are ingested with status='early'. After several days, they are replaced by assets with status='provisional'. After about 2 months, they are replaced by the final assets with status='permanent'. 
        :param example: var dataset = ee.ImageCollection('IDAHO_EPSCOR/PDSI')                   .filter(ee.Filter.date('2018-07-01', '2018-08-01')); var pdsi = dataset.select('pdsi'); var pdsiVis = {   min: -5.0,   max: 10.0,   palette: ['red', 'yellow', 'green', 'cyan', 'blue'], }; Map.setCenter(-115.356, 38.686, 5); Map.addLayer(pdsi, pdsiVis, 'PDSI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IDAHO_EPSCOR_TERRACLIMATE:
    def __init__(self,):
        self.sensor = 'IDAHO_EPSCOR_TERRACLIMATE'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IDAHO_EPSCOR_TERRACLIMATE.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IDAHO_EPSCOR_TERRACLIMATE.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IDAHO_EPSCOR_TERRACLIMATE(example: str = ''):
        """
        TerraClimate is a dataset of monthly climate and climatic water balance for global terrestrial surfaces. It uses climatically aided interpolation, combining high-spatial resolution climatological normals from the [WorldClim dataset](https://www.worldclim.org/), with coarser spatial resolution, but time-varying data from [CRU Ts4.0](https://data.ceda.ac.uk/badc/cru/data/cru_ts/) and the [Japanese 55-year Reanalysis (JRA55)](https://jra.kishou.go.jp/JRA-55/index_en.html). Conceptually, the procedure applies interpolated time-varying anomalies from CRU Ts4.0/JRA55 to the high-spatial resolution climatology of WorldClim to create a high-spatial resolution dataset that covers a broader temporal record.  Temporal information is inherited from CRU Ts4.0 for most global land surfaces for temperature, precipitation, and vapor pressure. However, JRA55 data is used for regions where CRU data had zero climate stations contributing (including all of Antarctica, and parts of Africa, South America, and scattered islands). For primary climate variables of temperature, vapor pressure, and precipitation, the University of Idaho provides additional data on the number of stations (between 0 and 8) that contributed to the CRU Ts4.0 data used by TerraClimate. JRA55 was used exclusively for solar radiation and wind speeds.  TerraClimate additionally produces monthly surface water balance datasets using a water balance model that incorporates reference evapotranspiration, precipitation, temperature, and interpolated plant extractable soil water capacity. A modified Thornthwaite-Mather climatic water-balance model and extractable soil water storage capacity data was used at a 0.5° grid from Wang-Erlandsson et al. (2016).  Data Limitations:   1. Long-term trends in data are inherited from parent datasets.     TerraClimate should not be used directly for independent assessments of     trends.   2. TerraClimate will not capture temporal variability at finer scales than     parent datasets and thus is not able to capture variability in     orographic precipitation ratios and inversions.   3. The water balance model is very simple and does not account for     heterogeneity in vegetation types or their physiological response to     changing environmental conditions.   4. Limited validation in data-sparse regions (e.g., Antarctica). 
        :param example: var dataset = ee.ImageCollection('IDAHO_EPSCOR/TERRACLIMATE')                   .filter(ee.Filter.date('2017-07-01', '2017-08-01')); var maximumTemperature = dataset.select('tmmx'); var maximumTemperatureVis = {   min: -300.0,   max: 300.0,   palette: [     '1a3678', '2955bc', '5699ff', '8dbae9', 'acd1ff', 'caebff', 'e5f9ff',     'fdffb4', 'ffe6a2', 'ffc969', 'ffa12d', 'ff7c1f', 'ca531a', 'ff0000',     'ab0000'   ], }; Map.setCenter(71.72, 52.48, 3); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class IGN_RGE_ALTI_1M_2_0:
    def __init__(self,):
        self.sensor = 'IGN_RGE_ALTI_1M_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/IGN_RGE_ALTI_1M_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/IGN_RGE_ALTI_1M_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_IGN_RGE_ALTI_1M_2_0(example: str = ''):
        """
        The RGE ALTI dataset describes the digital elevation model (DEM) of France with the pixel size of 1m.  It was created from surveys obtained by airborne lidar or by correlation of aerial images.  Lidar was deployed for flood-prone, coastal, and large forest areas. The vertical accuracy of the DEM in these areas is between 0.2m and 0.5m. Radar was used in mountain areas (Alps, Pyrenees, Cevennes, Corsica). Caution: in areas with steep slopes, the average vertical accuracy is the order of 7m.  The accuracy of these fields has been checked against various sources: the road and hydrographic networks of the [BD TOPO](https://geoservices.ign.fr/bdtopo), geodetic terminals and points calculated on the ground.  Aerial photo correlation techniques are used in the rest of the territory. On certain zones treated by correlation, ground measurements are absent over large extents due to the presence of vegetation (wooded areas, for example). 1987-2001 altimetry data (BD Alti) are used to fill these gaps. The vertical accuracy of the DEM on these areas is between 0.5m and 0.7m.  Currently the collection includes a single image IGN/RGE_ALTI/1M/2_0/FXX showing metropolitan France.  This dataset was prepared and ingested with the support of Guillaume Attard and Julien Bardonnet ([AGEOCE](https://www.ageoce.com)). The preparation process is [described here](https://medium.com/@gui.attard/pre-processing-the-dem-of-france-rge-alti-5m-for-implementation-into-earth-engine-de9a0778e0d9).  See also: [user's guide](https://geoservices.ign.fr/sites/default/files/2021-07/DC_RGEALTI_2-0.pdf).  
        :param example: var dataset = ee.Image('IGN/RGE_ALTI/1M/2_0/FXX'); var elevation = dataset.select('MNT');  var elevationVis = {   min: 0,   max: 1000,   palette: ['006600', '002200', 'fff700', 'ab7634', 'c4d0ff', 'ffffff'] };  Map.addLayer(elevation, elevationVis, 'Elevation'); Map.setCenter(3, 47, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_aluminium_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_aluminium_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_aluminium_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_aluminium_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_aluminium_extractable(example: str = ''):
        """
        Extractable aluminium at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil).  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen. 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-21.2" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#0C0927" label="21.2-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#231151" label="35.6-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#410F75" label="53.6-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#5F187F" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#7B2382" label="72.7-80.5" opacity="1" quantity="44"/>' +   '<ColorMapEntry color="#982D80" label="80.5-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#B63679" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#D3436E" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#EB5760" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#F8765C" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FD9969" label="133.3-147.4" opacity="1" quantity="50"/>' +   '<ColorMapEntry color="#FEBA80" label="147.4-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#FDDC9E" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#FCFDBF" label="199.3-1800" opacity="1" quantity="55"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-21.2" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#0C0927" label="21.2-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#231151" label="35.6-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#410F75" label="53.6-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#5F187F" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#7B2382" label="72.7-80.5" opacity="1" quantity="44"/>' +   '<ColorMapEntry color="#982D80" label="80.5-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#B63679" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#D3436E" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#EB5760" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#F8765C" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FD9969" label="133.3-147.4" opacity="1" quantity="50"/>' +   '<ColorMapEntry color="#FEBA80" label="147.4-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#FDDC9E" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#FCFDBF" label="199.3-1800" opacity="1" quantity="55"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="14"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="14"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  Map.setCenter(25, -3, 2);  var raw = ee.Image("ISDASOIL/Africa/v1/aluminium_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Aluminium, extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Aluminium, extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Aluminium, extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Aluminium, extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1); Map.addLayer(     converted.select(0), {min: 0, max: 100},     "Aluminium, extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_bedrock_depth:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_bedrock_depth'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_bedrock_depth.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_bedrock_depth.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_bedrock_depth(example: str = ''):
        """
        Depth to bedrock at 0-200 cm depth, predicted mean and standard deviation.  Due to the potential cropland mask that was used for generating the data, many areas of exposed rock (where depth to bedrock would be 0 cm) have been masked out and therefore appear as nodata values. The maximum depth of this layer is 200 cm, but this does not represent the maximum possible soil depth, therefore values of 200 should be interpreted as >= 200.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_200 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-13" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#002D6C" label="13-26" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#16396D" label="26-39" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#36476B" label="39-52" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#4B546C" label="52-65" opacity="1" quantity="65"/>' +   '<ColorMapEntry color="#5C616E" label="65-78" opacity="1" quantity="78"/>' +   '<ColorMapEntry color="#6C6E72" label="78-91" opacity="1" quantity="91"/>' +   '<ColorMapEntry color="#7C7B78" label="91-104" opacity="1" quantity="104"/>' +   '<ColorMapEntry color="#8E8A79" label="104-117" opacity="1" quantity="117"/>' +   '<ColorMapEntry color="#A09877" label="117-130" opacity="1" quantity="130"/>' +   '<ColorMapEntry color="#B3A772" label="130-143" opacity="1" quantity="143"/>' +   '<ColorMapEntry color="#C6B66B" label="143-156" opacity="1" quantity="156"/>' +   '<ColorMapEntry color="#DBC761" label="156-169" opacity="1" quantity="169"/>' +   '<ColorMapEntry color="#F0D852" label="169-182" opacity="1" quantity="182"/>' +   '<ColorMapEntry color="#FFEA46" label="182-200" opacity="1" quantity="195"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_200 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="25"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/bedrock_depth"); Map.addLayer(     raw.select(0).sldStyle(mean_0_200), {},     "Bedrock depth, mean visualization, 0-200 cm"); Map.addLayer(     raw.select(1).sldStyle(stdev_0_200), {},     "Bedrock depth, stdev visualization, 0-200 cm");  var visualization = {min: 27, max: 200};  Map.setCenter(25, -3, 2);  Map.addLayer(raw.select(0), visualization, "Bedrock depth, mean, 0-200 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_bulk_density:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_bulk_density'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_bulk_density.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_bulk_density.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_bulk_density(example: str = ''):
        """
        Bulk density, <2mm fraction at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `x/100`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0.8-1.05" opacity="1" quantity="105"/>' +   '<ColorMapEntry color="#002D6C" label="1.05-1.19" opacity="1" quantity="119"/>' +   '<ColorMapEntry color="#16396D" label="1.19-1.23" opacity="1" quantity="123"/>' +   '<ColorMapEntry color="#36476B" label="1.23-1.25" opacity="1" quantity="125"/>' +   '<ColorMapEntry color="#4B546C" label="1.25-1.28" opacity="1" quantity="128"/>' +   '<ColorMapEntry color="#5C616E" label="1.28-1.31" opacity="1" quantity="131"/>' +   '<ColorMapEntry color="#6C6E72" label="1.31-1.34" opacity="1" quantity="134"/>' +   '<ColorMapEntry color="#7C7B78" label="1.34-1.36" opacity="1" quantity="136"/>' +   '<ColorMapEntry color="#8E8A79" label="1.36-1.38" opacity="1" quantity="138"/>' +   '<ColorMapEntry color="#A09877" label="1.38-1.41" opacity="1" quantity="141"/>' +   '<ColorMapEntry color="#B3A772" label="1.41-1.43" opacity="1" quantity="143"/>' +   '<ColorMapEntry color="#C6B66B" label="1.43-1.45" opacity="1" quantity="145"/>' +   '<ColorMapEntry color="#DBC761" label="1.45-1.48" opacity="1" quantity="148"/>' +   '<ColorMapEntry color="#F0D852" label="1.48-1.51" opacity="1" quantity="151"/>' +   '<ColorMapEntry color="#FFEA46" label="1.51-1.85" opacity="1" quantity="154"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0.8-1.05" opacity="1" quantity="105"/>' +   '<ColorMapEntry color="#002D6C" label="1.05-1.19" opacity="1" quantity="119"/>' +   '<ColorMapEntry color="#16396D" label="1.19-1.23" opacity="1" quantity="123"/>' +   '<ColorMapEntry color="#36476B" label="1.23-1.25" opacity="1" quantity="125"/>' +   '<ColorMapEntry color="#4B546C" label="1.25-1.28" opacity="1" quantity="128"/>' +   '<ColorMapEntry color="#5C616E" label="1.28-1.31" opacity="1" quantity="131"/>' +   '<ColorMapEntry color="#6C6E72" label="1.31-1.34" opacity="1" quantity="134"/>' +   '<ColorMapEntry color="#7C7B78" label="1.34-1.36" opacity="1" quantity="136"/>' +   '<ColorMapEntry color="#8E8A79" label="1.36-1.38" opacity="1" quantity="138"/>' +   '<ColorMapEntry color="#A09877" label="1.38-1.41" opacity="1" quantity="141"/>' +   '<ColorMapEntry color="#B3A772" label="1.41-1.43" opacity="1" quantity="143"/>' +   '<ColorMapEntry color="#C6B66B" label="1.43-1.45" opacity="1" quantity="145"/>' +   '<ColorMapEntry color="#DBC761" label="1.45-1.48" opacity="1" quantity="148"/>' +   '<ColorMapEntry color="#F0D852" label="1.48-1.51" opacity="1" quantity="151"/>' +   '<ColorMapEntry color="#FFEA46" label="1.51-1.85" opacity="1" quantity="154"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="9"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="9"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/bulk_density"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Bulk density, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Bulk density, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Bulk density, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Bulk density, stdev visualization, 20-50 cm");  var converted = raw.divide(100);  var visualization = {min: 1, max: 1.5};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Bulk density, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_calcium_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_calcium_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_calcium_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_calcium_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_calcium_extractable(example: str = ''):
        """
        Extractable calcium at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#350498" label="65.7-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#5402A3" label="120.5-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#7000A8" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#8B0AA5" label="199.3-269.4" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#A31E9A" label="269.4-329.3" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#B93289" label="329.3-402.4" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#CC4678" label="402.4-491.7" opacity="1" quantity="62"/>' +   '<ColorMapEntry color="#DB5C68" label="491.7-600.8" opacity="1" quantity="64"/>' +   '<ColorMapEntry color="#E97158" label="600.8-664.1" opacity="1" quantity="65"/>' +   '<ColorMapEntry color="#F48849" label="664.1-811.4" opacity="1" quantity="67"/>' +   '<ColorMapEntry color="#FBA139" label="811.4-896.8" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#FEBC2A" label="896.8-1095.6" opacity="1" quantity="70"/>' +   '<ColorMapEntry color="#FADA24" label="1095.6-1479.3" opacity="1" quantity="73"/>' +   '<ColorMapEntry color="#F0F921" label="1479.3-12000" opacity="1" quantity="77"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#350498" label="65.7-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#5402A3" label="120.5-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#7000A8" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#8B0AA5" label="199.3-269.4" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#A31E9A" label="269.4-329.3" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#B93289" label="329.3-402.4" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#CC4678" label="402.4-491.7" opacity="1" quantity="62"/>' +   '<ColorMapEntry color="#DB5C68" label="491.7-600.8" opacity="1" quantity="64"/>' +   '<ColorMapEntry color="#E97158" label="600.8-664.1" opacity="1" quantity="65"/>' +   '<ColorMapEntry color="#F48849" label="664.1-811.4" opacity="1" quantity="67"/>' +   '<ColorMapEntry color="#FBA139" label="811.4-896.8" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#FEBC2A" label="896.8-1095.6" opacity="1" quantity="70"/>' +   '<ColorMapEntry color="#FADA24" label="1095.6-1479.3" opacity="1" quantity="73"/>' +   '<ColorMapEntry color="#F0F921" label="1479.3-12000" opacity="1" quantity="77"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/calcium_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Calcium, extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Calcium, extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Calcium, extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Calcium, extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 100, max: 2000};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Calcium, extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_carbon_organic:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_carbon_organic'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_carbon_organic.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_carbon_organic.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_carbon_organic(example: str = ''):
        """
        Organic carbon at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#0C0927" label="2.3-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#231151" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#410F75" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#5F187F" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#7B2382" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#982D80" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#B63679" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#D3436E" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#EB5760" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#F8765C" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FD9969" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FEBA80" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#FDDC9E" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#FCFDBF" label="13.9-40" opacity="1" quantity="28"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#0C0927" label="2.3-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#231151" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#410F75" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#5F187F" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#7B2382" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#982D80" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#B63679" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#D3436E" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#EB5760" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#F8765C" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FD9969" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FEBA80" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#FDDC9E" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#FCFDBF" label="13.9-40" opacity="1" quantity="28"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/carbon_organic"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Carbon, organic, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Carbon, organic, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Carbon, organic, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Carbon, organic, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 20};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Carbon, organic, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_carbon_total:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_carbon_total'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_carbon_total.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_carbon_total.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_carbon_total(example: str = ''):
        """
        Total carbon at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#0C0927" label="2-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#231151" label="5.7-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#410F75" label="10-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#5F187F" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#7B2382" label="13.9-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#982D80" label="15.4-17.2" opacity="1" quantity="29"/>' +   '<ColorMapEntry color="#B63679" label="17.2-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#D3436E" label="19.1-21.2" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#EB5760" label="21.2-23.5" opacity="1" quantity="32"/>' +   '<ColorMapEntry color="#F8765C" label="23.5-26.1" opacity="1" quantity="33"/>' +   '<ColorMapEntry color="#FD9969" label="26.1-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#FEBA80" label="29-32.1" opacity="1" quantity="35"/>' +   '<ColorMapEntry color="#FDDC9E" label="32.1-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#FCFDBF" label="35.6-40" opacity="1" quantity="39"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#0C0927" label="2-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#231151" label="5.7-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#410F75" label="10-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#5F187F" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#7B2382" label="13.9-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#982D80" label="15.4-17.2" opacity="1" quantity="29"/>' +   '<ColorMapEntry color="#B63679" label="17.2-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#D3436E" label="19.1-21.2" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#EB5760" label="21.2-23.5" opacity="1" quantity="32"/>' +   '<ColorMapEntry color="#F8765C" label="23.5-26.1" opacity="1" quantity="33"/>' +   '<ColorMapEntry color="#FD9969" label="26.1-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#FEBA80" label="29-32.1" opacity="1" quantity="35"/>' +   '<ColorMapEntry color="#FDDC9E" label="32.1-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#FCFDBF" label="35.6-40" opacity="1" quantity="39"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/carbon_total"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Carbon, total, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Carbon, total, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Carbon, total, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Carbon, total, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 60};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Carbon, total, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_cation_exchange_capacity:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_cation_exchange_capacity'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_cation_exchange_capacity.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_cation_exchange_capacity.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_cation_exchange_capacity(example: str = ''):
        """
        Effective Cation Exchange Capacity predicted mean and standard deviation at soil depths of 0-20 cm and 20-50 cm,  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#0C0927" label="3.5-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#231151" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#410F75" label="5-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#5F187F" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#7B2382" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#982D80" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#B63679" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#D3436E" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#EB5760" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#F8765C" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#FD9969" label="13.9-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#FEBA80" label="15.4-17.2" opacity="1" quantity="29"/>' +   '<ColorMapEntry color="#FDDC9E" label="17.2-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#FCFDBF" label="19.1-130" opacity="1" quantity="31"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#0C0927" label="3.5-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#231151" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#410F75" label="5-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#5F187F" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#7B2382" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#982D80" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#B63679" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#D3436E" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#EB5760" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#F8765C" label="12.5-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#FD9969" label="13.9-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#FEBA80" label="15.4-17.2" opacity="1" quantity="29"/>' +   '<ColorMapEntry color="#FDDC9E" label="17.2-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#FCFDBF" label="19.1-130" opacity="1" quantity="31"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/cation_exchange_capacity"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Cation exchange capacity, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Cation exchange capacity, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Cation exchange capacity, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Cation exchange capacity, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 25};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Cation exchange capacity, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_clay_content:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_clay_content'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_clay_content.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_clay_content.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_clay_content(example: str = ''):
        """
        Clay content at soil depths of 0-20 cm and 20-50 cm,\npredicted mean and standard deviation. In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-8" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#002D6C" label="8-14" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#16396D" label="14-17" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#36476B" label="17-19" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#4B546C" label="19-21" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#5C616E" label="21-22" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#6C6E72" label="22-24" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#7C7B78" label="24-25" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#8E8A79" label="25-26" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#A09877" label="26-28" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#B3A772" label="28-30" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#C6B66B" label="30-31" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#DBC761" label="31-33" opacity="1" quantity="33"/>' +   '<ColorMapEntry color="#F0D852" label="33-36" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#FFEA46" label="36-70" opacity="1" quantity="40"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-8" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#002D6C" label="8-14" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#16396D" label="14-17" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#36476B" label="17-19" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#4B546C" label="19-21" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#5C616E" label="21-22" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#6C6E72" label="22-24" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#7C7B78" label="24-25" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#8E8A79" label="25-26" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#A09877" label="26-28" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#B3A772" label="28-30" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#C6B66B" label="30-31" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#DBC761" label="31-33" opacity="1" quantity="33"/>' +   '<ColorMapEntry color="#F0D852" label="33-36" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#FFEA46" label="36-70" opacity="1" quantity="40"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/clay_content"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Clay content, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Clay content, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Clay content, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Clay content, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 50};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Clay content, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_fcc:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_fcc'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_fcc.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_fcc.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_fcc(example: str = ''):
        """
        Soil fertility capability classification derived using slope, chemical, and physical soil properties.  For more information about this layer, please visit [this page](https://www.isda-africa.com/isdasoil/faq/#faq7).  The classes for the 'fcc' band apply to pixel values that must be back-transformed with `x modulo 3000`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var raw = ee.Image("ISDASOIL/Africa/v1/fcc").select(0);  var converted = ee.Image(raw.mod(3000).copyProperties(raw));  Map.setCenter(25, -3, 2);  Map.addLayer(converted, {}, "Fertility Capability Classification"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_iron_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_iron_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_iron_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_iron_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_iron_extractable(example: str = ''):
        """
        Extractable iron at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#350498" label="6.4-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#5402A3" label="13.9-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#7000A8" label="29-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#8B0AA5" label="35.6-43.7" opacity="1" quantity="38"/>' +   '<ColorMapEntry color="#A31E9A" label="43.7-48.4" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#B93289" label="48.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#CC4678" label="53.6-59.3" opacity="1" quantity="41"/>' +   '<ColorMapEntry color="#DB5C68" label="59.3-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#E97158" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#F48849" label="72.7-80.5" opacity="1" quantity="44"/>' +   '<ColorMapEntry color="#FBA139" label="80.5-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#FEBC2A" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#FADA24" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#F0F921" label="108.9-1200" opacity="1" quantity="48"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#350498" label="6.4-13.9" opacity="1" quantity="27"/>' +   '<ColorMapEntry color="#5402A3" label="13.9-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#7000A8" label="29-35.6" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#8B0AA5" label="35.6-43.7" opacity="1" quantity="38"/>' +   '<ColorMapEntry color="#A31E9A" label="43.7-48.4" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#B93289" label="48.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#CC4678" label="53.6-59.3" opacity="1" quantity="41"/>' +   '<ColorMapEntry color="#DB5C68" label="59.3-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#E97158" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#F48849" label="72.7-80.5" opacity="1" quantity="44"/>' +   '<ColorMapEntry color="#FBA139" label="80.5-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#FEBC2A" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#FADA24" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#F0F921" label="108.9-1200" opacity="1" quantity="48"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="6"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/iron_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Iron, extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Iron, extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Iron, extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Iron, extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 140};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Iron, extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_magnesium_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_magnesium_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_magnesium_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_magnesium_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_magnesium_extractable(example: str = ''):
        """
        Extractable magnesium at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#350498" label="19.1-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#5402A3" label="29-39.4" opacity="1" quantity="37"/>' +   '<ColorMapEntry color="#7000A8" label="39.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#8B0AA5" label="53.6-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#A31E9A" label="72.7-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#B93289" label="89-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#CC4678" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#DB5C68" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#E97158" label="133.3-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#F48849" label="163-180.3" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#FBA139" label="180.3-220.4" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#FEBC2A" label="220.4-243.7" opacity="1" quantity="55"/>' +   '<ColorMapEntry color="#FADA24" label="243.7-297.9" opacity="1" quantity="57"/>' +   '<ColorMapEntry color="#F0F921" label="243.7-1200" opacity="1" quantity="60"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-19.1" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#350498" label="19.1-29" opacity="1" quantity="34"/>' +   '<ColorMapEntry color="#5402A3" label="29-39.4" opacity="1" quantity="37"/>' +   '<ColorMapEntry color="#7000A8" label="39.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#8B0AA5" label="53.6-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#A31E9A" label="72.7-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#B93289" label="89-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#CC4678" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#DB5C68" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#E97158" label="133.3-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#F48849" label="163-180.3" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#FBA139" label="180.3-220.4" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#FEBC2A" label="220.4-243.7" opacity="1" quantity="55"/>' +   '<ColorMapEntry color="#FADA24" label="243.7-297.9" opacity="1" quantity="57"/>' +   '<ColorMapEntry color="#F0F921" label="243.7-1200" opacity="1" quantity="60"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/magnesium_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Magnesium, extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Magnesium, extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Magnesium, extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Magnesium, extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 500};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Magnesium, extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_nitrogen_total:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_nitrogen_total'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_nitrogen_total.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_nitrogen_total.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_nitrogen_total(example: str = ''):
        """
        Total nitrogen at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/100)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-0.2" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#0C0927" label="0.2-0.3" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#231151" label="0.3-0.4" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#410F75" label="0.4-0.5" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#5F187F" label="0.5-0.6" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#7B2382" label="0.6-0.7" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#982D80" label="0.7-0.8" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#B63679" label="0.8-0.9" opacity="1" quantity="64"/>' +   '<ColorMapEntry color="#D3436E" label="0.9-1" opacity="1" quantity="67"/>' +   '<ColorMapEntry color="#EB5760" label="1-1.1" opacity="1" quantity="75"/>' +   '<ColorMapEntry color="#F8765C" label="1.1-1.2" opacity="1" quantity="79"/>' +   '<ColorMapEntry color="#FD9969" label="1.2-1.3" opacity="1" quantity="83"/>' +   '<ColorMapEntry color="#FEBA80" label="1.3-1.4" opacity="1" quantity="89"/>' +   '<ColorMapEntry color="#FDDC9E" label="1.4-1.5" opacity="1" quantity="93"/>' +   '<ColorMapEntry color="#FCFDBF" label="1.5-10" opacity="1" quantity="99"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#000004" label="0-0.2" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#0C0927" label="0.2-0.3" opacity="1" quantity="30"/>' +   '<ColorMapEntry color="#231151" label="0.3-0.4" opacity="1" quantity="36"/>' +   '<ColorMapEntry color="#410F75" label="0.4-0.5" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#5F187F" label="0.5-0.6" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#7B2382" label="0.6-0.7" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#982D80" label="0.7-0.8" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#B63679" label="0.8-0.9" opacity="1" quantity="64"/>' +   '<ColorMapEntry color="#D3436E" label="0.9-1" opacity="1" quantity="67"/>' +   '<ColorMapEntry color="#EB5760" label="1-1.1" opacity="1" quantity="75"/>' +   '<ColorMapEntry color="#F8765C" label="1.1-1.2" opacity="1" quantity="79"/>' +   '<ColorMapEntry color="#FD9969" label="1.2-1.3" opacity="1" quantity="83"/>' +   '<ColorMapEntry color="#FEBA80" label="1.3-1.4" opacity="1" quantity="89"/>' +   '<ColorMapEntry color="#FDDC9E" label="1.4-1.5" opacity="1" quantity="93"/>' +   '<ColorMapEntry color="#FCFDBF" label="1.5-10" opacity="1" quantity="99"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="60"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="60"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/nitrogen_total"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Nitrogen, total, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Nitrogen, total, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Nitrogen, total, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Nitrogen, total, stdev visualization, 20-50 cm");  var converted = raw.divide(100).exp().subtract(1);  var visualization = {min: 0, max: 10000};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Nitrogen, total, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_ph:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_ph'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_ph.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_ph.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_ph(example: str = ''):
        """
        pH at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `x/10`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#CC0000" label="3.5-4.6" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#FF0000" label="4.6-4.9" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FF5500" label="4.9-5.2" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#FFAA00" label="5.2-5.4" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#FFFF00" label="5.4-5.5" opacity="1" quantity="55"/>' +   '<ColorMapEntry color="#D4FF2B" label="5.5-5.6" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#AAFF55" label="5.6-5.7" opacity="1" quantity="57"/>' +   '<ColorMapEntry color="#80FF80" label="5.7-5.9" opacity="1" quantity="59"/>' +   '<ColorMapEntry color="#55FFAA" label="5.9-6" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#2BFFD5" label="6-6.2" opacity="1" quantity="62"/>' +   '<ColorMapEntry color="#00FFFF" label="6.2-6.3" opacity="1" quantity="63"/>' +   '<ColorMapEntry color="#00AAFF" label="6.3-6.6" opacity="1" quantity="66"/>' +   '<ColorMapEntry color="#0055FF" label="6.6-6.8" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#0000FF" label="6.8-7.1" opacity="1" quantity="71"/>' +   '<ColorMapEntry color="#0000CC" label="7.1-10.5" opacity="1" quantity="76"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#CC0000" label="3.5-4.6" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#FF0000" label="4.6-4.9" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FF5500" label="4.9-5.2" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#FFAA00" label="5.2-5.4" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#FFFF00" label="5.4-5.5" opacity="1" quantity="55"/>' +   '<ColorMapEntry color="#D4FF2B" label="5.5-5.6" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#AAFF55" label="5.6-5.7" opacity="1" quantity="57"/>' +   '<ColorMapEntry color="#80FF80" label="5.7-5.9" opacity="1" quantity="59"/>' +   '<ColorMapEntry color="#55FFAA" label="5.9-6" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#2BFFD5" label="6-6.2" opacity="1" quantity="62"/>' +   '<ColorMapEntry color="#00FFFF" label="6.2-6.3" opacity="1" quantity="63"/>' +   '<ColorMapEntry color="#00AAFF" label="6.3-6.6" opacity="1" quantity="66"/>' +   '<ColorMapEntry color="#0055FF" label="6.6-6.8" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#0000FF" label="6.8-7.1" opacity="1" quantity="71"/>' +   '<ColorMapEntry color="#0000CC" label="7.1-10.5" opacity="1" quantity="76"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>'; var raw = ee.Image("ISDASOIL/Africa/v1/ph"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "ph, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "ph, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "ph, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "ph, stdev visualization, 20-50 cm");  var converted = raw.divide(10);  var visualization = {min: 4, max: 8};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "ph, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_phosphorus_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_phosphorus_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_phosphorus_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_phosphorus_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_phosphorus_extractable(example: str = ''):
        """
        Extractable phosphorus at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#350498" label="2.7-3" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#5402A3" label="3-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#7000A8" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#8B0AA5" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#A31E9A" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#B93289" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#CC4678" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#DB5C68" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#E97158" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#F48849" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#FBA139" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FEBC2A" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FADA24" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#F0F921" label="12.5-125" opacity="1" quantity="27"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#350498" label="2.7-3" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#5402A3" label="3-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#7000A8" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#8B0AA5" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#A31E9A" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#B93289" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#CC4678" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#DB5C68" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#E97158" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#F48849" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#FBA139" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FEBC2A" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FADA24" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#F0F921" label="12.5-125" opacity="1" quantity="27"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/phosphorus_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Phosphorus extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Phosphorus extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Phosphorus extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Phosphorus extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 15};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Phosphorus extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_potassium_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_potassium_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_potassium_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_potassium_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_potassium_extractable(example: str = ''):
        """
        Extractable potassium at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-32.1" opacity="1" quantity="35"/>' +   '<ColorMapEntry color="#350498" label="32.1-43.7" opacity="1" quantity="38"/>' +   '<ColorMapEntry color="#5402A3" label="43.7-48.4" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#7000A8" label="48.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#8B0AA5" label="53.6-59.3" opacity="1" quantity="41"/>' +   '<ColorMapEntry color="#A31E9A" label="59.3-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#B93289" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#CC4678" label="72.7-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#DB5C68" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#E97158" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#F48849" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#FBA139" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FEBC2A" label="133.3-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#FADA24" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#F0F921" label="163-1200" opacity="1" quantity="55"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-32.1" opacity="1" quantity="35"/>' +   '<ColorMapEntry color="#350498" label="32.1-43.7" opacity="1" quantity="38"/>' +   '<ColorMapEntry color="#5402A3" label="43.7-48.4" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#7000A8" label="48.4-53.6" opacity="1" quantity="40"/>' +   '<ColorMapEntry color="#8B0AA5" label="53.6-59.3" opacity="1" quantity="41"/>' +   '<ColorMapEntry color="#A31E9A" label="59.3-65.7" opacity="1" quantity="42"/>' +   '<ColorMapEntry color="#B93289" label="65.7-72.7" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#CC4678" label="72.7-89" opacity="1" quantity="45"/>' +   '<ColorMapEntry color="#DB5C68" label="89-98.5" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#E97158" label="98.5-108.9" opacity="1" quantity="47"/>' +   '<ColorMapEntry color="#F48849" label="108.9-120.5" opacity="1" quantity="48"/>' +   '<ColorMapEntry color="#FBA139" label="120.5-133.3" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#FEBC2A" label="133.3-163" opacity="1" quantity="51"/>' +   '<ColorMapEntry color="#FADA24" label="163-199.3" opacity="1" quantity="53"/>' +   '<ColorMapEntry color="#F0F921" label="163-1200" opacity="1" quantity="55"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/potassium_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Potassium extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Potassium extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Potassium extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Potassium extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 250};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Potassium extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_sand_content:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_sand_content'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_sand_content.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_sand_content.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_sand_content(example: str = ''):
        """
        Sand content at soil depths of 0-20 cm and 20-50 cm,\npredicted mean and standard deviation. In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-31" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#002D6C" label="31-39" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#16396D" label="39-43" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#36476B" label="43-46" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#4B546C" label="46-49" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#5C616E" label="49-52" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#6C6E72" label="52-54" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#7C7B78" label="54-56" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#8E8A79" label="56-58" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#A09877" label="58-60" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#B3A772" label="60-63" opacity="1" quantity="63"/>' +   '<ColorMapEntry color="#C6B66B" label="63-65" opacity="1" quantity="65"/>' +   '<ColorMapEntry color="#DBC761" label="65-68" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#F0D852" label="68-71" opacity="1" quantity="71"/>' +   '<ColorMapEntry color="#FFEA46" label="71-100" opacity="1" quantity="75"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-31" opacity="1" quantity="31"/>' +   '<ColorMapEntry color="#002D6C" label="31-39" opacity="1" quantity="39"/>' +   '<ColorMapEntry color="#16396D" label="39-43" opacity="1" quantity="43"/>' +   '<ColorMapEntry color="#36476B" label="43-46" opacity="1" quantity="46"/>' +   '<ColorMapEntry color="#4B546C" label="46-49" opacity="1" quantity="49"/>' +   '<ColorMapEntry color="#5C616E" label="49-52" opacity="1" quantity="52"/>' +   '<ColorMapEntry color="#6C6E72" label="52-54" opacity="1" quantity="54"/>' +   '<ColorMapEntry color="#7C7B78" label="54-56" opacity="1" quantity="56"/>' +   '<ColorMapEntry color="#8E8A79" label="56-58" opacity="1" quantity="58"/>' +   '<ColorMapEntry color="#A09877" label="58-60" opacity="1" quantity="60"/>' +   '<ColorMapEntry color="#B3A772" label="60-63" opacity="1" quantity="63"/>' +   '<ColorMapEntry color="#C6B66B" label="63-65" opacity="1" quantity="65"/>' +   '<ColorMapEntry color="#DBC761" label="65-68" opacity="1" quantity="68"/>' +   '<ColorMapEntry color="#F0D852" label="68-71" opacity="1" quantity="71"/>' +   '<ColorMapEntry color="#FFEA46" label="71-100" opacity="1" quantity="75"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="7"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="7"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>'; var raw = ee.Image("ISDASOIL/Africa/v1/sand_content"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Sand content, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Sand content, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Sand content, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Sand content, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 3000};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Sand content, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_silt_content:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_silt_content'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_silt_content.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_silt_content.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_silt_content(example: str = ''):
        """
        Silt content at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-7" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#002D6C" label="7-9" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#16396D" label="9-10" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#36476B" label="10-11" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#4B546C" label="11-12" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#5C616E" label="12-13" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#6C6E72" label="13-14" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#7C7B78" label="14-15" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#8E8A79" label="15-16" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#A09877" label="16-17" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#B3A772" label="17-18" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#C6B66B" label="18-19" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#DBC761" label="19-20" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#F0D852" label="20-22" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#FFEA46" label="22-70" opacity="1" quantity="24"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-7" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#002D6C" label="7-9" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#16396D" label="9-10" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#36476B" label="10-11" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#4B546C" label="11-12" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#5C616E" label="12-13" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#6C6E72" label="13-14" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#7C7B78" label="14-15" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#8E8A79" label="15-16" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#A09877" label="16-17" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#B3A772" label="17-18" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#C6B66B" label="18-19" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#DBC761" label="19-20" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#F0D852" label="20-22" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#FFEA46" label="22-70" opacity="1" quantity="24"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="4.19000000000005"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="4.19000000000005"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/silt_content"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Silt content, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Silt content, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Silt content, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Silt content, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 15};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Silt content, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_stone_content:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_stone_content'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_stone_content.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_stone_content.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_stone_content(example: str = ''):
        """
        Stone content at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-0.1" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#002D6C" label="0.1-0.3" opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#16396D" label="0.3-0.5" opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#36476B" label="0.5-0.6" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#4B546C" label="0.6-0.8" opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#5C616E" label="0.8-1" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#6C6E72" label="1-1.2" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#7C7B78" label="1.2-1.5" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#8E8A79" label="1.5-1.7" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#A09877" label="1.7-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#B3A772" label="2-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#C6B66B" label="2.3-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#DBC761" label="2.7-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#F0D852" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#FFEA46" label="3.5-80" opacity="1" quantity="16"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#00204D" label="0-0.1" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#002D6C" label="0.1-0.3" opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#16396D" label="0.3-0.5" opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#36476B" label="0.5-0.6" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#4B546C" label="0.6-0.8" opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#5C616E" label="0.8-1" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#6C6E72" label="1-1.2" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#7C7B78" label="1.2-1.5" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#8E8A79" label="1.5-1.7" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#A09877" label="1.7-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#B3A772" label="2-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#C6B66B" label="2.3-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#DBC761" label="2.7-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#F0D852" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#FFEA46" label="3.5-80" opacity="1" quantity="16"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/stone_content"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Stone content, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Stone content, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Stone content, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Stone content, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 6};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Stone content, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_sulphur_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_sulphur_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_sulphur_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_sulphur_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_sulphur_extractable(example: str = ''):
        """
        Extractable sulfur at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#350498" label="2.3-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#5402A3" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#7000A8" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#8B0AA5" label="4-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#A31E9A" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#B93289" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#CC4678" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#DB5C68" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#E97158" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#F48849" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FBA139" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FEBC2A" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#FADA24" label="12.5-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#F0F921" label="15.4-125" opacity="1" quantity="30"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#350498" label="2.3-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#5402A3" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#7000A8" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#8B0AA5" label="4-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#A31E9A" label="5-5.7" opacity="1" quantity="19"/>' +   '<ColorMapEntry color="#B93289" label="5.7-6.4" opacity="1" quantity="20"/>' +   '<ColorMapEntry color="#CC4678" label="6.4-7.2" opacity="1" quantity="21"/>' +   '<ColorMapEntry color="#DB5C68" label="7.2-8" opacity="1" quantity="22"/>' +   '<ColorMapEntry color="#E97158" label="8-9" opacity="1" quantity="23"/>' +   '<ColorMapEntry color="#F48849" label="9-10" opacity="1" quantity="24"/>' +   '<ColorMapEntry color="#FBA139" label="10-11.2" opacity="1" quantity="25"/>' +   '<ColorMapEntry color="#FEBC2A" label="11.2-12.5" opacity="1" quantity="26"/>' +   '<ColorMapEntry color="#FADA24" label="12.5-15.4" opacity="1" quantity="28"/>' +   '<ColorMapEntry color="#F0F921" label="15.4-125" opacity="1" quantity="30"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="14"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="14"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/sulphur_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Sulphur extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Sulphur extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Sulphur extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Sulphur extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 20};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Sulphur extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_texture_class:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_texture_class'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_texture_class.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_texture_class.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_texture_class(example: str = ''):
        """
        USDA Texture Class at soil depths of 0-20 cm and 20-50 cm. In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var raw = ee.Image("ISDASOIL/Africa/v1/texture_class"); Map.addLayer(     raw.select(0), {}, "Texture class, 0-20 cm"); Map.addLayer(     raw.select(1), {}, "Texture class, 20-50 cm");  Map.setCenter(25, -3, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ISDASOIL_Africa_v1_zinc_extractable:
    def __init__(self,):
        self.sensor = 'ISDASOIL_Africa_v1_zinc_extractable'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ISDASOIL_Africa_v1_zinc_extractable.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ISDASOIL_Africa_v1_zinc_extractable.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ISDASOIL_Africa_v1_zinc_extractable(example: str = ''):
        """
        Extractable zinc at soil depths of 0-20 cm and 20-50 cm, predicted mean and standard deviation.  Pixel values must be back-transformed with `exp(x/10)-1`.  In areas of dense jungle (generally over central Africa), model accuracy is low and therefore artifacts such as banding (striping) might be seen.  Soil property predictions were made by [Innovative Solutions for Decision Agriculture Ltd. (iSDA)](https://isda-africa.com/) at 30 m pixel size using machine learning coupled with remote sensing data and a training set of over 100,000 analyzed soil samples.  Further information can be found in the [FAQ](https://www.isda-africa.com/isdasoil/faq/) and [technical information documentation](https://www.isda-africa.com/isdasoil/technical-information/). To submit an issue or request support, please visit [the iSDAsoil site](https://isda-africa.com/isdasoil). 
        :param example: var mean_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-0.6" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#350498" label="0.6-0.8" opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#5402A3" label="0.8-1" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#7000A8" label="1-1.2" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#8B0AA5" label="1.2-1.5" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#A31E9A" label="1.5-1.7" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#B93289" label="1.7-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#CC4678" label="2-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#DB5C68" label="2.3-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#E97158" label="2.7-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#F48849" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#FBA139" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#FEBC2A" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#FADA24" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#F0F921" label="5-125" opacity="1" quantity="19"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var mean_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#0D0887" label="0-0.6" opacity="1" quantity="5"/>' +   '<ColorMapEntry color="#350498" label="0.6-0.8" opacity="1" quantity="6"/>' +   '<ColorMapEntry color="#5402A3" label="0.8-1" opacity="1" quantity="7"/>' +   '<ColorMapEntry color="#7000A8" label="1-1.2" opacity="1" quantity="8"/>' +   '<ColorMapEntry color="#8B0AA5" label="1.2-1.5" opacity="1" quantity="9"/>' +   '<ColorMapEntry color="#A31E9A" label="1.5-1.7" opacity="1" quantity="10"/>' +   '<ColorMapEntry color="#B93289" label="1.7-2" opacity="1" quantity="11"/>' +   '<ColorMapEntry color="#CC4678" label="2-2.3" opacity="1" quantity="12"/>' +   '<ColorMapEntry color="#DB5C68" label="2.3-2.7" opacity="1" quantity="13"/>' +   '<ColorMapEntry color="#E97158" label="2.7-3.1" opacity="1" quantity="14"/>' +   '<ColorMapEntry color="#F48849" label="3.1-3.5" opacity="1" quantity="15"/>' +   '<ColorMapEntry color="#FBA139" label="3.5-4" opacity="1" quantity="16"/>' +   '<ColorMapEntry color="#FEBC2A" label="4-4.5" opacity="1" quantity="17"/>' +   '<ColorMapEntry color="#FADA24" label="4.5-5" opacity="1" quantity="18"/>' +   '<ColorMapEntry color="#F0F921" label="5-125" opacity="1" quantity="19"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_0_20 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var stdev_20_50 = '<RasterSymbolizer>' +  '<ColorMap type="ramp">' +   '<ColorMapEntry color="#fde725" label="low" opacity="1" quantity="1"/>' +   '<ColorMapEntry color="#5dc962" label=" " opacity="1" quantity="2"/>' +   '<ColorMapEntry color="#20908d" label=" " opacity="1" quantity="3"/>' +   '<ColorMapEntry color="#3a528b" label=" " opacity="1" quantity="4"/>' +   '<ColorMapEntry color="#440154" label="high" opacity="1" quantity="5"/>' +  '</ColorMap>' +  '<ContrastEnhancement/>' + '</RasterSymbolizer>';  var raw = ee.Image("ISDASOIL/Africa/v1/zinc_extractable"); Map.addLayer(     raw.select(0).sldStyle(mean_0_20), {},     "Zinc, extractable, mean visualization, 0-20 cm"); Map.addLayer(     raw.select(1).sldStyle(mean_20_50), {},     "Zinc, extractable, mean visualization, 20-50 cm"); Map.addLayer(     raw.select(2).sldStyle(stdev_0_20), {},     "Zinc, extractable, stdev visualization, 0-20 cm"); Map.addLayer(     raw.select(3).sldStyle(stdev_20_50), {},     "Zinc, extractable, stdev visualization, 20-50 cm");  var converted = raw.divide(10).exp().subtract(1);  var visualization = {min: 0, max: 10};  Map.setCenter(25, -3, 2);  Map.addLayer(converted.select(0), visualization, "Zinc, extractable, mean, 0-20 cm"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_AVNIR_2_ORI:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_AVNIR_2_ORI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_AVNIR-2_ORI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_AVNIR-2_ORI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_AVNIR_2_ORI(example: str = ''):
        """
        This dataset is contains orthorectified imagery from the Advanced Visible and Near Infrared Radiometer type 2 (AVNIR-2) sensor on-board the Advanced Land Observing Satellite (ALOS) \"DAICHI\".  The AVNIR-2 ORI product was created from AVNIR-2 1B1 data after stereo matching with reference to ALOS's Panchromatic Remote-sensing Instrument for Stereo Mapping (PRISM)-derived DSM AW3D30. The orthorectification process used AW3D30 DSM data when available and SRTM (The Shuttle Radar Topography Mission) DSM data otherwise. 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/AVNIR-2/ORI')                   .filter(ee.Filter.date('2011-01-01', '2011-04-01')); var avnir2OriRgb = dataset.select(['B3', 'B2', 'B1']); var avnir2OriRgbVis = {   min: 0.0,   max: 255.0, }; Map.setCenter(138.7302, 35.3641, 12); Map.addLayer(avnir2OriRgb, avnir2OriRgbVis, 'AVNIR-2 ORI RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_AW3D30_V1_1:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_AW3D30_V1_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_AW3D30_V1_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_AW3D30_V1_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_AW3D30_V1_1(example: str = ''):
        """
        ALOS World 3D - 30m (AW3D30) is a global digital surface model (DSM) dataset with a horizontal resolution of approximately 30 meters (1 arcsec mesh). The dataset is based on the DSM dataset (5-meter mesh version) of the [World 3D Topographic Data](https://www.aw3d.jp/en/). More details are available in the dataset [documentation](https://www.eorc.jaxa.jp/ALOS/en/aw3d30/aw3d30v11_format_e.pdf).  In the version 1.1, released in March 2017, void values in the cloud and snow pixels between 60 degrees North and 60 degrees South were filled with existing DEMs using the Delta Surface Fill method.  The AW3D DSM elevation is calculated by an image matching process that uses a stereo pair of optical images. Clouds, snow, and ice are automatically identified during processing and applied the mask information. However, mismatched points sometimes remain especially surrounding (or at the edges of) clouds, snow, and ice areas, which cause some height errors in the final DSM.  Here are some example areas with data values outside of valid elevation range. Impossibly low negative values are concentrated in Antarctica around (-63.77, -61.660), (-77.22, -150.27), and (-73.29, 168.14); in Indonesia around (-5.36, 134.55); in Brazil around (-1.667113844, -50.6269684); and in Peru around (-10.45048137, -75.39459876) with approximate values of -1013, -998, -635, and -610 respectively. Impossibly high positive values are found in several locations in the Arctic around (79.83, -77.67) and (69.54, -75.42); in Fiji around (-16.58, 179.44) and (-18.96, 178.39); and in Nepal around (28.50, 84.56) with approximate values of 15369, 15213, and 10900 respectively. 
        :param example: var dataset = ee.Image('JAXA/ALOS/AW3D30/V1_1'); var elevation = dataset.select('AVE'); var elevationVis = {   min: 0.0,   max: 4000.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_AW3D30_V2_1:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_AW3D30_V2_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_AW3D30_V2_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_AW3D30_V2_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_AW3D30_V2_1(example: str = ''):
        """
        ALOS World 3D - 30m (AW3D30) is a global digital surface model (DSM) dataset with a horizontal resolution of approximately 30 meters (1 arcsec mesh). The dataset is based on the DSM dataset (5-meter mesh version) of the [World 3D Topographic Data](https://www.aw3d.jp/en/). More details are available in the dataset [documentation](https://www.eorc.jaxa.jp/ALOS/en/aw3d30/aw3d30v11_format_e.pdf).  In the version 2.1, released in April 2018, the source AW3D DSM has been upgraded to version 2. Masks of the land water and low correlation pixels were also filled with existing DEMs in addition to the cloud and snow pixels between 60 degrees North and 60 degrees South. In Japan area, filling was carried out after updating coastline information.  The AW3D DSM elevation is calculated by an image matching process that uses a stereo pair of optical images. Clouds, snow, and ice are automatically identified during processing and applied the mask information. However, mismatched points sometimes remain especially surrounding (or at the edges of) clouds, snow, and ice areas, which cause some height errors in the final DSM.  Here are some example areas with data values outside of valid elevation range. Impossibly low negative values are concentrated in Antarctica around (-63.77, -61.660), (-77.22, -150.27), and (-73.29, 168.14); in Indonesia around (-5.36, 134.55); in Brazil around (-1.667113844, -50.6269684); and in Peru around (-10.45048137, -75.39459876) with approximate values of -1013, -998, -635, and -610 respectively. Impossibly high positive values are found in several locations in the Arctic around (79.83, -77.67) and (69.54, -75.42); in Fiji around (-16.58, 179.44) and (-18.96, 178.39); and in Nepal around (28.50, 84.56) with approximate values of 15369, 15213, and 10900 respectively. 
        :param example: var dataset = ee.Image('JAXA/ALOS/AW3D30/V2_1'); var elevation = dataset.select('AVE_DSM'); var elevationVis = {   min: 0.0,   max: 4000.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_AW3D30_V2_2:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_AW3D30_V2_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_AW3D30_V2_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_AW3D30_V2_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_AW3D30_V2_2(example: str = ''):
        """
        ALOS World 3D - 30m (AW3D30) is a global digital surface model (DSM) dataset with a horizontal resolution of approximately 30 meters (1 arcsec mesh). The dataset is based on the DSM dataset (5-meter mesh version) of the [World 3D Topographic Data](https://www.aw3d.jp/en/). More details are available in the dataset [documentation](https://www.eorc.jaxa.jp/ALOS/en/aw3d30/aw3d30v11_format_e.pdf).  Version 2.2, released in April 2019 is an improved version of the northern region over 60 degrees north. Along with the complement of no-data or low-quality area, updating of coastline was also performed.  The AW3D DSM elevation is calculated by an image matching process that uses a stereo pair of optical images. Clouds, snow, and ice are automatically identified during processing and applied the mask information. However, mismatched points sometimes remain especially surrounding (or at the edges of) clouds, snow, and ice areas, which cause some height errors in the final DSM.  Here are some example areas with data values outside of valid elevation range. Impossibly low negative values are concentrated in Antarctica around (-63.77, -61.660), (-77.22, -150.27), and (-73.29, 168.14); in Indonesia around (-5.36, 134.55); in Brazil around (-1.667113844, -50.6269684); and in Peru around (-10.45048137, -75.39459876) with approximate values of -1013, -998, -635, and -610 respectively. Impossibly high positive values are found in several locations in the Arctic around (79.83, -77.67) and (69.54, -75.42); in Fiji around (-16.58, 179.44) and (-18.96, 178.39); and in Nepal around (28.50, 84.56) with approximate values of 15369, 15213, and 10900 respectively. 
        :param example: var dataset = ee.Image('JAXA/ALOS/AW3D30/V2_2'); var elevation = dataset.select('AVE_DSM'); var elevationVis = {   min: -9999,   max: 15355,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_AW3D30_V3_2:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_AW3D30_V3_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_AW3D30_V3_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_AW3D30_V3_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_AW3D30_V3_2(example: str = ''):
        """
        ALOS World 3D - 30m (AW3D30) is a global digital surface model (DSM) dataset with a horizontal resolution of approximately 30 meters (1 arcsec mesh). The dataset is based on the DSM dataset (5-meter mesh version) of the [World 3D Topographic Data](https://www.aw3d.jp/en/). More details are available in the dataset [documentation](https://www.eorc.jaxa.jp/ALOS/en/aw3d30/aw3d30v11_format_e.pdf).  Version 3.2, released in January 2021, is an improved version created by reconsidering the format in the high latitude area, auxiliary data, and processing method. Different pixel spacing for each latitude zone was adopted at high latitude area. Coastline data, which is one of the auxiliary datasets, was changed, and new supplementary data was used. In addition, as a source data for Japan, AW3D version 3 was also used. Furthermore, the method of detecting anomalous values in the process was improved.  Note: See the code example for the recommended way of computing slope. Unlike most DEMs in Earth Engine, this is an image collection due to multiple resolutions of source files that make it impossible to mosaic them into a single asset, so the slope computations need a reprojection.  The AW3D DSM elevation is calculated by an image matching process that uses a stereo pair of optical images. Clouds, snow, and ice are automatically identified during processing and applied the mask information. However, mismatched points sometimes remain especially surrounding (or at the edges of) clouds, snow, and ice areas, which cause some height errors in the final DSM.  Here are some example areas with data values outside of valid elevation range. Impossibly low negative values are concentrated in Antarctica around (-63.77, -61.660), (-77.22, -150.27), and (-73.29, 168.14); in Indonesia around (-5.36, 134.55); in Brazil around (-1.667113844, -50.6269684); and in Peru around (-10.45048137, -75.39459876) with approximate values of -1013, -998, -635, and -610 respectively. Impossibly high positive values are found in several locations in the Arctic around (79.83, -77.67) and (69.54, -75.42); in Fiji around (-16.58, 179.44) and (-18.96, 178.39); and in Nepal around (28.50, 84.56) with approximate values of 15369, 15213, and 10900 respectively. 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/AW3D30/V3_2'); var elevation = dataset.select('DSM'); var elevationVis = {   min: 0,   max: 5000,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'] }; Map.setCenter(138.73, 35.36, 11); Map.addLayer(elevation, elevationVis, 'Elevation');  // Reproject an image mosaic using a projection from one of the image tiles, // rather than using the default projection returned by .mosaic(). var proj = elevation.first().select(0).projection(); var slopeReprojected = ee.Terrain.slope(elevation.mosaic()                              .setDefaultProjection(proj)); Map.addLayer(slopeReprojected, {min: 0, max: 45}, 'Slope'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_2_Level2_1_StripMap_202401:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_2_Level2_1_StripMap_202401'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR-2_Level2_1_StripMap_202401.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR-2_Level2_1_StripMap_202401.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_2_Level2_1_StripMap_202401(example: str = ''):
        """
        Starting from the night of January 1st, 2024, based on the request from Japanese ministries and related organization, JAXA implemented ALOS-2 PALSAR-2 emergency observation. Since JAXA expects these emergency observation data to be extremely useful for disaster management, JAXA decided to open these data on Google Earth Engine for public and research usage.  JAXA released PALSAR-2 Level 2.1 strip map mode observation data with 3m single polarization for January 1-3 and January 8 2024, together with some archive data. PALSAR-2 Level 2.1 data is orthorectified from level 1.1 data by using digital elevation model. The DN values can be converted to sigma naught values in decibel unit (dB) using the following equation:  * &sigma;<sub>0</sub> = 10*log<sub>10</sub>(DN<sup>2</sup>) - 83.0 dB  Below are the dates for which the dataset has data.  Obs date                   | Frame     |  Beam     | A/D :--------------------------|:----------|:----------|:--------------- 2024/01/01 and 2022/09/26  | 0750, 0760, 0770 | U2-6L | Asc. 2024/01/02 and 2023/06/06  | 2820, 2830, 2840 | U2-8L | Desc. 2024/01/08, 2024/01/03 and 2023/12/06  | 0720, 0730 | U2-9R | Asc. 
        :param example: var coll = ee.ImageCollection('JAXA/ALOS/PALSAR-2/Level2_1/StripMap_202401');  var vis = {min: 0, max: 8000};  // Visualize different date ranges var visualizeDateRange = function(startDate, endDate, layerName) {   var dateRange = coll.filterDate(startDate, endDate);   Map.addLayer(dateRange, vis, layerName); };  visualizeDateRange('2023-06-06', '2023-06-07', 'Before-2023-06-06'); visualizeDateRange('2023-06-12', '2023-06-13', 'Before-2023-06-12'); visualizeDateRange('2022-09-26', '2022-09-27', 'Before-2022-09-26'); visualizeDateRange('2023-12-06', '2023-12-07', 'Before-2023-12-06'); visualizeDateRange('2024-01-01', '2024-01-02', 'After-2024-01-01'); visualizeDateRange('2024-01-02', '2024-01-03', 'After-2024-01-02'); visualizeDateRange('2024-01-03', '2024-01-04', 'After-2024-01-03'); visualizeDateRange('2024-01-08', '2024-01-09', 'After-2024-01-08');  Map.setCenter(137.2228, 37.1204, 8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_2_Level2_2_ScanSAR:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_2_Level2_2_ScanSAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR-2_Level2_2_ScanSAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR-2_Level2_2_ScanSAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_2_Level2_2_ScanSAR(example: str = ''):
        """
        The 25 m PALSAR-2 ScanSAR is normalized backscatter data of PALSAR-2 broad area observation mode with observation width of 350 km. The SAR imagery was ortho-rectificatied and slope corrected using the ALOS World 3D - 30 m (AW3D30) Digital Surface Model. Polarization data are stored as 16-bit digital numbers (DN). The DN values can be converted to gamma naught values in decibel unit (dB) using the following equation:  * &gamma;<sub>0</sub> = 10*log<sub>10</sub>(DN<sup>2</sup>) - 83.0 dB  Level 2.2 data are ortho-rectified and radiometrically terrain-corrected.  This dataset is compatible with the [Committee on Earth Observation (CEOS)](https://ceos.org/) [Analysis Ready Data for LAND (CARD4L)](https://ceos.org/ard/files/PFS/NRB/v5.5/CARD4L-PFS_NRB_v5.5.pdf) standard. 
        :param example: var collection = ee.ImageCollection('JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR')   .filterBounds(ee.Geometry.Point(143, -5)); var image = collection.first();  Map.addLayer(image.select(['HH']), {min: 0, max: 8000}, 'HH polarization'); Map.centerObject(image); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_YEARLY_FNF:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_YEARLY_FNF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR_YEARLY_FNF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR_YEARLY_FNF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_YEARLY_FNF(example: str = ''):
        """
        A newer version of this dataset with 4 classes for 2017-2020 can be found in [JAXA/ALOS/PALSAR/YEARLY/FNF4](JAXA_ALOS_PALSAR_YEARLY_FNF4.html)  The global forest/non-forest map (FNF) is generated by classifying the SAR image (backscattering coefficient) in the global 25m resolution PALSAR-2/PALSAR SAR mosaic so that strong and low backscatter pixels are assigned as \"forest\" and \"non-forest\", respectively. Here, \"forest\" is defined as the natural forest with the area larger than 0.5 ha and forest cover over 10%. This definition is the same as the Food and Agriculture Organization (FAO) definition. Since the radar backscatter from the forest depends on the region (climate zone), the classification of Forest/Non-Forest is conducted by using a region-dependent threshold of backscatter. The classification accuracy is checked by using in-situ photos and high-resolution optical satellite images. Detailed information is available in the provider's [Dataset Description](https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/DatasetDescription_PALSAR2_Mosaic_FNF_revE.pdf).  Attention:  *   Backscatter values may vary significantly from path to path     over high latitude forest areas. This is due to the change of     backscattering intensity caused by freezing trees in winter.     Please note that this may affect the classification of     forest/non-forest. 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/FNF')                   .filterDate('2017-01-01', '2017-12-31'); var forestNonForest = dataset.select('fnf'); var forestNonForestVis = {   min: 1,   max: 3,   palette: ['006400', 'feff99', '0000ff'], }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(forestNonForest, forestNonForestVis, 'Forest/Non-Forest'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_YEARLY_FNF4:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_YEARLY_FNF4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR_YEARLY_FNF4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR_YEARLY_FNF4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_YEARLY_FNF4(example: str = ''):
        """
        The global forest/non-forest map (FNF) is generated by classifying the SAR image (backscattering coefficient) in the global 25m resolution PALSAR-2/PALSAR SAR mosaic so that strong and low backscatter pixels are assigned as \"forest\" and \"non-forest\", respectively. Here, \"forest\" is defined as the natural forest with the area larger than 0.5 ha and forest cover over 10%. This definition is the same as the Food and Agriculture Organization (FAO) definition. Since the radar backscatter from the forest depends on the region (climate zone), the classification of Forest/Non-Forest is conducted by using a region-dependent threshold of backscatter. The classification accuracy is checked by using in-situ photos and high-resolution optical satellite images.  Detailed information:  *   [2017 - 2020](https://www.eorc.jaxa.jp/ALOS/en/dataset/pdf/DatasetDescription_PALSAR2_FNF_v200a.pdf)  Attention:  *   Backscatter values may vary significantly from path to path     over high latitude forest areas. This is due to the change of     backscattering intensity caused by freezing trees in winter.     Please note that this may affect the classification of     forest/non-forest. 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/FNF4')                   .filterDate('2018-01-01', '2018-12-31'); var forestNonForest = dataset.select('fnf'); var forestNonForestVis = {   min: 1,   max: 4,   palette: ['00b200','83ef62','ffff99','0000ff'], }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(forestNonForest, forestNonForestVis, 'Forest/Non-Forest'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_YEARLY_SAR:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_YEARLY_SAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR_YEARLY_SAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR_YEARLY_SAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_YEARLY_SAR(example: str = ''):
        """
        A newer version of this dataset with data for 2015-2021 can be found in [JAXA/ALOS/PALSAR/YEARLY/SAR_EPOCH](JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH.html)  The global 25m PALSAR/PALSAR-2 mosaic is a seamless global SAR image created by mosaicking strips of SAR imagery from PALSAR/PALSAR-2. For each year and location, the strip data were selected through visual inspection of the browse mosaics available over the period, with those showing minimum response to surface moisture preferentially used. In cases where the availability was limited (e.g., because of the requirement for observations during specific emergencies), data were necessarily selected from the year before or after, including from 2006. [Shimada et al. 2014](https://doi.org/10.1016/j.rse.2014.04.014)  There is no data for 2011-2014 due to the gap between ALOS and ALOS-2 temporal coverage.  The SAR imagery was ortho-rectificatied and slope corrected using the 90m SRTM Digital Elevation Model. A destriping process (Shimada & Isoguchi, 2002, 2010) was applied to equalize the intensity differences between neighboring strips, occurring largely due to seasonal and daily differences in surface moisture conditions.  Polarization data are stored as 16-bit digital numbers (DN). The DN values can be converted to gamma naught values in decibel unit (dB) using the following equation:    *    &#947;&#8320; = 10log&#8321;&#8320;(DN&#178;) - 83.0 dB  Attention:  *   Backscatter values may vary significantly from path to path     over high latitude forest areas. This is due to the change of     backscattering intensity caused by freezing trees in winter.  More information is available in the provider's [Dataset Description](https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/DatasetDescription_PALSAR2_Mosaic_FNF_revH.pdf). 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR')                   .filter(ee.Filter.date('2017-01-01', '2018-01-01')); var sarHh = dataset.select('HH'); var sarHhVis = {   min: 0.0,   max: 10000.0, }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(sarHh, sarHhVis, 'SAR HH'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH:
    def __init__(self,):
        self.sensor = 'JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_ALOS_PALSAR_YEARLY_SAR_EPOCH(example: str = ''):
        """
        The global 25m PALSAR/PALSAR-2 mosaic is a seamless global SAR image created by mosaicking strips of SAR imagery from PALSAR/PALSAR-2. For each year and location, the strip data were selected through visual inspection of the browse mosaics available over the period, with those showing minimum response to surface moisture preferentially used. Only data from the target year have been used for each annual mosaic, and hence no gap-filling using data from previous years in case of gaps in the annual global coverage.  There is no data for 2011-2014 due to the gap between ALOS and ALOS-2 temporal coverage.  The SAR imagery was ortho-rectificatied and slope corrected using the digital surface model ALOS World 3D - 30m (AW3D30).  A destriping process (Shimada & Isoguchi, 2002, 2010) was applied to equalize the intensity differences between neighboring strips, occurring largely due to seasonal and daily differences in surface moisture conditions.  Polarization data are stored as 16-bit digital numbers (DN). The DN values can be converted to gamma naught values in decibel unit (dB) using the following equation:    *    &#947;&#8320; = 10log&#8321;&#8320;(DN&#178;) - 83.0 dB  Attention:  *   Backscatter values may vary significantly from path to path     over high latitude forest areas. This is due to the change of     backscattering intensity caused by freezing trees in winter.  More information is available in the provider's [Dataset Description](https://www.eorc.jaxa.jp/ALOS/en/dataset/pdf/DatasetDescription_PALSAR2_Mosaic_ver212.pdf). 
        :param example: var dataset = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/SAR_EPOCH')                   .filter(ee.Filter.date('2017-01-01', '2018-01-01')); var sarHh = dataset.select('HH'); var sarHhVis = {   min: 0.0,   max: 10000.0, }; Map.setCenter(136.85, 37.37, 4); Map.addLayer(sarHh, sarHhVis, 'SAR HH'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LAI_V1:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LAI_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LAI_V1(example: str = ''):
        """
        This product is the sum of the one-sided green leaf area per unit ground area.  A newer version [JAXA/GCOM-C/L3/LAND/LAI/V3](JAXA_GCOM-C_L3_LAND_LAI_V3) is also available for this dataset which uses this [algorithm](https://suzaku.eorc.jaxa.jp/GCOM_C/data/product_std.html) for processing.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LAI/V1')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.001);  var visualization = {   bands: ['LAI_AVE'],   min: -7,   max: 7,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Leaf Area Index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LAI_V2:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LAI_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LAI_V2(example: str = ''):
        """
        This product is the sum of the one-sided green leaf area per unit ground area.  For data after 2021-11-28, see [the V3 dataset](JAXA/GCOM-C/L3/LAND/LAI/V3).  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LAI/V2')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.001);  var visualization = {   bands: ['LAI_AVE'],   min: -7,   max: 7,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Leaf Area Index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LAI_V3:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LAI_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LAI_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LAI_V3(example: str = ''):
        """
        This product is the sum of the one-sided green leaf area per unit ground area.  This is an ongoing dataset with a latency of 3-4 days.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LAI/V3')                 .filterDate('2021-12-01', '2022-01-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.001);  var visualization = {   bands: ['LAI_AVE'],   min: -7,   max: 7,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Leaf Area Index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LST_V1:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LST_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LST_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LST_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LST_V1(example: str = ''):
        """
        This product is the temperature of terrestrial land surface.  A newer version [JAXA/GCOM-C/L3/LAND/LST/V3](JAXA_GCOM-C_L3_LAND_LST_V3) is also available for this dataset which uses this [algorithm](https://suzaku.eorc.jaxa.jp/GCOM_C/data/product_std.html) for processing.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LST/V1')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.02);  var visualization = {   bands: ['LST_AVE'],   min: 250,   max: 316,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LST_V2:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LST_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LST_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LST_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LST_V2(example: str = ''):
        """
        This product is the temperature of terrestrial land surface.  For data after 2021-11-28, see [the V3 dataset](JAXA/GCOM-C/L3/LAND/LST/V3).  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LST/V2')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.02);  var visualization = {   bands: ['LST_AVE'],   min: 250,   max: 316,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_LAND_LST_V3:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_LAND_LST_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_LAND_LST_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_LAND_LST_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_LAND_LST_V3(example: str = ''):
        """
        This product is the temperature of terrestrial land surface.  This is an ongoing dataset with a latency of 3-4 days.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/LAND/LST/V3')                 .filterDate('2021-12-01', '2022-01-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var dataset = dataset.mean().multiply(0.02);  var visualization = {   bands: ['LST_AVE'],   min: 250,   max: 316,   palette: [     '040274','040281','0502a3','0502b8','0502ce','0502e6',     '0602ff','235cb1','307ef3','269db1','30c8e2','32d3ef',     '3be285','3ff38f','86e26f','3ae237','b5e22e','d6e21f',     'fff705','ffd611','ffb613','ff8b13','ff6e08','ff500d',     'ff0000','de0101','c21301','a71001','911003',   ] };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, visualization, 'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_CHLA_V1:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_CHLA_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_CHLA_V1(example: str = ''):
        """
        This product is the concentration of the photosynthetic pigment (chlorophyll-a) in phytoplankton in the sea surface layer.  A newer version [JAXA/GCOM-C/L3/OCEAN/CHLA/V3](JAXA_GCOM-C_L3_OCEAN_CHLA_V3) is also available for this dataset which uses this [algorithm](https://suzaku.eorc.jaxa.jp/GCOM_C/data/product_std.html) for processing.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/CHLA/V1')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var image = dataset.mean().multiply(0.0016).log10();  var vis = {   bands: ['CHLA_AVE'],   min: -2,   max: 2,   palette: [     '3500a8','0800ba','003fd6',     '00aca9','77f800','ff8800',     'b30000','920000','880000'   ] };  Map.addLayer(image, vis, 'Chlorophyll-a concentration');  Map.setCenter(128.45, 33.33, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_CHLA_V2:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_CHLA_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_CHLA_V2(example: str = ''):
        """
        This product is the concentration of the photosynthetic pigment (chlorophyll-a) in phytoplankton in the sea surface layer.  For data after 2021-11-28, see [the V3 dataset](JAXA/GCOM-C/L3/LAND/CHLA/V3).  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/CHLA/V2')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var image = dataset.mean().multiply(0.0016).log10();  var vis = {   bands: ['CHLA_AVE'],   min: -2,   max: 2,   palette: [     '3500a8','0800ba','003fd6',     '00aca9','77f800','ff8800',     'b30000','920000','880000'   ] };  Map.addLayer(image, vis, 'Chlorophyll-a concentration');  Map.setCenter(128.45, 33.33, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_CHLA_V3:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_CHLA_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_CHLA_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_CHLA_V3(example: str = ''):
        """
        This product is the concentration of the photosynthetic pigment (chlorophyll-a) in phytoplankton in the sea surface layer.  This is an ongoing dataset with a latency of 3-4 days.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/CHLA/V3')                 .filterDate('2021-12-01', '2022-01-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient var image = dataset.mean().multiply(0.0016).log10();  var vis = {   bands: ['CHLA_AVE'],   min: -2,   max: 2,   palette: [     '3500a8','0800ba','003fd6',     '00aca9','77f800','ff8800',     'b30000','920000','880000'   ] };  Map.addLayer(image, vis, 'Chlorophyll-a concentration');  Map.setCenter(128.45, 33.33, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_SST_V1:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_SST_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_SST_V1(example: str = ''):
        """
        This product is the temperature of sea surface.  A newer version [JAXA/GCOM-C/L3/OCEAN/SST/V3](JAXA_GCOM-C_L3_OCEAN_SST_V3) is also available for this dataset which uses this [algorithm](https://suzaku.eorc.jaxa.jp/GCOM_C/data/product_std.html) for processing.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/SST/V1')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient and add offset var dataset = dataset.mean().multiply(0.0012).add(-10);  var vis = {   bands: ['SST_AVE'],   min: 0,   max: 30,   palette: ['000000', '005aff', '43c8c8', 'fff700', 'ff0000'], };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, vis, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_SST_V2:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_SST_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_SST_V2(example: str = ''):
        """
        This product is the temperature of sea surface.  For data after 2021-11-28, see [the V3 dataset](JAXA/GCOM-C/L3/LAND/SST/V3).  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/SST/V2')                 .filterDate('2020-01-01', '2020-02-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient and add offset var dataset = dataset.mean().multiply(0.0012).add(-10);  var vis = {   bands: ['SST_AVE'],   min: 0,   max: 30,   palette: ['000000', '005aff', '43c8c8', 'fff700', 'ff0000'], };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, vis, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GCOM_C_L3_OCEAN_SST_V3:
    def __init__(self,):
        self.sensor = 'JAXA_GCOM_C_L3_OCEAN_SST_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GCOM-C_L3_OCEAN_SST_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GCOM_C_L3_OCEAN_SST_V3(example: str = ''):
        """
        This product is the temperature of sea surface.  This is an ongoing dataset with a latency of 3-4 days.  GCOM-C conducts long-term and continuous global observation and data collection to elucidate the mechanism behind fluctuations in radiation budget and carbon cycle needed to make accurate projections regarding future temperature rise. At the same time, cooperating with research institutions having a climate numerical model, it contributes to reduction of errors in temperature rise prediction derived from the climate numerical model and improvement of accuracy of prediction of various environmental changes. SGLI mounted on GCOM-C is the succession sensor of the Global Imager (GLI) mounted on ADEOS-II (MIDORI II) and is the Imaging Radiometer which measures the radiation from near-ultraviolet to thermal infrared region (380 nm-12 um) in 19 channels. Global observation of once for approximately every two days is possible at mid-latitude near Japan by observation width at ground greater than 1,000 km. In addition, SGLI realizes high resolution than the similar global sensor and has a polarized observation function and a multi-angle observation function. 
        :param example: var dataset = ee.ImageCollection('JAXA/GCOM-C/L3/OCEAN/SST/V3')                 .filterDate('2021-12-01', '2022-01-01')                 // filter to daytime data only                 .filter(ee.Filter.eq('SATELLITE_DIRECTION', 'D'));  // Multiply with slope coefficient and add offset var dataset = dataset.mean().multiply(0.0012).add(-10);  var vis = {   bands: ['SST_AVE'],   min: 0,   max: 30,   palette: ['000000', '005aff', '43c8c8', 'fff700', 'ff0000'], };  Map.setCenter(128.45, 33.33, 5);  Map.addLayer(dataset, vis, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GPM_L3_GSMaP_v6_operational:
    def __init__(self,):
        self.sensor = 'JAXA_GPM_L3_GSMaP_v6_operational'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GPM_L3_GSMaP_v6_operational.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GPM_L3_GSMaP_v6_operational.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GPM_L3_GSMaP_v6_operational(example: str = ''):
        """
        Global Satellite Mapping of Precipitation (GSMaP) provides a global hourly rain rate with a 0.1 x 0.1 degree resolution. GSMaP is a product of the Global Precipitation Measurement (GPM) mission, which provides global precipitation observations at three hour intervals.  Values are estimated using multi-band passive microwave and infrared radiometers from the GPM Core Observatory satellite and with the assistance of a constellation of other satellites.  GPM's precipitation rate retrieval algorithm is based on a radiative transfer model. The gauge-adjusted rate is calculated based on the optimization of the 24h accumulation of GSMaP hourly rain rate to daily precipitation by NOAA/CPC gauge measurement. This dataset is processed by GSMaP algorithm version 6 (product version 3). See [GSMaP Technical Documentation](https://www.eorc.jaxa.jp/GPM/doc/product/format/en/07.GPM_GSMaP_Product_Format_V5_E.pdf) for more details.  This dataset contains provisional products GSMaP_NRT that are regularly replaced with updated versions when the GSMaP_MVK data become available. The products are marked with a metadata property called ''status''. When a product is initially made available, the property value is ''provisional''. Once a provisional product has been updated with the final version, this value is updated to ''permanent''. For more information please refer [General Documentation](https://eolp.jaxa.jp/GSMaP_Hourly.html) 
        :param example: var dataset = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational')                   .filter(ee.Filter.date('2018-08-06', '2018-08-07')); var precipitation = dataset.select('hourlyPrecipRate'); var precipitationVis = {   min: 0.0,   max: 30.0,   palette:       ['1621a2', 'ffffff', '03ffff', '13ff03', 'efff00', 'ffb103', 'ff2300'], }; Map.setCenter(-90.7, 26.12, 2); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GPM_L3_GSMaP_v6_reanalysis:
    def __init__(self,):
        self.sensor = 'JAXA_GPM_L3_GSMaP_v6_reanalysis'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GPM_L3_GSMaP_v6_reanalysis.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GPM_L3_GSMaP_v6_reanalysis.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GPM_L3_GSMaP_v6_reanalysis(example: str = ''):
        """
        Global Satellite Mapping of Precipitation (GSMaP) provides a global hourly rain rate with a 0.1 x 0.1 degree resolution. GSMaP is a product of the Global Precipitation Measurement (GPM) mission, which provides global precipitation observations at three hour intervals.  Values are estimated using multi-band passive microwave and infrared radiometers from the GPM Core Observatory satellite and with the assistance of a constellation of other satellites.  GPM's precipitation rate retrieval algorithm is based on a radiative transfer model. The gauge-adjusted rate is calculated based on the optimization of the 24h accumulation of GSMaP hourly rain rate to daily precipitation by NOAA/CPC gauge measurement. This dataset is processed by GSMaP algorithm version 6 (product version 3). See [GSMaP Technical Documentation](https://www.eorc.jaxa.jp/GPM/doc/algorithm/GSMaPforGPM_20140902_E.pdf) for more details.  The operational GSMaP dataset (from 2014 to present) is also [available](JAXA_GPM_L3_GSMaP_v6_operational]. 
        :param example: var dataset = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/reanalysis')                   .filter(ee.Filter.date('2014-02-01', '2014-02-02')); var precipitation = dataset.select('hourlyPrecipRate'); var precipitationVis = {   min: 0.0,   max: 30.0,   palette:       ['1621a2', 'ffffff', '03ffff', '13ff03', 'efff00', 'ffb103', 'ff2300'], }; Map.setCenter(-90.7, 26.12, 2); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GPM_L3_GSMaP_v7_operational:
    def __init__(self,):
        self.sensor = 'JAXA_GPM_L3_GSMaP_v7_operational'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GPM_L3_GSMaP_v7_operational.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GPM_L3_GSMaP_v7_operational.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GPM_L3_GSMaP_v7_operational(example: str = ''):
        """
        Global Satellite Mapping of Precipitation (GSMaP) provides a global hourly rain rate with a 0.1 x 0.1 degree resolution. GSMaP is a product of the Global Precipitation Measurement (GPM) mission, which provides global precipitation observations at three hour intervals.  Values are estimated using multi-band passive microwave and infrared radiometers from the GPM Core Observatory satellite and with the assistance of a constellation of other satellites.  GPM's precipitation rate retrieval algorithm is based on a radiative transfer model. The gauge-adjusted rate is calculated based on the optimization of the 24h accumulation of GSMaP hourly rain rate to daily precipitation by NOAA/CPC gauge measurement. This dataset is processed by GSMaP algorithm version 7 (product version 4). See [GSMaP Technical Documentation](https://www.eorc.jaxa.jp/GPM/doc/product/format/en/07.GPM_GSMaP_Product_Format_V5_E.pdf) for more details.  This dataset contains provisional products GSMaP_NRT that are regularly replaced with updated versions when the GSMaP_MVK data become available. The products are marked with a metadata property called ''status''. When a product is initially made available, the property value is ''provisional''. Once a provisional product has been updated with the final version, this value is updated to ''permanent''. For more information please refer [General Documentation](https://eolp.jaxa.jp/GSMaP_Hourly.html) 
        :param example: var dataset = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v7/operational')                   .filter(ee.Filter.date('2023-09-10', '2023-09-11')); var precipitation = dataset.select('hourlyPrecipRate'); var precipitationVis = {   min: 0.0,   max: 10.0,   palette:       ['1621a2', 'ffffff', '03ffff', '13ff03', 'efff00', 'ffb103', 'ff2300'], }; Map.setCenter(-90.7, 26.12, 3); Map.addLayer(precipitation, precipitationVis, 'Precipitation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class JAXA_GPM_L3_GSMaP_v8_operational:
    def __init__(self,):
        self.sensor = 'JAXA_GPM_L3_GSMaP_v8_operational'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JAXA_GPM_L3_GSMaP_v8_operational.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JAXA_GPM_L3_GSMaP_v8_operational.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JAXA_GPM_L3_GSMaP_v8_operational(example: str = ''):
        """
        Global Satellite Mapping of Precipitation (GSMaP) provides a global hourly rain rate with a 0.1 x 0.1 degree resolution. GSMaP is a product of the Global Precipitation Measurement (GPM) mission, which provides global precipitation observations at three hour intervals.  Values are estimated using multi-band passive microwave and infrared radiometers from the GPM Core Observatory satellite and with the assistance of a constellation of other satellites.  GPM's precipitation rate retrieval algorithm is based on a radiative transfer model. The gauge-adjusted rate is calculated based on the optimization of the 24h accumulation of GSMaP hourly rain rate to daily precipitation by NOAA/CPC gauge measurement. This dataset is processed by GSMaP algorithm version 8 (product version 5). See [GSMaP Technical Documentation](https://www.eorc.jaxa.jp/GPM/doc/product/format/en/07.GPM_GSMaP_Product_Format_V5_E.pdf) for more details.  This dataset contains provisional products GSMaP_NRT that are regularly replaced with updated versions when the GSMaP_MVK data become available. The products are marked with a metadata property called ''status''. When a product is initially made available, the property value is ''provisional''. Once a provisional product has been updated with the final version, this value is updated to ''permanent''. For more information please refer [General Documentation](https://eolp.jaxa.jp/GSMaP_Hourly.html) 
        :param example: var dataset = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v8/operational')                   .filter(ee.Filter.date('2023-09-12', '2023-09-13')); var precipitation = dataset.select('hourlyPrecipRate'); var precipitationVis = {   min: 0.0,   max: 10.0,   palette:       ['1621a2', 'ffffff', '03ffff', '13ff03', 'efff00', 'ffb103', 'ff2300'], }; Map.setCenter(-90.7, 26.12, 3); Map.addLayer(precipitation, precipitationVis, 'Precipitation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class JCU_Murray_GIC_global_tidal_wetland_change_2019:
    def __init__(self,):
        self.sensor = 'JCU_Murray_GIC_global_tidal_wetland_change_2019'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JCU_Murray_GIC_global_tidal_wetland_change_2019.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JCU_Murray_GIC_global_tidal_wetland_change_2019.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JCU_Murray_GIC_global_tidal_wetland_change_2019(example: str = ''):
        """
        The Murray Global Tidal Wetland Change Dataset contains maps of the global extent of tidal wetlands and their change. The maps were developed from a three stage classification that sought to (i) estimate the global distribution of tidal wetlands (defined as either tidal marsh, tidal flat or mangrove ecosystems), (ii) detect their change over the study period, and (iii) estimate the ecosystem type and timing of tidal wetland change events.  The dataset was produced by combining observations from 1,166,385 satellite images acquired by Landsat 5 to 8 with environmental data of variables known to influence the distributions of each ecosystem type, including temperature, slope, and elevation. The image contains bands for a tidal wetland extent product (random forest probability of tidal wetland occurrence) for the start and end time-steps of the study period and a tidal wetland change product over the full study period (loss and gain of tidal wetlands).  Please see the [usage notes](https://www.globalintertidalchange.org/data-usage) on the [project website](https://www.globalintertidalchange.org/). A full description of the methods, validation, and limitations of the data produced by this software is available in the associated scientific paper.  See also [UQ/murray/Intertidal/v1_1/global_intertidal](UQ_murray_Intertidal_v1_1_global_intertidal) for global maps of the distribution of tidal flat ecosystems. 
        :param example: var dataset = ee.Image('JCU/Murray/GIC/global_tidal_wetland_change/2019');  Map.setCenter(103.7, 1.3, 12); Map.setOptions('SATELLITE');  var plasma = [   '0d0887', '3d049b', '6903a5', '8d0fa1', 'ae2891', 'cb4679', 'df6363',   'f0844c', 'faa638', 'fbcc27', 'f0f921' ]; Map.addLayer(     dataset.select('twprobabilityStart'), {palette: plasma, min: 0, max: 100},     'twprobabilityStart', false, 1); Map.addLayer(     dataset.select('twprobabilityEnd'), {palette: plasma, min: 0, max: 100},     'twprobabilityEnd', false, 1);  var lossPalette = ['fe4a49']; var gainPalette = ['2ab7ca']; Map.addLayer(     dataset.select('loss'), {palette: lossPalette, min: 1, max: 1},     'Tidal wetland loss', true, 1); Map.addLayer(     dataset.select('gain'), {palette: gainPalette, min: 1, max: 1},     'Tidal wetland gain', true, 1);  var viridis = ['440154', '414487', '2a788e', '22a884', '7ad151', 'fde725']; Map.addLayer(     dataset.select('lossYear'), {palette: viridis, min: 4, max: 19},     'Year of loss', false, 0.9); Map.addLayer(     dataset.select('gainYear'), {palette: viridis, min: 4, max: 19},     'Year of gain', false, 0.9);  // Ecosystem type. var classPalette = ['9e9d9d', 'ededed', 'ff9900', '009966', '960000', '006699']; var classNames =     ['null', 'null', 'Tidal flat', 'Mangrove', 'null', 'Tidal marsh']; Map.addLayer(     dataset.select('lossType'), {palette: classPalette, min: 0, max: 5},     'Loss type', false, 0.9); Map.addLayer(     dataset.select('gainType'), {palette: classPalette, min: 0, max: 5},     'Gain type', false, 0.9); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_D5_EUCROPMAP_V1:
    def __init__(self,):
        self.sensor = 'JRC_D5_EUCROPMAP_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_D5_EUCROPMAP_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_D5_EUCROPMAP_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_D5_EUCROPMAP_V1(example: str = ''):
        """
        European crop type map based on Sentinel-1 and LUCAS Copernicus in-situ observations for 2018.  Capitalizing on the unique [LUCAS 2018 Copernicus in-situ survey](JRC_LUCAS_HARMO_THLOC_V1), this dataset is the first continental crop type map with 10m pixel size for the EU based on S1A and S1B Synthetic Aperture Radar observations for the year 2018. 
        :param example: var image = ee.ImageCollection('JRC/D5/EUCROPMAP/V1').filterDate(     '2018-01-01', '2019-01-01').first(); Map.addLayer(image, {}, 'EUCROPMAP 2018'); Map.setCenter(10, 48, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GFC2020_V1:
    def __init__(self,):
        self.sensor = 'JRC_GFC2020_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GFC2020_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GFC2020_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GFC2020_V1(example: str = ''):
        """
        The EC JRC global map of forest cover provides a spatially explicit representation of forest presence and absence for the year 2020 at 10m spatial resolution.  The year 2020 corresponds to the cut-off date of the Regulation from the European Union "on the making available on the Union market and the export from the Union of certain commodities and products associated with deforestation and forest degradation" (EUDR, [Regulation (EU) 2023/1115](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32023R1115)). In the context of the EUDR, the global forest cover map can be used as a non-mandatory, non-exclusive, and not legally binding source of information. Further information about the map and its use can be found on the [EU Observatory on Deforestation and Forest Degradation](https://forest-observatory.ec.europa.eu/forest/) (EUFO) in the section on Frequently Asked Questions.  Forest means land spanning more than 0.5 hectares with trees higher than 5 meters and a canopy cover of more than 10%, or trees able to reach those thresholds in situ, excluding land that is predominantly under agricultural or urban land use. Agricultural use means the use of land for the purpose of agriculture, including for agricultural plantations (i.e. tree stands in agricultural production systems such as fruit tree plantations, oil palm plantations, olive orchards and agroforestry systems) and set- aside agricultural areas, and for rearing livestock. All plantations of relevant commodities other than wood, that is cattle, cocoa, coffee, oil palm, rubber, soya, are excluded from the forest definition.  The global map of forest cover was created by combining available global datasets (wall-to-wall or global in their scope) on tree cover, tree height, land cover and land use into a single harmonized globally-consistent representation of where forests existed in 2020.  The workflow consisted in first mapping the global maximum extent of tree cover circa the year 2020 from the combination of ESA World Cover 2020 and 2021, WRI Tropical Tree Cover 2020, UMD Global land cover and land use 2019, Global Mangrove Watch 2020, and JRC Tropical Moist Forest 2020 datasets. In the second step, a series of overlays and decision rules were applied to reduce this maximum extent of tree cover and align it with the Forest definition using datasets covering cropland and commodity expansion (ESA World Cereal, UMD Global land cover and land use 2019, UMD Global Cropland Expansion, High-resolution global map of smallholder and industrial oil palm plantations, and WRI Spatial Database of Planted Trees), land use change (UMD global forest cover loss, JRC Tropical Moist Forest, IIASA Global Forest Management), built-up (JRC Global Human Settlement), and water (JRC Global Surface Water).  The detailed mapping approach will be described in a separate technical report expected to be released by March 2024. The accuracy of this map has not been yet assessed but will be reported as soon as available.  Please also refer to the [list of known issues](https://forobs.jrc.ec.europa.eu/GFC) and to the [JRC Data Catalogue entry](https://data.jrc.ec.europa.eu/dataset/10d1b337-b7d1-4938-a048-686c8185b290). 
        :param example: var image2020 = ee.ImageCollection('JRC/GFC2020/V1').filterDate(   '2020-12-31').first();  var visualization = {   bands: ['Map'],   palette: ['4D9221']};  Map.setCenter(0.0, 0.0, 2);  Map.addLayer(image2020, visualization, 'EC JRC Global forest cover 2020 – V1'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2016_BUILT_LDSMT_GLOBE_V1:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2016_BUILT_LDSMT_GLOBE_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2016_BUILT_LDSMT_GLOBE_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2016_BUILT_LDSMT_GLOBE_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2016_BUILT_LDSMT_GLOBE_V1(example: str = ''):
        """
        The GHSL relies on the design and implementation of new spatial data mining technologies allowing to automatically process and extract analytics and knowledge from large amount of heterogeneous data including: global, fine-scale satellite image data streams, census data, and crowd sources or volunteered geographic information sources.  These data contain a multitemporal information layer on built-up presence as derived from Landsat image collections (GLS1975, GLS1990, GLS2000, and ad-hoc Landsat 8 collection 2013/2014).  The data have been produced by means of [Global Human Settlement Layer methodology](https://publications.jrc.ec.europa.eu/repository/handle/JRC97705) in 2015.  For more information visit: [https://ghsl.jrc.ec.europa.eu/ghs_bu.php](https://ghsl.jrc.ec.europa.eu/ghs_bu.php) and [https://ghsl.jrc.ec.europa.eu/documents/GHSL_data_access.pdf](https://ghsl.jrc.ec.europa.eu/documents/GHSL_data_access.pdf).  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Center, and Directorate-General for Regional and Urban Policy. The GHSL produces new global spatial information, evidence-based analytics, and knowledge describing the human presence in the planet. 
        :param example: var dataset = ee.Image('JRC/GHSL/P2016/BUILT_LDSMT_GLOBE_V1'); var builtUpMultitemporal = dataset.select('built'); var visParams = {   min: 1.0,   max: 6.0,   palette: ['0c1d60', '000000', '448564', '70daa4', '83ffbf', 'ffffff'], }; Map.setCenter(8.9957, 45.5718, 12); Map.addLayer(builtUpMultitemporal, visParams, 'Built-Up Multitemporal'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2016_POP_GPW_GLOBE_V1:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2016_POP_GPW_GLOBE_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2016_POP_GPW_GLOBE_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2016_POP_GPW_GLOBE_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2016_POP_GPW_GLOBE_V1(example: str = ''):
        """
        The GHSL relies on the design and implementation of new spatial data mining technologies allowing to automatically process and extract analytics and knowledge from large amount of heterogeneous data including: global, fine-scale satellite image data streams, census data, and crowd sources or volunteered geographic information sources.  This dataset depicts the distribution and density of population, expressed as the number of people per cell, for reference epochs: 1975, 1990, 2000, 2015.  Residential population estimates were provided by CIESIN GPW v4. These were disaggregated from census or administrative units to grid cells, informed by the distribution and density of built-up as mapped in the GHSL global layer per corresponding epoch. (See ["Development of New Open and Free Multi-temporal Global Population Grids at 250 m Resolution."](https://publications.jrc.ec.europa.eu/repository/handle/JRC100523))  This dataset was produced in the World Mollweide projection (EPSG:54009).  For more information visit: [https://ghsl.jrc.ec.europa.eu/ghs_pop.php](https://ghsl.jrc.ec.europa.eu/ghs_pop.php).  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Center, and Directorate-General for Regional and Urban Policy. The GHSL produces new global spatial information, evidence-based analytics, and knowledge describing the human presence in the planet. 
        :param example: var dataset = ee.ImageCollection('JRC/GHSL/P2016/POP_GPW_GLOBE_V1')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var populationCount = dataset.select('population_count'); var populationCountVis = {   min: 0.0,   max: 200.0,   palette: ['060606', '337663', '337663', 'ffffff'], }; Map.setCenter(78.22, 22.59, 3); Map.addLayer(populationCount, populationCountVis, 'Population Count'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2016_SMOD_POP_GLOBE_V1:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2016_SMOD_POP_GLOBE_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2016_SMOD_POP_GLOBE_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2016_SMOD_POP_GLOBE_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2016_SMOD_POP_GLOBE_V1(example: str = ''):
        """
        The GHSL relies on the design and implementation of new spatial data mining technologies allowing to automatically process and extract analytics and knowledge from large amount of heterogeneous data including: global, fine-scale satellite image data streams, census data, and crowd sources or volunteered geographic information sources.  The GHS-SMOD is the rural-urban Settlement classification MODel adopted by the GHSL. It is the representation of the degree of urbanization ([DEGURBA](https://ec.europa.eu/eurostat/web/degree-of-urbanisation/background)) concept into the GHSL data scenario. Each grid in the GHS-SMOD has been generated by integrating the GHSL built-up areas and GHSL population grids data for reference epochs: 1975, 1990, 2000, 2015.  The DEGURBA classification schema is a people-based definition of cities and settlements: it operates using as main input a 1 km² grid cell accounting for population at a given point in time. The DEGURBA discriminates the population grid cells in three main classes: '[urban centers](https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Urban_centre)' (cities), '[urban clusters](https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Urban_cluster)' (towns and suburbs), and '[rural grid cells](https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Rural_grid_cell)'. (base). These class abstractions translate to 'high density clusters (HDC)', 'low density clusters (LDC)', and 'rural grid cells (RUR)', respectively, in the GHS-SMOD implementation.  The 'HDC' differ from the DEGURBA '[urban centers](https://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Urban_centre)' in that they account for the over-fragmentation of cities in regions with large low-density residential development by integrating the built-up layer. In the GHS-SMOD representation, the 'HDC' are the spatial generalization of contiguous population grid cells (4-connectivity, gap-filling) with a density of at least 1500 inhabitants per km² or a density of built-up surface > 50%, and a minimum total resident population of 50000. The 'LDC' are continuous grid cells with a density of at least 300 inhabitants per km² and a minimum total population of 5000. The 'RUR' are grid cells outside 'HDC' and 'LDC' with population > 0 and < 300. Everything else is classified as inhabited areas where population = 0.  This dataset was produced in the World Mollweide projection (EPSG:54009).  For more information visit: [http://ghsl.jrc.ec.europa.eu/ghs_smod.php](http://ghsl.jrc.ec.europa.eu/ghs_smod.php).  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Center, and Directorate-General for Regional and Urban Policy. The GHSL produces new global spatial information, evidence-based analytics, and knowledge describing the human presence in the planet. 
        :param example: var dataset = ee.ImageCollection('JRC/GHSL/P2016/SMOD_POP_GLOBE_V1')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var degreeOfUrbanization = dataset.select('smod_code'); var visParams = {   min: 0.0,   max: 3.0,   palette: ['000000', '448564', '70daa4', 'ffffff'], }; Map.setCenter(114.96, 31.13, 4); Map.addLayer(degreeOfUrbanization, visParams, 'Degree of Urbanization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_BUILT_C:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_BUILT_C'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_BUILT_C.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_BUILT_C.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_BUILT_C(example: str = ''):
        """
        This spatial raster dataset delineates human settlements at 10 m resolution, and describes their inner characteristics in terms of the functional and height-related components of the built environment.  More information about the GHSL data products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422)  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Centre, and Directorate-General for Regional and Urban Policy. 
        :param example: var image = ee.Image("JRC/GHSL/P2023A/GHS_BUILT_C/2018"); var built = image.select('built_characteristics'); Map.setCenter(77.58, 12.97, 13); Map.addLayer(built, {}, 'Settlement_characteristics (2018)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_BUILT_H:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_BUILT_H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_BUILT_H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_BUILT_H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_BUILT_H(example: str = ''):
        """
        This spatial raster dataset depicts the global distribution of building heights at a resolution of 100 m, referred to the year 2018. The input data used to predict building heights are the ALOS Global Digital Surface Model (30 m), the NASA Shuttle Radar Topographic Mission data (30 m), and a global Sentinel-2 image composite from L1C data for the period 2017-2018.  More information about the GHSL data products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422), where the building height layer is referred to as the Average Net Building Height (ANBH).  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Centre, and Directorate-General for Regional and Urban Policy. 
        :param example: var image = ee.Image("JRC/GHSL/P2023A/GHS_BUILT_H/2018"); var built = image.select('built_height'); var visParams = {   min: 0.0,   max: 12.0,   palette: ['000000', '0d0887', '7e03a8', 'cc4778', 'f89540', 'f0f921'], };  Map.setCenter(2.349014, 48.864716, 10); Map.addLayer(built, visParams, 'Average building height [m], 2018');
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_BUILT_S:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_BUILT_S'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_BUILT_S.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_BUILT_S.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_BUILT_S(example: str = ''):
        """
        These raster datasets depict the distribution of built-up surfaces, expressed in square metres per 100 m grid cell. The datasets measure: a) the total built-up surface, and b) the built-up surface allocated to grid cells of predominant non-residential (NRES) use. Data are spatially-temporally interpolated or extrapolated from 1975 to 2030 in 5 year intervals.  The complete information about the GHSL main products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422)  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Centre, and Directorate-General for Regional and Urban Policy. 
        :param example: var image_1975 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/1975'); var built_1975 = image_1975.select('built_surface'); var image_2020 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_S/2020'); var built_2020 = image_2020.select('built_surface'); var visParams = {min: 0.0, max: 8000.0, palette: ['000000', 'FFFFFF']};  Map.setCenter(77.156, 28.6532, 10); Map.addLayer(built_1975, visParams, 'Built-up surface [m2], 1975'); Map.addLayer(built_2020, visParams, 'Built-up surface [m2], 2020'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_BUILT_V:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_BUILT_V'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_BUILT_V.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_BUILT_V.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_BUILT_V(example: str = ''):
        """
        These raster datasets depict the global distribution of building volume, expressed in cubic metres per 100 m grid cell. The datasets measure the total building volume and the building volume allocated to grid cells of predominant non-residential (NRES) use. Estimates are based on the (built-up surface) [ https://developers.google.com/earth-engine/datasets/catalog/JRC_GHSL_P2023A_GHS_BUILT_S] and (building height)) [https://developers.google.com/earth-engine/datasets/catalog/JRC_GHSL_P2023A_GHS_BUILT_H] products.  More information about the GHSL data products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422)  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Centre, and Directorate-General for Regional and Urban Policy. 
        :param example: var image_1975 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_V/1975'); var image_2020 = ee.Image('JRC/GHSL/P2023A/GHS_BUILT_V/2020'); var volume_total_1975 = image_1975.select('built_volume_total'); var volume_total_2020 = image_2020.select('built_volume_total');   var visParams = {   min: 0,   max: 80000,   palette: ['000004', '51127c', 'b73779', 'fc8961', 'fcfdbf'], };  Map.setCenter(77.156, 28.6532, 10); Map.addLayer(volume_total_1975, visParams, 'Total building volume [m3], 1975'); Map.addLayer(volume_total_2020, visParams, 'Total building volume [m3], 2020');
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_POP:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_POP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_POP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_POP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_POP(example: str = ''):
        """
        This raster dataset depicts the spatial distribution of residential population, expressed as the absolute number of inhabitants of the cell. Residential population estimates between 1975 and 2020 in 5-year intervals and projections to 2025 and 2030 derived from CIESIN GPWv4.11 were disaggregated from census or administrative units to grid cells, informed by the distribution, volume, and classification of built-up area as mapped in the global GHSL built-up surface layers per epoch.  More information about the GHSL main products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422)  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Center, and Directorate-General for Regional and Urban Policy. 
        :param example: var baseChange =     [{featureType: 'all', stylers: [{saturation: -100}, {lightness: 45}]}]; Map.setOptions('baseChange', {'baseChange': baseChange}); var image1975 = ee.Image('JRC/GHSL/P2023A/GHS_POP/1975'); var image1990 = ee.Image('JRC/GHSL/P2023A/GHS_POP/1990'); var image2020 = ee.Image('JRC/GHSL/P2023A/GHS_POP/2020'); var populationCountVis = {   min: 0.0,   max: 100.0,   palette:       ['000004', '320A5A', '781B6C', 'BB3654', 'EC6824', 'FBB41A', 'FCFFA4'] }; Map.setCenter(8, 48, 7); image1975 = image1975.updateMask(image1975.gt(0)); image1990 = image1990.updateMask(image1990.gt(0)); image2020 = image2020.updateMask(image2020.gt(0)); Map.addLayer(image1975, populationCountVis, 'Population count, 1975'); Map.addLayer(image1990, populationCountVis, 'Population count, 1990'); Map.addLayer(image2020, populationCountVis, 'Population count, 2020'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GHSL_P2023A_GHS_SMOD:
    def __init__(self,):
        self.sensor = 'JRC_GHSL_P2023A_GHS_SMOD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GHSL_P2023A_GHS_SMOD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GHSL_P2023A_GHS_SMOD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GHSL_P2023A_GHS_SMOD(example: str = ''):
        """
        This raster dataset represents a global, multitemporal rural-urban classification, applying the "Degree of Urbanisation" stage I methodology recommended by UN Statistical Commission, based on global gridded population and built-up surface data generated by the GHSL project for the epochs 1975-2030 in 5-year intervals. The Degree of Urbanisation layers have been generated by integrating information on built-up surface extracted from Landsat and Sentinel-2 data [GHS-BUILT-S R2023] (https://developers.google.com/earth-engine/datasets/catalog/JRC_GHSL_P2023A_GHS_BUILT_S), and gridded population data derived from CIESIN GPW v4.11 [GHS-POP R2023] (https://developers.google.com/earth-engine/datasets/catalog/JRC_GHSL_P2023A_GHS_POP). This product is an update of the data released in 2022 based on the updates of the GHS-BUILT-S and GHS-POP. The Settlement Model is provided at the detailed level (Second Level - L2). The first-level classification can be obtained by aggregating L2.  The complete information about the GHSL main products can be found in the [GHSL Data Package 2023 report] (https://ghsl.jrc.ec.europa.eu/documents/GHSL_Data_Package_2023.pdf?t=1683540422)  The Global Human Settlement Layer (GHSL) project is supported by the European Commission, Joint Research Center, and Directorate-General for Regional and Urban Policy. 
        :param example: var image = ee.Image("JRC/GHSL/P2023A/GHS_SMOD/2030"); var smod = image.select('smod_code'); Map.setCenter(84, 25, 5); Map.addLayer(image, {}, 'Degree of Urbanization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_0_GlobalSurfaceWater:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_0_GlobalSurfaceWater'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_0_GlobalSurfaceWater.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_0_GlobalSurfaceWater.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_0_GlobalSurfaceWater(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2015 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,066,102 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 10 October 2015. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2015) for change detection.  This mapping layers product consists of 1 image containing 7 bands. It maps different facets of the spatial and temporal distribution of surface water over the last 32 years. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_0/GlobalSurfaceWater'); var occurrence = dataset.select('occurrence'); var occurrenceVis = {   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'], }; Map.setCenter(59.414, 45.182, 6); Map.addLayer(occurrence, occurrenceVis, 'Occurrence');
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_0_Metadata:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_0_Metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_0_Metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_0_Metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_0_Metadata(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2015 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,066,102 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 10 October 2015. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2015) for change detection.  This product contains metadata about the observations that went into computing The Global Surface Water dataset. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_0/Metadata'); var detectionsObservations =     dataset.select(['detections', 'valid_obs', 'total_obs']); var visParams = {   min: 100.0,   max: 900.0, }; Map.setCenter(4.72, -2.48, 2); Map.addLayer(detectionsObservations, visParams, 'Detections/Observations'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_0_MonthlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_0_MonthlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_0_MonthlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_0_MonthlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_0_MonthlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2015 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,066,102 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 10 October 2015. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2015) for change detection.  This Monthly History collection holds the entire history of water detection on a month-by-month basis. The collection contains 380 images, one for each month between March 1984 and October 2015. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_0/MonthlyHistory')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var water = dataset.select('water'); var waterVis = {   min: 0.0,   max: 2.0,   palette: ['ffffff', 'fffcb8', '0905ff'], }; Map.setCenter(-58.999, -3.373, 7); Map.addLayer(water, waterVis, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_0_MonthlyRecurrence:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_0_MonthlyRecurrence'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_0_MonthlyRecurrence.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_0_MonthlyRecurrence.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_0_MonthlyRecurrence(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2015 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,066,102 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 10 October 2015. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2015) for change detection.  The Monthly Recurrence collection contains 12 images: monthly measures of the seasonality of water based on the occurrence values detected in that month over all years. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_0/MonthlyRecurrence').first(); var monthlyRecurrence = dataset.select('monthly_recurrence'); var monthlyRecurrenceVis = {   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'], }; Map.setCenter(-51.482, -0.835, 9); Map.addLayer(monthlyRecurrence, monthlyRecurrenceVis, 'Monthly Recurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_0_YearlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_0_YearlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_0_YearlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_0_YearlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_0_YearlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2015 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,066,102 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 10 October 2015. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2015) for change detection.  This Yearly Seasonality Classification collection contains a year-by-year classification of the seasonality of water based on the occurrence values detected throughout the year. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_0/YearlyHistory')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var waterClass = dataset.select('waterClass'); var waterClassVis = {   min: 0.0,   max: 3.0,   palette: ['cccccc', 'ffffff', '99d9ea', '0000ff'], }; Map.setCenter(59.414, 45.182, 7); Map.addLayer(waterClass, waterClassVis, 'Water Class'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_1_GlobalSurfaceWater:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_1_GlobalSurfaceWater'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_1_GlobalSurfaceWater.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_1_GlobalSurfaceWater.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_1_GlobalSurfaceWater(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2018 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,865,618 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2018. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2018) for change detection.  This mapping layers product consists of 1 image containing 7 bands. It maps different facets of the spatial and temporal distribution of surface water over the last 35 years. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_1/GlobalSurfaceWater');  var visualization = {   bands: ['occurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(59.414, 45.182, 6);  Map.addLayer(dataset, visualization, 'Occurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_1_Metadata:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_1_Metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_1_Metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_1_Metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_1_Metadata(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2018 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,865,618 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2018. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2018) for change detection.  This product contains metadata about the observations that went into computing The Global Surface Water dataset. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_1/Metadata');  var visualization = {   bands: ['detections', 'valid_obs', 'total_obs'],   min: 100.0,   max: 900.0, };  Map.setCenter(71.72, 52.48, 0);  Map.addLayer(dataset, visualization, 'Detections/Observations'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_1_MonthlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_1_MonthlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_1_MonthlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_1_MonthlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_1_MonthlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2018 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,865,618 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2018. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2018) for change detection.  This Monthly History collection holds the entire history of water detection on a month-by-month basis. The collection contains 418 images, one for each month between March 1984 and December 2018. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_1/MonthlyHistory');  var visualization = {   bands: ['water'],   min: 0.0,   max: 2.0,   palette: ['ffffff', 'fffcb8', '0905ff'] };  Map.setCenter(-121.234, 38.109, 7);  Map.addLayer(dataset, visualization, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_1_MonthlyRecurrence:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_1_MonthlyRecurrence'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_1_MonthlyRecurrence.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_1_MonthlyRecurrence.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_1_MonthlyRecurrence(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2018 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,865,618 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2018. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2018) for change detection.  The Monthly Recurrence collection contains 12 images: monthly measures of the seasonality of water based on the occurrence values detected in that month over all years. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_1/MonthlyRecurrence');  var visualization = {   bands: ['monthly_recurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(-51.482, -0.835, 6);  Map.addLayer(dataset, visualization, 'Monthly Recurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_1_YearlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_1_YearlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_1_YearlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_1_YearlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_1_YearlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2018 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 3,865,618 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2018. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2018) for change detection.  This Yearly Seasonality Classification collection contains a year-by-year classification of the seasonality of water based on the occurrence values detected throughout the year. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_1/YearlyHistory');  var visualization = {   bands: ['waterClass'],   min: 0.0,   max: 3.0,   palette: ['cccccc', 'ffffff', '99d9ea', '0000ff'] };  Map.setCenter(59.414, 45.182, 7);  Map.addLayer(dataset, visualization, 'Water Class'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_2_GlobalSurfaceWater:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_2_GlobalSurfaceWater'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_2_GlobalSurfaceWater.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_2_GlobalSurfaceWater.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_2_GlobalSurfaceWater(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2019 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,185,439 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2019. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2019) for change detection.  This mapping layers product consists of 1 image containing 7 bands. It maps different facets of the spatial and temporal distribution of surface water over the last 35 years. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_2/GlobalSurfaceWater');  var visualization = {   bands: ['occurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(59.414, 45.182, 6);  Map.addLayer(dataset, visualization, 'Occurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_2_Metadata:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_2_Metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_2_Metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_2_Metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_2_Metadata(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2019 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,185,439 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2019. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2019) for change detection.  This product contains metadata about the observations that went into computing The Global Surface Water dataset. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_2/Metadata');  var visualization = {   bands: ['detections', 'valid_obs', 'total_obs'],   min: 100.0,   max: 900.0, };  Map.setCenter(71.72, 52.48, 0);  Map.addLayer(dataset, visualization, 'Detections/Observations'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_2_MonthlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_2_MonthlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_2_MonthlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_2_MonthlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_2_MonthlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2019 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,185,439 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2019. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2019) for change detection.  This Monthly History collection holds the entire history of water detection on a month-by-month basis. The collection contains 430 images, one for each month between March 1984 and December 2019. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_2/MonthlyHistory');  var visualization = {   bands: ['water'],   min: 0.0,   max: 2.0,   palette: ['ffffff', 'fffcb8', '0905ff'] };  Map.setCenter(-121.234, 38.109, 7);  Map.addLayer(dataset, visualization, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_2_MonthlyRecurrence:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_2_MonthlyRecurrence'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_2_MonthlyRecurrence.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_2_MonthlyRecurrence.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_2_MonthlyRecurrence(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2019 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,185,439 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2019. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2019) for change detection.  The Monthly Recurrence collection contains 12 images: monthly measures of the seasonality of water based on the occurrence values detected in that month over all years. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_2/MonthlyRecurrence');  var visualization = {   bands: ['monthly_recurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(-51.482, -0.835, 6);  Map.addLayer(dataset, visualization, 'Monthly Recurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_2_YearlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_2_YearlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_2_YearlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_2_YearlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_2_YearlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2019 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,185,439 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2019. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2019) for change detection.  This Yearly Seasonality Classification collection contains a year-by-year classification of the seasonality of water based on the occurrence values detected throughout the year. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_2/YearlyHistory');  var visualization = {   bands: ['waterClass'],   min: 0.0,   max: 3.0,   palette: ['cccccc', 'ffffff', '99d9ea', '0000ff'] };  Map.setCenter(59.414, 45.182, 7);  Map.addLayer(dataset, visualization, 'Water Class'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_3_GlobalSurfaceWater:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_3_GlobalSurfaceWater'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_3_GlobalSurfaceWater.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_3_GlobalSurfaceWater.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_3_GlobalSurfaceWater(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2020 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,453,989 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2020. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2020) for change detection.  This mapping layers product consists of 1 image containing 7 bands. It maps different facets of the spatial and temporal distribution of surface water over the last 35 years. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_3/GlobalSurfaceWater');  var visualization = {   bands: ['occurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(59.414, 45.182, 6);  Map.addLayer(dataset, visualization, 'Occurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_3_Metadata:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_3_Metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_3_Metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_3_Metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_3_Metadata(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2020 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,453,989 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2020. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2020) for change detection.  This product contains metadata about the observations that went into computing The Global Surface Water dataset. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_3/Metadata');  var visualization = {   bands: ['detections', 'valid_obs', 'total_obs'],   min: 100.0,   max: 900.0, };  Map.setCenter(71.72, 52.48, 0);  Map.addLayer(dataset, visualization, 'Detections/Observations'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_3_MonthlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_3_MonthlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_3_MonthlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_3_MonthlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_3_MonthlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2020 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,453,989 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2020. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2020) for change detection.  This Monthly History collection holds the entire history of water detection on a month-by-month basis. The collection contains 442 images, one for each month between March 1984 and December 2020. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_3/MonthlyHistory');  var visualization = {   bands: ['water'],   min: 0.0,   max: 2.0,   palette: ['ffffff', 'fffcb8', '0905ff'] };  Map.setCenter(-121.234, 38.109, 7);  Map.addLayer(dataset, visualization, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_3_MonthlyRecurrence:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_3_MonthlyRecurrence'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_3_MonthlyRecurrence.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_3_MonthlyRecurrence.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_3_MonthlyRecurrence(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2020 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,453,989 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2020. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2020) for change detection.  The Monthly Recurrence collection contains 12 images: monthly measures of the seasonality of water based on the occurrence values detected in that month over all years. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_3/MonthlyRecurrence');  var visualization = {   bands: ['monthly_recurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(-51.482, -0.835, 6);  Map.addLayer(dataset, visualization, 'Monthly Recurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_3_YearlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_3_YearlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_3_YearlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_3_YearlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_3_YearlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2020 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2.pdf).  These data were generated using 4,453,989 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2020. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2020) for change detection.  This Yearly Seasonality Classification collection contains a year-by-year classification of the seasonality of water based on the occurrence values detected throughout the year. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_3/YearlyHistory');  var visualization = {   bands: ['waterClass'],   min: 0.0,   max: 3.0,   palette: ['cccccc', 'ffffff', '99d9ea', '0000ff'] };  Map.setCenter(59.414, 45.182, 7);  Map.addLayer(dataset, visualization, 'Water Class'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_4_GlobalSurfaceWater:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_4_GlobalSurfaceWater'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_4_GlobalSurfaceWater.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_4_GlobalSurfaceWater.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_4_GlobalSurfaceWater(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2021 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf).  These data were generated using 4,716,475 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2021. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2021) for change detection.  This mapping layers product consists of 1 image containing 7 bands. It maps different facets of the spatial and temporal distribution of surface water over the last 38 years. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_4/GlobalSurfaceWater');  var visualization = {   bands: ['occurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(59.414, 45.182, 6);  Map.addLayer(dataset, visualization, 'Occurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_4_Metadata:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_4_Metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_4_Metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_4_Metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_4_Metadata(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2021 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf).  These data were generated using 4,716,475 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2021. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2021) for change detection.  This product contains metadata about the observations that went into computing The Global Surface Water dataset. Areas where water has never been detected are masked. 
        :param example: var dataset = ee.Image('JRC/GSW1_4/Metadata');  var visualization = {   bands: ['detections', 'valid_obs', 'total_obs'],   min: 100.0,   max: 900.0, };  Map.setCenter(71.72, 52.48, 0);  Map.addLayer(dataset, visualization, 'Detections/Observations'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_4_MonthlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_4_MonthlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_4_MonthlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_4_MonthlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_4_MonthlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2021 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf).  These data were generated using 4,716,475 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2021. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2021) for change detection.  This Monthly History collection holds the entire history of water detection on a month-by-month basis. The collection contains 454 images, one for each month between March 1984 and December 2021. 
        :param example: var dataset = ee.Image('JRC/GSW1_4/MonthlyHistory/2020_06');  var visualization = {   bands: ['water'],   min: 0.0,   max: 2.0,   palette: ['ffffff', 'fffcb8', '0905ff'] };  Map.setCenter(-121.234, 38.109, 7);  Map.addLayer(dataset, visualization, 'Water'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_4_MonthlyRecurrence:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_4_MonthlyRecurrence'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_4_MonthlyRecurrence.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_4_MonthlyRecurrence.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_4_MonthlyRecurrence(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2021 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf).  These data were generated using 4,716,475 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2021. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2021) for change detection.  The Monthly Recurrence collection contains 12 images: monthly measures of the seasonality of water based on the occurrence values detected in that month over all years. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_4/MonthlyRecurrence');  var visualization = {   bands: ['monthly_recurrence'],   min: 0.0,   max: 100.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  Map.setCenter(-51.482, -0.835, 6);  Map.addLayer(dataset, visualization, 'Monthly Recurrence'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GSW1_4_YearlyHistory:
    def __init__(self,):
        self.sensor = 'JRC_GSW1_4_YearlyHistory'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GSW1_4_YearlyHistory.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GSW1_4_YearlyHistory.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GSW1_4_YearlyHistory(example: str = ''):
        """
        This dataset contains maps of the location and temporal distribution of surface water from 1984 to 2021 and provides statistics on the extent and change of those water surfaces. For more information see the associated journal article: [High-resolution mapping of global surface water and its long-term changes](https://www.nature.com/nature/journal/v540/n7633/full/nature20584.html) (Nature, 2016) and the online [Data Users Guide](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf).  These data were generated using 4,716,475 scenes from Landsat 5, 7, and 8 acquired between 16 March 1984 and 31 December 2021. Each pixel was individually classified into water / non-water using an expert system and the results were collated into a monthly history for the entire time period and two epochs (1984-1999, 2000-2021) for change detection.  This Yearly Seasonality Classification collection contains a year-by-year classification of the seasonality of water based on the occurrence values detected throughout the year. 
        :param example: var dataset = ee.ImageCollection('JRC/GSW1_4/YearlyHistory');  var visualization = {   bands: ['waterClass'],   min: 0.0,   max: 3.0,   palette: ['cccccc', 'ffffff', '99d9ea', '0000ff'] };  Map.setCenter(59.414, 45.182, 7);  Map.addLayer(dataset, visualization, 'Water Class'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GWIS_GlobFire_v2_DailyPerimeters:
    def __init__(self,):
        self.sensor = 'JRC_GWIS_GlobFire_v2_DailyPerimeters'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GWIS_GlobFire_v2_DailyPerimeters.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GWIS_GlobFire_v2_DailyPerimeters.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GWIS_GlobFire_v2_DailyPerimeters(example: str = ''):
        """
        Fire boundaries based on the MODIS dataset MCD64A1. The data were computed based on an algorithm that relies on encoding in a graph structure a space-time relationship among patches of burned areas.  Each fire has a unique number identifying the event. 
        :param example: // Folder name for a series of tables. var folder = 'JRC/GWIS/GlobFire/v2/DailyPerimeters';  // List available tables using ee.data.listAssets with asynchronous callback. function printAssetList(listAssetsOutput) {   print('Asset list:', listAssetsOutput['assets']); } ee.data.listAssets(folder, {}, printAssetList);  // Define a table name (table id) identified from the list of available tables. var tableName = 'JRC/GWIS/GlobFire/v2/DailyPerimeters/2020';  var computeArea = function(f) {   return f.set({'area': f.area()}); };  // Import a selected table as a FeatureCollection. var features = ee.FeatureCollection(tableName).map(computeArea);  // Visualization parameters for linear fire area gradient. var visParams = {   palette: ['f5ff64', 'b5ffb4', 'beeaff', 'ffc0e8', '8e8dff', 'adadad'],   min: 0,   max: 600000000,   opacity: 0.8, };  // Paint fire perimeters to an image using computed fire area as the value property. var image = ee.Image().float().paint(features, 'area');  // Display the image to the map (include features for exploring with Inspector). Map.addLayer(image, visParams, 'GlobFire 2020'); Map.addLayer(features, null, 'For Inspector', false); Map.setCenter(-121.23, 39.7, 12); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_GWIS_GlobFire_v2_FinalPerimeters:
    def __init__(self,):
        self.sensor = 'JRC_GWIS_GlobFire_v2_FinalPerimeters'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_GWIS_GlobFire_v2_FinalPerimeters.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_GWIS_GlobFire_v2_FinalPerimeters.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_GWIS_GlobFire_v2_FinalPerimeters(example: str = ''):
        """
        Fire boundaries based on the MODIS dataset MCD64A1. The data were computed based on an algorithm that relies on encoding in a graph structure a space-time relationship among patches of burned areas.  Each fire has a unique number identifying the event. 
        :param example: var dataset = ee.FeatureCollection('JRC/GWIS/GlobFire/v2/FinalPerimeters'); var visParams = {   palette: ['f5ff64', 'b5ffb4', 'beeaff', 'ffc0e8', '8e8dff', 'adadad'],   min: 0,   max: 600000000,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'area'); Map.addLayer(image, visParams, 'GlobFire Final'); Map.addLayer(dataset, null, 'for Inspector', false); Map.setCenter(-122.121, 38.56, 12); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018:
    def __init__(self,):
        self.sensor = 'JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018(example: str = ''):
        """
        The [Land Use/Cover Area frame Survey (LUCAS)](https://ec.europa.eu/eurostat/web/lucas) in the European Union (EU) was set up to provide statistical information. It represents a triennial in-situ landcover and land-use data-collection exercise that extends over the whole of the EU's territory.  LUCAS collects information on land cover and land use, agro-environmental variables, soil, and grassland. The surveys also provide spatial information to analyse the mutual influences between agriculture, environment, and countryside, such as irrigation and land management.  The dataset presented here is the LUCAS Copernicus module. It was set set up in 2018 to provide Earth Observation relevant data for the first time in LUCAS history. The dataset consist of 63,287 polygons of various sizes and shapes with consistent land cover, making the ideal tool for polygon-based extraction from remote sensing data. The harmonization process has improved the land cover legend to LUCAS Level-3, and has joined, wherever deemed appropriate, the attribute data from the 2018 LUCAS survey, augmenting the possibilities for data extraction to the fullest potential of the LUCAS collected variables.  The text "C1 (Instructions)" in the table schema descriptions refers to [this document](https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/LUCAS/LUCAS_harmonised/3_supporting/LUCAS2018-C1-Instructions.pdf).  See also [the LUCAS points dataset](JRC_LUCAS_HARMO_THLOC_V1). 
        :param example: var dataset = ee.FeatureCollection(     'JRC/LUCAS_HARMO/COPERNICUS_POLYGONS/V1/2018');  var visParams = {   min: 35,   max: 60, };  // plotting the GPS latitude per polygon var dataset2 = dataset.map(function (f) {   return ee.Feature(f.buffer(5000)); });  var image = ee.Image().float().paint(dataset2, 'gps_lat').randomVisualizer();  Map.addLayer(ee.Image(1), {min:0, max:1}, 'background'); Map.addLayer(image, visParams, 'LUCAS Polygons'); Map.addLayer(dataset, null, 'for Inspector', false);  Map.setCenter(19.514, 51.82, 8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class JRC_LUCAS_HARMO_THLOC_V1:
    def __init__(self,):
        self.sensor = 'JRC_LUCAS_HARMO_THLOC_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/JRC_LUCAS_HARMO_THLOC_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/JRC_LUCAS_HARMO_THLOC_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_JRC_LUCAS_HARMO_THLOC_V1(example: str = ''):
        """
        The [Land Use/Cover Area frame Survey (LUCAS)](https://ec.europa.eu/eurostat/web/lucas) in the European Union (EU) was set up to provide statistical information. It represents a triennial in-situ landcover and land-use data-collection exercise that extends over the whole of the EU's territory.  LUCAS collects information on land cover and land use, agro-environmental variables, soil, and grassland. The surveys also provide spatial information to analyse the mutual influences between agriculture, environment, and countryside, such as irrigation and land management.  The dataset presented here is the harmonized version of all yearly LUCAS surveys with a total of 106 attributes. Each point's location is using the fields 'th_lat' and 'th_lon', that is, the LUCAS theoretical location (THLOC), as prescribed by the LUCAS grid.  For more information please see Citations. Note that not every field is present for every year - see the \"Years\" section in property descriptions.  The text \"C1 (Instructions)\" in the table schema descriptions refers to [this document](https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/LUCAS/LUCAS_harmonised/3_supporting/LUCAS2018-C1-Instructions.pdf).  See also [the 2018 LUCAS polygons dataset](JRC_LUCAS_HARMO_COPERNICUS_POLYGONS_V1_2018). 
        :param example: var dataset = ee.FeatureCollection('JRC/LUCAS_HARMO/THLOC/V1');  // For the Inspector Map.addLayer(dataset, {}, 'LUCAS Points (data)', false);  dataset = dataset.style({   color: '489734',   pointSize: 3, });  Map.setCenter(-3.8233, 40.609, 10);  Map.addLayer(dataset, {}, 'LUCAS Points (styled green)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class KNTU_LiDARLab_IranLandCover_V1:
    def __init__(self,):
        self.sensor = 'KNTU_LiDARLab_IranLandCover_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/KNTU_LiDARLab_IranLandCover_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/KNTU_LiDARLab_IranLandCover_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_KNTU_LiDARLab_IranLandCover_V1(example: str = ''):
        """
        The Iran-wide land cover map was generated by processing Sentinel imagery within the Google Earth Engine Cloud platform. For this purpose, over 2,500 Sentinel-1 and over 11,000 Sentinel-2 images were processed to produce a single mosaic dataset for the year 2017. Then, an object-based Random Forest classification method was trained by a large number of reference samples for 13 classes to generate the Iran-wide land cover map. 
        :param example: var dataset = ee.Image('KNTU/LiDARLab/IranLandCover/V1');  var visualization = {   bands: ['classification'] };  Map.setCenter(54.0, 33.0, 5);  Map.addLayer(dataset, visualization, 'Classification'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_FRG_v1_2_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_FRG_v1_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_FRG_v1_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_FRG_v1_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_FRG_v1_2_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  Fire Regime Groups (FRG) are created by linking the Biophysical Settings (BPS) Group attribute in the BpS layer with the Refresh Model Tracker (RMT) data and assigning the FRG attribute. This geospatial product should display a reasonable approximation of FRG, as documented in the RMT. (LF 1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM.) FRG can be used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/FRG/v1_2_0');  var visualization = {   bands: ['FRG'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'FRG'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_MFRI_v1_2_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_MFRI_v1_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_MFRI_v1_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_MFRI_v1_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_MFRI_v1_2_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  The Mean Fire Return Interval (MFRI) layer quantifies the average period between fires under the presumed historical fire regime. MFRI is intended to describe one component of historical fire regime characteristics in the context of the broader historical time period represented by the LANDFIRE (LF) Biophysical Settings (BPS) layer and BPS Model documentation. MFRI is derived from the vegetation and disturbance dynamics model VDDT (Vegetation Dynamics Development Tool) (LF 1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM). This layer is created by linking the BpS Group attribute in the BpS layer with the Refresh Model Tracker (RMT) data and assigning the MFRI attribute. This geospatial product should display a reasonable approximation of MFRI, as documented in the RMT. MFRI is used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/MFRI/v1_2_0');  var visualization = {   bands: ['MFRI'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'MFRI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_PLS_v1_2_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_PLS_v1_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_PLS_v1_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_PLS_v1_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_PLS_v1_2_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  The Percent of Low-severity Fire (PLS) layer quantifies the amount of low-severity fires relative to mixed- and replacement-severity fires under the presumed historical fire regime. Low severity is defined as less than 25 percent average top-kill within a typical fire perimeter for a given vegetation type. PLS was derived from the vegetation and disturbance dynamics model VDDT (Vegetation Dynamics Development Tool) (LF 1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM). This layer is intended to describe one component of historical fire regime characteristics in the context of the broader historical time period represented by the LANDFIRE (LF) Biophysical Settings (BPS) layer and BPS Model documentation. This layer is created by linking the BPS Group attribute in the BPS layer with the Refresh Model Tracker (RMT) data and assigning the PLS attribute. This geospatial product should display a reasonable approximation of PLS, as documented in the RMT. PLS is used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/PLS/v1_2_0');  var visualization = {   bands: ['PLS'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'PLS'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_PMS_v1_2_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_PMS_v1_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_PMS_v1_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_PMS_v1_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_PMS_v1_2_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  The Percent of Mixed-severity Fire (PMS) layer quantifies the amount of mixed-severity fires relative to low- and replacement-severity fires under the presumed historical fire regime. Mixed severity is defined as between 25 and 75 percent average top-kill within a typical fire perimeter for a given vegetation type. PMS was derived from the vegetation and disturbance dynamics model VDDT (Vegetation Dynamics Development Tool) (LF 1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM). This layer is intended to describe one component of historical fire regime characteristics in the context of the broader historical time period represented by the LANDFIRE (LF) Biophysical Settings (BPS) layer and BPS Model documentation. This layer is created by linking the BPS Group attribute in the BPS layer with the Refresh Model Tracker (RMT) data and assigning the PMS attribute. This geospatial product should display a reasonable approximation of PMS, as documented in the RMT. PMS is used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/PMS/v1_2_0');  var visualization = {   bands: ['PMS'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'PMS'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_PRS_v1_2_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_PRS_v1_2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_PRS_v1_2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_PRS_v1_2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_PRS_v1_2_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  The Percent of Replacement-severity Fire (PRS) layer quantifies the amount of replacement-severity fires relative to low- and mixed-severity fires under the presumed historical fire regime. Replacement severity is defined as greater than 75 percent average top-kill within a typical fire perimeter for a given vegetation type. PRS was derived from the vegetation and disturbance dynamics model VDDT (Vegetation Dynamics Development Tool) (LF 1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM). This layer is intended to describe one component of historical fire regime characteristics in the context of the broader historical time period represented by the LANDFIRE(LF) Biophysical Settings (BPS) layer and BPS Model documentation. This layer is created by linking the BPS Group attribute in the BPS layer with the Refresh Model Tracker (RMT) data and assigning the PRS attribute. This geospatial product should display a reasonable approximation of PRS, as documented in the RMT. PRS is used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/PRS/v1_2_0');  var visualization = {   bands: ['PRS'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'PRS'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_SClass_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_SClass_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_SClass_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_SClass_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_SClass_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  The Succession Classes (SClass) layer characterizes current vegetation conditions with respect to the vegetation species composition, cover, and height ranges of successional states that occur within each biophysical setting. SClass can also represent uncharacteristic vegetation components, such as exotic species, that are not found within the compositional or structural variability of successional states defined for a biophysical setting. Succession classes do not directly quantify fuel characteristics of the current vegetation, but rather represent vegetative states with unique succession or disturbance-related dynamics, such as structural development or fire frequency. To produce SClass, the historical reference conditions of these successional states were derived from the vegetation and disturbance dynamics model VDDT (Vegetation Dynamics Development Tool) (LF_1.0.0 CONUS only used the vegetation and disturbance dynamics model LANDSUM). The area contained in succession classes is compared to the simulated historical reference conditions to calculate measurements of vegetation departure, such as fire regime condition class. SClass is used in landscape assessments.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/SClass/v1_4_0');  var visualization = {   bands: ['SClass'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'SClass'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_VCC_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_VCC_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_VCC_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_VCC_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_VCC_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  Vegetation Condition Class (VCC) represents a simple categorization of the associated Vegetation Departure (VDEP) layer and indicates the general level to which current vegetation is different from the simulated historical vegetation reference conditions. VDEP and VCC are based upon methods originally described in Interagency Fire Regime Condition Class Guidebook, but are not identical to those methods. Full descriptions of the methods used can be found in the VDEP product description. Users should review those methods before comparing VDEP or VCC values across LANDFIRE (LF) versions. VCC is a derivative of the VDEP layer. It is important to read and understand the characteristics of the VDEP spatial product, particularly if VCC values are compared across versions as the VDEP methods varied which directly impacts across-version VDEP and VCC comparability. In LF 2012, the original three VCC classes were divided in half to create six VCC classes to provide additional precision.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/VCC/v1_4_0');  var visualization = {   bands: ['VCC'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'VCC'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Fire_VDep_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Fire_VDep_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Fire_VDep_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Fire_VDep_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Fire_VDep_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  Landfire (LF) Historical fire regimes, intervals, and vegetation conditions are mapped using the Vegetation Dynamics Development Tool (VDDT). These data support fire and landscape management planning goals in the National Cohesive Wildland Fire Management Strategy, the Federal Wildland Fire Management Policy, and the Healthy Forests Restoration Act.  Vegetation Departure (VDep) indicates how different current vegetation on a landscape is from estimated historical conditions. VDep is based on changes to species composition, structural stage, and canopy closure using methods originally described in the Interagency Fire Regime Condition Class Guidebook, but is not identical to those methods. LANDFIRE (LF) VDep is based only on departure of current vegetation conditions from reference vegetation conditions, whereas the Guidebook approach includes departure of current fire regimes from those of the reference period. VDep is a landscape metric and is scale dependent. Every pixel in a unique biophysical settings (BpS) in a summary unit has the same VDep value. These large landscape values may not represent smaller areas within a summary unit. The VDep metric ranges from 0 - 100, and is based on four factors. These inputs are held constant within a single version of LF, but can be different across LF versions, which directly impacts VDep comparability across versions. VDep can be compared across versions but caution is advised.  The LANDIFRE Fire datasets include:  * Fire Regime Groups (FRG) is intended to characterize presumed historical   fire regimes within landscapes based on interactions between vegetation   dynamics, fire spread, fire effects, and spatial context * Mean Fire Return Interval (MFRI) quantifies the average period between   fires under the presumed historical fire regime * Percent of Low-severity Fire (PLS) image quantifies the amount of   low-severity fires relative to mixed- and replacement-severity fires   under the presumed historical fire regime and is defined as less than 25   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Mixed-severity Fire (PMS) layer quantifies the amount of   mixed-severity fires relative to low- and replacement-severity fires under   the presumed historical fire regime, and is defined as between 25 and 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Percent of Replacement-severity Fire (PRS) layer quantifies the amount of   replacement-severity fires relative to low- and mixed-severity fires under   the presumed historical fire regime, and is defined as greater than 75   percent average top-kill within a typical fire perimeter for a given   vegetation type * Succession Classes (SClass) layer characterizes current vegetation conditions   with respect to the vegetation species composition, cover, and height ranges   of successional states that occur within each biophysical setting * Vegetation Condition Class (VCC) represents a simple categorization of the   associated Vegetation Departure (VDEP) layer and indicates the general level   to which current vegetation is different from the simulated historical   vegetation reference conditions * Vegetation Departure (VDep) indicates how different current vegetation on a   landscape is from estimated historical conditions. VDep is based on changes   to species composition, structural stage, and canopy closure. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Fire/VDep/v1_4_0');  var visualization = {   bands: ['VDep'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'VDep'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_BPS_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_BPS_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_BPS_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_BPS_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_BPS_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Biophysical Settings (BPS) represents the vegetation that may have been dominant on the landscape prior to Euro-American settlement and is based on both the current biophysical environment and an approximation of the historical disturbance regime. Map units are based on NatureServe's Ecological Systems classification and represent the natural plant communities that may have been present during the reference period. Each BPS map unit is matched with a model of vegetation succession, and both serve as key inputs to the LANDSUM landscape succession model. The actual time period for this data set is a composite of both the historical context provided by the fire regime and vegetation dynamics models and the more recent field and geospatial inputs used to create it. LF's current BPS is unchanged from LF National's BPS except for updates made to water, barren, and snow classes (additions or removal), so that non-vegetated cover types within the BPS product matches LF existing vegetation and fuel products. With the final release of LF Remap for CONUS in mid to late 2020, the LF Remap BPS product will include the following as attributes: Mean Fire Return Interval (MFRI), Percent of Low-severity Fire (PLS), Percent of Mixed-severity Fire (PMS), Percent of Replacement-severity Fire (PRS), and Fire Regime Groups (FRG), so that the linkage of these characteristics to BPS is maintained. LF uses BPS to depict reference conditions of vegetation across landscapes.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Vegetation/BPS/v1_4_0');  var visualization = {   bands: ['BPS'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'BPS'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_ESP_v1_2_0_AK:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_ESP_v1_2_0_AK'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_AK.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_AK.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_ESP_v1_2_0_AK(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Environmental Site Potential (ESP) represents the vegetation that could be supported at a given site based on the biophysical environment. Map units are based on NatureServe's Ecological Systems classification and represent the natural plant communities that may have been present during the reference period. ESP map units represent the natural plant communities that would become established at late or climax stages of successional development in the absence of disturbance. They reflect the current climate and physical environment, as well as the competitive potential of native plant species. The ESP concept is similar to that used in classifications of potential vegetation, including habitat types and plant associations. In early versions of LF, ESP was used to inform the existing vegetation and fuel mapping processes.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.Image('LANDFIRE/Vegetation/ESP/v1_2_0/AK');  var visualization = {   bands: ['ESP'], };  Map.setCenter(-151.011, 63.427, 8);  Map.addLayer(dataset, visualization, 'ESP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_ESP_v1_2_0_CONUS:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_ESP_v1_2_0_CONUS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_CONUS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_CONUS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_ESP_v1_2_0_CONUS(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Environmental Site Potential (ESP) represents the vegetation that could be supported at a given site based on the biophysical environment. Map units are based on NatureServe's Ecological Systems classification and represent the natural plant communities that may have been present during the reference period. ESP map units represent the natural plant communities that would become established at late or climax stages of successional development in the absence of disturbance. They reflect the current climate and physical environment, as well as the competitive potential of native plant species. The ESP concept is similar to that used in classifications of potential vegetation, including habitat types and plant associations. In early versions of LF, ESP was used to inform the existing vegetation and fuel mapping processes.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.Image('LANDFIRE/Vegetation/ESP/v1_2_0/CONUS');  var visualization = {   bands: ['ESP'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'ESP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_ESP_v1_2_0_HI:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_ESP_v1_2_0_HI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_HI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_ESP_v1_2_0_HI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_ESP_v1_2_0_HI(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Environmental Site Potential (ESP) represents the vegetation that could be supported at a given site based on the biophysical environment. Map units are based on NatureServe's Ecological Systems classification and represent the natural plant communities that may have been present during the reference period. ESP map units represent the natural plant communities that would become established at late or climax stages of successional development in the absence of disturbance. They reflect the current climate and physical environment, as well as the competitive potential of native plant species. The ESP concept is similar to that used in classifications of potential vegetation, including habitat types and plant associations. In early versions of LF, ESP was used to inform the existing vegetation and fuel mapping processes.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.Image('LANDFIRE/Vegetation/ESP/v1_2_0/HI');  var visualization = {   bands: ['ESP'], };  Map.setCenter(-155.3, 19.627, 8);  Map.addLayer(dataset, visualization, 'ESP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_EVC_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_EVC_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_EVC_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_EVC_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_EVC_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Existing Vegetation Cover (EVC) represents the vertically projected percent cover of the live canopy layer for a 30-m cell. EVC is generated separately for tree, shrub, and herbaceous cover lifeforms using training data and other geospatial layers. Percentage tree, shrub, and herbaceous canopy cover training data are generated using plot-level ground-based visual assessments and lidar observations. * Once the training data are developed, relationships are then established separately for each lifeform between the training data and combination of Landsat and ancillary data. Each of the derived data layers (tree, shrub, herbaceous) has a potential range from 0-100 percent which are merged into a single composite EVC layer. * Disturbance data were used to develop LF Remap products for LFRDB plot filtering and to ensure 2015 and 2016 disturbances were included that were not visible in the source imagery. * The EVC product is then reconciled through QA/QC measures to ensure life-form is synchronized with both Existing Vegetation Height and Existing Vegetation Type products. LF uses EVC in several subsequent layers, including the development of the fuel layers.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Vegetation/EVC/v1_4_0');  var visualization = {   bands: ['EVC'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'EVC'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_EVH_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_EVH_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_EVH_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_EVH_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_EVH_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  Existing Vegetation Height (EVH) represents the average height of the dominant vegetation for a 30-m cell. Canopy height is generated separately for tree, shrub, and herbaceous lifeforms using training data and other geospatial layers. EVH is determined by the average height weighted by species cover and based on the Existing Vegetation Type (EVT) lifeform.  * Decision tree models using field reference data, lidar, Landsat, and ancillary data are developed separately for each lifeform. Decision tree relationships are used to generate lifeform specific height class layers, which are merged into a single composite EVH layer.  * Disturbance data were used to develop LF Remap products for LFRDB plot filtering and to ensure 2015 and 2016 disturbances were included that were not visible in the source imagery.  * The EVC product is then reconciled through QA/QC measures to ensure life-form is synchronized with both Existing Vegetation Cover and EVT products.  LF uses EVH in several subsequent layers, including the development of the fuel products.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Vegetation/EVH/v1_4_0');  var visualization = {   bands: ['EVH'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'EVH'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDFIRE_Vegetation_EVT_v1_4_0:
    def __init__(self,):
        self.sensor = 'LANDFIRE_Vegetation_EVT_v1_4_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDFIRE_Vegetation_EVT_v1_4_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDFIRE_Vegetation_EVT_v1_4_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDFIRE_Vegetation_EVT_v1_4_0(example: str = ''):
        """
        LANDFIRE (LF), Landscape Fire and Resource Management Planning Tools, is a shared program between the wildland fire management programs of the U.S. Department of Agriculture's Forest Service, U.S. Department of the Interior's Geological Survey, and The Nature Conservancy.  LANDFIRE (LF) layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees.  LANDFIRE's (LF) Existing Vegetation Type (EVT) represents the current distribution of the terrestrial ecological systems classification, developed by NatureServe for the western hemisphere, through 2016. A terrestrial ecological system is defined as a group of plant community types (associations) that tend to co-occur within landscapes with similar ecological processes, substrates, and/or environmental gradients.  *The LF Ecological Systems Descriptions for CONUS provides descriptions for each Ecological System including species, distribution and classification information.  EVT also includes ruderal or semi-natural vegetation types within the U.S. National Vegetation Classification. The LF Ruderal NVC Groups Descriptions for CONUS provides descriptions for each ruderal NVC Group including species, distribution, and classification information.  EVT is mapped using decision tree models, field data, Landsat imagery, elevation, and biophysical gradient data.  * Decision tree models are developed separately for each of the three lifeforms-tree, shrub, and herbaceous and are then used to generate lifeform specific EVT layers.  * Disturbance products are included in LF Remap products to describe areas on the landscape that have experienced change within the previous 10-year period.  * The EVT product is reconciled through QA/QC measures to ensure life-form is synchronized with both Existing Vegetation Cover and Existing Vegetation Height.  The LANDIFRE Vegetation datasets include:  * Biophysical Settings (BPS) * Environmental Site Potential (ESP) * Existing Vegetation Canopy Cover (EVC) * Existing Vegetation Height (EVH). * Existing Vegetation Type (EVT) These layers are created using predictive landscape models based on extensive field-referenced data, satellite imagery and biophysical gradient layers using classification and regression trees. 
        :param example: var dataset = ee.ImageCollection('LANDFIRE/Vegetation/EVT/v1_4_0');  var visualization = {   bands: ['EVT'], };  Map.setCenter(-121.671, 40.699, 5);  Map.addLayer(dataset, visualization, 'EVT'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_GLS1975:
    def __init__(self,):
        self.sensor = 'LANDSAT_GLS1975'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_GLS1975.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_GLS1975.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_GLS1975(example: str = ''):
        """
        The Global Land Survey (GLS) 1975 is a global collection of imagery from the Landsat Multispectral Scanner (MSS).  Most scenes were acquired by Landsat 1-3 in 1972-1983.  A few gaps in the Landsat 1-3 data have been filled with scenes acquired by Landsat 4-5 during the years 1982-1987.  These data contain 4 spectral bands: Green, Red, an NIR band, and a SWIR band.  In the typical False-color presentation, the images appear red because the NIR band, displayed as red, highlights vegetation. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/GLS1975'); var falseColor = dataset.select(['30', '20', '10']); var falseColorVis = {   gamma: 1.6, }; Map.setCenter(44.517, 25.998, 5); Map.addLayer(falseColor, falseColorVis, 'False Color');
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_GLS1975_MOSAIC:
    def __init__(self,):
        self.sensor = 'LANDSAT_GLS1975_MOSAIC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_GLS1975_MOSAIC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_GLS1975_MOSAIC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_GLS1975_MOSAIC(example: str = ''):
        """
        The Global Land Survey (GLS) 1975 is a global collection of imagery from the Landsat Multispectral Scanner (MSS).  Most scenes were acquired by Landsat 1&ndash;3 during the years from 1972&ndash;1983.  A few gaps in the Landsat 1&ndash;3 data have been filled with scenes acquired by Landsat 4&ndash;5 during the years 1982&ndash;1987.  These data contain 4 spectral bands: Green, Red, an NIR band, and a SWIR band.  In the typical false-color presentation the images appear red because the NIR band, displayed as red, highlights vegetation.  All scenes in the collection are included in this composite image. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/GLS1975_MOSAIC'); var falseColor = dataset.select(['30', '20', '10']); var falseColorVis = {   gamma: 1.6, }; Map.setCenter(44.517, 25.998, 5); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_GLS2005:
    def __init__(self,):
        self.sensor = 'LANDSAT_GLS2005'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_GLS2005.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_GLS2005.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_GLS2005(example: str = ''):
        """
        The GLS2005 data set is a collection of 9500 orthorectified leaf-on medium-resolution satellite images collected between 2004 and 2007 and covering the Earth's land masses. GLS2005 uses mainly Landsat 5 and gap-filled Landsat 7 data with EO-1 ALI and Terra ASTER data filling in any data holes.  This dataset contains images from just the L5 TM and L7 ETM+ sensors, and only the 6 bands that those two sensors have in common: 10, 20, 30, 40, 50, and 70. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/GLS2005'); var trueColor321 = dataset.select(['30', '20', '10']); Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, {}, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_GLS2005_L5:
    def __init__(self,):
        self.sensor = 'LANDSAT_GLS2005_L5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_GLS2005_L5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_GLS2005_L5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_GLS2005_L5(example: str = ''):
        """
        The GLS2005 data set is a collection of 9500 orthorectified leaf-on medium-resolution satellite images collected between 2004 and 2007 and covering the Earth's land masses. GLS2005 uses mainly Landsat 5 and gap-filled Landsat 7 data with EO-1 ALI and Terra ASTER data filling in any data holes.  This collection contains just the subset of the GLS2005 images       from the L5 ETM sensor. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/GLS2005_L5'); var trueColor321 = dataset.select(['30', '20', '10']); Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, {}, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_GLS2005_L7:
    def __init__(self,):
        self.sensor = 'LANDSAT_GLS2005_L7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_GLS2005_L7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_GLS2005_L7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_GLS2005_L7(example: str = ''):
        """
        The GLS2005 data set is a collection of 9500 orthorectified leaf-on medium-resolution satellite images collected between 2004 and 2007 and covering the Earth's land masses. GLS2005 uses mainly Landsat 5 and gap-filled Landsat 7 data with EO-1 ALI and Terra ASTER data filling in any data holes.  This collection contains just the subset of the GLS2005 images       from the L7 ETM+ sensor. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/GLS2005_L7'); var trueColor321 = dataset.select(['30', '20', '10']); Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, {}, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_BAI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_EVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_NBRT(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_NDSI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_NDVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_NDWI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_RAW(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_32DAY_TOA(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_BAI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_EVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_NBRT(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_NDSI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_NDVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_NDWI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_RAW(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_8DAY_TOA(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 8 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_RT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_RT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_RT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_RT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_RT(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 and Real-Time data DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_RT_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_RT_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_RT_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_RT_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_RT_TOA(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 and Real-Time data calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 8 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and two thermal infrared (TIR) bands processed to orthorectified brightness temperature  These data have been atmospherically corrected using [LaSRC](https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/atoms/files/LSDS-1368_L8_C1-LandSurfaceReflectanceCode-LASRC_ProductGuide-v3.pdf) and includes a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/core-science-systems/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping "scenes" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes:  - Although Surface Reflectance can be processed only from the Operational   Land Imager (OLI) bands, SR requires combined OLI/Thermal Infrared   Sensor (TIRS) product (LC8) input in order to generate the accompanying   cloud mask. Therefore, OLI only (LO8), and TIRS only (LT8) data products   cannot be calculated to SR. - SR is not run for a scene with a solar zenith angle greater than 76&deg;. - Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;). - The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance. - Efficacy of SR correction will be likely reduced in areas where atmospheric   correction is affected by adverse conditions:     - Hyper-arid or snow-covered regions     - Low sun angle conditions     - Coastal regions where land area is small relative to adjacent water     - Areas with extensive cloud contamination  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T1_TOA(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T2(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T2_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T2_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T2_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T2_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T2_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 8 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and two thermal infrared (TIR) bands processed to orthorectified brightness temperature  These data have been atmospherically corrected using [LaSRC](https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/atoms/files/LSDS-1368_L8_C1-LandSurfaceReflectanceCode-LASRC_ProductGuide-v3.pdf) and includes a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/core-science-systems/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping "scenes" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes:  - Although Surface Reflectance can be processed only from the Operational   Land Imager (OLI) bands, SR requires combined OLI/Thermal Infrared   Sensor (TIRS) product (LC8) input in order to generate the accompanying   cloud mask. Therefore, OLI only (LO8), and TIRS only (LT8) data products   cannot be calculated to SR. - SR is not run for a scene with a solar zenith angle greater than 76&deg;. - Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;). - The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance. - Efficacy of SR correction will be likely reduced in areas where atmospheric   correction is affected by adverse conditions:     - Hyper-arid or snow-covered regions     - Low sun angle conditions     - Coastal regions where land area is small relative to adjacent water     - Areas with extensive cloud contamination  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C01_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C01_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C01_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C01_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C01_T2_TOA(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 2 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T1(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1')                   .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 30000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T1_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T1_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T1_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T1_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T1_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 8 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 8 SR products are created with the Land Surface Reflectance Code (LaSRC). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')     .filterDate('2021-05-01', '2021-06-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBands, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B4', 'SR_B3', 'SR_B2'],   min: 0.0,   max: 0.3, };  Map.setCenter(-114.2579, 38.9275, 8);  Map.addLayer(dataset, visualization, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T1_RT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T1_RT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T1_RT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T1_RT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T1_RT(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 1 and Real-Time data DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_RT')                   .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 30000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T1_RT_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T1_RT_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T1_RT_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T1_RT_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T1_RT_TOA(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 1 and Real-Time data   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_RT_TOA')     .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 0.4, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T1_TOA(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')   .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 0.4, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T2(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T2')                   .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 30000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T2_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T2_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T2_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T2_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T2_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 8 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 8 SR products are created with the Land Surface Reflectance Code (LaSRC). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T2_L2')     .filterDate('2021-05-01', '2021-06-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBands, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B4', 'SR_B3', 'SR_B2'],   min: 0.0,   max: 0.3, };  Map.setCenter(-83, 24, 8);  Map.addLayer(dataset, visualization, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC08_C02_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC08_C02_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC08_C02_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC08_C02_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC08_C02_T2_TOA(example: str = ''):
        """
        Landsat 8 Collection 2 Tier 2   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC08/C02/T2_TOA')     .filterDate('2017-01-01', '2017-12-31'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 0.4, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T1(example: str = ''):
        """
        Landsat 9 Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T1')                   .filterDate('2022-01-01', '2022-02-01'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 30000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T1_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T1_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T1_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T1_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T1_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 9 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 9 SR products are created with the Land Surface Reflectance Code (LaSRC). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')     .filterDate('2022-01-01', '2022-02-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBands, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B4', 'SR_B3', 'SR_B2'],   min: 0.0,   max: 0.3, };  Map.setCenter(-114.2579, 38.9275, 8);  Map.addLayer(dataset, visualization, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T1_TOA(example: str = ''):
        """
        Landsat 9 Collection 2 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T1_TOA')   .filterDate('2022-01-01', '2022-02-01'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 0.4, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T2(example: str = ''):
        """
        Landsat 9 Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T2')                   .filterDate('2022-01-01', '2022-02-01'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 30000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T2_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T2_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T2_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T2_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T2_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 9 OLI/TIRS sensors. These images contain 5 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 9 SR products are created with the Land Surface Reflectance Code (LaSRC). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T2_L2')     .filterDate('2022-01-01', '2022-02-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBands, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B4', 'SR_B3', 'SR_B2'],   min: 0.0,   max: 0.3, };  Map.setCenter(-83, 24, 8);  Map.addLayer(dataset, visualization, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC09_C02_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC09_C02_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC09_C02_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC09_C02_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC09_C02_T2_TOA(example: str = ''):
        """
        Landsat 9 Collection 2 Tier 2   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LC09/C02/T2_TOA')       .filterDate('2022-01-01', '2022-02-01'); var trueColor432 = dataset.select(['B4', 'B3', 'B2']); var trueColor432Vis = {   min: 0.0,   max: 0.4, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor432, trueColor432Vis, 'True Color (432)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8(example: str = ''):
        """
        Landsat 8 DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T(example: str = ''):
        """
        Landsat 8 DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_BAI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_EVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_NBRT(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_NDSI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_NDVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_NDWI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_RAW(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_32DAY_TOA(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_BAI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_EVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_NBRT(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_NDSI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_NDVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_NDWI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_RAW(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_8DAY_TOA(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 8 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LC8_L1T_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LC8_L1T_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LC8_L1T_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LC8_L1T_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LC8_L1T_TOA(example: str = ''):
        """
        Landsat 8 calibrated top-of-atmosphere reflectance, orthorectified scenes only. For recently-acquired scenes calibration coefficients are extracted from the image metadata; for older scenes the coefficients are derived from [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_BAI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_EVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_NBRT(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_NDSI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_NDVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_NDWI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_RAW(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_32DAY_TOA(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_BAI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_EVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_NBRT(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_NDSI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_NDVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_NDWI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_RAW(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_8DAY_TOA(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub).  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 7 Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_RT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_RT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_RT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_RT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_RT(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 1 and Real-Time data DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_RT_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_RT_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_RT_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_RT_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_RT_TOA(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 1 and Real-Time data calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 7 ETM+ sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T1_TOA(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 1 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T2(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T2_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T2_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T2_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T2_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T2_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 7 ETM+ sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C01_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C01_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C01_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C01_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C01_T2_TOA(example: str = ''):
        """
        Landsat 7 Collection 1 Tier 2 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T1(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T1')                   .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T1_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T1_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T1_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T1_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T1_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 7 ETM+ sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 7 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged)  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')     .filterDate('2017-06-01', '2017-07-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(-114.2579, 38.9275, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T1_RT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T1_RT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T1_RT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T1_RT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T1_RT(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 1 and Real-Time data DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T1_RT')                   .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T1_RT_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T1_RT_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T1_RT_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T1_RT_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T1_RT_TOA(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 1 and Real-Time data   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T1_RT_TOA')     .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T1_TOA(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA')     .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T2(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T2')                   .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T2_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T2_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T2_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T2_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T2_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat 7 ETM+ sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 7 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged)  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T2_L2')     .filterDate('2017-06-01', '2017-07-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(-83, 24, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE07_C02_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE07_C02_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE07_C02_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE07_C02_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE07_C02_T2_TOA(example: str = ''):
        """
        Landsat 7 Collection 2 Tier 2   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LE07/C02/T2_TOA')     .filterDate('1999-01-01', '2002-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7(example: str = ''):
        """
        Landsat 7 DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T(example: str = ''):
        """
        Landsat 7 DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_BAI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_EVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_NBRT(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_NDSI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_NDVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_NDWI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_RAW(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_32DAY_TOA(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_BAI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_EVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_NBRT(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_NDSI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_NDVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_NDWI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_RAW(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_8DAY_TOA(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 7 composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_L1T_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_L1T_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_L1T_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_L1T_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_L1T_TOA(example: str = ''):
        """
        Landsat 7 calibrated top-of-atmosphere reflectance, orthorectified scenes only. For recently-acquired scenes calibration coefficients are extracted from the image metadata; for older scenes the coefficients are derived from [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_TOA_1YEAR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_TOA_1YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_TOA_1YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_TOA_1YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_TOA_1YEAR(example: str = ''):
        """
        These 1-year composites were created   from all Landsat 7 images in the specified composite period, excluding   images marked with a negative sun elevation in their metadata.  The   composites were created using   the [ee.Algorithms.Landsat.simpleComposite()](https://developers.google.com/earth-engine/landsat#simple-composite)   method with its default settings.   Reflectance ([0,1]) in bands B1, B2, B3, B4, B5, and B7 is scaled to 8 bits   ([0,255]) and temperature in band B6_VCID_2 is converted to units of   Kelvin-100. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_TOA_3YEAR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_TOA_3YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_TOA_3YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_TOA_3YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_TOA_3YEAR(example: str = ''):
        """
        These 3-year composites were created   from all Landsat 7 images in the specified composite period, excluding   images marked with a negative sun elevation in their metadata.  The   composites were created using   the [ee.Algorithms.Landsat.simpleComposite()](https://developers.google.com/earth-engine/landsat#simple-composite)   method with its default settings.   Reflectance ([0,1]) in bands B1, B2, B3, B4, B5, and B7 is scaled to 8 bits   ([0,255]) and temperature in band B6_VCID_2 is converted to units of   Kelvin-100. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LE7_TOA_5YEAR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LE7_TOA_5YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LE7_TOA_5YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LE7_TOA_5YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LE7_TOA_5YEAR(example: str = ''):
        """
        These 5-year composites were created   from all Landsat 7 images in the specified composite period, excluding   images marked with a negative sun elevation in their metadata.  The   composites were created using   the [ee.Algorithms.Landsat.simpleComposite()](https://developers.google.com/earth-engine/landsat#simple-composite)   method with its default settings.   Reflectance ([0,1]) in bands B1, B2, B3, B4, B5, and B7 is scaled to 8 bits   ([0,255]) and temperature in band B6_VCID_2 is converted to units of   Kelvin-100. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM01_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM01_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM01_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM01_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM01_C01_T1(example: str = ''):
        """
        Landsat 1 MSS Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM01_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM01_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM01_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM01_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM01_C01_T2(example: str = ''):
        """
        Landsat 1 MSS Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM01_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM01_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM01_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM01_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM01_C02_T1(example: str = ''):
        """
        Landsat 1 MSS Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM01/C02/T1')                   .filterDate('1974-01-01', '1978-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM01_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM01_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM01_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM01_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM01_C02_T2(example: str = ''):
        """
        Landsat 1 MSS Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM01/C02/T2')                   .filterDate('1974-01-01', '1978-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM02_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM02_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM02_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM02_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM02_C01_T1(example: str = ''):
        """
        Landsat 2 MSS Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM02_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM02_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM02_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM02_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM02_C01_T2(example: str = ''):
        """
        Landsat 2 MSS Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM02_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM02_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM02_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM02_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM02_C02_T1(example: str = ''):
        """
        Landsat 2 MSS Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM02/C02/T1')                   .filterDate('1978-01-01', '1980-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM02_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM02_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM02_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM02_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM02_C02_T2(example: str = ''):
        """
        Landsat 2 MSS Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM02/C02/T2')                   .filterDate('1978-01-01', '1980-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM03_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM03_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM03_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM03_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM03_C01_T1(example: str = ''):
        """
        Landsat 3 MSS Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM03_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM03_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM03_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM03_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM03_C01_T2(example: str = ''):
        """
        Landsat 3 MSS Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM03_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM03_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM03_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM03_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM03_C02_T1(example: str = ''):
        """
        Landsat 3 MSS Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM03/C02/T1')                   .filterDate('1978-01-01', '1980-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM03_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM03_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM03_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM03_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM03_C02_T2(example: str = ''):
        """
        Landsat 3 MSS Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM03/C02/T2')                   .filterDate('1978-01-01', '1980-12-31'); var nearInfrared321 = dataset.select(['B6', 'B5', 'B4']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM04_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM04_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM04_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM04_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM04_C01_T1(example: str = ''):
        """
        Landsat 4 MSS Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM04_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM04_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM04_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM04_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM04_C01_T2(example: str = ''):
        """
        Landsat 4 MSS Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM04_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM04_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM04_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM04_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM04_C02_T1(example: str = ''):
        """
        Landsat 4 MSS Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM04/C02/T1')                   .filterDate('1989-01-01', '1992-12-31'); var nearInfrared321 = dataset.select(['B3', 'B2', 'B1']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM04_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM04_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM04_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM04_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM04_C02_T2(example: str = ''):
        """
        Landsat 4 MSS Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM04/C02/T2')                   .filterDate('1989-01-01', '1992-12-31'); var nearInfrared321 = dataset.select(['B3', 'B2', 'B1']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM05_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM05_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM05_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM05_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM05_C01_T1(example: str = ''):
        """
        Landsat 5 MSS Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM05_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM05_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM05_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM05_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM05_C01_T2(example: str = ''):
        """
        Landsat 5 MSS Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM05_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM05_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM05_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM05_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM05_C02_T1(example: str = ''):
        """
        Landsat 5 MSS Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM05/C02/T1')                   .filterDate('1985-01-01', '1989-12-31'); var nearInfrared321 = dataset.select(['B3', 'B2', 'B1']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM05_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM05_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM05_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM05_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM05_C02_T2(example: str = ''):
        """
        Landsat 5 MSS Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LM05/C02/T2')                   .filterDate('1985-01-01', '1989-12-31'); var nearInfrared321 = dataset.select(['B3', 'B2', 'B1']); var nearInfrared321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(nearInfrared321, nearInfrared321Vis, 'Near Infrared (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM1(example: str = ''):
        """
        Landsat 1 MSS DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM1_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM1_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM1_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM1_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM1_L1T(example: str = ''):
        """
        Landsat 1 MSS DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM2(example: str = ''):
        """
        Landsat 2 MSS DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM2_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM2_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM2_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM2_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM2_L1T(example: str = ''):
        """
        Landsat 2 MSS DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM3:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM3(example: str = ''):
        """
        Landsat 3 MSS DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM3_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM3_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM3_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM3_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM3_L1T(example: str = ''):
        """
        Landsat 3 MSS DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM4:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM4(example: str = ''):
        """
        Landsat 4 MSS DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM4_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM4_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM4_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM4_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM4_L1T(example: str = ''):
        """
        Landsat 4 MSS DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM5:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM5(example: str = ''):
        """
        Landsat 5 MSS DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LM5_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LM5_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LM5_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LM5_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LM5_L1T(example: str = ''):
        """
        Landsat 5 MSS DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LO08_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LO08_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LO08_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LO08_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LO08_C01_T1(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 OLI DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LO08_C01_T1_RT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LO08_C01_T1_RT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LO08_C01_T1_RT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LO08_C01_T1_RT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LO08_C01_T1_RT(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 1 and Real-Time data OLI DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections).  The T1_RT collection contains both Tier 1 and Real-Time (RT) assets. Newly-acquired Landsat 7 ETM+ and Landsat 8 OLI/TIRS data are processed upon downlink but use predicted ephemeris, initial bumper mode parameters, or initial TIRS line of sight model parameters. The data is placed in the Real-Time tier and made available for immediate download. Once the data have been reprocessed with definitive ephemeris, updated bumper mode parameters and refined TIRS parameters, the products are transitioned to either Tier 1 or Tier 2 and removed from the Real-Time tier. The transition delay from Real-Time to Tier 1 or Tier 2 is between 14 and 26 days. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LO08_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LO08_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LO08_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LO08_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LO08_C01_T2(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 2 OLI DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1(example: str = ''):
        """
        Landsat 4 TM Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_BAI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_EVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_NBRT(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_NDSI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_NDVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_NDWI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_RAW(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_32DAY_TOA(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_BAI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_EVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_NBRT(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_NDSI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_NDVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_NDWI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_RAW(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_8DAY_TOA(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        Landsat 4 TM Collection 1 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 4 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 4 ETM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T1_TOA(example: str = ''):
        """
        Landsat 4 TM Collection 1 Tier 1 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T2(example: str = ''):
        """
        Landsat 4 TM Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T2_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T2_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T2_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T2_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T2_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 4 ETM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C01_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C01_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C01_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C01_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C01_T2_TOA(example: str = ''):
        """
        Landsat 4 TM Collection 1 Tier 2 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T1(example: str = ''):
        """
        Landsat 4 TM Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T1')                   .filterDate('1989-01-01', '1992-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T1_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T1_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T1_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T1_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T1_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat TM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 4 and 5 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T1_L2')     .filterDate('1990-04-01', '1990-05-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(15, 53, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T1_TOA(example: str = ''):
        """
        Landsat 4 TM Collection 2 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T1_TOA')                   .filterDate('1989-01-01', '1992-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T2(example: str = ''):
        """
        Landsat 4 TM Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T2')                   .filterDate('1989-01-01', '1992-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T2_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T2_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T2_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T2_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T2_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat TM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 4 and 5 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T2_L2')     .filterDate('1990-04-01', '1990-05-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(-83, 24, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT04_C02_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT04_C02_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT04_C02_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT04_C02_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT04_C02_T2_TOA(example: str = ''):
        """
        Landsat 4 TM Collection 2 Tier 2   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT04/C02/T2_TOA')                   .filterDate('1989-01-01', '1992-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1(example: str = ''):
        """
        Landsat 5 TM Collection 1 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_BAI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_EVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_NBRT(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_NDSI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_NDVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_NDWI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_RAW(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_32DAY_TOA(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_BAI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_EVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_NBRT(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_NDSI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_NDVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_NDWI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_RAW(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_8DAY_TOA(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        Landsat 5 TM Collection 1 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 5 TM Collection 1 Tier 1 composites are made from Tier 1 orthorectified scenes, using the   computed top-of-atmosphere (TOA) reflectance.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 5 ETM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T1_TOA(example: str = ''):
        """
        Landsat 5 TM Collection 1 Tier 1 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T2(example: str = ''):
        """
        Landsat 5 TM Collection 1 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T2_SR:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T2_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T2_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T2_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T2_SR(example: str = ''):
        """
        This dataset is the atmospherically corrected surface reflectance from the Landsat 5 ETM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified brightness temperature.  The VNIR and SWIR bands have a resolution of 30m / pixel. The TIR band, while originally collected with a resolution of 120m / pixel (60m / pixel for Landsat 7) has been resampled using cubic convolution to 30m.  These data have been atmospherically corrected using [LEDAPS](https://www.usgs.gov/media/files/landsat-4-7-surface-reflectance-code-ledaps-product-guide), and include a cloud, shadow, water and snow mask produced using [CFMASK](https://www.usgs.gov/land-resources/nli/landsat/cfmask-algorithm), as well as a per-pixel saturation mask.  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://www.usgs.gov/faqs/what-worldwide-reference-system-wrs).  Note that [Landsat 7's orbit has been drifting to an earlier acquisition time since 2017](https://www.sciencedirect.com/science/article/pii/S2666017221000134?via%3Dihub).  See also [the USGS page on SR QA bands](https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-quality-assessment).  SR can only be produced for Landsat assets processed to the [L1TP level](https://www.usgs.gov/land-resources/nli/landsat/landsat-levels-processing)  Data provider notes: <ul>   <li>SR is not run for a scene with a solar zenith angle greater than 76&deg;.</li>   <li>Users are cautioned to avoid using SR for data acquired   over high latitudes (&gt; 65&deg;).</li>   <li>The panchromatic band (ETM+ Band 7, OLI Band 8) is not processed to   Surface Reflectance.</li>   <li>Efficacy of SR correction will be likely reduced in areas   where atmospheric correction is affected by adverse conditions:     <ul>       <li>Hyper-arid or snow-covered regions</li>       <li>Low sun angle conditions</li>       <li>Coastal regions where land area is small relative to adjacent water</li>       <li>Areas with extensive cloud contamination</li>     </ul>   </li> </ul>  This product is generated by Google using a Docker image supplied by USGS. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C01_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C01_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C01_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C01_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C01_T2_TOA(example: str = ''):
        """
        Landsat 5 TM Collection 1 Tier 2 calibrated top-of-atmosphere (TOA) reflectance. Calibration coefficients are extracted from the image metadata. See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T1:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T1(example: str = ''):
        """
        Landsat 5 TM Collection 2 Tier 1 DN values, representing scaled, calibrated at-sensor radiance.  Landsat scenes with the highest available data quality are placed into Tier 1 and are considered suitable for time-series processing analysis. Tier 1 includes Level-1 Precision Terrain (L1TP) processed data that have well-characterized radiometry and are inter-calibrated across the different Landsat sensors. The georegistration of Tier 1 scenes will be consistent and within prescribed tolerances [<=12 m root mean square error (RMSE)]. All Tier 1 Landsat data can be considered consistent and inter-calibrated (regardless of sensor) across the full collection. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T1')                   .filterDate('2011-01-01', '2011-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T1_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T1_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T1_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T1_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T1_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat TM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 4 and 5 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')     .filterDate('2000-06-01', '2000-07-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(-114.2579, 38.9275, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T1_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T1_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T1_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T1_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T1_TOA(example: str = ''):
        """
        Landsat 5 TM Collection 2 Tier 1   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T1_TOA')   .filterDate('2011-01-01', '2011-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T2(example: str = ''):
        """
        Landsat 5 TM Collection 2 Tier 2 DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T2')                   .filterDate('2011-01-01', '2011-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {}; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T2_L2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T2_L2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T2_L2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T2_L2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T2_L2(example: str = ''):
        """
        This dataset contains atmospherically corrected surface reflectance and land surface temperature derived from the data produced by the Landsat TM sensor. These images contain 4 visible and near-infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed to orthorectified surface reflectance, and one thermal infrared (TIR) band processed to orthorectified surface temperature. They also contain intermediate bands used in calculation of the ST products, as well as QA bands.  Landsat 4 and 5 SR products are created with the Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) algorithm (version 3.4.0). All Collection 2 ST products are created with a single-channel algorithm jointly created by the Rochester Institute of Technology (RIT) and National Aeronautics and Space Administration (NASA) Jet Propulsion Laboratory (JPL).  Strips of collected data are packaged into overlapping \"scenes\" covering approximately 170km x 183km using a [standardized reference grid](https://landsat.gsfc.nasa.gov/about/worldwide-reference-system).  Some assets have only SR data, in which case ST bands are present but empty. For assets with both ST and SR bands, 'PROCESSING_LEVEL' is set to 'L2SP'. For assets with only SR bands, 'PROCESSING_LEVEL' is set to 'L2SR'.  [Additional documentation and usage examples.](/earth-engine/guides/landsat)  Data provider notes:  * Data products must contain both optical and thermal data to be   successfully processed to surface temperature, as ASTER NDVI is   required to temporally adjust the ASTER GED product to the target Landsat   scene. Therefore, night time acquisitions cannot be processed to   surface temperature.  * A known error exists in the surface temperature retrievals relative   to clouds and possibly cloud shadows. The characterization of these   issues has been documented by   [Cook et al., (2014)](https://doi.org/10.3390/rs61111244).  * ASTER GED contains areas of missing mean emissivity data required for   successful ST product generation. If there is missing ASTER GED   information, there will be missing ST data in those areas.  * The ASTER GED dataset is created from all clear-sky pixels of ASTER scenes   acquired from 2000 through 2008. While this dataset has a global spatial   extent, there are areas missing mean emissivity information due to   persistent cloud contamination in the ASTER measurements.  * The USGS further screens unphysical values (emissivity < 0.6) in ASTER   GED to remove any emissivity underestimation due to undetected clouds. For   any given pixel with no ASTER GED input or unphysical emissivity value,   the resulting Landsat ST products have missing pixels. The missing Landsat   ST pixels will be consistent through time (1982-present) given the static   nature of ASTER GED mean climatology data. For more information refer to   [landsat-collection-2-surface-temperature-data-gaps-due-missing](https://www.usgs.gov/landsat-missions/landsat-collection-2-surface-temperature-data-gaps-due-missing-aster-ged) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T2_L2')     .filterDate('2000-06-01', '2000-07-01');  // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  dataset = dataset.map(applyScaleFactors);  var visualization = {   bands: ['SR_B3', 'SR_B2', 'SR_B1'],   min: 0.0,   max: 0.3, };  Map.setCenter(-83, 24, 8);  Map.addLayer(dataset, visualization, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT05_C02_T2_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT05_C02_T2_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT05_C02_T2_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT05_C02_T2_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT05_C02_T2_TOA(example: str = ''):
        """
        Landsat 5 TM Collection 2 Tier 2   calibrated top-of-atmosphere (TOA) reflectance.   Calibration coefficients are extracted from the image metadata.   See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169)   for details on the TOA computation. 
        :param example: var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T2_TOA')   .filterDate('2011-01-01', '2011-12-31'); var trueColor321 = dataset.select(['B3', 'B2', 'B1']); var trueColor321Vis = {   min: 0.0,   max: 0.4,   gamma: 1.2, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor321, trueColor321Vis, 'True Color (321)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT08_C01_T2:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT08_C01_T2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT08_C01_T2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT08_C01_T2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT08_C01_T2(example: str = ''):
        """
        Landsat 8 Collection 1 Tier 2 TIRS DN values, representing scaled, calibrated at-sensor radiance. Scenes not meeting Tier 1 criteria during processing are assigned to Tier 2. This includes Systematic terrain (L1GT) and Systematic (L1GS) processed scenes, as well as any L1TP scenes that do not meet the Tier 1 specifications due to significant cloud cover, insufficient ground control, and other factors. Users interested in Tier 2 scenes can analyze the RMSE and other properties to determine the suitability for use in individual applications and studies. See more information [in the USGS docs](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collections). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4(example: str = ''):
        """
        Landsat 4 TM DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T(example: str = ''):
        """
        Landsat 4 TM DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_BAI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_EVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_NBRT(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_NDSI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_NDVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_NDWI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_RAW(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_32DAY_TOA(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_BAI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_EVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_NBRT(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_NDSI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_NDVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_NDWI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_RAW(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_8DAY_TOA(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 4 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT4_L1T_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT4_L1T_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT4_L1T_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT4_L1T_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT4_L1T_TOA(example: str = ''):
        """
        Landsat 4 TM calibrated top-of-atmosphere reflectance, orthorectified scenes only. For recently-acquired scenes calibration coefficients are extracted from the image metadata; for older scenes the coefficients are derived from [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5(example: str = ''):
        """
        Landsat 5 TM DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T(example: str = ''):
        """
        Landsat 5 TM DN values, representing scaled, calibrated at-sensor radiance, orthorectified scenes only.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_BAI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129 for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_EVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_NBRT(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_NDSI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_NDVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_NDWI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_RAW(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_32DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_32DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_32DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_32DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_32DAY_TOA(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 32-day period beginning from the first day of the year and continuing to the 352nd day of the year.  The last composite of the year, beginning on day 353, will overlap the first composite of the following year by 20 days.  All the images from each 32-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_BAI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129 for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_EVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_NBRT(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_NDSI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_NDVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_NDWI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_RAW(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_8DAY_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_8DAY_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_8DAY_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_8DAY_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_8DAY_TOA(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each 8-day period beginning from the first day of the year and continuing to the 360th day of the year.  The last composite of the year, beginning on day 361, will overlap the first composite of the following year by 3 days.  All the images from each 8-day period are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_BAI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_BAI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_EVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_EVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_GREENEST_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_GREENEST_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_GREENEST_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_GREENEST_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_GREENEST_TOA(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the greenest pixel as the composite value, where the greenest pixel means the pixel with the highest value of the Normalized Difference Vegetation Index (NDVI). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_NBRT:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_NBRT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_NBRT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_NBRT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_NBRT(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Burn Ratio Thermal (NBRT) index is generated from the Near-IR, Mid-IR (2215 nm), and Thermal bands, and has a range from -1.0 to 1.0. See [Holden et al. (2005)](https://www.tandfonline.com/doi/abs/10.1080/01431160500239008) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_NDSI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_NDSI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_NDVI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_NDVI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_NDWI:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_NDWI(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_RAW:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_RAW'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_RAW.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_RAW.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_RAW(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the DN values, representing scaled, calibrated at-sensor radiance.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_ANNUAL_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_ANNUAL_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_ANNUAL_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_ANNUAL_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_ANNUAL_TOA(example: str = ''):
        """
        These Landsat 5 TM composites are made from Level L1T orthorectified scenes, using the computed top-of-atmosphere (TOA) reflectance.  See [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169) for details on the TOA computation.  As of May 1, 2017, the USGS is no longer producing Pre-Collection Landsat, and therefore this collection is complete. Please switch to a Collection 1-based dataset. See [this documentation page](https://developers.google.com/earth-engine/landsat) for more information.  These composites are created from all the scenes in each annual period beginning from the first day of the year and continuing to the last day of the year.  All the images from each year are included in the composite, with the most recent pixel as the composite value. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_LT5_L1T_TOA:
    def __init__(self,):
        self.sensor = 'LANDSAT_LT5_L1T_TOA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_LT5_L1T_TOA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_LT5_L1T_TOA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_LT5_L1T_TOA(example: str = ''):
        """
        Landsat 5 TM calibrated top-of-atmosphere reflectance, orthorectified scenes only. For recently-acquired scenes calibration coefficients are extracted from the image metadata; for older scenes the coefficients are derived from [Chander et al. (2009)](https://www.sciencedirect.com/science/article/pii/S0034425709000169). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LANDSAT_MANGROVE_FORESTS:
    def __init__(self,):
        self.sensor = 'LANDSAT_MANGROVE_FORESTS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LANDSAT_MANGROVE_FORESTS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LANDSAT_MANGROVE_FORESTS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LANDSAT_MANGROVE_FORESTS(example: str = ''):
        """
        The database was prepared using Landsat satellite data from the year 2000. More than 1,000 Landsat scenes obtained from the USGS Earth Resources Observation and Science Center (EROS) were classified using hybrid supervised and unsupervised digital image classification techniques. This database is the first, most comprehensive mangrove assessment of the world ([Giri et al., 2011](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1466-8238.2010.00584.x)). Partial funding of this research was provided by NASA.  The mangrove database is being used for identifying priority areas for mangrove conservation, studying the role of mangrove forests in saving lives and properties from natural disasters (e.g. tsunami), carbon accounting, and biodiversity conservation. The USGS EROS has been using the data to study the impact of sea level rise on mangrove ecosystems. The database serves as a baseline for mangrove monitoring.  [General Documentation](https://sedac.ciesin.columbia.edu/data/set/lulc-global-mangrove-forests-distribution-2000/docs) 
        :param example: var dataset = ee.ImageCollection('LANDSAT/MANGROVE_FORESTS'); var mangrovesVis = {   min: 0,   max: 1.0,   palette: ['d40115'], }; Map.setCenter(-44.5626, -2.0164, 9); Map.addLayer(dataset, mangrovesVis, 'Mangroves'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_A_002:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_A_002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_A_002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_A_002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_A_002(example: str = ''):
        """
        GEDI's Level 2A Geolocated Elevation and Height Metrics Product (GEDI02_A) is primarily composed of 100 Relative Height (RH) metrics, which collectively describe the waveform collected by GEDI.  The original GEDI02_A product is a table of point with a spatial resolution (average footprint) of 25 meters.  Please see [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var dataset = ee.FeatureCollection('LARSE/GEDI/GEDI02_A_002/GEDI02_A_2021244154857_O15413_04_T05622_02_003_02_V002'); dataset = dataset.style({color: 'black',  pointSize: 1}); Map.setCenter(-64.88, -31.77, 15); Map.addLayer(dataset); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_A_002_INDEX:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_A_002_INDEX'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_A_002_INDEX.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_A_002_INDEX.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_A_002_INDEX(example: str = ''):
        """
        This is a feature collection created from the geometries of L2A tables in [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002). Each feature is a polygon footprint of a source table with its asset id and start/end timestamps.  Please see [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var rectangle = ee.Geometry.Rectangle([     -111.22, 24.06, -6.54, 51.9 ]); // Filter index by date and location var filter_index = ee.FeatureCollection(     'LARSE/GEDI/GEDI02_A_002_INDEX').filter(     'time_start > "2020-10-10T15:57:18Z" && time_end < "2020-10-11T01:20:45Z"')     .filterBounds(rectangle);  Map.addLayer(filter_index); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_A_002_MONTHLY:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_A_002_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_A_002_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_A_002_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_A_002_MONTHLY(example: str = ''):
        """
        GEDI's Level 2A Geolocated Elevation and Height Metrics Product (GEDI02_A) is primarily composed of 100 Relative Height (RH) metrics, which collectively describe the waveform collected by GEDI.  The original GEDI02_A product is a table of point with a spatial resolution (average footprint) of 25 meters. The dataset LARSE/GEDI/GEDI02_A_002_MONTHLY is a raster version of the original GEDI02_A product. The raster images are organized as monthly composites of individual orbits in the corresponding month. Only root-level RH values and their associated quality flags and metadata are preserved as raster bands. Each GEDI02_A_002 raster has 136 bands.  See [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var qualityMask = function(im) {   return im.updateMask(im.select('quality_flag').eq(1))       .updateMask(im.select('degrade_flag').eq(0)); }; var dataset = ee.ImageCollection('LARSE/GEDI/GEDI02_A_002_MONTHLY')                   .map(qualityMask)                   .select('rh98');  var gediVis = {   min: 1,   max: 60,   palette: 'darkred,red,orange,green,darkgreen', }; Map.setCenter(-74.803466, -9.342209, 10); Map.addLayer(dataset, gediVis, 'rh98'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_B_002:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_B_002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_B_002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_B_002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_B_002(example: str = ''):
        """
        GEDI Level 2B Canopy Cover and Vertical Profile Metrics product (GEDI02_B) extracts biophysical metrics from each GEDI waveform. These metrics are based on the directional gap probability profile derived from the L1B waveform.  The vertical step between foliage profile measurements (known as dZ in GEDI documentation) is always 5 meters. The original GEDI02_B product is a table of points with a spatial resolution (average footprint) of 25 meters.  Please see [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var dataset = ee.FeatureCollection(     'LARSE/GEDI/GEDI02_B_002/GEDI02_B_2021043114136_O12295_03_T07619_02_003_01_V002'); Map.setCenter(12.60033, 51.01051, 14); Map.addLayer(dataset); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_B_002_INDEX:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_B_002_INDEX'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_B_002_INDEX.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_B_002_INDEX.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_B_002_INDEX(example: str = ''):
        """
        This is a feature collection created from the geometries of L2B tables in [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002). Each feature is a polygon footprint of a source table with its asset id and start/end timestamps.  Please see [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var rectangle = ee.Geometry.Rectangle([     -111.22, 24.06, -6.54, 51.9 ]); // Filter index by date and location var filter_index = ee.FeatureCollection(     'LARSE/GEDI/GEDI02_B_002_INDEX').filter(     'time_start > "2020-10-10T15:57:18Z" && time_end < "2020-10-11T01:20:45Z"')     .filterBounds(rectangle);  Map.addLayer(filter_index); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI02_B_002_MONTHLY:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI02_B_002_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI02_B_002_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI02_B_002_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI02_B_002_MONTHLY(example: str = ''):
        """
        GEDI Level 2B Canopy Cover and Vertical Profile Metrics product (GEDI02_B) extracts biophysical metrics from each GEDI waveform. These metrics are based on the directional gap probability profile derived from the L1B waveform.  The vertical step between foliage profile measurements (known as dZ in GEDI documentation) is always 5 meters.  The dataset LARSE/GEDI/GEDI02_B_002_MONTHLY is a raster version of the original GEDI02_B product. The raster images are organized as monthly composites of individual orbits in the corresponding month. Only root-level cover, pai and pavd values and their associated quality flags and metadata are preserved as raster bands. Each GEDI02_B_002 raster has 109 bands.  See [User Guide](https://lpdaac.usgs.gov/documents/986/GEDI02_UserGuide_V2.pdf) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var qualityMask = function(im) {   return im.updateMask(im.select('l2b_quality_flag').eq(1))       .updateMask(im.select('degrade_flag').eq(0)); }; var dataset = ee.ImageCollection('LARSE/GEDI/GEDI02_B_002_MONTHLY')                   .map(qualityMask)                   .select('solar_elevation');  var gediVis = {   min: 1,   max: 60,   palette: 'red, green, blue', }; Map.setCenter(12.60033, 51.01051, 12); Map.addLayer(dataset, gediVis, 'Solar Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI04_A_002:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI04_A_002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI04_A_002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI04_A_002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI04_A_002(example: str = ''):
        """
        This dataset contains Global Ecosystem Dynamics Investigation (GEDI) Level 4A (L4A) Version 2 predictions of the aboveground biomass density (AGBD; in Mg/ha) and estimates of the prediction standard error within each sampled geolocated laser footprint. In this version, the granules are in sub-orbits. Height metrics from simulated waveforms associated with field estimates of AGBD from multiple regions and plant functional types (PFTs) were compiled to generate a calibration dataset for models representing the combinations of world regions and PFTs (i.e., deciduous broadleaf trees, evergreen broadleaf trees, evergreen needleleaf trees, deciduous needleleaf trees, and the combination of grasslands, shrubs, and woodlands).The algorithm setting group selection used for GEDI02_A Version 2 has been modified for evergreen broadleaf trees in South America to reduce false positive errors resulting from the selection of waveform modes above ground elevation as the lowest mode.  Please see [User Guide](https://daac.ornl.gov/GEDI/guides/GEDI_L4A_AGB_Density_V2_1.html) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var dataset = ee.FeatureCollection(   'LARSE/GEDI/GEDI04_A_002/GEDI04_A_2022157233128_O19728_03_T11129_02_003_01_V002'); Map.setCenter(-94.77616, 38.9587, 14); Map.addLayer(dataset); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI04_A_002_INDEX:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI04_A_002_INDEX'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI04_A_002_INDEX.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI04_A_002_INDEX.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI04_A_002_INDEX(example: str = ''):
        """
        This is a feature collection created from the geometries of L4A tables in [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002). Each feature is a polygon footprint of a source table with its asset id and start/end timestamps.  Please see [User Guide](https://daac.ornl.gov/GEDI/guides/GEDI_L4A_AGB_Density_V2_1.html) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var rectangle = ee.Geometry.Rectangle([   -111.22, 24.06, -6.54, 51.9 ]); // Filter index by date and location var filter_index = ee.FeatureCollection(   'LARSE/GEDI/GEDI04_A_002_INDEX').filter(   'time_start > "2020-10-10T15:57:18Z" && time_end < "2020-10-11T01:20:45Z"')   .filterBounds(rectangle);  Map.addLayer(filter_index); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI04_A_002_MONTHLY:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI04_A_002_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI04_A_002_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI04_A_002_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI04_A_002_MONTHLY(example: str = ''):
        """
        This dataset contains Global Ecosystem Dynamics Investigation (GEDI) Level 4A (L4A) Version 2 predictions of the aboveground biomass density (AGBD; in Mg/ha) and estimates of the prediction standard error within each sampled geolocated laser footprint. In this version, the granules are in sub-orbits. Height metrics from simulated waveforms associated with field estimates of AGBD from multiple regions and plant functional types (PFTs) were compiled to generate a calibration dataset for models representing the combinations of world regions and PFTs (i.e., deciduous broadleaf trees, evergreen broadleaf trees, evergreen needleleaf trees, deciduous needleleaf trees, and the combination of grasslands, shrubs, and woodlands).The algorithm setting group selection used for GEDI02_A Version 2 has been modified for evergreen broadleaf trees in South America to reduce false positive errors resulting from the selection of waveform modes above ground elevation as the lowest mode. The dataset LARSE/GEDI/GEDI04_A_002_MONTHLY is a raster version of the original GEDI04_A product. The raster images are organized as monthly composites of individual orbits in the corresponding month.  See [User Guide](https://daac.ornl.gov/GEDI/guides/GEDI_L4A_AGB_Density_V2_1.html) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var qualityMask = function(im) {   return im.updateMask(im.select('l4_quality_flag').eq(1))       .updateMask(im.select('degrade_flag').eq(0)); }; var dataset = ee.ImageCollection('LARSE/GEDI/GEDI04_A_002_MONTHLY')                   .map(qualityMask)                   .select('solar_elevation');  var gediVis = {   min: 1,   max: 60,   palette: 'red, green, blue', }; Map.setCenter(5.0198, 51.7564, 12); Map.addLayer(dataset, gediVis, 'Solar Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class LARSE_GEDI_GEDI04_B_002:
    def __init__(self,):
        self.sensor = 'LARSE_GEDI_GEDI04_B_002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/LARSE_GEDI_GEDI04_B_002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/LARSE_GEDI_GEDI04_B_002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_LARSE_GEDI_GEDI04_B_002(example: str = ''):
        """
        This Global Ecosystem Dynamics Investigation (GEDI) L4B product provides 1 km x 1 km estimates of mean aboveground biomass density (AGBD) based on observations from mission week 19 starting on 2019-04-18 to mission week 138 ending on 2021-08-04. The GEDI L4A Footprint Biomass product converts each high-quality waveform to an AGBD prediction, and the L4B product uses the sample present within the borders of each 1 km cell to statistically infer mean AGBD.  Please see [User Guide](https://daac.ornl.gov/GEDI/guides/GEDI_L4B_Gridded_Biomass.html) for more information.  The Global Ecosystem Dynamics Investigation [GEDI](https://gedi.umd.edu/) mission aims to characterize ecosystem structure and dynamics to enable radically improved quantification and understanding of the Earth's carbon cycle and biodiversity. The GEDI instrument, attached to the International Space Station (ISS), collects data globally between 51.6&deg; N and 51.6&deg; S latitudes at the highest resolution and densest sampling of the 3-dimensional structure of the Earth. The GEDI instrument consists of three lasers producing a total of eight beam ground transects, which instantaneously sample eight ~25 m footprints spaced approximately every 60 m along-track.  Product                 | Description :---------------------  | :---------------------------------------------- L2A Vector         | [LARSE/GEDI/GEDI02_A_002](LARSE_GEDI_GEDI02_A_002) L2A Monthly raster | [LARSE/GEDI/GEDI02_A_002_MONTHLY](LARSE_GEDI_GEDI02_A_002_MONTHLY) L2A table index    | [LARSE/GEDI/GEDI02_A_002_INDEX](LARSE_GEDI_GEDI02_A_002_INDEX) L2B Vector         | [LARSE/GEDI/GEDI02_B_002](LARSE_GEDI_GEDI02_B_002) L2B Monthly raster | [LARSE/GEDI/GEDI02_B_002_MONTHLY](LARSE_GEDI_GEDI02_B_002_MONTHLY) L2B table index    | [LARSE/GEDI/GEDI02_B_002_INDEX](LARSE_GEDI_GEDI02_B_002_INDEX) L4A Biomass Vector | [LARSE/GEDI/GEDI04_A_002](LARSE_GEDI_GEDI04_A_002) L4A Monthly raster | [LARSE/GEDI/GEDI04_A_002_MONTHLY](LARSE_GEDI_GEDI04_A_002_MONTHLY) L4A table index    | [LARSE/GEDI/GEDI04_A_002_INDEX](LARSE_GEDI_GEDI04_A_002_INDEX) L4B Biomass        | [LARSE/GEDI/GEDI04_B_002](LARSE_GEDI_GEDI04_B_002)
        :param example: var l4b = ee.Image('LARSE/GEDI/GEDI04_B_002')  Map.addLayer(     l4b.select('MU'),     {min: 10, max: 250, palette: '440154,414387,2a788e,23a884,7ad151,fde725'},     'Mean Biomass'); Map.addLayer(     l4b.select('SE'),     {min: 10, max: 50, palette: '000004,3b0f6f,8c2981,dd4a69,fe9f6d,fcfdbf'},     'Standard Error'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Latvia_Maamet_orthos_cir:
    def __init__(self,):
        self.sensor = 'Latvia_Maamet_orthos_cir'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Latvia_Maamet_orthos_cir.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Latvia_Maamet_orthos_cir.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Latvia_Maamet_orthos_cir(example: str = ''):
        """
        In Latvia, orthophoto maps are prepared in the Latvian coordinate system LKS-92 TM according to the TKS-93 map sheet division (scale 1:10000 map sheet corresponds to 5 x 5 kilometers in nature). Orthophoto maps are prepared for the whole territory of Latvia at the scale of 1:10000, but for separate territories - for cities and densely populated areas - at the scale of 1:2000 or 1:1000.  The CIR dataset has three bands: Near-Infrared, Red, and Green.  For more information, please see the [Latvia orthophotos documentation](https://www.lgia.gov.lv/lv/ortofotokartes-1) 
        :param example: var dataset = ee.ImageCollection('Latvia/Maamet/orthos/cir');  Map.setCenter(24.737, 56.861, 15); Map.addLayer(dataset, null, 'Latvia Maamet Color InfraRed (CIR)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class Latvia_Maamet_orthos_rgb:
    def __init__(self,):
        self.sensor = 'Latvia_Maamet_orthos_rgb'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Latvia_Maamet_orthos_rgb.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Latvia_Maamet_orthos_rgb.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Latvia_Maamet_orthos_rgb(example: str = ''):
        """
        In Latvia, orthophoto maps are prepared in the Latvian coordinate system LKS-92 TM according to the TKS-93 map sheet division (scale 1:10000 map sheet corresponds to 5 x 5 kilometers in nature). Orthophoto maps are prepared for the whole territory of Latvia at the scale of 1:10000, but for separate territories - for cities and densely populated areas - at the scale of 1:2000 or 1:1000.  The RGB dataset has three bands: red, green, and blue.  For more information, please see the [Latvia orthophotos documentation](https://www.lgia.gov.lv/lv/ortofotokartes-1) 
        :param example: var dataset = ee.ImageCollection('Latvia/Maamet/orthos/rgb');  Map.setCenter(24.737, 56.861, 15); Map.addLayer(dataset, null, 'Latvia Maamet RGB');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MERIT_DEM_v1_0_3:
    def __init__(self,):
        self.sensor = 'MERIT_DEM_v1_0_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MERIT_DEM_v1_0_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MERIT_DEM_v1_0_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MERIT_DEM_v1_0_3(example: str = ''):
        """
        MERIT DEM a high accuracy global DEM at 3 arc second resolution (~90 m at the equator) produced by eliminating major error components from existing DEMs (NASA SRTM3 DEM, JAXA AW3D DEM, Viewfinder Panoramas DEM).  MERIT DEM separates absolute bias, stripe noise, speckle noise and tree height bias using multiple satellite datasets and filtering techniques. After the error removal, land areas mapped with 2 m or better vertical accuracy were increased from 39% to 58%. Significant improvements were found in flat regions where height errors larger than topography variability, and landscapes such as river networks and hill-valley structures became clearly represented.  'MERIT DEM was developed by processing the following products as baseline data:  * [NASA SRTM3 DEM v2.1](https://dds.cr.usgs.gov/srtm/version2_1/SRTM3) * [JAXA AW3D - 30 m DEM v1](https://www.eorc.jaxa.jp/ALOS/en/aw3d30/index.htm) * [Viewfinder Panoramas DEM](http://www.viewfinderpanoramas.org/dem3.html)  In addition to the above baseline dems, these products were used as supplementary data:  * [NASA-NSIDC ICESat/GLAS GLA14 data](https://nsidc.org/data/gla14) * [U-Maryland Landsat forest cover data](https://glad.earthengine.app/view/global-forest-change) * [NASA Global Forest height data](https://www.nasa.gov/topics/earth/features/forest-height-map.html) * [JAMSTEC/U-Tokyo G3WBM water body data](http://hydro.iis.u-tokyo.ac.jp/~yamadai/G3WBM/index.html) 
        :param example: var dataset = ee.Image('MERIT/DEM/v1_0_3');  var visualization = {   bands: ['dem'],   min: -3,   max: 18,   palette: [     '000000', '478fcd', '86c58e', 'afc35e',     '8f7131', 'b78d4f', 'e2b8a6', 'ffffff'] };  Map.setCenter(90.301, 23.052, 10);  Map.addLayer(dataset, visualization, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MERIT_Hydro_reduced_v1_0_1:
    def __init__(self,):
        self.sensor = 'MERIT_Hydro_reduced_v1_0_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MERIT_Hydro_reduced_v1_0_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MERIT_Hydro_reduced_v1_0_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MERIT_Hydro_reduced_v1_0_1(example: str = ''):
        """
        Supplementary visualization layers for [MERIT Hydro](MERIT_Hydro_v1_0_1)
        :param example: var dataset = ee.Image('MERIT/Hydro_reduced/v1_0_1');  var visualization = {   bands: 'wth',   min: 0,   max: 400 };  Map.setCenter(90.301, 23.052, 10);  Map.addLayer(dataset, visualization, 'River width'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MERIT_Hydro_v1_0_1:
    def __init__(self,):
        self.sensor = 'MERIT_Hydro_v1_0_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MERIT_Hydro_v1_0_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MERIT_Hydro_v1_0_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MERIT_Hydro_v1_0_1(example: str = ''):
        """
        MERIT Hydro is a new global flow direction map at 3 arc-second resolution (~90 m at the equator) derived from the version 1.0.3 of the MERIT DEM elevation data and water body datasets (G1WBM, GSWO and OpenStreetMap).  MERIT Hydro contains the output of a new algorithm that extracts river networks near-automatically by separating actual inland basins from noise caused by the errors in input elevation data. After a minimum amount of hand-editing, the constructed hydrography map shows good agreement with existing quality-controlled river network datasets in terms of flow accumulation area and river basin shape (see Figure 9a in the paper). The location of river streamlines was realistically aligned with existing satellite-based global river channel data (see Figure 10a in the paper). Relative error in the drainage area was smaller than 0.05 for 90% of GRDC gauges, confirming the accuracy of the delineated global river networks. Discrepancies in flow accumulation area were found mostly in arid river basins containing depressions that are occasionally connected at high water levels and thus resulting in uncertain watershed boundaries.  MERIT Hydro improves on existing global hydrography datasets in terms of spatial coverage (between 90N and 60S) and representation of small streams, mainly due to increased availability of high-quality baseline geospatial datasets.  [You can use this web app to visualize MERIT Hydro data.](https://meritdataset.users.earthengine.app/view/merit-hydro-visualization-and-interactive-map) [The app's source code is available.](https://github.com/google/earthengine-community/blob/master/datasets/scripts/Hydro_Visualization.js)  Known Problems:  * River width (Update from GWD-LR v1): Width algorithm was updated to consider   sub-pixel water fraction. Now, 30 m water map is used for width calculation at   90 m resolution. Currently river width is calculated for each channel separately   in braided/anabranching sections. Merged river width should be calculated. * Water body map: There are some inconsistencies between the DEM land sea mask and   wate body data (such as new islands along the coast). The quality of OpenStreeetMap   water body layer is not uniform in all areas. * Channel bifurcations: Channel bifurcation is not well represented in the current   version. Each pixel is assumed to have only one downstream direction. Secondary   (or multiple) downstream direction should be considered, to represent complex   river networks in the delta regions, floodplains, and braided rivers. * Underground rivers/tunnels: Major underground rivers/tunnels should be implemented   to improve large-scale water balance. * River/lake separation: Rivers and lakes need to be separated better for some applications. * Below-sea-level areas: The areas below sea level in coastal regions are not well   represented in adjusted elevation data. * Flow direction over glaciers: Flow direction over glaciers is not well represented,   because the elevation of glacier centerline is higher than glacier edge. * Supplementary data: It would be better to add location of GRDC gauging stations, water   falls, reservoirs, etc.  Data Sources:  * [U-Tokyo MERIT DEM](http://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_DEM/index.html) * [U-Tokyo G1WBM water body data](http://hydro.iis.u-tokyo.ac.jp/~yamadai/G3WBM/index.html) * [OpenStreetMap water body layer](http://hydro.iis.u-tokyo.ac.jp/~yamadai/OSM_water/index.html) * [EC-JRC Global Surface Water Occurrence](http://hydro.iis.u-tokyo.ac.jp/~yamadai/G3WBM/index.html) * [U-Maryland Landsat forest cover data](https://glad.earthengine.app/view/global-forest-change) 
        :param example: var dataset = ee.Image('MERIT/Hydro/v1_0_1');  var visualization = {   bands: ['viswth'], };  Map.setCenter(90.301, 23.052, 10);  Map.addLayer(dataset, visualization, 'River width'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD12Q1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD12Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD12Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD12Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD12Q1(example: str = ''):
        """
        The MCD12Q1 V6 product provides global land cover types at yearly intervals (2001-2016) derived from six different classification schemes. It is derived using supervised classifications of MODIS Terra and Aqua reflectance data. The supervised classifications then undergo additional post-processing that incorporate prior knowledge and ancillary information to further refine specific classes.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/101/MCD12_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/86/MCD12_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD12Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD12Q1'); var igbpLandCover = dataset.select('LC_Type1'); var igbpLandCoverVis = {   min: 1.0,   max: 17.0,   palette: [     '05450a', '086a10', '54a708', '78d203', '009900', 'c6b044', 'dcd159',     'dade48', 'fbff13', 'b6ff05', '27ff87', 'c24f44', 'a5a5a5', 'ff6d4c',     '69fff8', 'f9ffa4', '1c0dff'   ], }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(igbpLandCover, igbpLandCoverVis, 'IGBP Land Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD12Q2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD12Q2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD12Q2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD12Q2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD12Q2(example: str = ''):
        """
        The MCD12Q2 V6 Land Cover Dynamics product (informally called the MODIS Global Vegetation Phenology product) provides estimates of the timing of vegetation phenology at global scales. Additionally, it provides information related to the range and summation of the enhanced vegetation index (EVI) computed from MODIS surface reflectance data at each pixel. It identifies the onset of greenness, greenup midpoint, maturity, peak greenness, senescence, greendown midpoint, dormancy, EVI2 minimum, EVI2 amplitude, integrated EVI2 over a vegetation cycle, as well as overall and phenology metric-specific quality information.  The MCD12Q2 Version 6 data product is derived from time series of the 2-band Enhanced Vegetation Index (EVI2) calculated from MODIS Nadir Bidirectional Reflectance Distribution Function (BRDF)-Adjusted Reflectance (NBAR). Vegetation phenology metrics are identified for up to two detected growing cycles per year. For pixels with more than two valid vegetation cycles, the data represent the two cycles with the largest NBAR-EVI2 amplitudes. 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD12Q2')                   .filter(ee.Filter.date('2001-01-01', '2002-01-01')); var vegetationPeak = dataset.select('Peak_1'); var vegetationPeakVis = {   min: 11400,   max: 11868,   palette: ['0f17ff', 'b11406', 'f1ff23'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     vegetationPeak, vegetationPeakVis,     'Vegetation Peak 2001'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD15A3H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD15A3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD15A3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD15A3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD15A3H(example: str = ''):
        """
        The MCD15A3H V6 level 4, Combined Fraction of Photosynthetically Active Radiation (FPAR), and Leaf Area Index (LAI) product is a 4-day composite data set with 500 meter pixel size. The algorithm chooses the \"best\" pixel available from all the acquisitions of both MODIS sensors located on NASA's Terra and Aqua satellites from within the 4-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD15A3H) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD15A3H'); var defaultVisualization = dataset.first().select('Fpar'); var defaultVisualizationVis = {   min: 0.0,   max: 100.0,   palette: ['e1e4b4', '999d60', '2ec409', '0a4b06'], }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD19A2_GRANULES:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD19A2_GRANULES'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD19A2_GRANULES.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD19A2_GRANULES.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD19A2_GRANULES(example: str = ''):
        """
        The MCD19A2 V6 data product is a MODIS Terra and Aqua combined Multi-angle Implementation of Atmospheric Correction (MAIAC) Land Aerosol Optical Depth (AOD) gridded Level 2 product produced daily at 1 km resolution. For more information see the [MAIAC user guide](https://lpdaac.usgs.gov/documents/110/MCD19_User_Guide_V6.pdf).  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/110/MCD19_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/111/MCD19_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD19A2) 
        :param example: var collection = ee.ImageCollection('MODIS/006/MCD19A2_GRANULES')                   .select('Optical_Depth_047')                   .filterDate('2019-01-01', '2019-01-15');  var band_viz = {   min: 0,   max: 500,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'Optical Depth 047'); Map.setCenter(76, 13, 6); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD43A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD43A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD43A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD43A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD43A1(example: str = ''):
        """
        The MCD43A1 V6 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Model Parameters dataset is a 500 meter daily 16-day product. The Julian date represents the 9th day of the 16-day retrieval period, and consequently the observations are weighted to estimate the BRDF/Albedo for that day. The MCD43A1 algorithm, as is with all combined products, chooses the best representative pixel from a pool that includes all the acquisitions from both the Terra and Aqua sensors from the retrieval period.  The MCD43A1 provides the three model weighting parameters (isotropic, volumetric, and geometric) for each of the MODIS bands 1 through 7 and the visible (vis), near infrared (nir), and shortwave bands used to derive the Albedo and BRDF products (MCD43A3 and MCD43A4). The Mandatory Quality layers for each of the 10 bands are supplied as well.  See [dataset user guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43a1_brdif_albedo_model_parameters_product) for more information.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD43A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD43A1')                   .filter(ee.Filter.date('2018-05-01', '2018-07-01')); var defaultVisualization = dataset.select([   'BRDF_Albedo_Parameters_Band1_iso', 'BRDF_Albedo_Parameters_Band4_iso',   'BRDF_Albedo_Parameters_Band3_iso' ]); var defaultVisualizationVis = {   min: 0.0,   max: 1400.0,   gamma: 2.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD43A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD43A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD43A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD43A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD43A2(example: str = ''):
        """
        The MCD43A2 V6 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Quality dataset is a 500 meter daily 16-day product. It contains all the quality information for the corresponding 16-day MCD43A3 Albedo and the MCD43A4 Nadir-BRDF (NBAR) products.  The MCD43A2 contains individual band quality and observation information for the MODIS land bands 1-7, along with the overall BRDF/Albedo quality information.  See [dataset user guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43a2_albedo_product) for more information.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD43A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD43A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var defaultVisualization = dataset.select('Snow_BRDF_Albedo'); var defaultVisualizationVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD43A3:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD43A3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD43A3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD43A3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD43A3(example: str = ''):
        """
        The MCD43A3 V6 Albedo Model dataset is a daily 16-day product. It provides both directional hemispherical reflectance (black sky albedo) and bihemispherical reflectance (white sky albedo) for each of the MODIS surface reflectance bands (band 1 through band 7) as well as 3 broad spectrum bands (visible, near infrared, and shortwave).  Each 500m/pixel daily image is generated using 16 days of data, centered on the given day.  A quality band is also provided for each of the 10 albedo bands.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD43A3) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD43A3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var blackSkyAlbedo = dataset.select('Albedo_BSA_Band1'); var blackSkyAlbedoVis = {   min: 0.0,   max: 400.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(blackSkyAlbedo, blackSkyAlbedoVis, 'Black-Sky Albedo'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD43A4:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD43A4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD43A4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD43A4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD43A4(example: str = ''):
        """
        The MCD43A4 V6 Nadir Bidirectional Reflectance Distribution Function Adjusted Reflectance (NBAR) product provides 500 meter reflectance data of the MODIS \"land\" bands 1-7. These are adjusted using a bidirectional reflectance distribution function to model the values as if they were collected from a nadir view.  The data are produced daily based on a 16-day retrieval period, with the image's date occurring on the 9th day. This product combines data from both the Terra and Aqua spacecrafts, choosing the best representative pixel from the 16-day period.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD43A4) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD43A4')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor = dataset.select([   'Nadir_Reflectance_Band1',   'Nadir_Reflectance_Band4',   'Nadir_Reflectance_Band3' ]); var trueColorVis = {   min: 0,   max: 4000,   gamma: 1.4, }; Map.setCenter(-7.03, 31.06, 2); Map.addLayer(trueColor, trueColorVis, 'True Color');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD43C3:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD43C3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD43C3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD43C3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD43C3(example: str = ''):
        """
        The MCD43C3 Version 6 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Albedo dataset is produced daily using 16 days of Terra and Aqua MODIS data in a 0.05 degree (5,600 meters at the equator) Climate Modeling Grid (CMG). Data are temporally weighted to the ninth day of the retrieval period which is reflected in the Julian date in the file name. This CMG product covers the entire globe for use in climate simulation models.  MCD43C3 provides black-sky albedo (directional hemispherical reflectance) and white-sky albedo (bihemispherical reflectance) at local solar noon. Black-sky albedo and white-sky albedo values are available as a separate layer for MODIS spectral bands 1 through 7 as well as the visible, near infrared (NIR), and shortwave bands. Along with the 20 albedo layers are ancillary layers for quality, local solar noon, percent finer resolution inputs, snow cover, and uncertainty.  See [dataset user guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43c3) for more information. 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD43C3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var blackSkyAlbedo = dataset.select('Albedo_BSA_Band1'); var blackSkyAlbedoVis = {   min: 0,   max: 400, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(blackSkyAlbedo, blackSkyAlbedoVis, 'Black-Sky Albedo'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MCD64A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MCD64A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MCD64A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MCD64A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MCD64A1(example: str = ''):
        """
        The Terra and Aqua combined MCD64A1 Version 6 Burned Area data product is a monthly, global gridded 500m product containing per-pixel burned-area and quality information. The MCD64A1 burned-area mapping approach employs 500m MODIS Surface Reflectance imagery coupled with 1km MODIS active fire observations. The algorithm uses a burn sensitive vegetation index (VI) to create dynamic thresholds that are applied to the composite data. The VI is derived from MODIS shortwave infrared atmospherically corrected surface reflectance bands 5 and 7 with a measure of temporal texture. The algorithm identifies the date of burn for the 500m grid cells within each individual MODIS tile. The date is encoded in a single data layer as the ordinal day of the calendar year on which the burn occurred, with values assigned to unburned land pixels and additional special values reserved for missing data and water grid cells.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/751/MCD64_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/115/MCD64_ATBD_V6.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MCD64A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MCD64A1')                   .filter(ee.Filter.date('2017-01-01', '2018-05-01')); var burnedArea = dataset.select('BurnDate'); var burnedAreaVis = {   min: 30,   max: 341,   palette: ['4e0400', '951003', 'c61503', 'ff1901'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(burnedArea, burnedAreaVis, 'Burned Area'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD08_M3:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD08_M3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD08_M3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD08_M3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD08_M3(example: str = ''):
        """
        MOD08_M3 V6 is an atmosphere global product that contains monthly 1 x 1 degree grid average values of atmospheric parameters. These parameters are related to atmospheric aerosol particle properties, total ozone burden, atmospheric water vapor, cloud optical and physical properties, and atmospheric stability indices. The product also provides means, standard deviations, QA weighted statistics, log-normal distributions, uncertainty estimates, and statistics for fractions of pixels that satisfy some condition. Below is a subset of the bands, for a complete list see the [MOD08 Band List](https://developers.google.com/earth-engine/MOD08_bands.html).  Documentation:  * [User's Guide](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_ATBD_C6_C61_2019_02_20.pdf)  * [Science Data Product Software Documentation](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_C61_Changes_v2.pdf)  * [MYD08_M3 product description](https://modis-atmos.gsfc.nasa.gov/products/monthly)  * [File specification document](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/MOD08_M3_fs_3045.txt) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD08_M3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var aerosolOpticalDepth =     dataset.select('Aerosol_Optical_Depth_Land_Ocean_Mean_Mean'); var aerosolOpticalDepthVis = {   min: 0,   max: 3000,   palette: ['ffffff', '1303ff', '01ff09', 'ff2f00'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     aerosolOpticalDepth, aerosolOpticalDepthVis, 'Aerosol Optical Depth'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD09A1(example: str = ''):
        """
        The MOD09A1 V6 product provides an estimate of the surface spectral reflectance of Terra MODIS bands 1-7 at 500m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the seven reflectance bands is a quality layer and four observation bands. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD09A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD09A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var trueColor =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColorVis = {   min: -100.0,   max: 3000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor, trueColorVis, 'True Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MOD09GA version 6 provides bands 1-7 in a daily gridded L2G product in the sinusoidal projection, including 500m reflectance values and 1km observation and geolocation statistics.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD09GA) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD09GA')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor143 =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColor143Vis = {   min: -100,   max: 8000, }; Map.setCenter(-7.03, 31.05, 2); Map.addLayer(trueColor143, trueColor143Vis, 'True Color (143)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MOD09GQ version 6 provides bands 1 and 2 at a 250m resolution in a daily gridded L2G product in the Sinusoidal projection, including a QC and five observation layers. This product is meant to be used in conjunction with the MOD09GA where important quality and viewing geometry information is stored.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD09GQ) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD09GQ')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100,   max: 8000,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD09Q1(example: str = ''):
        """
        The MOD09Q1 product provides an estimate of the surface spectral reflectance of bands 1 and 2 at 250m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the two reflectance bands, a quality layer is also included. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD09Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD09Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100,   max: 8000,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD10A1(example: str = ''):
        """
        The MOD10A1 V6 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests.  [General documentation](https://doi.org/10.5067/MODIS/MOD10A1.006) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD10A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var snowCover = dataset.select('NDSI_Snow_Cover'); var snowCoverVis = {   min: 0.0,   max: 100.0,   palette: ['black', '0dffff', '0524ff', 'ffffff'], }; Map.setCenter(-41.13, 76.35, 2); Map.addLayer(snowCover, snowCoverVis, 'Snow Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD11A1(example: str = ''):
        """
        The MOD11A1 V6 product provides daily land surface temperature (LST) and emissivity values in a 1200 x 1200 kilometer grid. The temperature value is derived from the MOD11_L2 swath product. Above 30 degrees latitude, some pixels may have multiple observations where the criteria for clear-sky are met. When this occurs, the pixel value is the average of all qualifying observations. Provided along with both the day-time and night-time surface temperature bands and their quality indicator layers are MODIS bands 31 and 32 and six observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD11A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD11A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 13000,   max: 16500,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD11A2(example: str = ''):
        """
        The MOD11A2 V6 product provides an average 8-day land surface temperature (LST)  in a 1200 x 1200 kilometer grid.  Each pixel value in MOD11A2 is a simple average of all the corresponding MOD11A1 LST pixels collected within that 8 day period.  The 8 day compositing period was chosen because twice that period is the exact ground track repeat period of the Terra and Aqua platforms. In this product, along with both the day- and night-time surface temperature bands and their quality indicator (QC) layers, are also MODIS bands 31 and 32 and eight observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD11A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD11A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 14000,   max: 16000,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD13A1(example: str = ''):
        """
        The MOD13A1 V6 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD13A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD13A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD13A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD13A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD13A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD13A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD13A2(example: str = ''):
        """
        The MOD13A2 V6 product provides two Vegetation Indices (VI): the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI). The NDVI is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The EVI has improved sensitivity over high biomass regions.  The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD13A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD13Q1(example: str = ''):
        """
        The MOD13Q1 V6 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD13Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 8000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD14A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD14A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD14A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD14A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD14A1(example: str = ''):
        """
        The MOD14A1 V6 dataset provides daily fire mask composites at 1km resolution derived from the MODIS 4- and 11-micrometer radiances. The fire detection strategy is based on absolute detection of a fire (when the fire strength is sufficient to detect), and on detection relative to its background (to account for variability of the surface temperature and reflection by sunlight). The product distinguishes between fire, no fire and no observation. This information is used for monitoring the spatial and temporal distribution of fires in different ecosystems, detecting changes in fire distribution and identifying new fire frontiers, wild fires, and changes in the frequency of the fires  or their relative strength.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD14A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD14A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMaskVis = {   min: 0,   max: 6000,   bands: ['MaxFRP', 'FireMask', 'FireMask'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD14A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD14A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD14A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD14A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD14A2(example: str = ''):
        """
        The MOD14A2 V6 dataset provides 8-day fire mask composites at 1km resolution. It contains the maximum value of the individual pixel classes over the compositing period. Along with the fire mask, an associated quality information layer is also provided.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD14A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD14A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMask = dataset.select('FireMask'); var fireMaskVis = {   min: 3,   max: 8, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(fireMask, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD15A2H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD15A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD15A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD15A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD15A2H(example: str = ''):
        """
        The MOD15A2H V6 MODIS combined Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) product is an 8-day composite dataset at 500m resolution. The algorithm chooses the \"best\" pixel available from all the acquisitions of the Terra sensor from within the 8-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD15A2H) 
        :param example: var collection = ee.ImageCollection('MODIS/006/MOD15A2H')                   .filterDate('2019-01-01', '2019-10-01');  var colorizedVis = {   min: 0,   max: 100,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], };  Map.setCenter(-10.88, 40.94, 2); Map.addLayer(collection.select('Lai_500m'), colorizedVis, 'Lai'); Map.addLayer(collection.select('Fpar_500m'), colorizedVis, 'Fpar'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD16A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD16A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD16A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD16A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD16A2(example: str = ''):
        """
        The MOD16A2 Version 6 Evapotranspiration/Latent Heat Flux product is an 8-day composite product produced at 500 meter pixel resolution. The algorithm used for the MOD16 data product collection is based on the logic of the Penman-Monteith equation, which includes inputs of daily meteorological reanalysis data along with MODIS remotely sensed data products such as vegetation property dynamics, albedo, and land cover.  The pixel values for the two Evapotranspiration layers (ET & PET) are the sum of all eight days within the composite period. The pixel values for the two Latent Heat layers (LE & PLE) are the average of all eight days within the composite period. Note that the last 8-day period of each year is a 5 or 6-day composite period, depending on the year.  According to [the \"Layers\" section of the dataset docs](https://lpdaac.usgs.gov/products/mod16a2v006), the class assignment in fill values 32761 through 32767 might be inaccurate. They are not included in the EE assets.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/494/MOD16_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/93/MOD16_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD16A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD16A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var evapotranspiration = dataset.select('ET'); var evapotranspirationVis = {   min: 0,   max: 300,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(evapotranspiration, evapotranspirationVis, 'Evapotranspiration'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD17A2H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD17A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD17A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD17A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD17A2H(example: str = ''):
        """
        The MOD17A2H V6 Gross Primary Productivity (GPP) product is a cumulative 8-day composite with a 500m pixel size. The product is based on the radiation-use efficiency concept and can be potentially used as inputs to data models to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/495/MOD17_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/95/MOD17_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD17A2H) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD17A2H')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01'));  var gpp = dataset.select('Gpp'); var gppVis = {   min: 0,   max: 600,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD17A3H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD17A3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD17A3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD17A3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD17A3H(example: str = ''):
        """
        The MOD17A3H V6 product provides information about annual Net Primary Productivity (NPP) at 500m pixel resolution.  Annual NPP is derived from the sum of the 45 8-day Net Photosynthesis (PSN) products (MOD17A2H) from the given year.  The PSN value is the difference of the GPP and the Maintenance Respiration (MR) (GPP-MR).  This is a NASA version of this product. Another version is produced by the Numerical Terradynamic Simulation Group ([NTSG](https://www.ntsg.umt.edu)), University of Montana (UMT).  The NTSG version corrects the problem with cloud-contaminated MODIS LAI-FPAR inputs to the MOD17 algorithm, but its resolution is 1km. It is ingested into Earth Engine as MODIS/055/MOD17A3.  For further details regarding the differences between the NTSG and NASA versions of this product, please consult [this document ](https://lpdaac.usgs.gov/documents/188/MOD17_NTSG_Note.pdf). 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD17A3H')                   .filter(ee.Filter.date('2014-01-01', '2015-05-01')); var npp = dataset.select('Npp'); var nppVis = {   min: 0,   max: 19000,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD17A3HGF:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD17A3HGF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD17A3HGF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD17A3HGF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD17A3HGF(example: str = ''):
        """
        The MOD17A3HGF V6 product provides information about annual Net Primary Productivity (NPP) at 500m pixel resolution.  Annual NPP is derived from the sum of all 8-day Net Photosynthesis (PSN) products (MOD17A2H) from the given year.  The PSN value is the difference of the Gross Primary Productivity (GPP) and the Maintenance Respiration (MR) (GPP-MR). 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD17A3HGF');  var visualization = {   bands: ['Npp'],   min: 0,   max: 19000,   palette: ['bbe029', '0a9501', '074b03'] };  Map.setCenter(6.746, 46.529, 3);  Map.addLayer(dataset, visualization, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD44B:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD44B'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD44B.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD44B.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD44B(example: str = ''):
        """
        The Terra MODIS Vegetation Continuous Fields (VCF) product is a sub-pixel-level representation of surface vegetation cover estimates globally. Designed to continuously represent Earth's terrestrial surface as a proportion of basic vegetation traits, it provides a gradation of three surface cover components: percent tree cover, percent non-tree cover, and percent bare. VCF products provide a continuous, quantitative portrayal of land surface cover with improved spatial detail, and hence, are widely used in environmental modeling and monitoring applications.  Generated yearly, the VCF product is produced using monthly composites of Terra MODIS 250 and 500 meters Land Surface Reflectance data, including all seven bands, and Land Surface Temperature.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1322/MOD44B_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/113/MOD44B_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD44B) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD44B');  var visualization = {   bands: ['Percent_Tree_Cover'],   min: 0,   max: 100,   palette: ['bbe029', '0a9501', '074b03'] };  Map.setCenter(6.746, 46.529, 3);  Map.addLayer(dataset, visualization, 'Percent Tree Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MOD44W:
    def __init__(self,):
        self.sensor = 'MODIS_006_MOD44W'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MOD44W.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MOD44W.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MOD44W(example: str = ''):
        """
        The MOD44W V6 land/water mask 250m product is derived using a decision tree classifier trained with MODIS data and validated with the MOD44W V5 product. A series of masks are applied to address known issues caused by terrain shadow, burn scars, cloudiness, or ice cover in oceans. 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MOD44W')                   .filter(ee.Filter.date('2015-01-01', '2015-05-01')); var waterMask = dataset.select('water_mask'); var waterMaskVis = {   min: 0,   max: 1,   palette: ['bcba99', '2d0491'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(waterMask, waterMaskVis, 'Water Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MODOCGA:
    def __init__(self,):
        self.sensor = 'MODIS_006_MODOCGA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MODOCGA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MODOCGA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MODOCGA(example: str = ''):
        """
        The MODOCGA V6 ocean reflectance product consists of 1 kilometer reflectance data from Terra MODIS bands 8-16. The product is referred to as ocean reflectance, because bands 8-16 are used primarily to produce ocean products, but this is not an ocean product as the tiles produced are land tiles.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MODOCGA) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MODOCGA')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColor =     dataset.select(['sur_refl_b11', 'sur_refl_b10', 'sur_refl_b09']); var falseColorVis = {   min: 0,   max: 2000, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD08_M3:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD08_M3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD08_M3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD08_M3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD08_M3(example: str = ''):
        """
        MYD08_M3 V6 is an atmosphere global product that contains monthly 1 x 1 degree grid average values of atmospheric parameters. These parameters are related to atmospheric aerosol particle properties, total ozone burden, atmospheric water vapor, cloud optical and physical properties, and atmospheric stability indices. The product also provides means, standard deviations, QA weighted statistics, log-normal distributions, uncertainty estimates, and statistics for fractions of pixels that satisfy some condition. Below is a subset of the bands, for a complete list see the [MOD08 Band List](https://developers.google.com/earth-engine/MOD08_bands.html).  Documentation:  * [User's Guide](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_ATBD_C6_C61_2019_02_20.pdf)  * [Science Data Product Software Documentation](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_C61_Changes_v2.pdf)  * [MYD08_M3 product description](https://modis-atmos.gsfc.nasa.gov/products/monthly)  * [File specification document](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/MOD08_M3_fs_3045.txt) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD08_M3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var aerosolOpticalDepth =     dataset.select('Aerosol_Optical_Depth_Land_Ocean_Mean_Mean'); var aerosolOpticalDepthVis = {   min: 0.0,   max: 3000.0,   palette: ['ffffff', '1303ff', '01ff09', 'ff2f00'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     aerosolOpticalDepth, aerosolOpticalDepthVis, 'Aerosol Optical Depth'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD09A1(example: str = ''):
        """
        The MYD09A1 V6 product provides an estimate of the surface spectral reflectance of Aqua MODIS bands 1-7 at 500m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the seven reflectance bands is a quality layer and four observation bands. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD09A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD09A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var trueColor =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColorVis = {   min: -100.0,   max: 3000.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(trueColor, trueColorVis, 'True Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MYD09GA version 6 provides bands 1-7 in a daily gridded L2G product in the sinusoidal projection, including 500m reflectance values and 1km observation and geolocation statistics.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD09GA) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD09GA')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor143 =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColor143Vis = {   min: -100.0,   max: 8000.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(trueColor143, trueColor143Vis, 'True Color (143)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MYD09GQ version 6 provides bands 1 and 2 at a 250m resolution in a daily gridded L2G product in the Sinusoidal projection, including a QC and five observation layers. This product is meant to be used in conjunction with the MYD09GA where important quality and viewing geometry information is stored.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD09GQ) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD09GQ')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100.0,   max: 8000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD09Q1(example: str = ''):
        """
        The MYD09Q1 product provides an estimate of the surface spectral reflectance of bands 1 and 2 at 250m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the two reflectance bands, a quality layer is also included. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD09Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD09Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01'));  var falseColorVis = {   min: -100.0,   max: 6000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD10A1(example: str = ''):
        """
        The MYD10A1 V6 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests.  [General documentation](https://doi.org/10.5067/MODIS/MYD10A1.006) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD10A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var snowCover = dataset.select('NDSI_Snow_Cover'); var snowCoverVis = {   min: 0.0,   max: 100.0,   palette: ['black', '0dffff', '0524ff', 'ffffff'], }; Map.setCenter(-38.13, 40, 2); Map.addLayer(snowCover, snowCoverVis, 'Snow Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD11A1(example: str = ''):
        """
        The MYD11A1 V6 product provides daily land surface temperature (LST) and emissivity values in a 1200 x 1200 kilometer grid. The temperature value is derived from the MYD11_L2 swath product. Above 30 degrees latitude, some pixels may have multiple observations where the criteria for clear-sky are met. When this occurs, the pixel value is the average of all qualifying observations. Provided along with both the day-time and night-time surface temperature bands and their quality indicator layers are MODIS bands 31 and 32 and six observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD11A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD11A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 13000.0,   max: 16500.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD11A2(example: str = ''):
        """
        The MYD11A2 V6 product provides an average 8-day land surface temperature (LST)  in a 1200 x 1200 kilometer grid.  Each pixel value in MYD11A2 is a simple average of all the corresponding MYD11A1 LST pixels collected within that 8 day period.  The 8 day compositing period was chosen because twice that period is the exact ground track repeat period of the Terra and Aqua platforms. In this product, along with both the day- and night-time surface temperature bands and their quality indicator (QC) layers, are also MODIS bands 31 and 32 and eight observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD11A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD11A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 14000.0,   max: 16000.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD13A1(example: str = ''):
        """
        The MYD13A1 V6 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD13A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD13A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0.0,   max: 9000.0,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD13A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD13A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD13A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD13A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD13A2(example: str = ''):
        """
        The MYD13A2 V6 product provides two Vegetation Indices (VI): the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI). The NDVI is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The EVI has improved sensitivity over high biomass regions.  The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD13A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD13Q1(example: str = ''):
        """
        The MYD13Q1 V6 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD13Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 8000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD14A1:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD14A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD14A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD14A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD14A1(example: str = ''):
        """
        The MYD14A1 V6 dataset provides daily fire mask composites at 1km resolution derived from the MODIS 4- and 11-micrometer radiances. The fire detection strategy is based on absolute detection of a fire (when the fire strength is sufficient to detect), and on detection relative to its background (to account for variability of the surface temperature and reflection by sunlight). The product distinguishes between fire, no fire and no observation. This information is used for monitoring the spatial and temporal distribution of fires in different ecosystems, detecting changes in fire distribution and identifying new fire frontiers, wild fires, and changes in the frequency of the fires  or their relative strength.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD14A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD14A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMaskVis = {   min: 0.0,   max: 6000.0,   bands: ['MaxFRP', 'FireMask', 'FireMask'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD14A2:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD14A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD14A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD14A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD14A2(example: str = ''):
        """
        The MYD14A2 V6 dataset provides 8-day fire mask composites at 1km resolution. It contains the maximum value of the individual pixel classes over the compositing period. Along with the fire mask, an associated quality information layer is also provided.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD14A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD14A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMask = dataset.select('FireMask'); var fireMaskVis = {   min: 3.0,   max: 8.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(fireMask, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD15A2H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD15A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD15A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD15A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD15A2H(example: str = ''):
        """
        The MYD15A2H V6 MODIS combined Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) product is an 8-day composite dataset at 500m resolution. The algorithm chooses the \"best\" pixel available from all the acquisitions of the Aqua sensor from within the 8-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD15A2H) 
        :param example: var collection = ee.ImageCollection('MODIS/006/MYD15A2H')                   .filterDate('2019-01-01', '2019-10-01');  var colorizedVis = {   min: 0,   max: 100,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], };  Map.setCenter(-10.88, 40.94, 2); Map.addLayer(collection.select('Lai_500m'), colorizedVis, 'Lai'); Map.addLayer(collection.select('Fpar_500m'), colorizedVis, 'Fpar'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD17A2H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD17A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD17A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD17A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD17A2H(example: str = ''):
        """
        The MYD17A2H V6 Gross Primary Productivity (GPP) product is a cumulative 8-day composite with a 500m resolution. The product is based on the radiation-use efficiency concept and can be potentially used as inputs to data models to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/495/MOD17_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/95/MOD17_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD17A2H) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD17A2H')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var gpp = dataset.select('Gpp'); var gppVis = {   min: 0.0,   max: 600.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD17A3H:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD17A3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD17A3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD17A3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD17A3H(example: str = ''):
        """
        The MYD17A3H V6 product provides information about annual Net Primary Productivity (NPP) at 500m pixel resolution.  Annual NPP is derived from the sum of the 45 8-day Net Photosynthesis (PSN) products (MYD17A2H) from the given year.  The PSN value is the difference of the GPP and the Maintenance Respiration (MR) (GPP-MR).  This is a NASA version of this product. Another version is produced by the Numerical Terradynamic Simulation Group ([NTSG](https://www.ntsg.umt.edu)), University of Montana (UMT).  The NTSG version corrects the problem with cloud-contaminated MODIS LAI-FPAR inputs to the MOD17 algorithm, but its resolution is 1km. It is ingested into Earth Engine as MODIS/055/MOD17A3.  For further details regarding the differences between the NTSG and NASA versions of this product, please consult [this document ](https://lpdaac.usgs.gov/documents/188/MOD17_NTSG_Note.pdf). 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD17A3H')                   .filter(ee.Filter.date('2014-01-01', '2014-05-01'));  var npp = dataset.select('Npp'); var nppVis = {   min: 0.0,   max: 19000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYD17A3HGF:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYD17A3HGF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYD17A3HGF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYD17A3HGF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYD17A3HGF(example: str = ''):
        """
        Version 6 MODIS data products. Users are advised to transition to the improved Version 6.1.  The MYD17A3HGF V6 product provides information about annual Net Primary Productivity (NPP) at 500m pixel resolution.  Annual NPP is derived from the sum of all 8-day Net Photosynthesis (PSN) products (MYD17A2H) from the given year.  The PSN value is the difference of the Gross Primary Productivity (GPP) and the Maintenance Respiration (MR) (GPP-MR). 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD17A3HGF')                   .filter(ee.Filter.date('2014-01-01', '2014-05-01'));  var npp = dataset.select('Npp'); var nppVis = {   min: 0.0,   max: 19000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_006_MYDOCGA:
    def __init__(self,):
        self.sensor = 'MODIS_006_MYDOCGA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_006_MYDOCGA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_006_MYDOCGA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_006_MYDOCGA(example: str = ''):
        """
        The MYDOCGA V6 ocean reflectance product consists of 1 kilometer reflectance data from Aqua MODIS bands 8-16. The product is referred to as ocean reflectance, because bands 8-16 are used primarily to produce ocean products, but this is not an ocean product as the tiles produced are land tiles.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYDOCGA) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYDOCGA')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColor =     dataset.select(['sur_refl_b11', 'sur_refl_b10', 'sur_refl_b09']); var falseColorVis = {   min: 0.0,   max: 2000.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_055_MOD17A3:
    def __init__(self,):
        self.sensor = 'MODIS_055_MOD17A3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_055_MOD17A3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_055_MOD17A3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_055_MOD17A3(example: str = ''):
        """
        The MOD17A3 V055 product provides information about annual Gross and Net Primary Productivity (NPP) at 1km pixel resolution. Net Primary Productivity (NPP) defines the rate at which all plants in an ecosystem produce net useful chemical energy.  In other words, NPP is equal to the difference between the rate at which plants in an ecosystem produce useful chemical energy (or GPP), and the rate at which they expend some of that energy for respiration.  The version 055 of the NPP product is produced by the Numerical Terradynamic Simulation Group ([NTSG](https://www.ntsg.umt.edu)), University of Montana (UMT).  It corrects the problem with cloud-contaminated MODIS LAI-FPAR inputs to the MOD17 algorithm. The original, uncorrected datasets constitute the version 4 NPP products. For further details regarding the differences between the NTSG and NASA versions of this product, please consult [this document](https://lpdaac.usgs.gov/documents/188/MOD17_NTSG_Note.pdf) 
        :param example: var dataset = ee.ImageCollection('MODIS/055/MOD17A3')                   .filter(ee.Filter.date('2014-01-01', '2014-05-01')); var npp = dataset.select('Npp'); var nppVis = {   min: 0,   max: 18000,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 3); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD12C1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD12C1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD12C1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD12C1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD12C1(example: str = ''):
        """
        The Terra and Aqua combined Moderate Resolution Imaging Spectroradiometer (MODIS) Land Cover Climate Modeling Grid (CMG) (MCD12C1) Version 6.1 data product provides a spatially aggregated and reprojected version of the tiled MCD12Q1 Version 6.1 data product. Maps of the International Geosphere-Biosphere Programme (IGBP), University of Maryland (UMD), and Leaf Area Index (LAI) classification schemes are provided at yearly intervals at 0.05 degree (5,600 meter) spatial resolution for the entire globe from 2001 to 2022. Additionally, sub-pixel proportions of each land cover class in each 0.05 degree pixel is provided along with the aggregated quality assessment information for each of the three land classification schemes.  Provided in each MCD12C1 Version 6.1 Hierarchical Data Format 4 (HDF4) file are layers for Majority Land Cover Type 1-3, Majority Land Cover Type 1-3 Assessment, and Majority Land Cover Type 1-3 Percent.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1409/MCD12_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/86/MCD12_ATBD.pdf) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD12C1'); var igbpLandCover = dataset.select('Majority_Land_Cover_Type_1'); var igbpLandCoverVis = {   min: 0,   max: 16.0,   palette: [     '1c0dff', '05450a', '086a10', '54a708', '78d203', '009900', 'c6b044', 'dcd159',     'dade48', 'fbff13', 'b6ff05', '27ff87', 'c24f44', 'a5a5a5', 'ff6d4c',     '69fff8', 'f9ffa4'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(igbpLandCover, igbpLandCoverVis, 'IGBP Land Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD12Q1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD12Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD12Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD12Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD12Q1(example: str = ''):
        """
        The Terra and Aqua combined Moderate Resolution Imaging Spectroradiometer (MODIS) Land Cover Type (MCD12Q1) Version 6.1 data product provides global land cover types at yearly intervals. The MCD12Q1 Version 6.1 data product is derived using supervised classifications of MODIS Terra and Aqua reflectance data. Land cover types are derived from the International Geosphere-Biosphere Programme (IGBP), University of Maryland (UMD), Leaf Area Index (LAI), BIOME-Biogeochemical Cycles (BGC), and Plant Functional Types (PFT) classification schemes. The supervised classifications then underwent additional post-processing that incorporate prior knowledge and ancillary information to further refine specific classes. Additional land cover property assessment layers are provided by the Food and Agriculture Organization (FAO) Land Cover Classification System (LCCS) for land cover, land use, and surface hydrology.  Layers for Land Cover Type 1-5, Land Cover Property 1-3, Land Cover Property Assessment 1-3, Land Cover Quality Control (QC), and a Land Water Mask are also provided.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1409/MCD12_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/86/MCD12_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD12Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD12Q1'); var igbpLandCover = dataset.select('LC_Type1'); var igbpLandCoverVis = {   min: 1.0,   max: 17.0,   palette: [     '05450a', '086a10', '54a708', '78d203', '009900', 'c6b044', 'dcd159',     'dade48', 'fbff13', 'b6ff05', '27ff87', 'c24f44', 'a5a5a5', 'ff6d4c',     '69fff8', 'f9ffa4', '1c0dff'   ], }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(igbpLandCover, igbpLandCoverVis, 'IGBP Land Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD12Q2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD12Q2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD12Q2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD12Q2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD12Q2(example: str = ''):
        """
        The Terra and Aqua combined Moderate Resolution Imaging Spectroradiometer (MODIS) Land Cover Dynamics (MCD12Q2) Version 6.1 data product provides global land surface phenology metrics at yearly intervals. The MCD12Q2 Version 6.1 data product is derived from time series of the 2-band Enhanced Vegetation Index (EVI2) calculated from MODIS Nadir Bidirectional Reflectance Distribution Function (BRDF)-Adjusted Reflectance(NBAR). Vegetation phenology metrics at 500 meter spatial resolution are identified for up to two detected growing cycles per year. For pixels with more than two valid vegetation cycles, the data represent the two cycles with the largest NBAR-EVI2 amplitudes.  Each asset contains bands are layers for the total number of vegetation cycles detected for the product year, the onset of greenness, greenup midpoint, maturity, peak greenness, senescence, greendown midpoint, dormancy, EVI2 minimum, EVI2 amplitude, integrated EVI2 over a vegetation cycle, as well as overall and phenology metric-specific quality information.  For areas where the NBAR-EVI2 values are missing due to cloud cover or other reasons, the data gaps are filled with good quality NBAR-EVI2 values from the year directly preceding or following the product year. 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD12Q2')                   .filter(ee.Filter.date('2001-01-01', '2002-01-01')); var vegetationPeak = dataset.select('Peak_1'); var vegetationPeakVis = {   min: 11400,   max: 11868,   palette: ['0f17ff', 'b11406', 'f1ff23'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     vegetationPeak, vegetationPeakVis,     'Vegetation Peak 2001'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD15A3H:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD15A3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD15A3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD15A3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD15A3H(example: str = ''):
        """
        The MCD15A3H Version 6.1 Moderate Resolution Imaging Spectroradiometer (MODIS) Level 4, Combined Fraction of Photosynthetically Active Radiation (FPAR), and Leaf Area Index (LAI) product is a 4-day composite data set with 500 meter pixel size. The algorithm chooses the best pixel available from all the acquisitions of both MODIS sensors located on NASA's Terra and Aqua satellites from within the 4-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD15A3H) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD15A3H'); var defaultVisualization = dataset.first().select('Fpar'); var defaultVisualizationVis = {   min: 0.0,   max: 100.0,   palette: ['e1e4b4', '999d60', '2ec409', '0a4b06'], }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD18A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD18A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD18A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD18A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD18A1(example: str = ''):
        """
        The MCD18A1 Version 6.1 is a Moderate Resolution Imaging Spectroradiometer (MODIS) Terra and Aqua combined Downward Shortwave Radiation (DSR) gridded Level 3 product produced daily at 1 kilometer pixel resolution with estimates of DSR every 3 hours. DSR is incident solar radiation over land surfaces in the shortwave spectrum (300-4,000 nanometers) and is an important variable in land-surface models that address a variety of scientific and application issues. The MCD18 products are based on a prototyping algorithm that uses multi-temporal signatures of MODIS data to derive surface reflectance and then calculate incident DSR using the look-up table (LUT) approach. The LUTs consider different types of loadings of aerosols and clouds at a variety of illumination/viewing geometry. Global DSR products are generated from MODIS and geostationary satellite data. Additional details regarding the methodology used to create the data are available in the [Algorithm Theoretical Basis Document](https://lpdaac.usgs.gov/documents/106/MCD18_ATBD.pdf)  Provided in the MOD18A1 product are layers for instantaneous DSR array for each individual MODIS overpass and 3-hour DSR array along with a View Zenith Angle layer. 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD18A1')                   .filter(ee.Filter.date('2000-01-01', '2001-01-01')); var gmt_1200_dsr = dataset.select('GMT_1200_DSR'); var gmt_1200_dsr_vis = {   min: 0,   max: 350,   palette: ['0f17ff', 'b11406', 'f1ff23'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     gmt_1200_dsr, gmt_1200_dsr_vis,     'Total dsr at GMT 12:00');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD18C2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD18C2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD18C2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD18C2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD18C2(example: str = ''):
        """
        The MCD18C2 Version 6.1 is a Moderate Resolution Imaging Spectroradiometer (MODIS) Terra and Aqua combined Photosynthetically Active Radiation (PAR) gridded Level 3 product produced daily at 0.05 degree (5,600 meters at the equator) resolution with estimates of PAR every 3 hours. PAR is incident solar radiation in the visible spectrum (400-700 nanometers) and is an important variable in land-surface models that address a variety of scientific and application issues. The MCD18 products are based on a prototyping algorithm that uses multi-temporal signatures of MODIS data to derive surface reflectance and then calculate incident PAR using the look-up table (LUT) approach. The LUTs consider different types of loadings of aerosols and clouds at a variety of illumination/viewing geometry. Global PAR products are generated from MODIS and geostationary satellite data. Additional details regarding the methodology used to create the data are available in the [Algorithm Theoretical Basis Document](https://lpdaac.usgs.gov/documents/106/MCD18_ATBD.pdf)  Provided in the MOD18C2 product are layers for instantaneous PAR array for each individual MODIS overpass and 3-hour PAR array along with a View Zenith Angle layer. 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD18C2')                   .filter(ee.Filter.date('2001-01-01', '2001-02-01')); var gmt_1200_par = dataset.select('GMT_1200_PAR'); var gmt_1200_par_vis = {   min: -236,   max: 316,   palette: ['0f17ff', 'b11406', 'f1ff23'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     gmt_1200_par, gmt_1200_par_vis,     'Total PAR at GMT 12:00');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD19A1_GRANULES:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD19A1_GRANULES'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD19A1_GRANULES.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD19A1_GRANULES.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD19A1_GRANULES(example: str = ''):
        """
        The MCD19A1 Version 6.1 data product is a Moderate Resolution Imaging Spectroradiometer (MODIS) Terra and Aqua combined Land Surface Bidirectional Reflectance Factor (BRF) gridded Level 2 product produced daily at 500 meter and 1 kilometer resolution. For more information see the [MAIAC user guide](https://lpdaac.usgs.gov/documents/1500/MCD19_User_Guide_V61.pdf). 
        :param example: var collection = ee.ImageCollection('MODIS/061/MCD19A1_GRANULES')                      .select('Sur_refl1')                      .filterDate('2000-01-01', '2000-03-07');  var band_viz = {   min: 0,   max: 1100,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'Surface Bidirectional Reflectance Factor'); Map.setCenter(76, 13, 6); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD19A2_GRANULES:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD19A2_GRANULES'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD19A2_GRANULES.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD19A2_GRANULES.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD19A2_GRANULES(example: str = ''):
        """
        The MCD19A2 V6.1 data product is a MODIS Terra and Aqua combined Multi-angle Implementation of Atmospheric Correction (MAIAC) Land Aerosol Optical Depth (AOD) gridded Level 2 product produced daily at 1 km resolution. For more information see the [MAIAC user guide](https://lpdaac.usgs.gov/documents/1500/MCD19_User_Guide_V61.pdf).  NOTE: This product has been released with the caveat that the reprocessing for the full mission is expected to continue through summer 2023. 
        :param example: var collection = ee.ImageCollection('MODIS/061/MCD19A2_GRANULES')                      .select('Optical_Depth_047')                      .filterDate('2023-01-01', '2023-01-15');  var band_viz = {   min: 0,   max: 1100,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.addLayer(collection.mean(), band_viz, 'Optical Depth 047'); Map.setCenter(76, 13, 6); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD43A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD43A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD43A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD43A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD43A1(example: str = ''):
        """
        The MCD43A1 V6.1 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Model Parameters dataset is a 500 meter daily 16-day product. The Julian date represents the 9th day of the 16-day retrieval period, and consequently the observations are weighted to estimate the BRDF/Albedo for that day. The MCD43A1 algorithm, as is with all combined products, chooses the best representative pixel from a pool that includes all the acquisitions from both the Terra and Aqua sensors from the retrieval period.  The MCD43A1 provides the three model weighting parameters (isotropic, volumetric, and geometric) for each of the MODIS bands 1 through 7 and the visible (vis), near infrared (nir), and shortwave bands used to derive the Albedo and BRDF products (MCD43A3 and MCD43A4). The Mandatory Quality layers for each of the 10 bands are supplied as well.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43a1_brdif_albedo_model_parameters_product)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD43A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD43A1')                   .filter(ee.Filter.date('2018-05-01', '2018-07-01')); var defaultVisualization = dataset.select([   'BRDF_Albedo_Parameters_Band1_iso', 'BRDF_Albedo_Parameters_Band4_iso',   'BRDF_Albedo_Parameters_Band3_iso' ]); var defaultVisualizationVis = {   min: 0.0,   max: 1400.0,   gamma: 2.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD43A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD43A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD43A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD43A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD43A2(example: str = ''):
        """
        The MCD43A2 V6.1 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Quality dataset is a 500 meter daily 16-day product. It contains all the quality information for the corresponding 16-day MCD43A3 Albedo and the MCD43A4 Nadir-BRDF (NBAR) products.  The MCD43A2 contains individual band quality and observation information for the MODIS land bands 1-7, along with the overall BRDF/Albedo quality information.  See [dataset user guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43a2_albedo_product) for more information.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD43A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD43A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var defaultVisualization = dataset.select('Snow_BRDF_Albedo'); var defaultVisualizationVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(     defaultVisualization, defaultVisualizationVis, 'Default visualization'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD43A3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD43A3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD43A3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD43A3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD43A3(example: str = ''):
        """
        The MCD43A3 V6.1 Albedo Model dataset is a daily 16-day product. It provides both directional hemispherical reflectance (black sky albedo) and bihemispherical reflectance (white sky albedo) for each of the MODIS surface reflectance bands (band 1 through band 7) as well as 3 broad spectrum bands (visible, near infrared, and shortwave).  Each 500m/pixel daily image is generated using 16 days of data, centered on the given day.  A quality band is also provided for each of the 10 albedo bands.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD43A3) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD43A3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var blackSkyAlbedo = dataset.select('Albedo_BSA_Band1'); var blackSkyAlbedoVis = {   min: 0.0,   max: 400.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(blackSkyAlbedo, blackSkyAlbedoVis, 'Black-Sky Albedo'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD43A4:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD43A4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD43A4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD43A4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD43A4(example: str = ''):
        """
        The MCD43A4 V6.1 Nadir Bidirectional Reflectance Distribution Function Adjusted Reflectance (NBAR) product provides 500 meter reflectance data of the MODIS \"land\" bands 1-7. These are adjusted using a bidirectional reflectance distribution function to model the values as if they were collected from a nadir view.  The data are produced daily based on a 16-day retrieval period, with the image's date occurring on the 9th day. This product combines data from both the Terra and Aqua spacecrafts, choosing the best representative pixel from the 16-day period.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/97/MCD43_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD43A4) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD43A4')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor = dataset.select([   'Nadir_Reflectance_Band1', 'Nadir_Reflectance_Band4',   'Nadir_Reflectance_Band3' ]); var trueColorVis = {   min: 0.0,   max: 4000.0,   gamma: 1.4, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(trueColor, trueColorVis, 'True Color');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD43C3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD43C3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD43C3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD43C3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD43C3(example: str = ''):
        """
        The MCD43C3 Version 6.1 Bidirectional Reflectance Distribution Function and Albedo (BRDF/Albedo) Albedo dataset is produced daily using 16 days of Terra and Aqua MODIS data in a 0.05 degree (5,600 meters at the equator) Climate Modeling Grid (CMG). Data are temporally weighted to the ninth day of the retrieval period which is reflected in the Julian date in the file name. This CMG product covers the entire globe for use in climate simulation models.  MCD43C3 provides black-sky albedo (directional hemispherical reflectance) and white-sky albedo (bihemispherical reflectance) at local solar noon. Black-sky albedo and white-sky albedo values are available as a separate layer for MODIS spectral bands 1 through 7 as well as the visible, near infrared (NIR), and shortwave bands. Along with the 20 albedo layers are ancillary layers for quality, local solar noon, percent finer resolution inputs, snow cover, and uncertainty.  See [dataset user guide](https://www.umb.edu/spectralmass/terra_aqua_modis/v006/mcd43c3) for more information. 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD43C3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var blackSkyAlbedo = dataset.select('Albedo_BSA_Band1'); var blackSkyAlbedoVis = {   min: 0.0,   max: 400.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(blackSkyAlbedo, blackSkyAlbedoVis, 'Black-Sky Albedo'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MCD64A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MCD64A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MCD64A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MCD64A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MCD64A1(example: str = ''):
        """
        The Terra and Aqua combined MCD64A1 Version 6.1 Burned Area data product is a monthly, global gridded 500m product containing per-pixel burned-area and quality information. The MCD64A1 burned-area mapping approach employs 500m MODIS Surface Reflectance imagery coupled with 1km MODIS active fire observations. The algorithm uses a burn sensitive vegetation index (VI) to create dynamic thresholds that are applied to the composite data. The VI is derived from MODIS shortwave infrared atmospherically corrected surface reflectance bands 5 and 7 with a measure of temporal texture. The algorithm identifies the date of burn for the 500m grid cells within each individual MODIS tile. The date is encoded in a single data layer as the ordinal day of the calendar year on which the burn occurred, with values assigned to unburned land pixels and additional special values reserved for missing data and water grid cells.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1006/MCD64_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/115/MCD64_ATBD_V6.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MCD64A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MCD64A1')                   .filter(ee.Filter.date('2017-01-01', '2018-05-01')); var burnedArea = dataset.select('BurnDate'); var burnedAreaVis = {   min: 30.0,   max: 341.0,   palette: ['4e0400', '951003', 'c61503', 'ff1901'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(burnedArea, burnedAreaVis, 'Burned Area'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD08_M3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD08_M3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD08_M3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD08_M3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD08_M3(example: str = ''):
        """
        MOD08_M3 V6.1 is an atmosphere global product that contains monthly 1 x 1 degree grid average values of atmospheric parameters. These parameters are related to atmospheric aerosol particle properties, total ozone burden, atmospheric water vapor, cloud optical and physical properties, and atmospheric stability indices. The product also provides means, standard deviations, QA weighted statistics, log-normal distributions, uncertainty estimates, and statistics for fractions of pixels that satisfy some condition. Below is a subset of the bands, for a complete list see the [MOD08 Band List](https://developers.google.com/earth-engine/MOD08_bands.html).  Documentation:  * [User's Guide](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_ATBD_C6_C61_2019_02_20.pdf)  * [Science Data Product Software Documentation](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_C61_Changes_v2.pdf)  * [MYD08_M3 product description](https://modis-atmos.gsfc.nasa.gov/products/monthly)  * [File specification document](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/MOD08_M3_fs_3045.txt) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD08_M3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var aerosolOpticalDepth =     dataset.select('Aerosol_Optical_Depth_Land_Ocean_Mean_Mean'); var aerosolOpticalDepthVis = {   min: 0,   max: 3000,   palette: ['ffffff', '1303ff', '01ff09', 'ff2f00'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     aerosolOpticalDepth, aerosolOpticalDepthVis, 'Aerosol Optical Depth'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD09A1(example: str = ''):
        """
        The MOD09A1 V6.1 product provides an estimate of the surface spectral reflectance of Terra MODIS bands 1-7 at 500m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the seven reflectance bands is a quality layer and four observation bands. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD09A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD09A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var trueColor =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColorVis = {   min: -100.0,   max: 3000.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor, trueColorVis, 'True Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD09CMG:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD09CMG'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD09CMG.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD09CMG.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD09CMG(example: str = ''):
        """
        The MOD09CMG Version 6.1 product provides an estimate of the surface spectral reflectance of Terra Moderate Resolution Imaging Spectroradiometer (MODIS) Bands 1 through 7, resampled to 5600 meter pixel resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. The MOD09CMG data product provides 25 layers including MODIS bands 1 through 7; Brightness Temperature data from thermal bands 20, 21, 31, and 32; along with Quality Assurance (QA) and observation bands. This product is based on a Climate Modeling Grid (CMG) for use in climate simulation models.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/925/MOD09_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD09CMG) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD09CMG')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var trueColor =     dataset.select([       'Coarse_Resolution_Surface_Reflectance_Band_1',       'Coarse_Resolution_Surface_Reflectance_Band_2',       'Coarse_Resolution_Surface_Reflectance_Band_3'       ]); var trueColorVis = {   min: -0.4,   max: 1.0, }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(trueColor, trueColorVis, 'True Color');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MOD09GA version 6.1 provides bands 1-7 in a daily gridded L2G product in the sinusoidal projection, including 500m reflectance values and 1km observation and geolocation statistics.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD09GA) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD09GA')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor143 =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColor143Vis = {   min: -100.0,   max: 8000.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(trueColor143, trueColor143Vis, 'True Color (143)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MOD09GQ version 6.1 provides bands 1 and 2 at a 250m resolution in a daily gridded L2G product in the Sinusoidal projection, including a QC and five observation layers. This product is meant to be used in conjunction with the MOD09GA where important quality and viewing geometry information is stored.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD09GQ) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD09GQ')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100.0,   max: 8000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD09Q1(example: str = ''):
        """
        The MOD09Q1 product provides an estimate of the surface spectral reflectance of bands 1 and 2 at 250m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the two reflectance bands, a quality layer is also included. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD09Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD09Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100.0,   max: 8000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD10A1(example: str = ''):
        """
        The MOD10A1 V6 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests.  [General documentation](https://doi.org/10.5067/MODIS/MOD10A1.061) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD10A1')                   .filter(ee.Filter.date('2018-04-01', '2018-05-01')); var snowCover = dataset.select('NDSI_Snow_Cover'); var snowCoverVis = {   min: 0.0,   max: 100.0,   palette: ['black', '0dffff', '0524ff', 'ffffff'], }; Map.setCenter(-41.13, 76.35, 3); Map.addLayer(snowCover, snowCoverVis, 'Snow Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD11A1(example: str = ''):
        """
        The MOD11A1 V6.1 product provides daily land surface temperature (LST) and emissivity values in a 1200 x 1200 kilometer grid. The temperature value is derived from the MOD11_L2 swath product. Above 30 degrees latitude, some pixels may have multiple observations where the criteria for clear-sky are met. When this occurs, the pixel value is the average of all qualifying observations. Provided along with both the day-time and night-time surface temperature bands and their quality indicator layers are MODIS bands 31 and 32 and six observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD11A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD11A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 13000.0,   max: 16500.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD11A2(example: str = ''):
        """
        The MOD11A2 V6.1 product provides an average 8-day land surface temperature (LST)  in a 1200 x 1200 kilometer grid. Each pixel value in MOD11A2 is a simple average of all the corresponding MOD11A1 LST pixels collected within that 8 day period. The MOD11A2 does a simple averaging of all daily LST values, without any filtering for specific QA bits. Each of the MOD11A2 QA values are set based on what majority of input daily QA values are for any given pixel.  The 8 day compositing period was chosen because twice that period is the exact ground track repeat period of the Terra and Aqua platforms. In this product, along with both the day- and night-time surface temperature bands and their quality indicator (QC) layers, are also MODIS bands 31 and 32 and eight observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD11A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD11A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 14000.0,   max: 16000.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD13A1(example: str = ''):
        """
        The MOD13A1 V6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD13A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD13A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD13A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD13A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD13A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD13A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD13A2(example: str = ''):
        """
        The MOD13A2 V6.1 product provides two Vegetation Indices (VI): the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI). The NDVI is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The EVI has improved sensitivity over high biomass regions.  The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD13A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD13A3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD13A3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD13A3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD13A3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD13A3(example: str = ''):
        """
        The MOD13A3 V6.1 product data is provided monthly at 1 kilometer (km) spatial resolution. In generating this monthly product, the algorithm ingests all the MOD13A2 products that overlap the month and employs a weighted temporal average.  Vegetation indices are used for global monitoring of vegetation conditions and are used in products displaying land cover and land cover changes. These data may be used as input for modeling global biogeochemical and hydrologic processes as well as global and regional climate. Additional applications include characterizing land surface biophysical properties and processes, such as primary production and land cover conversion.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/621/MOD13_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD13A3) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD13A3')                   .filter(ee.Filter.date('2020-01-01', '2023-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD13C1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD13C1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD13C1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD13C1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD13C1(example: str = ''):
        """
        The Terra Moderate Resolution Imaging Spectroradiometer (MODIS) Vegetation Indices 16-Day (MOD13C1) Version 6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI), which maintains continuity with the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI), which has improved sensitivity over high biomass regions. The Climate Modeling Grid (CMG) consists of 3,600 rows and 7,200 columns of 5,600 meter (m) pixels. Global MOD13C1 data are cloud-free spatial composites of the gridded 16-day 1 kilometer MOD13A2 data, and are provided as a Level 3 product projected on a 0.05 degree (5,600 m) geographic CMG. The MOD13C1 has data fields for NDVI, EVI, VI QA, reflectance data, angular information, and spatial statistics such as mean, standard deviation, and number of used input pixels at the 0.05 degree CMG resolution. 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD13C1')                   .filter(ee.Filter.date('2015-01-01', '2015-05-01')); var ndvi = dataset.select('NDVI'); print(ndvi); var ndviVis = {   min: 0,   max: .9,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD13Q1(example: str = ''):
        """
        The MOD13Q1 V6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD13Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 8000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD14A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD14A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD14A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD14A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD14A1(example: str = ''):
        """
        The MOD14A1 V6.1 dataset provides daily fire mask composites at 1km resolution derived from the MODIS 4- and 11-micrometer radiances. The fire detection strategy is based on absolute detection of a fire (when the fire strength is sufficient to detect), and on detection relative to its background (to account for variability of the surface temperature and reflection by sunlight). The product distinguishes between fire, no fire and no observation. This information is used for monitoring the spatial and temporal distribution of fires in different ecosystems, detecting changes in fire distribution and identifying new fire frontiers, wild fires, and changes in the frequency of the fires  or their relative strength.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1005/MOD14_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD14A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD14A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMaskVis = {   min: 0.0,   max: 6000.0,   bands: ['MaxFRP', 'FireMask', 'FireMask'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD14A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD14A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD14A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD14A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD14A2(example: str = ''):
        """
        The MOD14A2 V6.1 dataset provides 8-day fire mask composites at 1km resolution. It contains the maximum value of the individual pixel classes over the compositing period. Along with the fire mask, an associated quality information layer is also provided.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD14A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD14A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMask = dataset.select('FireMask'); var fireMaskVis = {   min: 3.0,   max: 8.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(fireMask, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD15A2H:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD15A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD15A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD15A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD15A2H(example: str = ''):
        """
        The MOD15A2H V6.1 MODIS combined Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) product is an 8-day composite dataset at 500m resolution. The algorithm chooses the \"best\" pixel available from all the acquisitions of the Terra sensor from within the 8-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD15A2H) 
        :param example: var collection = ee.ImageCollection('MODIS/061/MOD15A2H')                   .filterDate('2019-01-01', '2019-10-01');  var colorizedVis = {   min: 0,   max: 100,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], };  Map.setCenter(-10.88, 40.94, 2); Map.addLayer(collection.select('Lai_500m'), colorizedVis, 'Lai'); Map.addLayer(collection.select('Fpar_500m'), colorizedVis, 'Fpar'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD16A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD16A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD16A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD16A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD16A2(example: str = ''):
        """
        The MOD16A2 Version 6.1 Evapotranspiration/Latent Heat Flux product is an 8-day composite product produced at 500 meter pixel resolution. The algorithm used for the MOD16 data product collection is based on the logic of the Penman-Monteith equation, which includes inputs of daily meteorological reanalysis data along with MODIS remotely sensed data products such as vegetation property dynamics, albedo, and land cover.  The pixel values for the two Evapotranspiration layers (ET & PET) are the sum of all eight days within the composite period. The pixel values for the two Latent Heat layers (LE & PLE) are the average of all eight days within the composite period. Note that the last 8-day period of each year is a 5 or 6-day composite period, depending on the year.  Class assignment in fill values 32761 through 32767 might be inaccurate.  They are not included in the EE assets.  According to [the MODIS Science Team] (https://forum.earthdata.nasa.gov/viewtopic.php?p=15070#p15070), The MOD16A2 6.1 product will not have data prior to 2021. The MODIS Science  team recommends using the gap-filled MOD16A2GF 6.1 product for data from 2000 to 2021 -- and then also 2022 when the data are available. They recommend this as the gap-filled product is expected to be superior in product quality, especially over areas where otherwise the routine product performance would have been negatively impacted by cloudy or poor quality input observations. For the current year, there will not be a gap-filled product until early the following year (i.e. 2023 data should be available in early 2024). So, if a user needs MOD16A2GF 6.1 data for the year 2023 (or the "current" year in the future), they recommend using the MOD16A2 6.1 product, which is generated using the daily observation with climatology observation replacing for the cloudy or poor quality observations.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/494/MOD16_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/93/MOD16_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD16A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD16A2')                   .filter(ee.Filter.date('2022-01-01', '2022-05-01')); var evapotranspiration = dataset.select('ET'); var evapotranspirationVis = {   min: 0,   max: 300,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(0, 0, 2); Map.addLayer(evapotranspiration, evapotranspirationVis, 'Evapotranspiration'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD16A2GF:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD16A2GF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD16A2GF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD16A2GF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD16A2GF(example: str = ''):
        """
        The Terra Moderate Resolution Imaging Spectroradiometer (MODIS) MOD16A2GF Version 6.1 Evapotranspiration/Latent Heat Flux (ET/LE) product is a year-end gap-filled 8-day composite dataset produced at 500 meter (m) pixel resolution. The algorithm used for the MOD16 data product collection is based on the logic of the Penman-Monteith equation, which includes inputs of daily meteorological reanalysis data along with MODIS remotely sensed data products such as vegetation property dynamics, albedo, and land cover.  The pixel values for the two Evapotranspiration layers (ET and PET) are the sum of all eight days within the composite period, and the pixel values for the two Latent Heat layers (LE and PLE) are the average of all eight days within the composite period. The last acquisition period of each year is a 5 or 6-day composite period, depending on the year.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/931/MOD16_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/93/MOD16_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD16A2GF) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD16A2GF')                   .filter(ee.Filter.date('2022-01-01', '2022-05-01')); var evapotranspiration = dataset.select('ET'); var evapotranspirationVis = {   min: 0,   max: 300,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(0, 0, 2); Map.addLayer(evapotranspiration, evapotranspirationVis, 'Evapotranspiration'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD17A2H:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD17A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD17A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD17A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD17A2H(example: str = ''):
        """
        The MOD17A2H V6.1 Gross Primary Productivity (GPP) product is a cumulative 8-day composite with a 500m pixel size. The product is based on the radiation-use efficiency concept and can be potentially used as inputs to data models to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/972/MOD17_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/95/MOD17_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MOD17A2H) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD17A2H')                   .filter(ee.Filter.date('2021-01-01', '2021-05-01'));  var gpp = dataset.select('Gpp'); var gppVis = {   min: 0,   max: 600,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD17A3HGF:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD17A3HGF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD17A3HGF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD17A3HGF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD17A3HGF(example: str = ''):
        """
        The MOD17A3HGF V6.1 product provides information about annual Gross and Net Primary Productivity (GPP and NPP) at 500m pixel resolution. Annual NPP is derived from the sum of all 8-day Net Photosynthesis(PSN) products (MOD17A2H) from the given year.  The PSN value is the difference of the Gross Primary Productivity (GPP) and the Maintenance Respiration (MR) (GPP-MR). 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD17A3HGF');  var visualization = {   bands: ['Npp'],   min: 0,   max: 19000,   palette: ['bbe029', '0a9501', '074b03'] };  Map.setCenter(6.746, 46.529, 3);  Map.addLayer(dataset, visualization, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD21A1D:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD21A1D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD21A1D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD21A1D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD21A1D(example: str = ''):
        """
        The MOD21A1D dataset is produced daily from daytime Level 2 Gridded (L2G) intermediate LST products at a spatial resolution of 1,000 meters. The L2G process maps the daily MOD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MOD21A1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The daytime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MOD21A1D product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD21A1D) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD21A1D')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_1KM'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD21A1N:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD21A1N'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD21A1N.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD21A1N.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD21A1N(example: str = ''):
        """
        The MOD21A1N dataset is produced daily from nighttime Level 2 Gridded (L2G) intermediate LST products at a spatial resolution of 1,000 meters. The L2G process maps the daily MOD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MOD21A1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The nighttime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MOD21A1N product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD21A1N) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD21A1N')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_1KM'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD21C1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD21C1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD21C1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD21C1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD21C1(example: str = ''):
        """
        The MOD21C1 dataset is produced daily in a 0.05 degree (5,600 meters at the equator) Climate Modeling Grid (CMG) from daytime Level 2 Gridded (L2G) intermediate LST products. The L2G process maps the daily MOD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MOD21C1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The daytime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MOD21C1 product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD21C1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD21C1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD21C2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD21C2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD21C2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD21C2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD21C2(example: str = ''):
        """
        The MOD21C2 dataset is an 8-day composite LST product that uses an algorithm based on a simple averaging method. The algorithm calculates the average from all the cloud free MOD21A1D and MOD21A1N daily acquisitions from the 8-day period. Unlike the MOD21A1 data sets where the daytime and nighttime acquisitions are separate products, the MOD21A2 contains both daytime and nighttime acquisitions. The LST, Quality Control (QC), view zenith angle, and viewing time have separate day and night bands, while the values for the MODIS emissivity bands 29, 31, and 32 are the average of both the nighttime and daytime acquisitions.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD21C2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD21C2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MOD21C3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MOD21C3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MOD21C3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MOD21C3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MOD21C3(example: str = ''):
        """
        The MOD21C3 dataset is a monthly composite LST product that uses an algorithm based on a simple averaging method. The algorithm calculates the average from all the cloud free MOD21A1D and MOD21A1N daily acquisitions from the 8-day period. Unlike the MOD21A1 data sets where the daytime and nighttime acquisitions are separate products, the MOD21A2 contains both daytime and nighttime acquisitions. The LST, Quality Control (QC), view zenith angle, and viewing time have separate day and night bands, while the values for the MODIS emissivity bands 29, 31, and 32 are the average of both the nighttime and daytime acquisitions.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD21C3) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MOD21C3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD08_M3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD08_M3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD08_M3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD08_M3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD08_M3(example: str = ''):
        """
        MYD08_M3 V6.1 is an atmosphere global product that contains monthly 1 x 1 degree grid average values of atmospheric parameters. These parameters are related to atmospheric aerosol particle properties, total ozone burden, atmospheric water vapor, cloud optical and physical properties, and atmospheric stability indices. The product also provides means, standard deviations, QA weighted statistics, log-normal distributions, uncertainty estimates, and statistics for fractions of pixels that satisfy some condition. Below is a subset of the bands, for a complete list see the [MOD08 Band List](https://developers.google.com/earth-engine/MOD08_bands.html).  Documentation:  * [User's Guide](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_ATBD_C6_C61_2019_02_20.pdf)  * [Science Data Product Software Documentation](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/L3_C61_Changes_v2.pdf)  * [MYD08_M3 product description](https://modis-atmos.gsfc.nasa.gov/products/monthly)  * [File specification document](https://modis-atmos.gsfc.nasa.gov/sites/default/files/ModAtmo/MOD08_M3_fs_3045.txt) 
        :param example: var dataset = ee.ImageCollection('MODIS/006/MYD08_M3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var aerosolOpticalDepth =     dataset.select('Aerosol_Optical_Depth_Land_Ocean_Mean_Mean'); var aerosolOpticalDepthVis = {   min: 0,   max: 3000,   palette: ['ffffff', '1303ff', '01ff09', 'ff2f00'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     aerosolOpticalDepth, aerosolOpticalDepthVis, 'Aerosol Optical Depth'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD09A1(example: str = ''):
        """
        The MYD09A1 V6.1 product provides an estimate of the surface spectral reflectance of Aqua MODIS bands 1-7 at 500m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the seven reflectance bands is a quality layer and four observation bands. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD09A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD09A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var trueColor =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColorVis = {   min: -100.0,   max: 3000.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(trueColor, trueColorVis, 'True Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MYD09GA version 6.1 provides bands 1-7 in a daily gridded L2G product in the sinusoidal projection, including 500m reflectance values and 1km observation and geolocation statistics.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD09GA) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD09GA')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var trueColor143 =     dataset.select(['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03']); var trueColor143Vis = {   min: -100.0,   max: 8000.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(trueColor143, trueColor143Vis, 'True Color (143)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols. MYD09GQ version 6.1 provides bands 1 and 2 at a 250m resolution in a daily gridded L2G product in the Sinusoidal projection, including a QC and five observation layers. This product is meant to be used in conjunction with the MYD09GA where important quality and viewing geometry information is stored.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD09GQ) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD09GQ')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var falseColorVis = {   min: -100.0,   max: 8000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD09Q1(example: str = ''):
        """
        The MYD09Q1 product provides an estimate of the surface spectral reflectance of bands 1 and 2 at 250m resolution and corrected for atmospheric conditions such as gasses, aerosols, and Rayleigh scattering. Along with the two reflectance bands, a quality layer is also included. For each pixel, a value is selected from all the acquisitions within the 8-day composite on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/306/MOD09_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/305/MOD09_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD09Q1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD09Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01'));  var falseColorVis = {   min: -100.0,   max: 6000.0,   bands: ['sur_refl_b02', 'sur_refl_b02', 'sur_refl_b01'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD10A1(example: str = ''):
        """
        The MYD10A1 V6 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests.  [General documentation](https://doi.org/10.5067/MODIS/MYD10A1.061) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD10A1')                   .filter(ee.Filter.date('2018-04-01', '2018-05-01')); var snowCover = dataset.select('NDSI_Snow_Cover'); var snowCoverVis = {   min: 0.0,   max: 100.0,   palette: ['black', '0dffff', '0524ff', 'ffffff'], }; Map.setCenter(-38.13, 40, 2); Map.addLayer(snowCover, snowCoverVis, 'Snow Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD11A1(example: str = ''):
        """
        The MYD11A1 V6.1 product provides daily land surface temperature (LST) and emissivity values in a 1200 x 1200 kilometer grid. The temperature value is derived from the MYD11_L2 swath product. Above 30 degrees latitude, some pixels may have multiple observations where the criteria for clear-sky are met. When this occurs, the pixel value is the average of all qualifying observations. Provided along with both the day-time and night-time surface temperature bands and their quality indicator layers are MODIS bands 31 and 32 and six observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD11A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD11A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 13000.0,   max: 16500.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD11A2(example: str = ''):
        """
        The MYD11A2 V6.1 product provides an average 8-day land surface temperature (LST)  in a 1200 x 1200 kilometer grid.  Each pixel value in MYD11A2 is a simple average of all the corresponding MYD11A1 LST pixels collected within that 8 day period. The MYD11A2 does a simple averaging of all daily LST values, without any filtering for specific QA bits. Each of the MYD11A2 QA values are set based on what majority of input daily QA values are for any given pixel.  The 8 day compositing period was chosen because twice that period is the exact ground track repeat period of the Terra and Aqua platforms. In this product, along with both the day- and night-time surface temperature bands and their quality indicator (QC) layers, are also MODIS bands 31 and 32 and eight observation layers.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/118/MOD11_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/119/MOD11_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD11A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD11A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day_1km'); var landSurfaceTemperatureVis = {   min: 14000.0,   max: 16000.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD13A1(example: str = ''):
        """
        The MYD13A1 V6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD13A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD13A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0.0,   max: 9000.0,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD13A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD13A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD13A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD13A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD13A2(example: str = ''):
        """
        The MYD13A2 V6.1 product provides two Vegetation Indices (VI): the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI). The NDVI is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The EVI has improved sensitivity over high biomass regions.  The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD13A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD13A3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD13A3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD13A3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD13A3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD13A3(example: str = ''):
        """
        The Aqua Moderate Resolution Imaging Spectroradiometer (MODIS) Vegetation Indices (MYD13A3) Version 6.1 data are provided monthly at 1 kilometer (km) spatial resolution as a gridded Level 3 product in the sinusoidal projection. In generating this monthly product, the algorithm ingests all the MYD13A2 products that overlap the month and employs a weighted temporal average.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/621/MOD13_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD13A3) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD13A3')                   .filter(ee.Filter.date('2020-01-01', '2023-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 9000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD13C1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD13C1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD13C1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD13C1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD13C1(example: str = ''):
        """
        The Aqua Moderate Resolution Imaging Spectroradiometer (MODIS) Vegetation Indices 16-Day (MYD13C1) Version 6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI), which maintains continuity with the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI), which has improved sensitivity over high biomass regions. The Climate Modeling Grid (CMG) consists of 3,600 rows and 7,200 columns of 5,600 meter (m) pixels. Global MYD13C1 data are cloud-free spatial composites of the gridded 16-day 1 kilometer MYD13A2 data, and are provided as a Level 3 product projected on a 0.05 degree (5,600 m) geographic CMG. The MYD13C1 has data fields for NDVI, EVI, VI QA, reflectance data, angular information, and spatial statistics such as mean, standard deviation, and number of used input pixels at the 0.05 degree CMG resolution.  
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD13C1')                   .filter(ee.Filter.date('2023-01-01', '2023-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: .9,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD13Q1(example: str = ''):
        """
        The MYD13Q1 V6.1 product provides a Vegetation Index (VI) value at a per pixel basis. There are two primary vegetation layers. The first is the Normalized Difference Vegetation Index (NDVI) which is referred to as the continuity index to the existing National Oceanic and Atmospheric Administration-Advanced Very High Resolution Radiometer (NOAA-AVHRR) derived NDVI. The second vegetation layer is the Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/103/MOD13_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/104/MOD13_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MOD13A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD13Q1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: 0,   max: 8000,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD14A1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD14A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD14A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD14A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD14A1(example: str = ''):
        """
        The MYD14A1 V6.1 dataset provides daily fire mask composites at 1km resolution derived from the MODIS 4- and 11-micrometer radiances. The fire detection strategy is based on absolute detection of a fire (when the fire strength is sufficient to detect), and on detection relative to its background (to account for variability of the surface temperature and reflection by sunlight). The product distinguishes between fire, no fire and no observation. This information is used for monitoring the spatial and temporal distribution of fires in different ecosystems, detecting changes in fire distribution and identifying new fire frontiers, wild fires, and changes in the frequency of the fires  or their relative strength.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1005/MOD14_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD14A1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD14A1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMaskVis = {   min: 0.0,   max: 6000.0,   bands: ['MaxFRP', 'FireMask', 'FireMask'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(dataset, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD14A2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD14A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD14A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD14A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD14A2(example: str = ''):
        """
        The MYD14A2 V6.1 dataset provides 8-day fire mask composites at 1km resolution. It contains the maximum value of the individual pixel classes over the compositing period. Along with the fire mask, an associated quality information layer is also provided.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/88/MOD14_User_Guide_v6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/87/MOD14_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD14A2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD14A2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var fireMask = dataset.select('FireMask'); var fireMaskVis = {   min: 3.0,   max: 8.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(fireMask, fireMaskVis, 'Fire Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD15A2H:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD15A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD15A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD15A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD15A2H(example: str = ''):
        """
        The MYD15A2H V6.1 MODIS combined Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) product is an 8-day composite dataset at 500m resolution. The algorithm chooses the \"best\" pixel available from all the acquisitions of the Aqua sensor from within the 8-day period.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/624/MOD15_User_Guide_V6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/90/MOD15_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD15A2H) 
        :param example: var collection = ee.ImageCollection('MODIS/061/MYD15A2H')                   .filterDate('2019-01-01', '2019-10-01');  var colorizedVis = {   min: 0,   max: 100,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], };  Map.setCenter(-10.88, 40.94, 2); Map.addLayer(collection.select('Lai_500m'), colorizedVis, 'Lai'); Map.addLayer(collection.select('Fpar_500m'), colorizedVis, 'Fpar'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD17A2H:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD17A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD17A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD17A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD17A2H(example: str = ''):
        """
        The MYD17A2H V6.1 Gross Primary Productivity (GPP) product is a cumulative 8-day composite with a 500m resolution. The product is based on the radiation-use efficiency concept and can be potentially used as inputs to data models to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/972/MOD17_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/95/MOD17_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/6/MYD17A2H) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD17A2H')                   .filter(ee.Filter.date('2021-01-01', '2021-05-01')); var gpp = dataset.select('Gpp'); var gppVis = {   min: 0.0,   max: 600.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD17A3HGF:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD17A3HGF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD17A3HGF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD17A3HGF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD17A3HGF(example: str = ''):
        """
        The MYD17A3HGF V6.1 product provides information about annual Gross and Net Primary Productivity (GPP and NPP) at 500m pixel resolution. Annual NPP is derived from the sum of all 8-day Net Photosynthesis(PSN) products (MYD17A2H) from the given year.  The PSN value is the difference of the Gross Primary Productivity (GPP) and the Maintenance Respiration (MR) (GPP-MR). 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD17A3HGF');  var visualization = {   bands: ['Npp'],   min: 0.0,   max: 19000.0,   palette: ['bbe029', '0a9501', '074b03'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD21A1D:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD21A1D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD21A1D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD21A1D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD21A1D(example: str = ''):
        """
        The MYD21A1D dataset is produced daily from daytime Level 2 Gridded (L2G) intermediate LST products at a spatial resolution of 1,000 meters. The L2G process maps the daily MOD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MOD21A1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The daytime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MYD21A1D product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD21A1D) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD21A1D')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_1KM'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD21A1N:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD21A1N'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD21A1N.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD21A1N.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD21A1N(example: str = ''):
        """
        The MYD21A1N dataset is produced daily from nighttime Level 2 Gridded (L2G) intermediate LST products at a spatial resolution of 1,000 meters. The L2G process maps the daily MOD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MOD21A1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The nighttime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MYD21A1N product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD21A1N) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD21A1N')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_1KM'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD21C1:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD21C1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD21C1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD21C1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD21C1(example: str = ''):
        """
        The MYD21C1 dataset is produced daily in a 0.05 degree (5,600 meters at the equator) Climate Modeling Grid (CMG) from daytime Level 2 Gridded (L2G) intermediate LST products. The L2G process maps the daily MYD21 swath granules onto a sinusoidal MODIS grid and stores all observations falling over a gridded cell for a given day. The MYD21C1 algorithm sorts through these observations for each cell and estimates the final LST value as an average from all observations that are cloud free and have good LST&E accuracies. The daytime average is weighted by the observation coverage for that cell. Only observations having an observation coverage greater than a 15% threshold are considered. The MYD21C1 product contains the calculated LST as well as quality control, the three emissivity bands, view zenith angle, and time of observation.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD21C1) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD21C1')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD21C2:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD21C2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD21C2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD21C2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD21C2(example: str = ''):
        """
        The MYD21C2 dataset is an 8-day composite LST product that uses an algorithm based on a simple averaging method. The algorithm calculates the average from all the cloud free MYD21A1D and MYD21A1N daily acquisitions from the 8-day period. Unlike the MYD21A1 data sets where the daytime and nighttime acquisitions are separate products, the MYD21A2 contains both daytime and nighttime acquisitions. The LST, Quality Control (QC), view zenith angle, and viewing time have separate day and night bands, while the values for the MODIS emissivity bands 29, 31, and 32 are the average of both the nighttime and daytime acquisitions.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD21C2) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD21C2')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_061_MYD21C3:
    def __init__(self,):
        self.sensor = 'MODIS_061_MYD21C3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_061_MYD21C3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_061_MYD21C3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_061_MYD21C3(example: str = ''):
        """
        The MYD21C3 dataset is a monthly composite LST product that uses an algorithm based on a simple averaging method. The algorithm calculates the average from all the cloud free MYD21A1D and MYD21A1N daily acquisitions from the 8-day period. Unlike the MYD21A1 data sets where the daytime and nighttime acquisitions are separate products, the MYD21A2 contains both daytime and nighttime acquisitions. The LST, Quality Control (QC), view zenith angle, and viewing time have separate day and night bands, while the values for the MODIS emissivity bands 29, 31, and 32 are the average of both the nighttime and daytime acquisitions.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1398/MOD21_User_Guide_V61.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1399/MOD21_ATBD.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/MODIS/61/MYD21C3) 
        :param example: var dataset = ee.ImageCollection('MODIS/061/MYD21C3')                   .filter(ee.Filter.date('2018-01-01', '2018-05-01')); var landSurfaceTemperature = dataset.select('LST_Day'); var landSurfaceTemperatureVis = {   min: 216.0,   max: 348.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     landSurfaceTemperature, landSurfaceTemperatureVis,     'Average Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A1:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A1(example: str = ''):
        """
        The MODerate-resolution Imaging Spectroradiometer (MODIS) BRDF/Albedo Model Parameters product (MCD43A1) contains datasets providing users with weighting parameters for the models used to derive the Albedo and BRDF products (MCD43A3 and MCD43A4). The models support the spatial relationship and parameter characterization best describing the differences in radiation due to the scattering (anisotropy) of each pixel, relying on multi-date, atmospherically corrected, cloud-cleared input data measured over 16-day periods. Both Terra and Aqua data are used in the generation of this product, providing the highest probability for quality input data and designating it as an MCD, meaning Combined, product.  Version-5 MODIS/Terra+Aqua BRDF/Albedo products are Validated Stage 1, meaning that accuracy has been estimated using a small number of independent measurements obtained from selected locations and time periods and ground-truth/field program efforts. Although there may be later improved versions, these data are ready for use in scientific publications.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A2:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A2(example: str = ''):
        """
        The MODerate-resolution Imaging Spectroradiometer (MODIS) BRDF/Albedo Quality product (MCD43A2) describes the overall condition of the other BRDF and Albedo products. The MCD43A2 product contains 16 days of data at 500 meter spatial resolution provided in a level-3 gridded data set in Sinusoidal projection, and includes albedo quality, snow conditions, ancillary information, and inversion information.  Both Terra and Aqua data are used in the generation of this product, providing the highest probability for quality input data and designating it as an MCD, meaning Combined, product.  Version-5 MODIS/Terra+Aqua BRDF/Albedo products are Validated Stage 1, meaning that accuracy has been estimated using a small number of independent measurements obtained from selected locations and time periods and ground-truth/field program efforts. Although there may be later improved versions, these data are ready for use in scientific publications.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4(example: str = ''):
        """
        The MODerate-resolution Imaging Spectroradiometer (MODIS) Reflectance product MCD43A4 provides 500-meter reflectance data adjusted using a bidirectional reflectance distribution function (BRDF) to model the values as if they were taken from nadir view. The MCD43A4 product contains 16 days of data provided in a level-3 gridded data set in Sinusoidal projection.  Both Terra and Aqua data are used in the generation of this product, providing the highest probability for quality input data and designating it as an MCD, meaning Combined, product.  Version-5 MODIS/Terra+Aqua BRDF/Albedo products are Validated Stage 1, meaning that accuracy has been estimated using a small number of independent measurements obtained from selected locations and time periods and ground-truth/field program efforts. Although there may be later improved versions, these data are ready for use in scientific publications.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_006_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_006_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_006_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_006_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_006_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/006/MCD43A4 surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MCD43A4_006_BAI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var scaled = dataset.select('BAI'); var scaledVis = {   min: 0.0,   max: 100.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(scaled, scaledVis, 'Scaled');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_006_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_006_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_006_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_006_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_006_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/006/MCD43A4 surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MCD43A4_006_EVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('EVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_006_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_006_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_006_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_006_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_006_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/006/MCD43A4 surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MCD43A4_006_NDSI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDSI'); var colorizedVis = {   palette: ['000088', '0000ff', '8888ff', 'ffffff'], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_006_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_006_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_006_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_006_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_006_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/006/MCD43A4 surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MCD43A4_006_NDVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_006_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_006_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_006_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_006_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_006_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/006/MCD43A4 surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MCD43A4_006_NDWI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDWI'); var colorizedVis = {   min: 0.0,   max: 1.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/MCD43A4 surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/MCD43A4 surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/MCD43A4 surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/MCD43A4 surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MCD43A4_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MCD43A4_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MCD43A4_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MCD43A4_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MCD43A4_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/MCD43A4 surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09A1(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MOD09A1 provides Bands 1-7 at 500-meter resolution in an 8-day gridded level-3 product in the Sinusoidal projection. Each MOD09A1 pixel contains the best possible L2G observation during an 8-day period as selected on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading. Science Data Sets provided for this product include reflectance values for Bands 1-7, quality assessment, and the day of the year for the pixel along with solar, view, and zenith angles.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MOD09GA provides Bands 1-7 in a daily gridded L2G product in the Sinusoidal projection, including 500-meter reflectance values and 1-kilometer observation and geolocation statistics. 500-m Science Data Sets provided for this product include reflectance for Bands 1-7, a quality rating, observation coverage, observation number, and 250-m scan information. 1-kilometer Science Data Sets provided include number of observations, quality state, sensor angles, solar angles, geolocation flags, and orbit pointers.  Bands:  - num_observations_1km: Number of observations, 1km - state_1km: Reflectance Data State QA    - Bit 0-1: cloud state bits       - 00 (0):  clear       - 01 (1):  cloudy       - 10 (2):  mixed       - 11 (3):  not set, assumed clear    - Bit 2: cloud shadow data (1 = yes)    - Bit 3-5: land/water flag       - 000 (0):  shallow ocean       - 001 (1):  land       - 010 (2):  ocean coastlines and lake shorelines       - 011 (3):  shallow inland water       - 100 (4):  ephemeral water       - 101 (5):  deep inland water       - 110 (6):  continental/moderate ocean       - 111 (7):  deep ocean    - Bit 6-7: aerosol quantity       - 00 (0):  climatology       - 01 (1):  low       - 10 (2):  average       - 11 (3):  high    - Bit 8-9: cirrus detected       - 00 (0):  none       - 01 (1):  small       - 10 (2):  average       - 11 (3):  high    - Bit 10: internal cloud algorithm flag data (1 = Cloud)    - Bit 11: internal fire algorithm flag data (1 = Fire)    - Bit 12: MOD35 snow/ice flag data (1 = yes)    - Bit 13: Pixel is adjacent to cloud data (1 = yes)    - Bit 14: BRDF correction performed data (1 = yes)    - Bit 15: internal snow mask data (1 = Snow) - SensorZenith (degrees * 100): sensor zenith angle - SensorAzimuth (degrees * 100): sensor azimuth angle - Range (scale 25): pixel to sensor - SolarZenith (degrees * 100): solar zenith angle - SolarAzimuth (degrees * 100): solar azimuth angle - gflags: Geolocation flags    - Bit 0-2: Fill    - Bit 3: Sensor range validity flag (0 = Valid)    - Bit 4: Digital elevation model quality flag (0 = Valid, 1 = Missing/inferior)    - Bit 5: Terrain data validity (0 = Valid)    - Bit 6: Ellipsoid intersection flag (0 = Valid intersection, 1 = No intersection)    - Bit 7: Input data flag (0 = Valid) - orbit_pnt: Orbit pointer - granule_pnt: Granule pointer (v6 only) - num_observations_500m: Number of observations, 500m - sur_refl_b01: 500m Surface Reflectance Band 1 (620-670 nm) - sur_refl_b02: 500m Surface Reflectance Band 2 (841-876 nm) - sur_refl_b03: 500m Surface Reflectance Band 3 (459-479 nm) - sur_refl_b04: 500m Surface Reflectance Band 4 (545-565 nm) - sur_refl_b05: 500m Surface Reflectance Band 5 (1230-1250 nm) - sur_refl_b06: 500m Surface Reflectance Band 6 (1628-1652 nm) - sur_refl_b07: 500m Surface Reflectance Band 7 (2105-2155 nm) - QC_500m: 500m Reflectance Band Quality    - Bit 0-1: MODLAND QA bits       - 00 (0):  corrected product produced at ideal quality all bands       - 01 (1):  corrected product produced at less than ideal quality some or all bands       - 10 (2):  corrected product not produced due to cloud effects all bands       - 11 (3):  corrected product not produced due to other reasons some or all bands may be fill value [Note that a value of (11) overrides a value of (01)].    - Bit 2-5: band 1 data quality four bit range       - 0000 (0): highest quality       - 1000 (8): dead detector; data interpolated in L1B       - 1001 (9): solar zenith &ge; 86 degrees       - 1010 (10): solar zenith &ge; 85 and &lt; 86 degrees       - 1011 (11): missing input       - 1100 (12): internal constant used in place of climatological data for at least one atmospheric constant       - 1101 (13): correction out of bounds pixel constrained to extreme allowable value       - 1110 (14): L1B data faulty       - 1111 (15): not processed due to deep ocean or clouds    - Bit 6-9: band 2 data quality four bit range    - Bit 10-13: band 3 data quality four bit range    - Bit 14-17: band 4 data quality four bit range    - Bit 18-21: band 5 data quality four bit range    - Bit 22-25: band 6 data quality four bit range    - Bit 26-29: band 7 data quality four bit range    - Bit 30: atmospheric correction performed data (1 = yes)    - Bit 31: adjacency correction performed data (1 = yes) - obscov_500m (%): Observation coverage, 500m - iobs_res: Observation number in coarser grid - q_scan: 250m scan value information    - Bit 0: missing observation in quadrant 4 [+0.5 row, +0.5 column] data (1 = yes)    - Bit 1: missing observation in quadrant 3 [+0.5 row, -0.5 column] data (1 = yes)    - Bit 2: missing observation in quadrant 2 [-0.5 row, +0.5 column]data (1 = yes)    - Bit 3: missing observation in quadrant 1 [-0.5 row, -0.5 column] data (1 = yes)    - Bit 4: scan of observation in quadrant 4 [+0.5 row, +0.5 column] data (0 = different, 1 = same)    - Bit 5: scan of observation in quadrant 3 [+0.5 row, -0.5 column] data (0 = different, 1 = same)    - Bit 6: scan of observation in quadrant 2 [-0.5 row, +0.5 column] data (0 = different, 1 = same)    - Bit 7: scan of observation in quadrant 1 [-0.5 row, -0.5 column] data (0 = different, 1 = same)  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_006_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_006_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_006_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_006_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_006_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/006/MOD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD09GA_006_BAI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var scaled = dataset.select('BAI'); var scaledVis = {   min: 0.0,   max: 100.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(scaled, scaledVis, 'Scaled');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_006_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_006_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_006_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_006_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_006_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/006/MOD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD09GA_006_EVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('EVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_006_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_006_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_006_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_006_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_006_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/006/MOD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD09GA_006_NDSI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDSI'); var colorizedVis = {   palette: ['000088', '0000ff', '8888ff', 'ffffff'], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_006_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_006_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_006_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_006_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_006_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/006/MOD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD09GA_006_NDVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_006_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_006_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_006_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_006_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_006_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/006/MOD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD09GA_006_NDWI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDWI'); var colorizedVis = {   min: 0.0,   max: 1.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/MOD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/MOD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/MOD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/MOD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GA_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GA_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GA_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GA_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GA_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/MOD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MOD09GQ provides Bands 1 and 2 at a 250-meter resolution in a daily gridded L2G product in the Sinusoidal projection. Science Data Sets provided for this product include reflectance for Bands 1 and 2, a quality rating, observation coverage, and observation number. This product is meant to be used in conjunction with the MOD09GA where important quality and viewing geometry information is stored.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD09Q1(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MOD09Q1 provides Bands 1 and 2 at 250-meter resolution in an 8-day gridded level-3 product in the Sinusoidal projection. Each MOD09Q1 pixel contains the best possible L2G observation during an 8-day period as selected on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading. Science Data Sets provided for this product include reflectance values for Bands 1 and 2, and a quality rating.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD10A1(example: str = ''):
        """
        The MOD10A1 V5 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD10A1')     .filterDate('2015-01-01', '2016-01-01');  var visualization = {   bands: ['Snow_Cover_Daily_Tile'],   min: 0.0,   max: 100.0,   palette: ['black', '0dffff', '0524ff', 'ffffff'] };  Map.setCenter(-41.13, 76.35, 3);  Map.addLayer(dataset, visualization, 'Snow Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD11A1(example: str = ''):
        """
        The MODIS/Terra Land Surface Temperature and Emissivity (LST/E) product, MOD11A1, provides per-pixel temperature and emissivity values, which are produced daily using the generalized split-window LST algorithm.  This algorithm is optimally used to separate ranges of atmospheric column water vapor and lower boundary air surface temperatures into tractable sub-ranges. The surface emissivities in bands 31 and 32 are estimated from land cover types.  The V5 MOD11A1 products are projected in a Sinusoidal grid by mapping the level-2 LST product (MOD11_L2) on 1-kilometer (precisely 0.928-km) grids. The MOD11A1 product comprises the following Science Data Set (SDS) layers for daytime and nighttime observations:  - LST_Day_1km: Daytime Land Surface Temperatures (K),  Scale 0.02 - QC_Day: Daytime Surface Temperature quality control assessments - Day_view_time: Daytime LST Observation Times (Hours), Scale 0.1 - Day_view_angle: Daytime View Zenith Angles (Degrees), Offset -65.0 - LST_Night_1km: Nighttime Land Surface Temperatures (K),  Scale 0.02 - QC_Night: Nighttime Surface Temperature quality control assessments - Night_view_time: Nighttime LST Observation Times (Hours), Scale 0.1 - Night_view_angle: Nighttime View Zenith Angles (Degrees), Offset -65.0 - Emis_31: Bands 31 Emissivity, Scale 0.002, Offset 0.49 - Emis_32: Bands 32 Emissivity, Scale 0.002, Offset 0.49 - Clear_night_cov: Nighttime Clear Sky Coverage, Scale 0.0005 - Clear_day_cov: Daytime Clear Sky Coverage, Scale 0.0005  QC bit flags:  - Bits 0-1: Mandatory QC Flag    - 00: LST produced, good quality, not necessary to examine detailed QC.    - 01: LST produced, unreliable or unquantifiable quality, recommend examination of more detailed QC.    - 10: LST not produced due to cloud effects.    - 11: LST not produced primarily due to reasons other than clouds. - Bits 2-3: Data Quality Flag    - 00: Good quality L1B in bands 31 and 32.    - 01: Other quality data.    - 10: TBD    - 11: TBD - Bits 4-5: Emissivity Error Flag    - 00: Average emissivity error &le; 0.01    - 01: Average emissivity error &le; 0.02    - 10: Average emissivity error &le; 0.04    - 11: Average emissivity error &gt; 0.04 - Bits 6-7: LST Error Flag    - 00: Average LST error &le; 1 K    - 01: Average LST error &le; 2 K    - 10: Average LST error &le; 3 K    - 11: Average LST error &gt; 3 K  The V5 Terra/MODIS LST/E products, including MOD11A1, are validated to Stage-2 through field campaigns and radiance-based validation studies.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_MOD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD11A2(example: str = ''):
        """
        The level-3 MODIS global Land Surface Temperature (LST) and Emissivity 8-day data are composed from the daily 1-kilometer LST product (MOD11A1) and stored on a 1-km Sinusoidal grid as the average values of clear-sky LSTs during an 8-day period.  MOD11A2 is comprised of the following layers for daytime and nighttime observations:  - LST_Day_1km: Daytime Land Surface Temperatures (K),  Scale 0.02 - QC_Day: Daytime Surface Temperature quality control assessments,       see QC bit flags - Day_view_time: Daytime LST Observation Times (Hours), Scale 0.1 - Day_view_angl: Daytime View Zenith Angles (Degrees), Offset -65.0 - LST_Night_1km: Nighttime Land Surface Temperatures (K),  Scale 0.02 - QC_Night: Nighttime Surface Temperature quality control assessments,       see QC bit flags - Night_view_time: Nighttime LST Observation Times (Hours), Scale 0.1 - Night_view_angl: Nighttime View Zenith Angles (Degrees), Offset -65.0 - Emis_31: Bands 31 Emissivity, Scale 0.002, Offset 0.49 - Emis_32: Bands 32 Emissivity, Scale 0.002, Offset 0.49 - Clear_sky_days: Clear Sky Day Coverage, see Clear Sky Flags. - Clear_sky_nights: Clear Sky Nighttime Coverage, see Clear Sky Flags.  QC bit flags:  - Bits 0-1: Mandatory QC Flag    - 00: LST produced, good quality, not necessary to examine detailed QC.    - 01: LST produced, unreliable or unquantifiable quality, recommend examination of more detailed QC.    - 10: LST not produced due to cloud effects.    - 11: LST not produced primarily due to reasons other than clouds. - Bits 2-3: Data Quality Flag    - 00: Good quality L1B in bands 31 and 32.    - 01: Other quality data.    - 10: TBD    - 11: TBD - Bits 4-5: Emissivity Error Flag    - 00: Average emissivity error &le; 0.01    - 01: Average emissivity error &le; 0.02    - 10: Average emissivity error &le; 0.04    - 11: Average emissivity error &gt; 0.04 - Bits 6-7: LST Error Flag    - 00: Average LST error &le; 1 K    - 01: Average LST error &le; 2 K    - 10: Average LST error &le; 3 K    - 11: Average LST error &gt; 3 K  Clear Sky Flags:  - Clear Sky Flag for each day (bit 0 is day 1, bit 1 is day 2, etc):    - 0: Day/Night is not clear-sky.    - 1: Day/Night is clear-sky.  Version-5 MODIS/Terra Land Surface Temperature/Emissivity products are Validated Stage 2, meaning that accuracy has been assessed over a widely distributed set of locations and time periods via several ground-truth and validation efforts. Although there may be later improved versions, these data are ready for use in scientific publications.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD13A1(example: str = ''):
        """
        Global MODIS vegetation indices are designed to provide consistent spatial and temporal comparisons of vegetation conditions. Blue, red, and near-infrared reflectances, centered at 469-nanometers, 645-nanometers, and 858-nanometers, respectively, are used to determine the MODIS daily vegetation indices.  The MODIS Normalized Difference Vegetation Index (NDVI) complements NOAA's Advanced Very High Resolution Radiometer (AVHRR) NDVI products provide continuity for time series historical applications. MODIS also includes a new Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Global MOD13A1 data are provided every 16 days at 500-meter spatial resolution as a gridded level-3 product in the Sinusoidal projection. Vegetation indices are used for global monitoring of vegetation conditions and are used in products displaying land cover and land cover changes. These data may be used as input for modeling global biogeochemical and hydrologic processes and global and regional climate. These data also may be used for characterizing land surface biophysical properties and processes, including primary production and land cover conversion.  Version-5 MODIS Vegetation Indices products have attained Validation Stage 3.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: var dataset = ee.ImageCollection('MODIS/MOD13A1')                   .filter(ee.Filter.date('2014-04-01', '2014-06-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03, 31.05, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_MOD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD13Q1(example: str = ''):
        """
        The MODIS Normalized Difference Vegetation Index (NDVI) complements NOAA's Advanced Very High Resolution Radiometer (AVHRR) NDVI products and provides continuity for time series historical applications. MODIS also includes a new Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  MOD13AQ1 is comprised of the following layers:  - NDVI: Normalized Difference Vegetation Index, Scale 0.0001 - EVI: Enhanced Vegetation Index, Scale 0.0001 - DetailedQA: VI Quality, see MOD13Q1 VI Quality - sur_refl_b01: Red surface reflectance, scale 0.0001 - sur_refl_b02: NIR surface reflectance, scale 0.0001 - sur_refl_b03: Blue surface reflectance, scale 0.0001 - sur_refl_b07: MIR surface reflectance, scale 0.0001 - ViewZenith: View zenith angle, scale 0.01 - SolarZenith: Solar zenith angle, scale 0.01 - RelativeAzimuth: Relative azimuth angle, scale 0.1 - DayOfYear: Julian day of year - SummaryQA: Pixel reliability summary QA    - -1 Fill/No data: Not processed    - 0 Good data: Use with confidence    - 1 Marginal data: Useful but look at detailed QA for more information    - 2 Snow/ice: Pixel covered with snow/ice    - 3: Cloudy: Pixel is cloudy  MOD13Q1 IV Quality  - Bits 0-1: MODLAND_QA    - 00 (0): VI produced, good quality    - 01 (1): VI produced, check other QA    - 10 (2): Pixel produced, probably cloudy    - 11 (3): Pixel not produced due to other reason (not clouds) - Bits 2-5: VI Usefulness    - 0000 (0): Highest quality    - 0001 (1): Lower quality    - 0010 (2): Decreasing quality    - 0100 (4): Decreasing quality    - 1000 (8): Decreasing quality    - 1001 (9): Decreasing quality    - 1010 (10): Decreasing quality    - 1100 (12): Lowest quality    - 1101 (13): Quality so low that it is not useful    - 1110 (14): L1B data faulty    - 1111 (15): Not useful for any other reason/not processed - Bits 6-7: Aerosol quantity    - 00 (0): Climatology    - 01 (1): Low    - 10 (2): Average    - 11 (3): High - Bit 8: Adjacent cloud detected    - 0: No    - 1: Yes - Bit 9: Atmosphere BRDF correction performed    - 0: No    - 1: Yes - Bit 10: Mixed Clouds     - 0: No     - 1: Yes - Bits 11-13: Land/Water flag    - 000 (0): Shallow ocean    - 001 (1): Land    - 010 (2): Ocean coastlines and lake shorelines    - 011 (3): Shallow inland water    - 100 (4): Ephemeral water    - 101 (5): Deep inland water    - 110 (6): Moderate or continental ocean    - 111 (7): Deep ocean - Bit 14: Possible snow/ice    - 0: No    - 1: Yes - Bit 15: Possible shadow    - 0: No    - 1: Yes  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MOD44W_MOD44W_005_2000_02_24:
    def __init__(self,):
        self.sensor = 'MODIS_MOD44W_MOD44W_005_2000_02_24'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MOD44W_MOD44W_005_2000_02_24.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MOD44W_MOD44W_005_2000_02_24.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MOD44W_MOD44W_005_2000_02_24(example: str = ''):
        """
        The Global Water Mask uses the SWBD (SRTM Water Body Data) in combination with MODIS 250m data to create a complete global map of surface water at 250m spatial resolution, circa 2000-2002.  This dataset is intended for use in processing of raster data and for masking out water in final raster data products. 
        :param example: var dataset = ee.Image('MODIS/MOD44W/MOD44W_005_2000_02_24'); var waterMask = dataset.select('water_mask'); var waterMaskVis = {   min: 0.0,   max: 1, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(waterMask, waterMaskVis, 'Water Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09A1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09A1(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MYD09A1 provides Bands 1-7 at 500-meter resolution in an 8-day gridded level-3 product in the Sinusoidal projection. Each MYD09A1 pixel contains the best possible L2G observation during an 8-day period as selected on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading. Science Data Sets provided for this product include reflectance values for Bands 1-7, quality assessment, and the day of the year for the pixel along with solar, view, and zenith angles.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MYD09GA provides Bands 1-7 in a daily gridded L2G product in the Sinusoidal projection, including 500-meter reflectance values and 1-kilometer observation and geolocation statistics. 500-m Science Data Sets provided for this product include reflectance for Bands 1-7, a quality rating, observation coverage, observation number, and 250-m scan information. 1-kilometer Science Data Sets provided include number of observations, quality state, sensor angles, solar angles, geolocation flags, and orbit pointers.  Bands:  - num_observations_1km: Number of observations, 1km - state_1km: Reflectance Data State QA    - Bit 0-1: cloud state bits       - 00 (0):  clear       - 01 (1):  cloudy       - 10 (2):  mixed       - 11 (3):  not set, assumed clear    - Bit 2: cloud shadow data (1 = yes)    - Bit 3-5: land/water flag       - 000 (0):  shallow ocean       - 001 (1):  land       - 010 (2):  ocean coastlines and lake shorelines       - 011 (3):  shallow inland water       - 100 (4):  ephemeral water       - 101 (5):  deep inland water       - 110 (6):  continental/moderate ocean       - 111 (7):  deep ocean    - Bit 6-7: aerosol quantity       - 00 (0):  climatology       - 01 (1):  low       - 10 (2):  average       - 11 (3):  high    - Bit 8-9: cirrus detected       - 00 (0):  none       - 01 (1):  small       - 10 (2):  average       - 11 (3):  high    - Bit 10: internal cloud algorithm flag data (1 = Cloud)    - Bit 11: internal fire algorithm flag data (1 = Fire)    - Bit 12: MOD35 snow/ice flag data (1 = yes)    - Bit 13: Pixel is adjacent to cloud data (1 = yes)    - Bit 14: BRDF correction performed data (1 = yes)    - Bit 15: internal snow mask data (1 = Snow) - SensorZenith (degrees * 100): sensor zenith angle - SensorAzimuth (degrees * 100): sensor azimuth angle - Range (scale 25): pixel to sensor - SolarZenith (degrees * 100): solar zenith angle - SolarAzimuth (degrees * 100): solar azimuth angle - gflags: Geolocation flags    - Bit 0-2: Fill    - Bit 3: Sensor range validity flag (0 = Valid)    - Bit 4: Digital elevation model quality flag (0 = Valid, 1 = Missing/inferior)    - Bit 5: Terrain data validity (0 = Valid)    - Bit 6: Ellipsoid intersection flag (0 = Valid intersection, 1 = No intersection)    - Bit 7: Input data flag (0 = Valid) - orbit_pnt: Orbit pointer - granule_pnt: Granule pointer (v6 only) - num_observations_500m: Number of observations, 500m - sur_refl_b01: 500m Surface Reflectance Band 1 (620-670 nm) - sur_refl_b02: 500m Surface Reflectance Band 2 (841-876 nm) - sur_refl_b03: 500m Surface Reflectance Band 3 (459-479 nm) - sur_refl_b04: 500m Surface Reflectance Band 4 (545-565 nm) - sur_refl_b05: 500m Surface Reflectance Band 5 (1230-1250 nm) - sur_refl_b06: 500m Surface Reflectance Band 6 (1628-1652 nm) - sur_refl_b07: 500m Surface Reflectance Band 7 (2105-2155 nm) - QC_500m: 500m Reflectance Band Quality    - Bit 0-1: MODLAND QA bits       - 00 (0):  corrected product produced at ideal quality all bands       - 01 (1):  corrected product produced at less than ideal quality some or all bands       - 10 (2):  corrected product not produced due to cloud effects all bands       - 11 (3):  corrected product not produced due to other reasons some or all bands may be fill value [Note that a value of (11) overrides a value of (01)].    - Bit 2-5: band 1 data quality four bit range       - 0000 (0): highest quality       - 1000 (8): dead detector; data interpolated in L1B       - 1001 (9): solar zenith &ge; 86 degrees       - 1010 (10): solar zenith &ge; 85 and &lt; 86 degrees       - 1011 (11): missing input       - 1100 (12): internal constant used in place of climatological data for at least one atmospheric constant       - 1101 (13): correction out of bounds pixel constrained to extreme allowable value       - 1110 (14): L1B data faulty       - 1111 (15): not processed due to deep ocean or clouds    - Bit 6-9: band 2 data quality four bit range    - Bit 10-13: band 3 data quality four bit range    - Bit 14-17: band 4 data quality four bit range    - Bit 18-21: band 5 data quality four bit range    - Bit 22-25: band 6 data quality four bit range    - Bit 26-29: band 7 data quality four bit range    - Bit 30: atmospheric correction performed data (1 = yes)    - Bit 31: adjacency correction performed data (1 = yes) - obscov_500m (%): Observation coverage, 500m - iobs_res: Observation number in coarser grid - q_scan: 250m scan value information    - Bit 0: missing observation in quadrant 4 [+0.5 row, +0.5 column] data (1 = yes)    - Bit 1: missing observation in quadrant 3 [+0.5 row, -0.5 column] data (1 = yes)    - Bit 2: missing observation in quadrant 2 [-0.5 row, +0.5 column]data (1 = yes)    - Bit 3: missing observation in quadrant 1 [-0.5 row, -0.5 column] data (1 = yes)    - Bit 4: scan of observation in quadrant 4 [+0.5 row, +0.5 column] data (0 = different, 1 = same)    - Bit 5: scan of observation in quadrant 3 [+0.5 row, -0.5 column] data (0 = different, 1 = same)    - Bit 6: scan of observation in quadrant 2 [-0.5 row, +0.5 column] data (0 = different, 1 = same)    - Bit 7: scan of observation in quadrant 1 [-0.5 row, -0.5 column] data (0 = different, 1 = same)  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_006_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_006_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_006_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_006_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_006_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/006/MYD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD09GA_006_BAI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var scaled = dataset.select('BAI'); var scaledVis = {   min: 0.0,   max: 100.0, }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(scaled, scaledVis, 'Scaled');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_006_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_006_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_006_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_006_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_006_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/006/MYD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD09GA_006_EVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('EVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03, 31.05, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_006_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_006_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_006_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_006_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_006_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/006/MYD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD09GA_006_NDSI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDSI'); var colorizedVis = {   palette: ['000088', '0000ff', '8888ff', 'ffffff'], }; Map.setCenter(-7.03, 31.05, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_006_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_006_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_006_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_006_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_006_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/006/MYD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD09GA_006_NDVI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDVI'); var colorizedVis = {   min: 0,   max: 1,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_006_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_006_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_006_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_006_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_006_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/006/MYD09GA surface reflectance composites. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD09GA_006_NDWI')                   .filter(ee.Filter.date('2018-04-01', '2018-06-01')); var colorized = dataset.select('NDWI'); var colorizedVis = {   min: 0.0,   max: 1.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'], }; Map.setCenter(-7.03125, 31.0529339857, 2); Map.addLayer(colorized, colorizedVis, 'Colorized');
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_BAI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_BAI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_BAI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_BAI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_BAI(example: str = ''):
        """
        The Burn Area Index (BAI) is generated from the Red and Near-IR bands, and measures the spectral distance of each pixel from a reference spectral point (the measured reflectance of charcoal).  This index is intended to emphasize the charcoal signal in post-fire images. See [Chuvieco et al. (2002)](https://www.tandfonline.com/doi/abs/10.1080/01431160210153129) for details. This product is generated from the MODIS/MYD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_EVI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_EVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_EVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_EVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_EVI(example: str = ''):
        """
        The Enhanced Vegetation Index (EVI) is generated from the Near-IR, Red and Blue bands of each scene, and ranges in value from -1.0 to 1.0. See [Huete et al. (2002)](https://www.sciencedirect.com/science/article/pii/S0034425702000962) for details. This product is generated from the MODIS/MYD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_NDSI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_NDSI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_NDSI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_NDSI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_NDSI(example: str = ''):
        """
        The Normalized Difference Snow Index is used to identify snow, based on its characteristically higher reflectance in the visible portion of the spectrum compared to the mid-IR.  NDSI is computed using the Green and Mid-IR bands, and has a range of -1.0 to 1.0. See [Riggs et al. (1994)](https://doi.org/10.1109/IGARSS.1994.399618) for details. This product is generated from the MODIS/MYD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_NDVI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_NDVI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_NDVI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_NDVI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_NDVI(example: str = ''):
        """
        The Normalized Difference Vegetation Index is generated from the Near-IR and Red bands of each scene as (NIR - Red) / (NIR + Red), and ranges in value from -1.0 to 1.0. This product is generated from the MODIS/MYD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GA_NDWI:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GA_NDWI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GA_NDWI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GA_NDWI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GA_NDWI(example: str = ''):
        """
        The Normalized Difference Water Index (NDWI) is sensitive to changes in liquid water content of vegetation canopies.  It is derived from the Near-IR band and a second IR band, &approx;1.24&mu;m when available and the nearest available IR band otherwise.  It ranges in value from -1.0 to 1.0.  See [Gao (1996)](https://www.sciencedirect.com/science/article/pii/S0034425796000673) for details. This product is generated from the MODIS/MYD09GA surface reflectance composites. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09GQ:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09GQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09GQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09GQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09GQ(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MYD09GQ provides Bands 1 and 2 at a 250-meter resolution in a daily gridded L2G product in the Sinusoidal projection. Science Data Sets provided for this product include reflectance for Bands 1 and 2, a quality rating, observation coverage, and observation number. This product is meant to be used in conjunction with the MOD09GA where important quality and viewing geometry information is stored.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD09Q1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD09Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD09Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD09Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD09Q1(example: str = ''):
        """
        The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  MYD09Q1 provides Bands 1 and 2 at 250-meter resolution in an 8-day gridded level-3 product in the Sinusoidal projection. Each MYD09Q1 pixel contains the best possible L2G observation during an 8-day period as selected on the basis of high observation coverage, low view angle, the absence of clouds or cloud shadow, and aerosol loading. Science Data Sets provided for this product include reflectance values for Bands 1 and 2, and a quality rating.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD10A1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD10A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD10A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD10A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD10A1(example: str = ''):
        """
        The MYD10A1 V5 Snow Cover Daily Global 500m product contains snow cover, snow albedo, fractional snow cover, and quality assessment (QA) data. Snow cover data are based on a snow mapping algorithm that employs a Normalized Difference Snow Index (NDSI) and other criteria tests. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD11A1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD11A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD11A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD11A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD11A1(example: str = ''):
        """
        The MODIS/Aqua Land Surface Temperature and Emissivity (LST/E) product, MYD11A1, provides per-pixel temperature and emissivity values, which are produced daily using the generalized split-window LST algorithm.  This algorithm is optimally used to separate ranges of atmospheric column water vapor and lower boundary air surface temperatures into tractable sub-ranges. The surface emissivities in bands 31 and 32 are estimated from land cover types.  The V5 MYD11A1 products are projected in a Sinusoidal grid by mapping the level-2 LST product (MYD11_L2) on 1-kilometer (precisely 0.928-km) grids. The MYD11A1 product comprises the following Science Data Set (SDS) layers for daytime and nighttime observations: LSTs, quality control assessments, observation times, view zenith angles, clear sky coverages, and bands 31 and 32 emissivities from land cover types.  The V5 Aqua/MODIS LST/E products, including MYD11A1, are validated to Stage-2 through field campaigns and radiance-based validation studies.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD11A2:
    def __init__(self,):
        self.sensor = 'MODIS_MYD11A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD11A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD11A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD11A2(example: str = ''):
        """
        The level-3 MODIS global Land Surface Temperature (LST) and Emissivity 8-day data are composed from the daily 1-kilometer LST product (MYD11A1) and stored on a 1-km Sinusoidal grid as the average values of clear-sky LSTs during an 8-day period.  MYD11A2 is comprised of the following layers for daytime and nighttime observations:  - LST_Day_1km: Daytime Land Surface Temperatures (K),  Scale 0.02 - QC_Day: Daytime Surface Temperature quality control assessments,       see QC bit flags - Day_view_time: Daytime LST Observation Times (Hours), Scale 0.1 - Day_view_angl: Daytime View Zenith Angles (Degrees), Offset -65.0 - LST_Night_1km: Nighttime Land Surface Temperatures (K),  Scale 0.02 - QC_Night: Nighttime Surface Temperature quality control assessments,       see QC bit flags - Night_view_time: Nighttime LST Observation Times (Hours), Scale 0.1 - Night_view_angl: Nighttime View Zenith Angles (Degrees), Offset -65.0 - Emis_31: Bands 31 Emissivity, Scale 0.002, Offset 0.49 - Emis_32: Bands 32 Emissivity, Scale 0.002, Offset 0.49 - Clear_sky_days: Clear Sky Day Coverage, see Clear Sky Flags. - Clear_sky_nights: Clear Sky Nighttime Coverage, see Clear Sky Flags.  QC bit flags:  - Bits 0-1: Mandatory QC Flag    - 00: LST produced, good quality, not necessary to examine detailed QC.    - 01: LST produced, unreliable or unquantifiable quality, recommend examination of more detailed QC.    - 10: LST not produced due to cloud effects.    - 11: LST not produced primarily due to reasons other than clouds. - Bits 2-3: Data Quality Flag    - 00: Good quality L1B in bands 31 and 32.    - 01: Other quality data.    - 10: TBD    - 11: TBD - Bits 4-5: Emissivity Error Flag    - 00: Average emissivity error &le; 0.01    - 01: Average emissivity error &le; 0.02    - 10: Average emissivity error &le; 0.04    - 11: Average emissivity error &gt; 0.04 - Bits 6-7: LST Error Flag    - 00: Average LST error &le; 1 K    - 01: Average LST error &le; 2 K    - 10: Average LST error &le; 3 K    - 11: Average LST error &gt; 3 K  Clear Sky Flags:  - Clear Sky Flag for each day (bit 0 is day 1, bit 1 is day 2, etc):    - 0: Day/Night is not clear-sky.    - 1: Day/Night is clear-sky.  Version-5 MODIS/Aqua Land Surface Temperature/Emissivity products are Validated Stage 2, meaning that accuracy has been assessed over a widely distributed set of locations and time periods via several ground-truth and validation efforts. Although there may be later improved versions, these data are ready for use in scientific publications.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD13A1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD13A1(example: str = ''):
        """
        Global MODIS vegetation indices are designed to provide consistent spatial and temporal comparisons of vegetation conditions. Blue, red, and near-infrared reflectances, centered at 469-nanometers, 645-nanometers, and 858-nanometers, respectively, are used to determine the MODIS daily vegetation indices.  The MODIS Normalized Difference Vegetation Index (NDVI) complements NOAA's Advanced Very High Resolution Radiometer (AVHRR) NDVI products provide continuity for time series historical applications. MODIS also includes a new Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  Global MYD13A1 data are provided every 16 days at 500-meter spatial resolution as a gridded level-3 product in the Sinusoidal projection. Vegetation indices are used for global monitoring of vegetation conditions and are used in products displaying land cover and land cover changes. These data may be used as input for modeling global biogeochemical and hydrologic processes and global and regional climate. These data also may be used for characterizing land surface biophysical properties and processes, including primary production and land cover conversion.  Version-5 MODIS Vegetation Indices products have attained Validation Stage 3.  Vegetation Indices production is phased between Terra and Aqua acquisitions, with Terra beginning on Day 001 and Aqua beginning on Day 008.  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: var dataset = ee.ImageCollection('MODIS/MYD13A1')                   .filter(ee.Filter.date('2014-04-01', '2014-06-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.setCenter(-7.03, 31.05, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_MYD13Q1:
    def __init__(self,):
        self.sensor = 'MODIS_MYD13Q1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_MYD13Q1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_MYD13Q1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_MYD13Q1(example: str = ''):
        """
        The MODIS Normalized Difference Vegetation Index (NDVI) complements NOAA's Advanced Very High Resolution Radiometer (AVHRR) NDVI products and provides continuity for time series historical applications. MODIS also includes a new Enhanced Vegetation Index (EVI) that minimizes canopy background variations and maintains sensitivity over dense vegetation conditions. The EVI also uses the blue band to remove residual atmosphere contamination caused by smoke and sub-pixel thin cloud clouds. The MODIS NDVI and EVI products are computed from atmospherically corrected bi-directional surface reflectances that have been masked for water, clouds, heavy aerosols, and cloud shadows.  MOD13AQ1 is comprised of the following layers:  - NDVI: Normalized Difference Vegetation Index, Scale 0.0001 - EVI: Enhanced Vegetation Index, Scale 0.0001 - DetailedQA: VI Quality, see MOD13Q1 VI Quality - sur_refl_b01: Red surface reflectance, scale 0.0001 - sur_refl_b02: NIR surface reflectance, scale 0.0001 - sur_refl_b03: Blue surface reflectance, scale 0.0001 - sur_refl_b07: MIR surface reflectance, scale 0.0001 - ViewZenith: View zenith angle, scale 0.01 - SolarZenith: Solar zenith angle, scale 0.01 - RelativeAzimuth: Relative azimuth angle, scale 0.1 - DayOfYear: Julian day of year - SummaryQA: Pixel reliability summary QA    - -1 Fill/No data: Not processed    - 0 Good data: Use with confidence    - 1 Marginal data: Useful but look at detailed QA for more information    - 2 Snow/ice: Pixel covered with snow/ice    - 3: Cloudy: Pixel is cloudy  MOD13Q1 IV Quality  - Bits 0-1: MODLAND_QA    - 00 (0): VI produced, good quality    - 01 (1): VI produced, check other QA    - 10 (2): Pixel produced, probably cloudy    - 11 (3): Pixel not produced due to other reason (not clouds) - Bits 2-5: VI Usefulness    - 0000 (0): Highest quality    - 0001 (1): Lower quality    - 0010 (2): Decreasing quality    - 0100 (4): Decreasing quality    - 1000 (8): Decreasing quality    - 1001 (9): Decreasing quality    - 1010 (10): Decreasing quality    - 1100 (12): Lowest quality    - 1101 (13): Quality so low that it is not useful    - 1110 (14): L1B data faulty    - 1111 (15): Not useful for any other reason/not processed - Bits 6-7: Aerosol quantity    - 00 (0): Climatology    - 01 (1): Low    - 10 (2): Average    - 11 (3): High - Bit 8: Adjacent cloud detected    - 0: No    - 1: Yes - Bit 9: Atmosphere BRDF correction performed    - 0: No    - 1: Yes - Bit 10: Mixed Clouds     - 0: No     - 1: Yes - Bits 11-13: Land/Water flag    - 000 (0): Shallow ocean    - 001 (1): Land    - 010 (2): Ocean coastlines and lake shorelines    - 011 (3): Shallow inland water    - 100 (4): Ephemeral water    - 101 (5): Deep inland water    - 110 (6): Moderate or continental ocean    - 111 (7): Deep ocean - Bit 14: Possible snow/ice    - 0: No    - 1: Yes - Bit 15: Possible shadow    - 0: No    - 1: Yes  Please visit [LP DAAC 'Citing Our Data' page](https://lpdaac.usgs.gov/citing_our_data) for information on citing LP DAAC datasets. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class MODIS_NTSG_MOD16A2_105:
    def __init__(self,):
        self.sensor = 'MODIS_NTSG_MOD16A2_105'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/MODIS_NTSG_MOD16A2_105.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/MODIS_NTSG_MOD16A2_105.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_MODIS_NTSG_MOD16A2_105(example: str = ''):
        """
        The MOD16A2 V105 product provides information about 8-day global terrestrial evapotranspiration at 1km pixel resolution. Evapotranspiration (ET) is the sum of evaporation and plant transpiration from the Earth's surface to the atmosphere. With long-term ET data, the effects of changes in climate, land use, and ecosystems disturbances can be quantified.  The MOD16A2 product is produced by the Numerical Terradynamic Simulation Group [NTSG](https://www.ntsg.umt.edu/), University of Montana (UMT) in conjunction with NASA Earth Observing System. For more details about the algorithm used see the [algorithm theoretical basis document](https://scholarworks.umt.edu/cgi/viewcontent.cgi?article=1267&context=ntsg_pubs).  * The period of coverage is 8 days with the exception of the last period at the end of the year which is either 5 or 6 days. ET/PET units are 0.1mm/5-day for December 27-31 of 2001, 2002, 2003, 2005, 2006, 2007, 2009, 2010, and 0.1mm/6-day for December 26-31 of 2000, 2004, 2008 (leap years).  ** For some pixels in African rainforest, the MODIS albedo data from MCD43B2/MCD43B3 have no cloud-free data throughout an entire year. As a result, pixels for that year in all data bands are masked out. 
        :param example: var dataset = ee.ImageCollection('MODIS/NTSG/MOD16A2/105')                   .filter(ee.Filter.date('2014-04-01', '2014-06-01')); var evapotranspiration = dataset.select('ET'); var evapotranspirationVis = {   min: 0,   max: 300,   palette:       ['a50000', 'ff4f1a', 'f1e342', 'c7ef1f', '05fff3', '1707ff', 'd90bff'], }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(evapotranspiration, evapotranspirationVis, 'Evapotranspiration'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_ASTER_GED_AG100_003:
    def __init__(self,):
        self.sensor = 'NASA_ASTER_GED_AG100_003'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_ASTER_GED_AG100_003.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_ASTER_GED_AG100_003.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_ASTER_GED_AG100_003(example: str = ''):
        """
        The Advanced Spaceborne Thermal Emission and Reflection Radiometer Global Emissivity Database (ASTER-GED) was developed by the National Aeronautics and Space Administration's (NASA) Jet Propulsion Laboratory (JPL), California Institute of Technology. This product includes the mean emissivity and standard deviation for all 5 ASTER Thermal Infrared bands, mean land surface temperature (LST) and standard deviation, a re-sampled ASTER GDEM, land-water mask, mean Normalized Difference Vegetation Index (NDVI) and standard deviation, and observation count.  ASTER-GED land surface temperature and emissivity (LST&E) are generated using the ASTER Temperature Emissivity Separation (TES) algorithm in combination with a Water Vapor Scaling (WVS) atmospheric correction method using MODIS MOD07 atmospheric profiles and the MODTRAN 5.2 radiative transfer model.  This product was derived from clear-sky pixels for all available ASTER data (2000-2008).  [User's Guide] (https://lpdaac.usgs.gov/documents/120/ASTERGED_User_Guide_V3.pdf) 
        :param example: var dataset = ee.Image('NASA/ASTER_GED/AG100_003'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -15.0,   max: 5000.0,   palette: [     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef', '3ae237',     'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08',     'ff500d', 'ff0000', 'de0101', 'c21301'   ], }; Map.setCenter(89.12, 37.72, 3); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_EMIT_L2B_CH4ENH:
    def __init__(self,):
        self.sensor = 'NASA_EMIT_L2B_CH4ENH'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_EMIT_L2B_CH4ENH.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_EMIT_L2B_CH4ENH.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_EMIT_L2B_CH4ENH(example: str = ''):
        """
        The EMIT Project is part of the Earth Venture-Instrument (EV-I) Program directed by the Program Director of the NASA Earth Science Division (ESD). EMIT is comprised of a VSWIR Infrared Dyson imaging spectrometer adapted for installation on the International Space Station (ISS). EMIT measures radiance between 380 and 2500 nanometers, with an approximate 7 nm bandpass. Data are collected in a swath that is approximately 75 km wide at the equator, with an approximate ground sampling distance of 60 m. See the provider's [NASA EMIT Overview](https://lpdaac.usgs.gov/documents/1695/EMIT_L2B_GHG_User_Guide_V1.pdf) for more details.  EMIT was a particularly useful tool for mapping out greenhouse gases, including methane, carbon dioxide, and water vapor. This is consistent with previous findings from airborne data, but global nature, revisit frequency and wide swath of EMIT provided an unprecedented opportunity to investigate greenhouse gas retrievals.  The EMIT Level 2B Methane Enhancement Data (EMITL2BCH4ENH) Version 1 data product is a total vertical column enhancement estimate of methane in parts per million meter (ppm m) based on an adaptive matched filter approach. EMITL2BCH4ENH provides per-pixel methane enhancement data used to identify methane plume complexes. The initial release of the EMITL2BCH4ENH data product will only include granules where methane plume complexes have been identified. 
        :param example: var dataset = ee.ImageCollection('NASA/EMIT/L2B/CH4ENH'); var emitEnhancement = dataset.select('vertical_column_enhancement'); var emitEnhancementVis = {   min: 0,   max: 100.0,   palette: ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], }; Map.setCenter(-100.24, 32.04, 5); Map.addLayer(     emitEnhancement, emitEnhancementVis,     'Emit Enhancement');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_EMIT_L2B_CH4PLM:
    def __init__(self,):
        self.sensor = 'NASA_EMIT_L2B_CH4PLM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_EMIT_L2B_CH4PLM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_EMIT_L2B_CH4PLM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_EMIT_L2B_CH4PLM(example: str = ''):
        """
        The EMIT Project is part of the Earth Venture-Instrument (EV-I) Program directed by the Program Director of the NASA Earth Science Division (ESD). EMIT is comprised of a VSWIR Infrared Dyson imaging spectrometer adapted for installation on the International Space Station (ISS). EMIT measures radiance between 380 and 2500 nanometers, with an approximate 7 nm bandpass. Data are collected in a swath that is approximately 75 km wide at the equator, with an approximate ground sampling distance of 60 m. See the provider's [NASA EMIT Overview](https://lpdaac.usgs.gov/documents/1695/EMIT_L2B_GHG_User_Guide_V1.pdf) for more details.  EMIT was a particularly useful tool for mapping out greenhouse gases, including methane, carbon dioxide, and water vapor. This is consistent with previous findings from airborne data, but global nature, revisit frequency and wide swath of EMIT provided an unprecedented opportunity to investigate greenhouse gas retrievals.  The EMIT Level 2B Estimated Methane Plume Complexes (EMITL2BCH4PLM) Version 1 data product provides estimated methane plume complexes in parts per million meter (ppm m) along with uncertainty data. The EMITL2BCH4PLM data product will only be generated where methane plume complexes have been identified. 
        :param example: var dataset = ee.ImageCollection('NASA/EMIT/L2B/CH4PLM'); var emitEnhancement = dataset.select('methane_plume_complex'); var emitEnhancementVis = {   min: 0,   max: 100.0,   palette: ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], }; Map.setCenter(53.99, 39.11, 8); Map.addLayer(     emitEnhancement, emitEnhancementVis,     'Emit Enhancement'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_FLDAS_NOAH01_C_GL_M_V001:
    def __init__(self,):
        self.sensor = 'NASA_FLDAS_NOAH01_C_GL_M_V001'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_FLDAS_NOAH01_C_GL_M_V001.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_FLDAS_NOAH01_C_GL_M_V001.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_FLDAS_NOAH01_C_GL_M_V001(example: str = ''):
        """
        The FLDAS dataset (McNally et al. 2017), was designed to assist with food security assessments in data-sparse, developing country settings. It includes information on many climate-related variables including moisture content, humidity, evapotranspiration, average soil temperature, total precipitation rate, etc.  There are multiple different FLDAS datasets; this one uses Noah version 3.6.1 surface model with CHIRPS-6 hourly rainfall that has been downscaled using the [NASA Land Surface Data Toolkit](https://lis.gsfc.nasa.gov/software/ldt). which is part of the [Land Information System framework](LIS; [https://lis.gsfc.nasa.gov/](https://lis.gsfc.nasa.gov/)). Temporal desegregation is required so that daily rainfall inputs can be used in both energy and water balance calculations  For forcing data, this simulation uses a combination of the new version of Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2) data and Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS), a quasi-global rainfall dataset designed for seasonal drought monitoring and trend analysis (Funk et al., 2015).  Documentation:  * [Readme](https://hydro1.gesdisc.eosdis.nasa.gov/data/FLDAS/FLDAS_NOAH01_C_GL_M.001/doc/README_FLDAS.pdf)  * [How-to](https://disc.gsfc.nasa.gov/information/howto?tags=hydrology)  * [GES DISC Hydrology Documentation](https://disc.gsfc.nasa.gov/information/documents?title=Hydrology%20Documentation) 
        :param example: var dataset=ee.ImageCollection('NASA/FLDAS/NOAH01/C/GL/M/V001')               .filter(ee.Filter.date('2018-11-01', '2018-12-01')); var layer = dataset.select('Evap_tavg');  var band_viz = {   min: 0.0,   max: 0.00005,   opacity: 1.0,   palette: ['black', 'blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  Map.setCenter(30.0, 30.0, 2); Map.addLayer(layer, band_viz, 'Average Evapotranspiration');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GDDP_CMIP6:
    def __init__(self,):
        self.sensor = 'NASA_GDDP_CMIP6'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GDDP-CMIP6.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GDDP-CMIP6.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GDDP_CMIP6(example: str = ''):
        """
        The NEX-GDDP-CMIP6 dataset is comprised of global downscaled climate scenarios derived from the General Circulation Model (GCM) runs conducted under the Coupled Model Intercomparison Project Phase 6 (CMIP6, see [Thrasher et al. 2022](https://doi.org/10.7917/OFSG3345)) and across two of the four "Tier 1" greenhouse gas emissions scenarios known as Shared Socioeconomic Pathways (SSPs).  The CMIP6 GCM runs were developed in support of the Sixth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC AR6). This dataset includes downscaled projections from ScenarioMIP model runs for which daily scenarios were produced and distributed through the Earth System Grid Federation.  See also [the provider tech note](https://www.nccs.nasa.gov/sites/default/files/NEX-GDDP-CMIP6-Tech_Note.pdf).  [You can submit data questions about CMIP6 to the provider](https://airtable.com/shr01weJfA7DYq6jf) and [see their answers](https://airtable.com/shrX4mj20TLSH0r2y/tblUMAYpCfCCwucSV). 
        :param example: var dataset = ee.ImageCollection('NASA/GDDP-CMIP6')                   .filter(ee.Filter.date('2014-07-01', '2014-07-02'))                   .filter(ee.Filter.eq('model', 'ACCESS-CM2')); var minimumAirTemperature = dataset.select('tasmin'); var minimumAirTemperatureVis = {   min: 240,   max: 310,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(71, 52, 3); Map.addLayer(     minimumAirTemperature, minimumAirTemperatureVis,     'Minimum Air Temperature (K)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GEOS_CF_v1_fcst_htf:
    def __init__(self,):
        self.sensor = 'NASA_GEOS_CF_v1_fcst_htf'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GEOS-CF_v1_fcst_htf.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GEOS-CF_v1_fcst_htf.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GEOS_CF_v1_fcst_htf(example: str = ''):
        """
        This dataset contains meteorological forecast (fcst) of high-temporal frequency data (htf). Use the 'creation_time' and 'forecast_time' properties to select data of interest. The Goddard Earth Observing System Composition Forecast (GEOS-CF) system is a high-resolution (0.25&deg;) global constituent prediction system from NASA's [Global Modeling and Assimilation Office(GMAO)]( https://gmao.gsfc.nasa.gov/).  GEOS-CF offers a new tool for atmospheric chemistry research, with the goal to supplement NASA's broad range of space-based and in-situ observations. GEOS-CF expands on the GEOS weather and aerosol modeling system by introducing the [GEOS-Chem](http://wiki.seas.harvard.edu/geos-chem/) chemistry module to provide hindcasts and 5-days forecasts of atmospheric constituents including ozone (O3), carbon monoxide (CO), nitrogen dioxide (NO2), sulfur dioxide (SO2), and fine particulate matter (PM2.5). The chemistry module integrated in GEOS-CF is identical to the offline GEOS-Chem model and readily benefits from the innovations provided by the GEOS-Chem community.  Evaluation of GEOS-CF against satellite, ozonesonde, and surface observations for years 2018&ndash;2019 shows realistic simulated concentrations of O3, NO2, and CO, with normalized mean biases of &minus;0.1 to 0.3, normalized root mean square errors between 0.1&ndash;0.4, and correlations between 0.3&ndash;0.8. Comparisons against surface observations highlight the successful representation of air pollutants in many regions of the world and during all seasons, yet also highlight current limitations, such as a global high bias in SO2 and an overprediction of summertime O3 over the Southeast United States.  GEOS-CF v1.0 generally overestimates aerosols by 20%&ndash;50% due to known issues in GEOS-Chem v12.0.1 that have been addressed in later versions. The 5-days forecasts have skill scores comparable to the 1-day hindcast. Model skills can be improved significantly by applying a bias-correction to the surface model output using a machine-learning approach. 
        :param example: var imageVisParamNO2 = {   'bands': ['NO2'],   'min': 6.96e-11,   'max': 4.42e-8, };  var imageVisParamT = {   'bands': ['T'],   'min': 220,   'max': 320,   'palette': ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], };  var geosCf = ee.ImageCollection('NASA/GEOS-CF/v1/fcst/htf');  Map.setCenter(100, 20, 3);  var weeklyT =     geosCf.select('T').filterDate('2022-11-01', '2022-11-08').median(); Map.addLayer(weeklyT, imageVisParamT, 'Weekly T', false, 1);  var NO2 = ee.Image('NASA/GEOS-CF/v1/fcst/htf/20221215_12z-20221216_1200z'); Map.addLayer(NO2, imageVisParamNO2, 'NO2', true, 1); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GEOS_CF_v1_fcst_tavg1hr:
    def __init__(self,):
        self.sensor = 'NASA_GEOS_CF_v1_fcst_tavg1hr'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GEOS-CF_v1_fcst_tavg1hr.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GEOS-CF_v1_fcst_tavg1hr.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GEOS_CF_v1_fcst_tavg1hr(example: str = ''):
        """
        This dataset contains meteorological forecast (fcst) of time-averaged frequency data (tavg1hr). Use the 'creation_time' and 'forecast_time' properties to select data of interest. The Goddard Earth Observing System Composition Forecast (GEOS-CF) system is a high-resolution (0.25&deg;) global constituent prediction system from NASA's [Global Modeling and Assimilation Office(GMAO)]( https://gmao.gsfc.nasa.gov/).  GEOS-CF offers a new tool for atmospheric chemistry research, with the goal to supplement NASA's broad range of space-based and in-situ observations. GEOS-CF expands on the GEOS weather and aerosol modeling system by introducing the [GEOS-Chem](http://wiki.seas.harvard.edu/geos-chem/) chemistry module to provide hindcasts and 5-days forecasts of atmospheric constituents including ozone (O3), carbon monoxide (CO), nitrogen dioxide (NO2), sulfur dioxide (SO2), and fine particulate matter (PM2.5). The chemistry module integrated in GEOS-CF is identical to the offline GEOS-Chem model and readily benefits from the innovations provided by the GEOS-Chem community.  Evaluation of GEOS-CF against satellite, ozonesonde, and surface observations for years 2018&ndash;2019 shows realistic simulated concentrations of O3, NO2, and CO, with normalized mean biases of &minus;0.1 to 0.3, normalized root mean square errors between 0.1&ndash;0.4, and correlations between 0.3&ndash;0.8. Comparisons against surface observations highlight the successful representation of air pollutants in many regions of the world and during all seasons, yet also highlight current limitations, such as a global high bias in SO2 and an overprediction of summertime O3 over the Southeast United States.  GEOS-CF v1.0 generally overestimates aerosols by 20%&ndash;50% due to known issues in GEOS-Chem v12.0.1 that have been addressed in later versions. The 5-days forecasts have skill scores comparable to the 1-day hindcast. Model skills can be improved significantly by applying a bias-correction to the surface model output using a machine-learning approach. 
        :param example: var imageVisParamNO2 = {   'bands': ['NO2'],   'min': 6.96e-11,   'max': 4.42e-8, };  var imageVisParamT = {   'bands': ['T'],   'min': 220,   'max': 320,   'palette': ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], };  var geosCf = ee.ImageCollection('NASA/GEOS-CF/v1/fcst/tavg1hr');  Map.setCenter(100, 20, 3);  var weeklyT =     geosCf.select('T').filterDate('2022-11-01', '2022-11-08').median(); Map.addLayer(weeklyT, imageVisParamT, 'Weekly T', false, 1);  var NO2 = ee.Image('NASA/GEOS-CF/v1/fcst/tavg1hr/20220921_12z-20220921_1230z'); Map.addLayer(NO2, imageVisParamNO2, 'NO2', true, 1); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GEOS_CF_v1_rpl_htf:
    def __init__(self,):
        self.sensor = 'NASA_GEOS_CF_v1_rpl_htf'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GEOS-CF_v1_rpl_htf.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GEOS-CF_v1_rpl_htf.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GEOS_CF_v1_rpl_htf(example: str = ''):
        """
        This dataset contains meteorological replay (rpl) of high-temporal frequency data (htf). The Goddard Earth Observing System Composition Forecast (GEOS-CF) system is a high-resolution (0.25&deg;) global constituent prediction system from NASA's [Global Modeling and Assimilation Office(GMAO)]( https://gmao.gsfc.nasa.gov/).  GEOS-CF offers a new tool for atmospheric chemistry research, with the goal to supplement NASA's broad range of space-based and in-situ observations. GEOS-CF expands on the GEOS weather and aerosol modeling system by introducing the [GEOS-Chem](http://wiki.seas.harvard.edu/geos-chem/) chemistry module to provide hindcasts and 5-days forecasts of atmospheric constituents including ozone (O3), carbon monoxide (CO), nitrogen dioxide (NO2), sulfur dioxide (SO2), and fine particulate matter (PM2.5). The chemistry module integrated in GEOS-CF is identical to the offline GEOS-Chem model and readily benefits from the innovations provided by the GEOS-Chem community.  Evaluation of GEOS-CF against satellite, ozonesonde, and surface observations for years 2018&ndash;2019 shows realistic simulated concentrations of O3, NO2, and CO, with normalized mean biases of &minus;0.1 to 0.3, normalized root mean square errors between 0.1&ndash;0.4, and correlations between 0.3&ndash;0.8. Comparisons against surface observations highlight the successful representation of air pollutants in many regions of the world and during all seasons, yet also highlight current limitations, such as a global high bias in SO2 and an overprediction of summertime O3 over the Southeast United States.  GEOS-CF v1.0 generally overestimates aerosols by 20%&ndash;50% due to known issues in GEOS-Chem v12.0.1 that have been addressed in later versions. The 5-days forecasts have skill scores comparable to the 1-day hindcast. Model skills can be improved significantly by applying a bias-correction to the surface model output using a machine-learning approach. 
        :param example: var imageVisParamNO2 = {   'bands': ['NO2'],   'min': 6.96e-11,   'max': 4.42e-8, };  var imageVisParamT = {   'bands': ['T'],   'min': 220,   'max': 320,   'palette': ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], };  var geosCf = ee.ImageCollection('NASA/GEOS-CF/v1/rpl/htf');  Map.setCenter(100, 20, 3);  var weeklyT =     geosCf.select('T').filterDate('2019-06-01', '2019-06-08').median(); Map.addLayer(weeklyT, imageVisParamT, 'Weekly T', false, 1);  var NO2 = ee.Image('NASA/GEOS-CF/v1/rpl/htf/20190601_0000z'); Map.addLayer(NO2, imageVisParamNO2, 'NO2', true, 1); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GEOS_CF_v1_rpl_tavg1hr:
    def __init__(self,):
        self.sensor = 'NASA_GEOS_CF_v1_rpl_tavg1hr'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GEOS-CF_v1_rpl_tavg1hr.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GEOS-CF_v1_rpl_tavg1hr.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GEOS_CF_v1_rpl_tavg1hr(example: str = ''):
        """
        This dataset contains meteorological replay (rpl) of time-average one hour data (tavg1hr). It is built by merging the original GEOS-CF collections chm_tavg_1hr_g1440x721_v1, met_tavg_1hr_g1440x721_x1, and xgc_tavg_1hr_g1440x721_x1. The Goddard Earth Observing System Composition Forecast (GEOS-CF) system is a high-resolution (0.25&deg;) global constituent prediction system from NASA's [Global Modeling and Assimilation Office(GMAO)]( https://gmao.gsfc.nasa.gov/).  GEOS-CF offers a new tool for atmospheric chemistry research, with the goal to supplement NASA's broad range of space-based and in-situ observations. GEOS-CF expands on the GEOS weather and aerosol modeling system by introducing the [GEOS-Chem](http://wiki.seas.harvard.edu/geos-chem/) chemistry module to provide hindcasts and 5-days forecasts of atmospheric constituents including ozone (O3), carbon monoxide (CO), nitrogen dioxide (NO2), sulfur dioxide (SO2), and fine particulate matter (PM2.5). The chemistry module integrated in GEOS-CF is identical to the offline GEOS-Chem model and readily benefits from the innovations provided by the GEOS-Chem community.  Evaluation of GEOS-CF against satellite, ozonesonde, and surface observations for years 2018&ndash;2019 shows realistic simulated concentrations of O3, NO2, and CO, with normalized mean biases of &minus;0.1 to 0.3, normalized root mean square errors between 0.1&ndash;0.4, and correlations between 0.3&ndash;0.8. Comparisons against surface observations highlight the successful representation of air pollutants in many regions of the world and during all seasons, yet also highlight current limitations, such as a global high bias in SO2 and an overprediction of summertime O3 over the Southeast United States.  GEOS-CF v1.0 generally overestimates aerosols by 20%&ndash;50% due to known issues in GEOS-Chem v12.0.1 that have been addressed in later versions. The 5-days forecasts have skill scores comparable to the 1-day hindcast. Model skills can be improved significantly by applying a bias-correction to the surface model output using a machine-learning approach. 
        :param example: var imageVisParamNO2 = {   'bands': ['NO2'],   'min': 6.96e-11,   'max': 4.42e-8, };  var imageVisParamT = {   'bands': ['T'],   'min': 220,   'max': 320,   'palette': ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'], };  var geosCf = ee.ImageCollection('NASA/GEOS-CF/v1/rpl/tavg1hr');  Map.setCenter(100, 20, 3);  var weeklyT =     geosCf.select('T').filterDate('2018-01-01', '2018-01-08').median(); Map.addLayer(weeklyT, imageVisParamT, 'Weekly T', false, 1);  var NO2 = ee.Image('NASA/GEOS-CF/v1/rpl/tavg1hr/20180101_0030z'); Map.addLayer(NO2, imageVisParamNO2, 'NO2', true, 1); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GIMMS_3GV0:
    def __init__(self,):
        self.sensor = 'NASA_GIMMS_3GV0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GIMMS_3GV0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GIMMS_3GV0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GIMMS_3GV0(example: str = ''):
        """
        GIMMS NDVI is generated from several NOAA's AVHRR sensors for a global 1/12-degree lat/lon grid. The latest version of the GIMMS NDVI dataset is named NDVI3g (third generation GIMMS NDVI from AVHRR sensors). 
        :param example: var dataset = ee.ImageCollection('NASA/GIMMS/3GV0')                   .filter(ee.Filter.date('2013-06-01', '2013-12-31')); var ndvi = dataset.select('ndvi'); var ndviVis = {   min: -1.0,   max: 1.0,   palette: ['000000', 'f5f5f5', '119701'], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GLDAS_V021_NOAH_G025_T3H:
    def __init__(self,):
        self.sensor = 'NASA_GLDAS_V021_NOAH_G025_T3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GLDAS_V021_NOAH_G025_T3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GLDAS_V021_NOAH_G025_T3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GLDAS_V021_NOAH_G025_T3H(example: str = ''):
        """
        NASA Global Land Data Assimilation System Version 2 (GLDAS-2) has three components: GLDAS-2.0, GLDAS-2.1, and GLDAS-2.2. GLDAS-2.0 is forced entirely with the Princeton meteorological forcing input data and provides a temporally consistent series from 1948 through 2014. GLDAS-2.1 is forced with a combination of model and observation data from 2000 to present. GLDAS-2.2 product suites use data assimilation (DA), whereas the GLDAS-2.0 and GLDAS-2.1 products are "open-loop" (i.e., no data assimilation). The choice of forcing data, as well as DA observation source, variable, and scheme, vary for different GLDAS-2.2 products.GLDAS-2.1 is one of two components of the GLDAS Version 2 (GLDAS-2) dataset, the second being GLDAS-2.0. GLDAS-2.1 is analogous to GLDAS-1 product stream, with upgraded models forced by a combination of [GDAS, disaggregated GPCP, and AGRMET radiation data sets](https://ldas.gsfc.nasa.gov/gldas/GLDASforcing.php).  The GLDAS-2.1 simulation started on January 1, 2000 using the conditions from the GLDAS-2.0 simulation. This simulation was forced with National Oceanic and Atmospheric Administration (NOAA)/Global Data Assimilation System (GDAS) atmospheric analysis fields (Derber et al., 1991), the disaggregated Global Precipitation Climatology Project (GPCP) precipitation fields (Adler et al., 2003), and the Air Force Weather Agency's AGRicultural METeorological modeling system (AGRMET) radiation fields which became available for March 1, 2001 onwards.  Documentation:  * [Readme](https://hydro1.gesdisc.eosdis.nasa.gov/data/GLDAS/GLDAS_NOAH025_3H.2.1/doc/README_GLDAS2.pdf)  * [How-to](https://disc.gsfc.nasa.gov/information/howto?tags=hydrology)  * [GES DISC Hydrology Documentation](https://disc.gsfc.nasa.gov/information/documents?title=Hydrology%20Documentation)  * [GES DISC Data Rods Documentation](https://disc.gsfc.nasa.gov/information/tools?title=Hydrology%20Data%20Rods)  Provider's Note: the names with extension _tavg are variables averaged over the past 3-hours, the names with extension '_acc' are variables accumulated over the past 3-hours, the names with extension '_inst' are instantaneous variables, and the names with '_f' are forcing variables. 
        :param example: var dataset = ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')                   .filter(ee.Filter.date('2010-06-01', '2010-06-02')); var averageSurfaceSkinTemperatureK = dataset.select('AvgSurfT_inst'); var averageSurfaceSkinTemperatureKVis = {   min: 250.0,   max: 300.0,   palette: ['1303ff', '42fff6', 'f3ff40', 'ff5d0f'], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(     averageSurfaceSkinTemperatureK, averageSurfaceSkinTemperatureKVis,     'Average Surface Skin Temperature [K]'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GLDAS_V022_CLSM_G025_DA1D:
    def __init__(self,):
        self.sensor = 'NASA_GLDAS_V022_CLSM_G025_DA1D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GLDAS_V022_CLSM_G025_DA1D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GLDAS_V022_CLSM_G025_DA1D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GLDAS_V022_CLSM_G025_DA1D(example: str = ''):
        """
        NASA Global Land Data Assimilation System Version 2 (GLDAS-2) has three components: GLDAS-2.0, GLDAS-2.1, and GLDAS-2.2. GLDAS-2.0 is forced entirely with the Princeton meteorological forcing input data and provides a temporally consistent series from 1948 through 2014. GLDAS-2.1 is forced with a combination of model and observation data from 2000 to present. GLDAS-2.2 product suites use data assimilation (DA), whereas the GLDAS-2.0 and GLDAS-2.1 products are "open-loop" (i.e., no data assimilation). The choice of forcing data, as well as DA observation source, variable, and scheme, vary for different GLDAS-2.2 products.GLDAS-2.2 is new to the GES DISC archive and currently includes a main product from CLSM-F2.5 with Data Assimilation for the Gravity Recovery and Climate Experiment (GRACE-DA) from February 2003 to present. The GLDAS-2.2 data are available in two production streams: main and Early, only main one is ingested.  The GLDAS-2.2 GRACE-DA product was simulated with Catchment-F2.5 in Land Information System (LIS) Version 7. The data product contains 24 land surface fields from February 1, 2003 to present.  The simulation started on February 1, 2003 using the conditions from the GLDAS-2.0 Daily Catchment model simulation, forced with the meteorological analysis fields from the operational European Centre for Medium-Range Weather Forecasts (ECMWF) Integrated Forecasting System. The total terrestrial water anomaly observation from GRACE satellite was assimilated (Li et al, 2019). Due to the data agreement with ECMWF, this GLDAS-2.2 daily product does not include the meteorological forcing fields.  Documentation:  * [Readme](https://hydro1.gesdisc.eosdis.nasa.gov/data/GLDAS/GLDAS_CLSM025_DA1_D.2.2/doc/README_GLDAS2.pdf)  * [How-to](https://disc.gsfc.nasa.gov/information/howto?tags=hydrology)  * [GES DISC Hydrology Documentation](https://disc.gsfc.nasa.gov/information/documents?title=Hydrology%20Documentation)  Provider's Note: the names with extension _tavg are variables averaged over the past 3-hours, the names with extension '_acc' are variables accumulated over the past 3-hours, the names with extension '_inst' are instantaneous variables, and the names with '_f' are forcing variables. 
        :param example: var dataset = ee.ImageCollection('NASA/GLDAS/V022/CLSM/G025/DA1D')                   .filter(ee.Filter.date('2010-06-01', '2010-06-02')); var averageSurfaceSkinTemperatureK = dataset.select('AvgSurfT_tavg'); var averageSurfaceSkinTemperatureKVis = {   min: 258,   max: 316,   palette: ['1303ff', '42fff6', 'f3ff40', 'ff5d0f'], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(     averageSurfaceSkinTemperatureK, averageSurfaceSkinTemperatureKVis,     'Average Surface Skin Temperature [K]'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GLDAS_V20_NOAH_G025_T3H:
    def __init__(self,):
        self.sensor = 'NASA_GLDAS_V20_NOAH_G025_T3H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GLDAS_V20_NOAH_G025_T3H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GLDAS_V20_NOAH_G025_T3H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GLDAS_V20_NOAH_G025_T3H(example: str = ''):
        """
        NASA Global Land Data Assimilation System Version 2 (GLDAS-2) has three components: GLDAS-2.0, GLDAS-2.1, and GLDAS-2.2. GLDAS-2.0 is forced entirely with the Princeton meteorological forcing input data and provides a temporally consistent series from 1948 through 2014. GLDAS-2.1 is forced with a combination of model and observation data from 2000 to present. GLDAS-2.2 product suites use data assimilation (DA), whereas the GLDAS-2.0 and GLDAS-2.1 products are "open-loop" (i.e., no data assimilation). The choice of forcing data, as well as DA observation source, variable, and scheme, vary for different GLDAS-2.2 products.GLDAS-2.0 is one of two components of the GLDAS Version 2 (GLDAS-2) dataset, the second being GLDAS-2.1. GLDAS-2.0 is reprocessed with the updated Princeton Global Meteorological Forcing Dataset (Sheffield et al., 2006) and upgraded Land Information System Version 7 (LIS-7). It covers the period 1948-2010, and will be extended to more recent years as corresponding forcing data become available.  The model simulation was initialized on January 1, 1948, using soil moisture and other state fields from the LSM climatology for that day of the year. The simulation used the common GLDAS datasets for land cover (MCD12Q1: Friedl et al., 2010), land water mask (MOD44W: Carroll et al., 2009), soil texture (Reynolds, 1999), and elevation (GTOPO30). The MODIS based land surface parameters are used in the current GLDAS-2.x products while the AVHRR base parameters were used in GLDAS-1 and previous GLDAS-2 products (prior to October 2012).  Documentation:  * [Readme](https://hydro1.gesdisc.eosdis.nasa.gov/data/GLDAS/GLDAS_NOAH025_3H.2.0/doc/README_GLDAS2.pdf)  * [How-to](https://disc.gsfc.nasa.gov/information/howto?tags=hydrology)  * [GES DISC Hydrology Documentation](https://disc.gsfc.nasa.gov/information/documents?title=Hydrology%20Documentation)  Provider's Note: the names with extension _tavg are variables averaged over the past 3-hours, the names with extension '_acc' are variables accumulated over the past 3-hours, the names with extension '_inst' are instantaneous variables, and the names with '_f' are forcing variables. 
        :param example: var dataset = ee.ImageCollection('NASA/GLDAS/V20/NOAH/G025/T3H')                   .filter(ee.Filter.date('2010-06-01', '2010-06-02')); var averageSurfaceSkinTemperatureK = dataset.select('AvgSurfT_inst'); var averageSurfaceSkinTemperatureKVis = {   min: 250.0,   max: 300.0,   palette: ['1303ff', '42fff6', 'f3ff40', 'ff5d0f'], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(     averageSurfaceSkinTemperatureK, averageSurfaceSkinTemperatureKVis,     'Average Surface Skin Temperature [K]'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GPM_L3_IMERG_MONTHLY_V06:
    def __init__(self,):
        self.sensor = 'NASA_GPM_L3_IMERG_MONTHLY_V06'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GPM_L3_IMERG_MONTHLY_V06.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GPM_L3_IMERG_MONTHLY_V06.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GPM_L3_IMERG_MONTHLY_V06(example: str = ''):
        """
        IMERG-Final version "06" stopped being produced in September, 2021. Version "07" is expected to be released in September 2022  Global Precipitation Measurement (GPM) is an international satellite mission to provide next-generation observations of rain and snow worldwide every three hours. The Integrated Multi-satellitE Retrievals for GPM (IMERG) is the unified algorithm that provides rainfall estimates combining data from all passive-microwave instruments in the GPM Constellation.  This algorithm is intended to intercalibrate, merge, and interpolate all satellite microwave precipitation estimates, together with microwave-calibrated infrared (IR) satellite estimates, precipitation gauge analyses, and potentially other precipitation estimators at fine time and space scales for the TRMM and GPM eras over the entire globe. The system is run several times for each observation time, first giving a quick estimate and successively providing better estimates as more data arrive. The final step uses monthly gauge data to create research-level products. See [IMERG Technical Documentation](https://pmm.nasa.gov/sites/default/files/document_files/IMERG_doc.pdf) for more details on the algorithm.  Documentation: * [Algorithm Theoretical Basis Document](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_ATBD_V06.pdf)  * [IMERG Quality Index](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERGV06_QI.pdf)  * [Caveats for IMERG extension into TRMM era](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERGV06_TRMMera-caveats.pdf)  * [IMERG Technical Documentation](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_doc.06.pdf)  * [Release notes; New Morphing algorithm](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/MorphingInV06IMERG.pdf)  * [Remote-Sensing Reflectance](https://gpm1.gesdisc.eosdis.nasa.gov/data/GPM_L3/doc/README.GPM.pdf)  * [Anomalies](ftp://gpmweb2.pps.eosdis.nasa.gov/tsdis/AB/docs/gpm_anomalous.html)  This collection contains data from [GPM_3IMERGM_06](https://disc.gsfc.nasa.gov/datasets/GPM_3IMERGM_V06/summary) 
        :param example: var dataset = ee.ImageCollection('NASA/GPM_L3/IMERG_MONTHLY_V06')     .filterDate('2019-01-01', '2020-01-01');  // Select the max precipitation and mask out low precipitation values. var precipitation = dataset.select('precipitation').max(); var mask = precipitation.gt(0.25); var precipitation = precipitation.updateMask(mask);  var palette = [   '000096','0064ff', '00b4ff', '33db80', '9beb4a',   'ffeb00', 'ffb300', 'ff6400', 'eb1e00', 'af0000' ]; var precipitationVis = {min: 0.0, max: 1.5, palette: palette}; Map.addLayer(precipitation, precipitationVis, 'Precipitation (mm/hr)'); Map.setCenter(-76, 33, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GPM_L3_IMERG_V06:
    def __init__(self,):
        self.sensor = 'NASA_GPM_L3_IMERG_V06'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GPM_L3_IMERG_V06.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GPM_L3_IMERG_V06.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GPM_L3_IMERG_V06(example: str = ''):
        """
        Global Precipitation Measurement (GPM) is an international satellite mission to provide next-generation observations of rain and snow worldwide every three hours. The Integrated Multi-satellitE Retrievals for GPM (IMERG) is the unified algorithm that provides rainfall estimates combining data from all passive-microwave instruments in the GPM Constellation.  This algorithm is intended to intercalibrate, merge, and interpolate all satellite microwave precipitation estimates, together with microwave-calibrated infrared (IR) satellite estimates, precipitation gauge analyses, and potentially other precipitation estimators at fine time and space scales for the TRMM and GPM eras over the entire globe. The system is run several times for each observation time, first giving a quick estimate and successively providing better estimates as more data arrive. The final step uses monthly gauge data to create research-level products. See [IMERG Technical Documentation](https://pmm.nasa.gov/sites/default/files/document_files/IMERG_doc.pdf) for more details on the algorithm.  Documentation: * [Algorithm Theoretical Basis Document](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_ATBD_V06.pdf)  * [IMERG Quality Index](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERGV06_QI.pdf)  * [Caveats for IMERG extension into TRMM era](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERGV06_TRMMera-caveats.pdf)  * [IMERG Technical Documentation](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/IMERG_doc.06.pdf)  * [Release notes; New Morphing algorithm](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/MorphingInV06IMERG.pdf)  * [Remote-Sensing Reflectance](https://gpm1.gesdisc.eosdis.nasa.gov/data/doc/README.GPM.pdf)  * [Anomalies](https://gpmweb2https.pps.eosdis.nasa.gov/tsdis/AB/docs/gpm_anomalous.html)  This collection contains provisional products that are regularly replaced with updated versions when the data become available. The products are marked with a metadata property called 'status'. When a product is initially made available, the property value is 'provisional'. Once a provisional product has been updated with the final version, this value is updated to 'permanent'.  This collection contains data from:  * GPM_3IMERGHH_V06 [doi:10.5067/GPM/IMERG/3B-HH-L/06](https://doi.org/10.5067/GPM/IMERG/3B-HH-L/06) * GPM_3IMERGHH_06 [doi:10.5067/GPM/IMERG/3B-HH/06](https://doi.org/10.5067/GPM/IMERG/3B-HH/06) 
        :param example: // GPM V6 30 minute data around hurricane Dorian for a single day. var range = ee.Date('2019-09-03').getRange('day'); var dataset = ee.ImageCollection('NASA/GPM_L3/IMERG_V06')     .filter(ee.Filter.date(range));  // Select the max precipitation and mask out low precipitation values. var precipitation = dataset.select('precipitationCal').max(); var mask = precipitation.gt(0.5); var precipitation = precipitation.updateMask(mask);  var palette = [   '000096','0064ff', '00b4ff', '33db80', '9beb4a',   'ffeb00', 'ffb300', 'ff6400', 'eb1e00', 'af0000' ]; var precipitationVis = {min: 0, max: 15, palette: palette}; Map.addLayer(precipitation, precipitationVis, 'Precipitation (mm/hr)'); Map.setCenter(-76, 33, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GRACE_MASS_GRIDS_LAND:
    def __init__(self,):
        self.sensor = 'NASA_GRACE_MASS_GRIDS_LAND'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GRACE_MASS_GRIDS_LAND.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GRACE_MASS_GRIDS_LAND.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GRACE_MASS_GRIDS_LAND(example: str = ''):
        """
        GRACE Tellus Monthly Mass Grids provides monthly gravitational anomalies relative to a 2004-2010 time-mean baseline. The data contained in this dataset are units of \"Equivalent Water Thickness\" which represent the deviations of mass in terms of vertical extent of water in centimeters. See the provider's [Monthly Mass Grids Overview](https://grace.jpl.nasa.gov/data/monthly-mass-grids/) for more details.  The GRACE Tellus (GRCTellus) Monthly Mass Grids dataset is produced by three centers: CSR (U. Texas / Center for Space Research), GFZ (GeoForschungsZentrum Potsdam), and JPL (NASA Jet Propulsion Laboratory). Each center is a part of the GRACE Ground System and generates Level-2 data (spherical harmonic fields) used in this dataset. The output includes spherical harmonic coefficients of the gravity field and of the dealiasing fields used to compute them. Since each center independently produces the coefficients, the results may be slightly different. It is recommended for most users to use the mean of all three datasets. See the provider's [choosing a solution](https://grace.jpl.nasa.gov/data/choosing-a-solution/) page for more details.  **Note**  * Due to the sampling and post-processing of GRACE observations,   surface mass variations at small spatial scales tend to be attenuated.   Therefore, users should multiply the GRCTellus Land data by the   scaling grid available at   [NASA/GRACE/MASS_GRIDS/LAND_AUX_2014](https://code.earthengine.google.com/?asset=NASA/GRACE/MASS_GRIDS/LAND_AUX_2014).  * The GRCTellus Land grids processed from the Spherical Harmonic   Level-2 data are not suited to accurately quantify ice mass   changes over Greenland or Antarctica, or glaciers and ice caps.   For those areas it is recommended to use JPL's mascon   solution available as the following image collection:   [NASA/GRACE/MASS_GRIDS/MASCON](https://developers.google.com/earth-engine/datasets/catalog/NASA_GRACE_MASS_GRIDS_MASCON) 
        :param example: var dataset = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/LAND')                   .filter(ee.Filter.date('2016-08-01', '2016-08-30')); var equivalentWaterThicknessCsr = dataset.select('lwe_thickness_csr'); var equivalentWaterThicknessCsrVis = {   min: -25.0,   max: 25.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     equivalentWaterThicknessCsr, equivalentWaterThicknessCsrVis,     'Equivalent Water Thickness CSR'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GRACE_MASS_GRIDS_MASCON:
    def __init__(self,):
        self.sensor = 'NASA_GRACE_MASS_GRIDS_MASCON'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GRACE_MASS_GRIDS_MASCON.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GRACE_MASS_GRIDS_MASCON.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GRACE_MASS_GRIDS_MASCON(example: str = ''):
        """
        GRACE Tellus Monthly Mass Grids provides monthly gravitational anomalies relative to a 2004-2010 time-mean baseline. The data contained in this dataset are units of \"Equivalent Water Thickness\" which represent the deviations of mass in terms of vertical extent of water in centimeters. See the provider's [Monthly Mass Grids Overview](https://grace.jpl.nasa.gov/data/monthly-mass-grids/) for more details.  The GRACE Tellus (GRCTellus) Global Mascon dataset is based on Level-1 GRACE observations and processed at NASA Jet Propulsion Laboratory (JPL).  This dataset uses a-priori constraints in space and time to estimate global, monthly gravity fields in terms of equal-area 3&deg;x3&deg; spherical cap mass concentration (mascon) functions to minimize the effect of measurement errors. No additional empirical destriping filter has been applied to the data. This results in better S/N ratios of the mascon fields compared to the conventional spherical-harmonic solutions.  **Note**  * Mascons which lie on coastlines contain mixed land and ocean signals.   A version of this dataset with the Coastline Resolution Improvement   (CRI) filter applied to separate the land and ocean portions of mass   within each land/ocean mascon in a post-processing step. This   dataset is available at   [NASA/GRACE/MASS_GRIDS/MASCON_CRI](https://developers.google.com/earth-engine/datasets/catalog/NASA_GRACE_MASS_GRIDS_MASCON_CRI).  * The data are represented on a 1/2 degree lon-lat grid, but they   represent the 3x3 degree equal-area caps, which is the current   native resolution of JPL-RL05M. 
        :param example: var dataset = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/MASCON')                   .filter(ee.Filter.date('2016-08-01', '2016-08-30')); var equivalentWaterThickness = dataset.select('lwe_thickness'); var equivalentWaterThicknessVis = {   min: -25.0,   max: 25.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     equivalentWaterThickness, equivalentWaterThicknessVis,     'Equivalent Water Thickness'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GRACE_MASS_GRIDS_MASCON_CRI:
    def __init__(self,):
        self.sensor = 'NASA_GRACE_MASS_GRIDS_MASCON_CRI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GRACE_MASS_GRIDS_MASCON_CRI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GRACE_MASS_GRIDS_MASCON_CRI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GRACE_MASS_GRIDS_MASCON_CRI(example: str = ''):
        """
        GRACE Tellus Monthly Mass Grids provides monthly gravitational anomalies relative to a 2004-2010 time-mean baseline. The data contained in this dataset are units of \"Equivalent Water Thickness\" which represent the deviations of mass in terms of vertical extent of water in centimeters. See the provider's [Monthly Mass Grids Overview](https://grace.jpl.nasa.gov/data/monthly-mass-grids/) for more details.  The GRACE Tellus (GRCTellus) Global Mascon dataset is based on Level-1 GRACE observations and processed at NASA Jet Propulsion Laboratory (JPL).  This dataset uses a-priori constraints in space and time to estimate global, monthly gravity fields in terms of equal-area 3&deg;x3&deg; spherical cap mass concentration (mascon) functions to minimize the effect of measurement errors. This results in better S/N ratios of the mascon fields compared to the conventional spherical-harmonic solutions.  This version of the Global Mascon dataset has a Coastline Resolution Improvement (CRI) filter applied to separate the land and ocean portions of mass within each land/ocean mascon in a post-processing step. For users who wish to do their own separation of land and ocean mass signals, a version of the data without the CRI filter is available at [NASA/GRACE/MASS_GRIDS/MASCON](https://developers.google.com/earth-engine/datasets/catalog/NASA_GRACE_MASS_GRIDS_MASCON).  **Note**  * A set of global gain factors to aid in the interpretation of signals   at sub-mascon resolution is available at   [NASA/GRACE/MASS_GRIDS/MASCON_SCALE_CRI_2015](https://code.earthengine.google.com/?asset=NASA/GRACE/MASS_GRIDS/MASCON_SCALE_CRI_2015).   **Please note**: the gain factors can be used for hydrology-related   signals, but not for mountain glaciers or ice sheets. For more   information on scaling the mascon solutions, please see [Wiese et al.   (2016)](https://doi.org/10.1002/2016WR019344).  * The data are represented on a 1/2 degree lon-lat grid, but they   represent the 3x3 degree equal-area caps, which is the current   native resolution of JPL-RL05M. 
        :param example: var dataset = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/MASCON_CRI')                   .filter(ee.Filter.date('2016-08-01', '2016-08-30')); var equivalentWaterThickness = dataset.select('lwe_thickness'); var equivalentWaterThicknessVis = {   min: -25.0,   max: 25.0, }; Map.setCenter(6.746, 46.529, 2); Map.addLayer(     equivalentWaterThickness, equivalentWaterThicknessVis,     'Equivalent Water Thickness'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GRACE_MASS_GRIDS_OCEAN:
    def __init__(self,):
        self.sensor = 'NASA_GRACE_MASS_GRIDS_OCEAN'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GRACE_MASS_GRIDS_OCEAN.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GRACE_MASS_GRIDS_OCEAN.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GRACE_MASS_GRIDS_OCEAN(example: str = ''):
        """
        GRACE Tellus Monthly Mass Grids provides monthly gravitational anomalies relative to a 2004-2010 time-mean baseline. The data contained in this dataset are units of \"Equivalent Water Thickness\" which represent the deviations of mass in terms of vertical extent of water in centimeters. See the provider's [Monthly Mass Grids Overview](https://grace.jpl.nasa.gov/data/monthly-mass-grids/) for more details.  The GRACE Tellus (GRCTellus) Monthly Mass Grids Ocean dataset is produced by three centers: CSR (U. Texas / Center for Space Research), GFZ (GeoForschungsZentrum Potsdam), and JPL (NASA Jet Propulsion Laboratory). Each center is a part of the GRACE Ground System and generates Level-2 data (spherical harmonic fields) used in this dataset. The output includes spherical harmonic coefficients of the gravity field and of the dealiasing fields used to compute them. Since each center independently produces the coefficients, the results may be slightly different. It is recommended for most users to use the mean of all three datasets. See the provider's [choosing a solution](https://grace.jpl.nasa.gov/data/choosing-a-solution/) page for more details.  **Note**  * Land leakage correction: Ocean signals are typically weaker   than land signals, by factors of 2 and more, on seasonal and   interannual time scales. To minimize leakage from high land   signals onto ocean signals, a destriping filter has been applied   which may cause cause correlations over much larger distances.  * The GRCTellus Ocean datasets are optimized to examine regional   ocean bottom pressure, but NOT intended to be spatially   averaged to determine global mean ocean mass.  * A filtered version of the  GRCTellus Ocean dataset is also available   which uses an alternative filtering method which may reduce leakage   errors, and have results which agree better with altimetric sea surface   height. [NASA/GRACE/MASS_GRIDS/OCEAN_EOFR](https://developers.google.com/earth-engine/datasets/catalog/NASA_GRACE_MASS_GRIDS_OCEAN_EOFR). 
        :param example: var dataset = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/OCEAN')                   .filter(ee.Filter.date('2016-08-01', '2016-08-30')); var equivalentWaterThicknessCsr = dataset.select('lwe_thickness_csr'); var equivalentWaterThicknessCsrVis = {   min: -10.0,   max: 10.0, }; Map.setCenter(6.746, 46.529, 1); Map.addLayer(     equivalentWaterThicknessCsr, equivalentWaterThicknessCsrVis,     'Equivalent Water Thickness CSR'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GRACE_MASS_GRIDS_OCEAN_EOFR:
    def __init__(self,):
        self.sensor = 'NASA_GRACE_MASS_GRIDS_OCEAN_EOFR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GRACE_MASS_GRIDS_OCEAN_EOFR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GRACE_MASS_GRIDS_OCEAN_EOFR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GRACE_MASS_GRIDS_OCEAN_EOFR(example: str = ''):
        """
        GRACE Tellus Monthly Mass Grids provides monthly gravitational anomalies relative to a 2004-2010 time-mean baseline. The data contained in this dataset are units of \"Equivalent Water Thickness\" which represent the deviations of mass in terms of vertical extent of water in centimeters. See the provider's [Monthly Mass Grids Overview](https://grace.jpl.nasa.gov/data/monthly-mass-grids/) for more details.  This dataset is a filtered version of the GRACE Tellus (GRCTellus) Ocean dataset. The 'EOFR' bottom pressure (OBP) grids are obtained by projecting the data from the regular GRC Ocean grids product onto the Empirical Orthogonal Functions (EOFs) of the Ocean Model for Circulation and Tides (OMCT). This effectively filters out signals in the GRACE data that are inconsistent with the physics and OBP variations in the OMCT ocean model.  The EOFR filtered reconstructed OBP fields agree better with radar altimetric sea surface height, reduce leakage around ice sheets and glaciers, and reduce noise in the mid latitudes where OBP variability is lower. [(Chambers and Willis, 2010)](https://doi.org/10.1175/2010JTECHO738.1)  **Note**  * The GRCTellus Ocean datasets are optimized to examine regional   ocean bottom pressure, but NOT intended to be spatially   averaged to determine global mean ocean mass. 
        :param example: var dataset = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/OCEAN_EOFR')                   .filter(ee.Filter.date('2016-08-01', '2016-08-30')); var equivalentWaterThicknessCsr = dataset.select('lwe_thickness_csr'); var equivalentWaterThicknessCsrVis = {   min: -10.0,   max: 10.0, }; Map.setCenter(6.746, 46.529, 1); Map.addLayer(     equivalentWaterThicknessCsr, equivalentWaterThicknessCsrVis,     'Equivalent Water Thickness CSR'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_aer_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_aer_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_aer_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_aer_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_aer_2(example: str = ''):
        """
        M2T1NXAER (or tavg1_2d_aer_Nx) is an hourly time-averaged 2-dimensional data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of assimilated aerosol diagnostics, such as column mass density of aerosol components (black carbon, dust, sea-salt, sulfate, and organic carbon), surface mass concentration of aerosol components, and total extinction (and scattering) aerosol optical thickness (AOT) at 550 nm. The total PM1.0, PM2.5, and PM10 may be derived with the formula described in the [in the FAQ] (https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/FAQ/)  The data field is time-stamped with the central time of an hour starting from 00:30 UTC, e.g.: 00:30, 01:30, ... , 23:30 UTC.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by NASA Global Modeling and Assimilation Office (GMAO) using the Goddard Earth Observing System Model (GEOS) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/aer/2')                   .filter(ee.Filter.date('2022-02-01', '2022-02-02')); var black_carbon_column_u_wind_mass_flux = dataset.select('BCFLUXU'); var bccVis = {   min: -0.0000116,   max: 0.0000165,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95.62, 39.91, 2); Map.addLayer(black_carbon_column_u_wind_mass_flux, bccVis); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_aer_nv_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_aer_nv_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_aer_nv_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_aer_nv_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_aer_nv_2(example: str = ''):
        """
        M2I3NVAER (or inst3_3d_aer_Nv) is an instantaneous 3-dimensional 3-hourly data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of assimilations of aerosol mixing ratio parameters at 72 model layers, such as dust, sulphur dioxide, sea salt, black carbon, and organic carbon. The data field is available every three hour starting from 00:00 UTC, e.g.: 00:00, 03:00,... ,21:00 UTC. Section 4.2 of the [MERRA-2 File Specification document](https://gmao.gsfc.nasa.gov/pubs/docs/Bosilovich785.pdf) provides pressure values nominal for a 1000 hPa surface pressure and refers to the top edge of the layer. The lev=1 is for the top layer, and lev=72 is for the bottom (or surface) model layer.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by NASA Global Modeling and Assimilation Office (GMAO) using the Goddard Earth Observing System Model (GEOS) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/aer_nv/2')                   .filter(ee.Filter.date('1985-02-01', '1985-02-02')); dataset = dataset.first() var pressure_thickness = dataset.select('DELP_72'); var bccVis = {   min: 1188.8580904647688,   max: 1761.7886613672472,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95.62, 39.91, 2); Map.addLayer(pressure_thickness, bccVis); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_flx_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_flx_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_flx_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_flx_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_flx_2(example: str = ''):
        """
        M2T1NXFLX (or tavg1_2d_flx_Nx) is an hourly time-averaged data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of assimilated surface flux diagnostics, such as total precipitation, bias corrected total precipitation, surface air temperature, surface specific humidity, surface wind speed, and evaporation from turbulence. The "surface" in this data collection is the model surface layer. The heights of the model surface layer (HLML) vary with time and location, with the value of ~60 meters above ground. The data field is time-stamped with the central time of an hour starting from 00:30 UTC, e.g.: 00:30, 01:30, ... , 23:30 UTC.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by [NASA Global Modeling and Assimilation Office (GMAO)](https://gmao.gsfc.nasa.gov/) using the [Goddard Earth Observing System Model (GEOS)](https://gmao.gsfc.nasa.gov/GEOS_systems/) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/flx/2')                   .filter(ee.Filter.date('2022-02-01', '2022-02-02')); var surface_buoyancy_scale = dataset.select('BSTAR'); var sbsVis = {   min: -0.00998,   max: 0.01174,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95, 39, 2); Map.addLayer(surface_buoyancy_scale, sbsVis, 'Surface buoyancy scale');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_lnd_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_lnd_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_lnd_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_lnd_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_lnd_2(example: str = ''):
        """
        M2T1NXLND (or tavg1_2d_lnd_Nx) is an hourly time-averaged data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of land surface diagnostics, such a baseflow flux, runoff, surface soil wetness, root zone soil wetness, water at surface layer, water at root zone layer, and soil temperature at six layers. The data field is time-stamped with the central time of an hour starting from 00:30 UTC, e.g.: 00:30, 01:30, ... , 23:30 UTC.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by NASA Global Modeling and Assimilation Office (GMAO) using the Goddard Earth Observing System Model (GEOS) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/lnd/2')                   .filter(ee.Filter.date('2022-02-01', '2022-02-02')); var baseflow_flux = dataset.select('BASEFLOW'); var bfVis = {   min: -0.00000913,   max:  0.00001076,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95, 39, 2); Map.addLayer(baseflow_flux, bfVis, 'Baseflow flux'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_rad_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_rad_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_rad_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_rad_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_rad_2(example: str = ''):
        """
        M2T1NXRAD (or tavg1_2d_rad_Nx) is an hourly time-averaged data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of radiation diagnostics, such as surface albedo, cloud area fraction, in cloud optical thickness, surface incoming shortwave flux (i.e. solar radiation), surface net downward shortwave flux, and upwelling longwave flux at TOA (top of atmosphere) (i.e. outgoing longwave radiation (OLR) at TOA). The data field is time-stamped with the central time of an hour starting from 00:30 UTC, e.g.: 00:30, 01:30, ... , 23:30 UTC.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by NASA Global Modeling and Assimilation Office (GMAO) using the Goddard Earth Observing System Model (GEOS) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/rad/2')                   .filter(ee.Filter.date('2022-02-01', '2022-02-02')).first(); var surface_albedo = dataset.select('ALBEDO'); var saVis = {   min: -0.428147,   max: 0.833350,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95, 39, 2); Map.addLayer(surface_albedo, saVis, 'Surface albedo');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_GSFC_MERRA_slv_2:
    def __init__(self,):
        self.sensor = 'NASA_GSFC_MERRA_slv_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_GSFC_MERRA_slv_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_GSFC_MERRA_slv_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_GSFC_MERRA_slv_2(example: str = ''):
        """
        M2T1NXSLV (or tavg1_2d_slv_Nx) is an hourly time-averaged 2-dimensional data collection in Modern-Era Retrospective analysis for Research and Applications version 2 (MERRA-2). This collection consists of meteorology diagnostics at popularly used vertical levels, such as air temperature at 2-meter (or at 10-meter, 850hPa, 500 hPa, 250hPa), wind components at 50-meter (or at 2-meter, 10-meter, 850 hPa, 500hPa, 250 hPa), sea level pressure, surface pressure, and total precipitable water vapor (or ice water, liquid water). The data field is time-stamped with the central time of an hour starting from 00:30 UTC, e.g.: 00:30, 01:30, ... , 23:30 UTC.  MERRA-2 is the latest version of global atmospheric reanalysis for the satellite era produced by NASA Global Modeling and Assimilation Office (GMAO) using the Goddard Earth Observing System Model (GEOS) version 5.12.4. The dataset covers the period of 1980-present with the latency of ~3 weeks after the end of a month. 
        :param example: var dataset = ee.ImageCollection('NASA/GSFC/MERRA/slv/2')                   .filter(ee.Filter.date('2022-02-01', '2022-02-02')); var surface_pressure = dataset.select('PS'); var surface_pressure_vis = {   min: 81100,   max: 117000,   palette: ['001137', '01abab', 'e7eb05', '620500'] }; Map.setCenter(-95.62, 39.91, 2); Map.addLayer(surface_pressure, surface_pressure_vis); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_HLS_HLSL30_v002:
    def __init__(self,):
        self.sensor = 'NASA_HLS_HLSL30_v002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_HLS_HLSL30_v002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_HLS_HLSL30_v002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_HLS_HLSL30_v002(example: str = ''):
        """
        The Harmonized Landsat Sentinel-2 (HLS) project provides consistent surface reflectance (SR) and top of atmosphere (TOA) brightness data from a virtual constellation of satellite sensors. The Operational Land Imager (OLI) is housed aboard the joint NASA/USGS Landsat 8 and Landsat 9 satellites, while the Multi-Spectral Instrument (MSI) is mounted aboard Europe's Copernicus Sentinel-2A and Sentinel-2B satellites. The combined measurement enables global observations of the land every 2 to 3 days at 30m spatial resolution. The HLS project uses a set of algorithms to obtain seamless products from OLI and MSI that include atmospheric correction, cloud and cloud-shadow masking, spatial co-registration and common gridding, illumination and view angle normalization, and spectral bandpass adjustment.  The HLS project distributes data as two separate products: HLSL30 (Landsat 8/9) and HLSS30 (Sentinel-2 A/B). They both provide 30m Nadir Bidirectional Reflectance Distribution Function (BRDF), Adjusted Reflectance (NBAR). **This is only the HLSL30 product (the Landsat component). Earth Engine does not currently offer the HLSS30 product (the Sentinel-2 component).** Therefore, observation frequency of the HLS products offered by Earth Engine is determined solely by the Landsat 8 and 9 acquisition plan.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/769/HLS_ATBD_V15_provisional.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/hlsl30v002/) 
        :param example: var collection = ee.ImageCollection("NASA/HLS/HLSL30/v002")                     .filter(ee.Filter.date('2013-04-25', '2013-04-28'))                     .filter(ee.Filter.lt('CLOUD_COVERAGE', 30)); var visParams = {   bands: ['B4', 'B3', 'B2'],   min:0.01,   max:0.18, };  var visualizeImage = function(image) {   var imageRGB = image.visualize(visParams);   return imageRGB; };  var rgbCollection = collection.map(visualizeImage);  Map.setCenter(-60.1765, -22.5318, 11) Map.addLayer(rgbCollection, {}, 'HLS RGB bands'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_JPL_global_forest_canopy_height_2005:
    def __init__(self,):
        self.sensor = 'NASA_JPL_global_forest_canopy_height_2005'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_JPL_global_forest_canopy_height_2005.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_JPL_global_forest_canopy_height_2005.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_JPL_global_forest_canopy_height_2005(example: str = ''):
        """
        This dataset represents global tree heights based on a fusion of spaceborne-lidar data (2005) from the Geoscience Laser Altimeter System (GLAS) and ancillary geospatial data. See [Simard et al. (2011)](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2011JG001708) for details. 
        :param example: var dataset = ee.Image('NASA/JPL/global_forest_canopy_height_2005'); var forestCanopyHeight = dataset.select('1'); var forestCanopyHeightVis = {   min: 0.0,   max: 30.0,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(-28.1, 28.3, 1); Map.addLayer(forestCanopyHeight, forestCanopyHeightVis, 'Forest Canopy Height');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_LANCE_NOAA20_VIIRS_C2:
    def __init__(self,):
        self.sensor = 'NASA_LANCE_NOAA20_VIIRS_C2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_LANCE_NOAA20_VIIRS_C2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_LANCE_NOAA20_VIIRS_C2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_LANCE_NOAA20_VIIRS_C2(example: str = ''):
        """
        NOAA-20 (JPSS-1) Visible Infrared Imaging Radiometer Suite (VIIRS) Active Fire detection product is based on the instrument's 375m nominal resolution data. Compared to other coarser resolution (&ge; 1km) satellite fire detection products,  the improved 375 m data provide greater response over fires of relatively small areas, as well as improved mapping of large fire perimeters. Consequently, the data are well suited for use in support of fire management (e.g., near real-time alert systems), as well as other science applications requiring improved fire mapping fidelity.  The data in the near-real-time dataset are not considered to be of science quality.  Additional information can be found [here](https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms). 
        :param example: var noaa_viirs = ee.ImageCollection('NASA/LANCE/NOAA20_VIIRS/C2')                    .filter(ee.Filter.date('2023-10-08', '2023-10-30')) var band_vis = {   min: [     280.0,   ],   max: [     400.0,   ],   palette: ['yellow', 'orange', 'red', 'white', 'darkred'],   bands: [     'Bright_ti4',   ], } Map.setCenter(-113.2487, 59.3943, 8); Map.addLayer(noaa_viirs, band_vis, 'NOAA nrt firms')
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_LANCE_SNPP_VIIRS_C2:
    def __init__(self,):
        self.sensor = 'NASA_LANCE_SNPP_VIIRS_C2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_LANCE_SNPP_VIIRS_C2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_LANCE_SNPP_VIIRS_C2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_LANCE_SNPP_VIIRS_C2(example: str = ''):
        """
        Suomi NPP Visible Infrared Imaging Radiometer Suite (VIIRS) Active Fire detection product is based on the instrument's 375m nominal resolution data. Compared to other coarser resolution (&ge; 1km) satellite fire detection products,  the improved 375 m data provide greater response over fires of relatively small areas, as well as improved mapping of large fire perimeters. Consequently, the data are well suited for use in support of fire management (e.g., near real-time alert systems), as well as other science applications requiring improved fire mapping fidelity.  The data in the near-real-time dataset are not considered to be of science quality.  Additional information can be found [here](https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms). 
        :param example: var suomi_viirs = ee.ImageCollection('NASA/LANCE/SNPP_VIIRS/C2')                       .filter(ee.Filter.date('2023-10-08', '2023-10-30')) var band_vis = {   min: [     280.0,   ],   max: [     400.0,   ],   palette: ['yellow', 'orange', 'red', 'white', 'darkred'],   bands: [     'Bright_ti4',   ], } Map.setCenter(-113.2487, 59.3943, 8); Map.addLayer(suomi_viirs, band_vis, 'Suomi nrt firms')
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_MEASURES_GFCC_TC_v3:
    def __init__(self,):
        self.sensor = 'NASA_MEASURES_GFCC_TC_v3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_MEASURES_GFCC_TC_v3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_MEASURES_GFCC_TC_v3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_MEASURES_GFCC_TC_v3(example: str = ''):
        """
        The Landsat Vegetation Continuous Fields (VCF) tree cover layers contain estimates of the percentage of horizontal ground in each 30-m pixel covered by woody vegetation greater than 5 meters in height. The dataset is available for four epochs centered on the years 2000, 2005, 2010 and 2015. The dataset is derived from the GFCC Surface Reflectance product (GFCC30SR), which is based on enhanced Global Land Survey (GLS) datasets. The GLS datasets are composed of high-resolution Landsat 5 Thematic Mapper (TM) and Landsat 7 Enhanced Thematic Mapper Plus (ETM+) images at 30 meter resolution.  Tree cover, the proportional, vertically projected area of vegetation (including leaves, stems, branches, etc.) of woody plants above a given height, affects terrestrial energy and water exchanges, photosynthesis and transpiration, net primary production, and carbon and nutrient fluxes. Tree cover also affects habitat quality and movements of wildlife, residential property value for humans, and other ecosystem services. The continuous classification scheme of the VCF product enables better depiction of land cover gradients than traditional discrete classification schemes. Importantly for detection and monitoring of forest changes (e.g., deforestation and degradation), tree cover provides a measurable attribute upon which to define forest cover and its changes. Changes in tree cover over time can be used to monitor and retrieve site-specific histories of forest change.  The dataset has been produced for four year epochs: 2000, 2005, 2010, and 2015 with an image in the collection for each available WRS2 path/row.  Documentation:  * [User's guide](https://lpdaac.usgs.gov/documents/1371/GFCC_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1370/GFCC_ATBD.pdf)  Provider's Note: Due to the end of NASA MEaSUREs funding, free versions of this dataset are no longer being produced. Interested parties can obtain updated and expanded versions at www.terraPulse.com. 
        :param example: var dataset = ee.ImageCollection('NASA/MEASURES/GFCC/TC/v3')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var treeCanopyCover = dataset.select('tree_canopy_cover'); var treeCanopyCoverVis = {   min: 0.0,   max: 100.0,   palette: ['ffffff', 'afce56', '5f9c00', '0e6a00', '003800'], }; Map.setCenter(-88.6, 26.4, 3); Map.addLayer(treeCanopyCover.mean(), treeCanopyCoverVis, 'Tree Canopy Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_NASADEM_HGT_001:
    def __init__(self,):
        self.sensor = 'NASA_NASADEM_HGT_001'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_NASADEM_HGT_001.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_NASADEM_HGT_001.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_NASADEM_HGT_001(example: str = ''):
        """
        NASADEM is a reprocessing of STRM data, with improved accuracy by incorporating auxiliary data from ASTER GDEM, ICESat GLAS, and PRISM datasets.  The most significant processing improvements involve void reduction through improved phase unwrapping and using ICESat GLAS data for control.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/592/NASADEM_User_Guide_V1.pdf) 
        :param example: // Import the dataset and select the elevation band. var dataset = ee.Image('NASA/NASADEM_HGT/001'); var elevation = dataset.select('elevation');  // Add a white background image to the map. var background = ee.Image(1); Map.addLayer(background, {min: 0, max: 1});  // Set elevation visualization properties. var elevationVis = {   min: 0,   max: 2000, };  // Set elevation <= 0 as transparent and add to the map. Map.addLayer(elevation.updateMask(elevation.gt(0)), elevationVis, 'Elevation'); Map.setCenter(17.93, 7.71, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_NEX_DCP30:
    def __init__(self,):
        self.sensor = 'NASA_NEX_DCP30'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_NEX-DCP30.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_NEX-DCP30.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_NEX_DCP30(example: str = ''):
        """
        The NASA NEX-DCP30 dataset is comprised of downscaled climate scenarios for the conterminous United States that are derived from the General Circulation Model (GCM) runs conducted under the Coupled Model Intercomparison Project Phase 5 (CMIP5, see [Taylor et al. 2012](https://journals.ametsoc.org/doi/abs/10.1175/BAMS-D-11-00094.1)) and across the four greenhouse gas emissions scenarios known as Representative Concentration Pathways (RCPs, see [Meinshausen et al. 2011](https://rd.springer.com/article/10.1007%2Fs10584-011-0156-z#page-1)) developed for the Fifth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC AR5). The purpose of these datasets is to provide a set of high resolution, bias-corrected climate change projections that can be used to evaluate climate change impacts on processes that are sensitive to finer-scale climate gradients and the effects of local topography on climate conditions.  The dataset contains monthly projections covering the periods from 1950 through 2005 (Retrospective Run) and from 2006 to 2099 (Prospective Run). It includes downscaled projections from 33 models. Not every scenario contains projections from every model.  NEX-DCP30 was prepared by the Climate Analytics Group and NASA Ames Research Center using the NASA Earth Exchange, and distributed by the NASA Center for Climate Simulation (NCCS). 
        :param example: var dataset = ee.ImageCollection('NASA/NEX-DCP30')                   .filter(ee.Filter.date('2018-07-01', '2018-07-30')); var minimumAirTemperature = dataset.select('tasmin'); var minimumAirTemperatureVis = {   min: 265.0,   max: 285.0,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(-115.356, 38.686, 5); Map.addLayer(     minimumAirTemperature, minimumAirTemperatureVis, 'Minimum Air Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_NEX_DCP30_ENSEMBLE_STATS:
    def __init__(self,):
        self.sensor = 'NASA_NEX_DCP30_ENSEMBLE_STATS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_NEX-DCP30_ENSEMBLE_STATS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_NEX-DCP30_ENSEMBLE_STATS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_NEX_DCP30_ENSEMBLE_STATS(example: str = ''):
        """
        The NASA NEX-DCP30 dataset is comprised of downscaled climate scenarios for the conterminous United States that are derived from the General Circulation Model (GCM) runs conducted under the Coupled Model Intercomparison Project Phase 5 (CMIP5, see [Taylor et al. 2012](https://journals.ametsoc.org/doi/abs/10.1175/BAMS-D-11-00094.1)) and across the four greenhouse gas emissions scenarios known as Representative Concentration Pathways (RCPs, see [Meinshausen et al. 2011](https://rd.springer.com/article/10.1007%2Fs10584-011-0156-z#page-1)) developed for the Fifth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC AR5). The purpose of these datasets is to provide a set of high resolution, bias-corrected climate change projections that can be used to evaluate climate change impacts on processes that are sensitive to finer-scale climate gradients and the effects of local topography on climate conditions.  The dataset contains monthly projections covering the periods from 1950 through 2005 (Retrospective Run) and from 2006 to 2099 (Prospective Run). It includes ensemble statistics calculated for each RCP from all model runs available for the pr, tasmin, and tasmax bands.  NEX-DCP30 was prepared by the Climate Analytics Group and NASA Ames Research Center using the NASA Earth Exchange, and distributed by the NASA Center for Climate Simulation (NCCS). 
        :param example: var dataset = ee.ImageCollection('NASA/NEX-DCP30_ENSEMBLE_STATS')                   .filter(ee.Filter.date('2018-07-01', '2018-07-30')); var monthlyMeanMinimumAirTemperature = dataset.select('tasmin_mean'); var monthlyMeanMinimumAirTemperatureVis = {   min: 247.0,   max: 311.0,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(-115.356, 38.686, 5); Map.addLayer(     monthlyMeanMinimumAirTemperature, monthlyMeanMinimumAirTemperatureVis,     'Monthly Mean Minimum Air Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_NEX_GDDP:
    def __init__(self,):
        self.sensor = 'NASA_NEX_GDDP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_NEX-GDDP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_NEX-GDDP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_NEX_GDDP(example: str = ''):
        """
        The NASA NEX-GDDP dataset is comprised of downscaled climate scenarios for the globe that are derived from the General Circulation Model (GCM) runs conducted under the Coupled Model Intercomparison Project Phase 5 (CMIP5, see [Taylor et al. 2012](https://journals.ametsoc.org/doi/abs/10.1175/BAMS-D-11-00094.1)) and across two of the four greenhouse gas emissions scenarios known as Representative Concentration Pathways (RCPs, see [Meinshausen et al. 2011](https://rd.springer.com/article/10.1007%2Fs10584-011-0156-z#page-1)). The CMIP5 GCM runs were developed in support of the Fifth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC AR5).  This dataset was prepared by the Climate Analytics Group and NASA Ames Research Center using the NASA Earth Exchange, and distributed by the NASA Center for Climate Simulation (NCCS). 
        :param example: var dataset = ee.ImageCollection('NASA/NEX-GDDP')                   .filter(ee.Filter.date('2018-07-01', '2018-07-02')); var minimumAirTemperature = dataset.select('tasmin'); var minimumAirTemperatureVis = {   min: 240.0,   max: 300.0,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(     minimumAirTemperature, minimumAirTemperatureVis, 'Minimum Air Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_NLDAS_FORA0125_H002:
    def __init__(self,):
        self.sensor = 'NASA_NLDAS_FORA0125_H002'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_NLDAS_FORA0125_H002.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_NLDAS_FORA0125_H002.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_NLDAS_FORA0125_H002(example: str = ''):
        """
        Land Data Assimilation System (LDAS) combines multiple sources of observations (such as precipitation gauge data, satellite data, and radar precipitation measurements) to produce estimates of climatological properties at or near the Earth''s surface.  This dataset is the primary (default) forcing file (File A) for Phase 2 of the North American Land Data Assimilation System (NLDAS-2). The data are in 1/8th-degree grid spacing; the temporal resolution is hourly.  NLDAS is a collaboration project among several groups: NOAA/NCEP''s Environmental Modeling Center (EMC), NASA''s Goddard Space Flight Center (GSFC), Princeton University, the University of Washington, the NOAA/NWS Office of Hydrological Development (OHD), and the NOAA/NCEP Climate Prediction Center (CPC). NLDAS is a core project with support from NOAA''s Climate Prediction Program for the Americas (CPPA).  Documentation:  * [Readme](https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/README.NLDAS2.pdf)  * [How-To](https://disc.gsfc.nasa.gov/information/howto?tags=hydrology)  * [GES DISC Hydrology Documentation](https://disc.gsfc.nasa.gov/information/documents?title=Hydrology%20Documentation)  * [GES DISC Data Rods Documentation](https://disc.gsfc.nasa.gov/information/tools?title=Hydrology%20Data%20Rods) 
        :param example: var dataset = ee.ImageCollection('NASA/NLDAS/FORA0125_H002')                   .filter(ee.Filter.date('2018-07-01', '2018-07-30')); var temperature = dataset.select('temperature'); var temperatureVis = {   min: -5.0,   max: 40.0,   palette: ['3d2bd8', '4e86da', '62c7d8', '91ed90', 'e4f178', 'ed6a4c'], }; Map.setCenter(-110.21, 35.1, 4); Map.addLayer(temperature, temperatureVis, 'Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_OCEANDATA_MODIS_Aqua_L3SMI:
    def __init__(self,):
        self.sensor = 'NASA_OCEANDATA_MODIS_Aqua_L3SMI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_OCEANDATA_MODIS-Aqua_L3SMI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_OCEANDATA_MODIS-Aqua_L3SMI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_OCEANDATA_MODIS_Aqua_L3SMI(example: str = ''):
        """
        This level 3 product includes ocean color and satellite ocean biology data produced or collected under [EOSDIS](https://earthdata.nasa.gov/about).  This dataset may be used for studying the biology and hydrology of coastal zones, changes in the diversity and geographical distribution of coastal marine habitats, biogeochemical fluxes and their influence in Earth's oceans and climate over time, and finally the impact of climate and environmental variability and change on ocean ecosystems and the biodiversity they support.  Scale factor and offset are already applied.  Documentation:  * [Ocean Color Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Chlorophyll Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Algorithm Theoretical Basis Document (Chlorophyll)](https://oceancolor.gsfc.nasa.gov/atbd/chlor_a)  * [Algorithm Theoretical Basis Document (Fluorescence Line Height)](https://oceancolor.gsfc.nasa.gov/atbd/nflh)  * [Algorithm Theoretical Basis Document (Particulate Organic Carbon)](https://oceancolor.gsfc.nasa.gov/atbd/poc)  * [Algorithm Theoretical Basis Document (Remote-Sensing Reflectance)](https://oceancolor.gsfc.nasa.gov/atbd/rrs)  * [Processing History](https://oceancolor.gsfc.nasa.gov/reprocessing)  Newer datasets have scaled POC values while older ones don't. This scaling gets rid of negative values but older datasets still retain them hence the -2147.48 estimated minimum value. For more information, visit the [Ocean Color Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/topic_show.pl?pid=33202;hl=poc%20values).  [MODIS-Aqua OceanData](https://oceancolor.gsfc.nasa.gov/data/aqua) 
        :param example: var dataset = ee.ImageCollection('NASA/OCEANDATA/MODIS-Aqua/L3SMI')                   .filterDate('2016-01-01', '2016-01-31'); var remoteSensingReflectance =     dataset.select(['Rrs_645', 'Rrs_555', 'Rrs_443']); var remoteSensingReflectanceVis = {   min: 0.0,   max: 0.011, }; Map.setCenter(-52.12, -46.13, 4); Map.addLayer(     remoteSensingReflectance, remoteSensingReflectanceVis,     'Remote Sensing Reflectance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_OCEANDATA_MODIS_Terra_L3SMI:
    def __init__(self,):
        self.sensor = 'NASA_OCEANDATA_MODIS_Terra_L3SMI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_OCEANDATA_MODIS-Terra_L3SMI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_OCEANDATA_MODIS-Terra_L3SMI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_OCEANDATA_MODIS_Terra_L3SMI(example: str = ''):
        """
        This level 3 product includes ocean color and satellite ocean biology data produced or collected under [EOSDIS](https://earthdata.nasa.gov/about).  This dataset may be used for studying the biology and hydrology of coastal zones, changes in the diversity and geographical distribution of coastal marine habitats, biogeochemical fluxes and their influence in Earth's oceans and climate over time, and finally the impact of climate and environmental variability and change on ocean ecosystems and the biodiversity they support.  Scale factor and offset are already applied.  Documentation:  * [Ocean Color Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Chlorophyll Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Algorithm Theoretical Basis Document (Chlorophyll)](https://oceancolor.gsfc.nasa.gov/resources/atbd/chlor_a)  * [Algorithm Theoretical Basis Document (Fluorescence Line Height)](https://oceancolor.gsfc.nasa.gov/resources/atbd/nflh)  * [Algorithm Theoretical Basis Document (Particulate Organic Carbon)](https://oceancolor.gsfc.nasa.gov/resources/atbd/poc)  * [Algorithm Theoretical Basis Document (Remote-Sensing Reflectance)](https://oceancolor.gsfc.nasa.gov/resources/atbd/rrs)  * [Processing History](https://oceancolor.gsfc.nasa.gov/reprocessing)  * [MODIS-Terra OceanData](https://oceancolor.gsfc.nasa.gov/data/terra) 
        :param example: var dataset = ee.ImageCollection('NASA/OCEANDATA/MODIS-Terra/L3SMI')                   .filterDate('2016-01-01', '2016-01-31'); var remoteSensingReflectance =     dataset.select(['Rrs_645', 'Rrs_555', 'Rrs_443']); var remoteSensingReflectanceVis = {   min: 0.0,   max: 0.02, }; Map.setCenter(-52.12, -46.13, 4); Map.addLayer(     remoteSensingReflectance, remoteSensingReflectanceVis,     'Remote Sensing Reflectance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_OCEANDATA_SeaWiFS_L3SMI:
    def __init__(self,):
        self.sensor = 'NASA_OCEANDATA_SeaWiFS_L3SMI'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_OCEANDATA_SeaWiFS_L3SMI.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_OCEANDATA_SeaWiFS_L3SMI.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_OCEANDATA_SeaWiFS_L3SMI(example: str = ''):
        """
        This level 3 product includes ocean color and satellite ocean biology data produced or collected under [EOSDIS](https://earthdata.nasa.gov/about).  This dataset may be used for studying the biology and hydrology of coastal zones, changes in the diversity and geographical distribution of coastal marine habitats, biogeochemical fluxes and their influence in Earth's oceans and climate over time, and finally the impact of climate and environmental variability and change on ocean ecosystems and the biodiversity they support.  Scale factor and offset are already applied.  Documentation:  * [Ocean Color Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Chlorophyll Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/forum_show.pl)  * [Algorithm Theoretical Basis Document (Chlorophyll)](https://oceancolor.gsfc.nasa.gov/atbd/chlor_a)  * [Algorithm Theoretical Basis Document (Fluorescence Line Height)](https://oceancolor.gsfc.nasa.gov/atbd/nflh)  * [Algorithm Theoretical Basis Document (Particulate Organic Carbon)](https://oceancolor.gsfc.nasa.gov/atbd/poc)  * [Algorithm Theoretical Basis Document (Remote-Sensing Reflectance)](https://oceancolor.gsfc.nasa.gov/atbd/rrs)  * [Processing History](https://oceancolor.gsfc.nasa.gov/reprocessing)  - There are number of missing data dates in this dataset. For example,   most dates are missing between 2009-04-29 and 2009-12-01.  - The estimated values for POC might be a result of the data being generated   without a scale. For more information, visit the   [Ocean Color Forum](https://oceancolor.gsfc.nasa.gov/forum/oceancolor/topic_show.pl?pid=33202;hl=poc%20values).    [SeaWiFS OceanData](https://oceancolor.gsfc.nasa.gov/data/seawifs) 
        :param example: var dataset = ee.ImageCollection('NASA/OCEANDATA/SeaWiFS/L3SMI')                   .filter(ee.Filter.date('2009-07-01', '2009-08-30')); var remoteSensingReflectance =     dataset.select(['Rrs_670', 'Rrs_555', 'Rrs_443']); var remoteSensingReflectanceVis = {   min: 0.0,   max: 0.03, }; Map.setCenter(-52.12, -46.13, 1); Map.addLayer(     remoteSensingReflectance, remoteSensingReflectanceVis,     'Remote Sensing Reflectance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_ORNL_biomass_carbon_density_v1:
    def __init__(self,):
        self.sensor = 'NASA_ORNL_biomass_carbon_density_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_ORNL_biomass_carbon_density_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_ORNL_biomass_carbon_density_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_ORNL_biomass_carbon_density_v1(example: str = ''):
        """
        This dataset provides temporally consistent and harmonized global maps of aboveground and belowground biomass carbon density for the year 2010 at a 300-m spatial resolution. The aboveground biomass map integrates land-cover specific, remotely sensed maps of woody, grassland, cropland, and tundra biomass. Input maps were amassed from the published literature and, where necessary, updated to cover the focal extent or time period. The belowground biomass map similarly integrates matching maps derived from each aboveground biomass map and land-cover specific empirical models. Aboveground and belowground maps were then integrated separately using ancillary maps of percent tree cover and landcover and a rule-based decision tree. Maps reporting the accumulated uncertainty of pixel-level estimates are also provided.  Provider's note: The UN Environment Programme World Conservation Monitoring Centre (UNEP-WCMC) carbon biomass dataset represents conditions between 1982 and 2010 depending on land cover type. The relative patterns of carbon stocks are well represented with this dataset. The [NASA/ORNL carbon biomass dataset](https://daac.ornl.gov/VEGETATION/guides/Global_Maps_C_Density_2010.html) represents biomass conditions for 2010, with uncertainty estimates at the pixel-level. Additional biomass of non-dominant land cover types are represented within each pixel. For more detailed information, please refer to the papers describing each dataset: [WCMC](WCMC_biomass_carbon_density_v1_0) [(Soto-Navarro et al. 2020)](https://royalsocietypublishing.org/doi/full/10.1098/rstb.2019.0128) and NASA/ORNL [(Spawn et al. 2020)](https://www.nature.com/articles/s41597-020-0444-4). 
        :param example: var dataset = ee.ImageCollection('NASA/ORNL/biomass_carbon_density/v1');  var visualization = {   bands: ['agb'],   min: -50.0,   max: 80.0,   palette: ['d9f0a3', 'addd8e', '78c679', '41ab5d', '238443', '005a32'] };  Map.setCenter(-60.0, 7.0, 4);  Map.addLayer(dataset, visualization, 'Aboveground biomass carbon');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_ORNL_DAYMET_V3:
    def __init__(self,):
        self.sensor = 'NASA_ORNL_DAYMET_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_ORNL_DAYMET_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_ORNL_DAYMET_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_ORNL_DAYMET_V3(example: str = ''):
        """
        Daymet V3 provides gridded estimates of daily weather parameters for United States, Mexico, Canada, Hawaii, and Puerto Rico. It is derived from selected meteorological station data and various supporting data sources.  Compared to the previous version, Daymet V3 uses an entirely new suite of inputs including:  - NASA SRTM DEM version 2.1.  - Land/Water Mask: MODIS 250 `MOD44W_v2.NASA_ORNL_`  - Horizon files derived from the SRTM DEM.  - Ground station weather inputs from several sources with QA/QC.  Documentation:  * [ORNL DAAC Dataset Documentation](https://daac.ornl.gov/DAYMET/guides/Daymet_V3_CFMosaics.html)  * [Dataset Documentation](https://daac.ornl.gov/daacdata/daymet/Daymet_V3_CFMosaics/comp/Daymet_V3_CFMosaics.pdf)  * [The THREDDS location for this Collection](https://thredds.daac.ornl.gov/thredds/catalog/ornldaac/1328/catalog.html) 
        :param example: var dataset = ee.ImageCollection('NASA/ORNL/DAYMET_V3')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30')); var maximumTemperature = dataset.select('tmax'); var maximumTemperatureVis = {   min: -40.0,   max: 30.0,   palette: ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'], }; Map.setCenter(-110.21, 35.1, 4); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_ORNL_DAYMET_V4:
    def __init__(self,):
        self.sensor = 'NASA_ORNL_DAYMET_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_ORNL_DAYMET_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_ORNL_DAYMET_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_ORNL_DAYMET_V4(example: str = ''):
        """
        Daymet V4 provides gridded estimates of daily weather parameters for Continental North America, Hawaii, and Puerto Rico (Data for Puerto Rico is available starting in 1950). It is derived from selected meteorological station data and various supporting data sources.  Compared to the previous version, Daymet V4 provides effective solutions to known issues and further considers improvements to what were believed to be input weather station biases. Improvements include:  - Reductions in the timing bias of input reporting weather station measurements.  - Improvement to the three-dimensional regression model techniques in the core algorithm.  - A novel approach to handling high elevation temperature measurement biases.  2020 and 2021 data are ingested from V4 R1 sources  Documentation:  * [ORNL DAAC Dataset Documentation](https://daac.ornl.gov/DAYMET/guides/Daymet_Daily_V4.html)  * [Dataset Documentation](https://daac.ornl.gov/daacdata/daymet/Daymet_Daily_V4/comp/Daymet_Daily_V4.pdf)  * [The THREDDS location for this Collection](https://thredds.daac.ornl.gov/thredds/catalogs/ornldaac/Regional_and_Global_Data/DAYMET_COLLECTIONS/DAYMET_COLLECTIONS.html) 
        :param example: var dataset = ee.ImageCollection('NASA/ORNL/DAYMET_V4')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30')); var maximumTemperature = dataset.select('tmax'); var maximumTemperatureVis = {   min: -40.0,   max: 30.0,   palette: ['1621A2', 'white', 'cyan', 'green', 'yellow', 'orange', 'red'], }; Map.setCenter(-110.21, 35.1, 4); Map.addLayer(maximumTemperature, maximumTemperatureVis, 'Maximum Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_SMAP_SPL3SMP_E_005:
    def __init__(self,):
        self.sensor = 'NASA_SMAP_SPL3SMP_E_005'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_SMAP_SPL3SMP_E_005.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_SMAP_SPL3SMP_E_005.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_SMAP_SPL3SMP_E_005(example: str = ''):
        """
        Data starting from 2023-12-04 are available in the [NASA/SMAP/SPL3SMP_E/006](NASA_SMAP_SPL3SMP_E_006) collection.  This Level-3 (L3) soil moisture product provides a daily composite of global land surface conditions retrieved by the Soil Moisture Active Passive (SMAP) L-Band radiometer. The daily data here were collected from the descending (local solar time of 6 am) and ascending (local solar time of 6 pm) passes.  The SMAP mission is an orbiting observatory that measures the amount of water in the surface soil everywhere on Earth. A detailed description can be found in the [SMAP Handbook](https://smap.jpl.nasa.gov/system/internal_resources/details/original/178_SMAP_Handbook_FINAL_1_JULY_2014_Web.pdf). It was launched in January 2015 and started operation in April 2015. The radar instrument, ceasing operation in early 2015 due to failure of radar power supply, collected close to 3 months of science data. The prime mission phase of three years was completed in 2018, and since then SMAP has been in extended operation phase.  SMAP measures soil moisture every 2-3 days. This permits changes around the world to be observed over time scales ranging from major storms to repeated measurements of changes over the seasons.  Everywhere on Earth not covered with water or not frozen, SMAP measures how much water is in the top layer of soil. It also distinguishes between ground that is frozen or thawed. Where the ground is not frozen, SMAP measures the amount of water found between the minerals, rocky material, and organic particles found in soil everywhere in the world (SMAP measures liquid water in the top layer of ground but is not able to measure the ice.)  SPL3SMP_E data are transformed to [geographic coordinates using GDAL libraries](https://github.com/google/earthengine-catalog/blob/main/pipelines/smap_convert_l3.py) before the data are ingested into Google Earth Engine.  See the [SMAP L3 Soil Moisture User Guide](https://nsidc.org/sites/default/files/spl3smp_e-v005-userguide.pdf) and references therein for additional documentation and algorithm details.  See [basic](https://developers.google.com/earth-engine/tutorials/community/smap-soil-moisture) and [advanced](https://developers.google.com/earth-engine/tutorials/community/anomalies-analysis-smo-and-pre) tutorials to learn how to use SMAP data in Earth Engine. 
        :param example: var dataset = ee.ImageCollection('NASA/SMAP/SPL3SMP_E/005')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30'));  var soilMositureSurface = dataset.select('soil_moisture_am'); var soilMositureSurfaceVis = {   min: 0.0,   max: 0.5,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 46.529, 2); Map.addLayer(soilMositureSurface, soilMositureSurfaceVis, 'Soil Mositure'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_SMAP_SPL3SMP_E_006:
    def __init__(self,):
        self.sensor = 'NASA_SMAP_SPL3SMP_E_006'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_SMAP_SPL3SMP_E_006.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_SMAP_SPL3SMP_E_006.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_SMAP_SPL3SMP_E_006(example: str = ''):
        """
        Data prior from 2023-12-04 are available in the older [NASA/SMAP/SPL3SMP_E/005](NASA_SMAP_SPL3SMP_E_005) collection. They will eventually be reprocessed and added to this collection.  This Level-3 (L3) soil moisture product provides a daily composite of global land surface conditions retrieved by the Soil Moisture Active Passive (SMAP) L-Band radiometer. The daily data here were collected from the descending (local solar time of 6 am) and ascending (local solar time of 6 pm) passes.  The SMAP mission is an orbiting observatory that measures the amount of water in the surface soil everywhere on Earth. A detailed description can be found in the [SMAP Handbook](https://smap.jpl.nasa.gov/system/internal_resources/details/original/178_SMAP_Handbook_FINAL_1_JULY_2014_Web.pdf). It was launched in January 2015 and started operation in April 2015. The radar instrument, ceasing operation in early 2015 due to failure of radar power supply, collected close to 3 months of science data. The prime mission phase of three years was completed in 2018, and since then SMAP has been in extended operation phase.  SMAP measures soil moisture every 2-3 days. This permits changes around the world to be observed over time scales ranging from major storms to repeated measurements of changes over the seasons.  Everywhere on Earth not covered with water or not frozen, SMAP measures how much water is in the top layer of soil. It also distinguishes between ground that is frozen or thawed. Where the ground is not frozen, SMAP measures the amount of water found between the minerals, rocky material, and organic particles found in soil everywhere in the world (SMAP measures liquid water in the top layer of ground but is not able to measure the ice.)  SPL3SMP_E data are transformed to [geographic coordinates using GDAL libraries](https://github.com/google/earthengine-catalog/blob/main/pipelines/smap_convert_l3.py) before the data are ingested into Google Earth Engine.  See the [SMAP L3 Soil Moisture User Guide](https://nsidc.org/sites/default/files/spl3smp_e-v005-userguide.pdf) and references therein for additional documentation and algorithm details.  See [basic](https://developers.google.com/earth-engine/tutorials/community/smap-soil-moisture) and [advanced](https://developers.google.com/earth-engine/tutorials/community/anomalies-analysis-smo-and-pre) tutorials to learn how to use SMAP data in Earth Engine. 
        :param example: var dataset = ee.ImageCollection('NASA/SMAP/SPL3SMP_E/006')                   .filter(ee.Filter.date('2024-01-01', '2024-01-31'));  var soilMositureSurface = dataset.select('soil_moisture_am'); var soilMositureSurfaceVis = {   min: 0.0,   max: 0.5,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 46.529, 2); Map.addLayer(soilMositureSurface, soilMositureSurfaceVis, 'Soil Mositure'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_SMAP_SPL4SMGP_007:
    def __init__(self,):
        self.sensor = 'NASA_SMAP_SPL4SMGP_007'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_SMAP_SPL4SMGP_007.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_SMAP_SPL4SMGP_007.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_SMAP_SPL4SMGP_007(example: str = ''):
        """
        The SMAP Level-4 (L4) Soil Moisture product includes surface soil moisture (0-5 cm vertical average), root-zone soil moisture (0-100 cm vertical average), and additional research products (not validated), including surface meteorological forcing variables, soil temperature, evapotranspiration, and net radiation.  SMAP L4 provides uninterrupted soil moisture data.  During outages of the SMAP instrument, SMAP L4 soil moisture is based on land model simulations alone, without the concomitant assimilation of SMAP brightness temperature observations.  Significant SMAP instrument outages occurred between 19 June and 23 July 2019 and between 6 August and 20 September 2022.  SMAP L-band brightness temperature data from descending and ascending half-orbit satellite passes (approximately 6:00 a.m. and 6:00 p.m. local solar time, respectively) are assimilated into a land surface model that is gridded using an Earth-fixed, global cylindrical 9 km Equal-Area Scalable Earth Grid, Version 2.0 (EASE-Grid 2.0) projection.  The SPL4SMGP product includes a series of 3-hourly time-averaged geophysical data fields from the assimilation system. SPL4SMGP data are transformed to [geographic coordinates using GDAL libraries](https://github.com/google/earthengine-catalog/blob/main/pipelines/smap_convert_l4.py) before the data are ingested into Google Earth Engine.  See the [SMAP L4 Soil Moisture User Guide](https://nsidc.org/sites/default/files/documents/user-guide/multi_spl4smau-v007-userguide.pdf) and references therein for additional documentation and algorithm details.  See [basic](https://developers.google.com/earth-engine/tutorials/community/smap-soil-moisture) and [advanced](https://developers.google.com/earth-engine/tutorials/community/anomalies-analysis-smo-and-pre) tutorials to learn how to use SMAP data in Earth Engine. 
        :param example: var dataset = ee.ImageCollection('NASA/SMAP/SPL4SMGP/007')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30'));  var smSurface = dataset.select('sm_surface'); var smSurfaceVis = {   min: 0.0,   max: 0.9,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 46.529, 2); Map.addLayer(smSurface, smSurfaceVis, 'SM Surface'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_USDA_HSL_SMAP10KM_soil_moisture:
    def __init__(self,):
        self.sensor = 'NASA_USDA_HSL_SMAP10KM_soil_moisture'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_USDA_HSL_SMAP10KM_soil_moisture.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_USDA_HSL_SMAP10KM_soil_moisture.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_USDA_HSL_SMAP10KM_soil_moisture(example: str = ''):
        """
        The NASA-USDA Enhanced SMAP Global soil moisture data provides soil moisture information across the globe at 10-km spatial resolution. This dataset includes: [surface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Surface_Soil_Moisture_SMAP.pdf) and [subsurface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Sub_SurfaceSoil_Moisture_SMAP.pdf) soil moisture (mm), [soil moisture profile](https://gimms.gsfc.nasa.gov/SMOS/SMAP/SoilMoisture_Profile_SMAP.pdf) (%), surface and subsurface soil moisture anomalies (-).  The dataset is generated by integrating satellite-derived Soil Moisture Active Passive (SMAP) Level 3 soil moisture observations into the modified two-layer Palmer model using a 1-D Ensemble Kalman Filter (EnKF) data assimilation approach. Soil moisture anomalies were computed from the climatology of the day of interest. The climatology was estimated based on the full data record of the SMAP satellite observation and the 31-day-centered moving-window approach. The assimilation of the SMAP soil moisture observations help improve the model-based soil moisture predictions particularly over poorly instrumented areas of the world that lack good quality precipitation data.  This dataset was developed by the Hydrological Science Laboratory at NASA's Goddard Space Flight Center in cooperation with USDA Foreign Agricultural Services and USDA Hydrology and Remote Sensing Lab. 
        :param example: var dataset = ee.ImageCollection('NASA_USDA/HSL/SMAP10KM_soil_moisture')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30')); var soilMoisture = dataset.select('ssm'); var soilMoistureVis = {   min: 0.0,   max: 28.0,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 46.529, 2); Map.addLayer(soilMoisture, soilMoistureVis, 'Soil Moisture'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_USDA_HSL_SMAP_soil_moisture:
    def __init__(self,):
        self.sensor = 'NASA_USDA_HSL_SMAP_soil_moisture'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_USDA_HSL_SMAP_soil_moisture.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_USDA_HSL_SMAP_soil_moisture.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_USDA_HSL_SMAP_soil_moisture(example: str = ''):
        """
        The NASA-USDA Global soil moisture and the NASA-USDA SMAP Global soil moisture datates provide soil moisture information across the globe at 0.25°x0.25° spatial resolution. These datasets include [surface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Surface_Soil_Moisture_SMAP.pdf) and [subsurface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Sub_SurfaceSoil_Moisture_SMAP.pdf) soil moisture (mm), [soil moisture profile](https://gimms.gsfc.nasa.gov/SMOS/SMAP/SoilMoisture_Profile_SMAP.pdf) (%), and surface and subsurface soil moisture anomalies. Soil moisture anomalies are unitless and represent standardized anomalies computed using a 31-days moving window. Values around 0 indicate typical moisture conditions, while very positive and very negative values indicate extreme wetting (soil moisture conditions are above average) and drying (soil moisture conditions are below average), respectively.  This dataset is generated by integrating satellite-derived Soil Moisture Active Passive (SMAP) Level 3 soil moisture observations into the modified two-layer Palmer model using a 1-D Ensemble Kalman Filter (EnKF) data assimilation approach. The assimilation of the SMAP soil moisture observations helped improve the model-based soil moisture predictions particularly over poorly instrumented areas of the world that lack good quality precipitation data.  This dataset was developed by the Hydrological Science Laboratory (HSL) at NASA's Goddard Space Flight Center in cooperation with USDA Foreign Agricultural Services and USDA Hydrology and Remote Sensing Lab. 
        :param example: var dataset = ee.ImageCollection('NASA_USDA/HSL/SMAP_soil_moisture')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30')); var soilMoisture = dataset.select('ssm'); var soilMoistureVis = {   min: 0.0,   max: 28.0,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 46.529, 2); Map.addLayer(soilMoisture, soilMoistureVis, 'Soil Moisture'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NASA_USDA_HSL_soil_moisture:
    def __init__(self,):
        self.sensor = 'NASA_USDA_HSL_soil_moisture'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NASA_USDA_HSL_soil_moisture.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NASA_USDA_HSL_soil_moisture.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NASA_USDA_HSL_soil_moisture(example: str = ''):
        """
        The NASA-USDA Global soil moisture and the NASA-USDA SMAP Global soil moisture dataset provide soil moisture information across the globe at 0.25°x0.25° spatial resolution. These datasets include [surface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Surface_Soil_Moisture_SMAP.pdf) and [subsurface](https://gimms.gsfc.nasa.gov/SMOS/SMAP/Sub_SurfaceSoil_Moisture_SMAP.pdf) soil moisture (mm), [soil moisture profile](https://gimms.gsfc.nasa.gov/SMOS/SMAP/SoilMoisture_Profile_SMAP.pdf) (%), and surface and subsurface soil moisture anomalies. Soil moisture anomalies are unitless and represent standardized anomalies computed using a 31-days moving window. Values around 0 indicate typical moisture conditions, while very positive and very negative values indicate extreme wetting (soil moisture conditions are above average) and drying (soil moisture conditions are below average), respectively.  This dataset is generated by integrating satellite-derived Soil Moisture Ocean Salinity (SMOS) Level 2 soil moisture observations into the modified two-layer Palmer model using a 1-D Ensemble Kalman Filter (EnKF) data assimilation approach. The assimilation of the SMOS soil moisture observations helped improve the model-based soil moisture predictions particularly over poorly instrumented areas (e.g., Southern African, Middle East) of the world that lack good quality precipitation data.  This dataset was developed by the Hydrological Science Laboratory (HSL) at NASA's Goddard Space Flight Center in cooperation with USDA Foreign Agricultural Services and USDA Hydrology and Remote Sensing Lab. 
        :param example: var dataset = ee.ImageCollection('NASA_USDA/HSL/soil_moisture')                   .filter(ee.Filter.date('2017-04-01', '2017-04-30')); var soilMoisture = dataset.select('ssm'); var soilMoistureVis = {   min: 0.0,   max: 28.0,   palette: ['0300ff', '418504', 'efff07', 'efff07', 'ff0303'], }; Map.setCenter(-6.746, 15.529, 2); Map.addLayer(soilMoisture, soilMoistureVis, 'Soil Moisture'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NCEP_RE_sea_level_pressure:
    def __init__(self,):
        self.sensor = 'NCEP_RE_sea_level_pressure'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NCEP_RE_sea_level_pressure.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NCEP_RE_sea_level_pressure.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NCEP_RE_sea_level_pressure(example: str = ''):
        """
        The NCEP/NCAR Reanalysis Project is a joint project between the National Centers for Environmental Prediction (NCEP, formerly "NMC") and the National Center for Atmospheric Research (NCAR). The goal of this joint effort is to produce new atmospheric analyses using historical data as well as to produce analyses of the current atmospheric state (Climate Data Assimilation System, CDAS). The NCEP/NCAR Reanalysis 1 project is using a state-of-the-art analysis/forecast system to perform data assimilation using past data from 1948 to the present. The data have 6-hour temporal resolution (0000, 0600, 1200, and 1800 UTC) and 2.5 degree spatial resolution. 
        :param example: var dataset = ee.ImageCollection('NCEP_RE/sea_level_pressure')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var seaLevelPressure = dataset.select('slp'); var seaLevelPressureVis = {   min: 96500.0,   max: 104500.0,   palette: ['800080', '0000ab', '008000', 'ffff00', 'ffa500', 'ff0000'], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(seaLevelPressure, seaLevelPressureVis, 'Sea Level Pressure'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NCEP_RE_surface_temp:
    def __init__(self,):
        self.sensor = 'NCEP_RE_surface_temp'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NCEP_RE_surface_temp.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NCEP_RE_surface_temp.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NCEP_RE_surface_temp(example: str = ''):
        """
        The NCEP/NCAR Reanalysis Project is a joint project between the National Centers for Environmental Prediction (NCEP, formerly "NMC") and the National Center for Atmospheric Research (NCAR). The goal of this joint effort is to produce new atmospheric analyses using historical data as well as to produce analyses of the current atmospheric state (Climate Data Assimilation System, CDAS). The NCEP/NCAR Reanalysis 1 project is using a state-of-the-art analysis/forecast system to perform data assimilation using past data from 1948 to the present. The data have 6-hour temporal resolution (0000, 0600, 1200, and 1800 UTC) and 2.5 degree spatial resolution. 
        :param example: var dataset = ee.ImageCollection('NCEP_RE/surface_temp')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var surfaceAirTemperature = dataset.select('air'); var surfaceAirTemperatureVis = {   min: 230.0,   max: 308.0,   palette: [     '800080', '0000ab', '0000ff', '008000', '19ff2b', 'a8f7ff', 'ffff00',     'd6d600', 'ffa500', 'ff6b01', 'ff0000'   ], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(     surfaceAirTemperature, surfaceAirTemperatureVis, 'Surface Air Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NCEP_RE_surface_wv:
    def __init__(self,):
        self.sensor = 'NCEP_RE_surface_wv'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NCEP_RE_surface_wv.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NCEP_RE_surface_wv.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NCEP_RE_surface_wv(example: str = ''):
        """
        The NCEP/NCAR Reanalysis Project is a joint project between the National Centers for Environmental Prediction (NCEP, formerly "NMC") and the National Center for Atmospheric Research (NCAR). The goal of this joint effort is to produce new atmospheric analyses using historical data as well as to produce analyses of the current atmospheric state (Climate Data Assimilation System, CDAS). The NCEP/NCAR Reanalysis 1 project is using a state-of-the-art analysis/forecast system to perform data assimilation using past data from 1948 to the present. The data have 6-hour temporal resolution (0000, 0600, 1200, and 1800 UTC) and 2.5 degree spatial resolution. 
        :param example: var dataset = ee.ImageCollection('NCEP_RE/surface_wv')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var totalColumnWaterVapor = dataset.select('pr_wtr'); var totalColumnWaterVaporVis = {   min: 0.0,   max: 60.0,   palette: ['0000ff', '00ffff', '008000', 'ffff00', 'ff0000'], }; Map.setCenter(-158.2, 2.81, 2); Map.addLayer(     totalColumnWaterVapor, totalColumnWaterVaporVis,     'Total Column Water Vapor'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Netherlands_Beeldmateriaal_LUCHTFOTO_RGB:
    def __init__(self,):
        self.sensor = 'Netherlands_Beeldmateriaal_LUCHTFOTO_RGB'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Netherlands_Beeldmateriaal_LUCHTFOTO_RGB.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Netherlands_Beeldmateriaal_LUCHTFOTO_RGB.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Netherlands_Beeldmateriaal_LUCHTFOTO_RGB(example: str = ''):
        """
        Orthophotos of Netherlands is a set of color orthoimages. Two nationwide aerial photographs are collected per year: a leafless image at 7.5 cm resolution in the spring and one with leaves on trees at 25 cm resolution in the summer.  For more information, please see the [Netherlands orthophotos documentation](https://opendata.beeldmateriaal.nl/) 
        :param example: var dataset = ee.ImageCollection('Netherlands/Beeldmateriaal/LUCHTFOTO_RGB');  Map.setCenter(5.54, 51.88, 15); Map.addLayer(dataset, {}, 'Netherlands orthophotos RGB');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_ATMOS_NEAR_SURFACE_V2:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_ATMOS_NEAR_SURFACE_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_ATMOS_NEAR_SURFACE_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_ATMOS_NEAR_SURFACE_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_ATMOS_NEAR_SURFACE_V2(example: str = ''):
        """
        The Ocean Near-Surface Atmospheric Properties dataset is part of the NOAA Ocean Surface Bundle (OSB) and provides a high quality Climate Data Record (CDR) of air temperature, wind speed, and specific humidity over ice-free ocean surfaces.  These atmospheric properties are calculated based on brightness temperature data from the Special Sensor Microwave/Imager (SSM/I) and the Special Sensor Microwave/Imager Sounder (SSMIS) on the Defense Meteorological Satellite Program (DMSP) spacecraft, using a neural network. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/ATMOS_NEAR_SURFACE/V2')                   .filter(ee.Filter.date('2017-05-01', '2017-05-02')); var airTemperature = dataset.select('air_temperature'); var airTemperatureVis = {   min: 0.0,   max: 30.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(28.3, -28.1, 1); Map.addLayer(airTemperature, airTemperatureVis, 'Air Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_AOT_V3:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_AOT_V3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_AOT_V3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_AOT_V3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_AOT_V3(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of Aerosol Optical Thickness (AOT) is a collection of global daily 0.1 degree derived data from the PATMOS-x AVHRR level-2b channel 1 (0.63 micron) orbital clear-sky radiance. The aerosol product is generated from AVHRR imagery in cloud-free conditions during daytime over oceans.  Due to the relatively large uncertainties associated with surface reflectance over water glint area and land surface as well as limited AVHRR retrieval channels, this dataset only includes retrieval over non-glint water surface (specifically at the anti-solar side of the orbit with viewing angle more than 40 degree away from the specular ray). For more details, see the [Algorithm Description](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Aerosol_Optical_Thickness/AlgorithmDescription_01B-04.pdf).  Image and data processing by NOAA's National Climatic Data Center. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/AOT/V3')                   .filter(ee.Filter.date('2018-02-01', '2018-03-01')); var aerosolOpticalThickness = dataset.select('aot'); var visParams = {   min: 0.0,   max: 0.5,   palette: ['800080', '0000ff', '00ffff', '008000', 'ffff00', 'ff0000'], }; Map.setCenter(-88.6, 26.4, 3); Map.addLayer(     aerosolOpticalThickness, visParams,     'Aerosol Optical Thickness'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_AOT_V4:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_AOT_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_AOT_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_AOT_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_AOT_V4(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of Aerosol Optical Thickness (AOT) is a collection of global daily 0.1 degree derived data from the PATMOS-x AVHRR level-2b channel 1 (0.63 micron) orbital clear-sky radiance. The aerosol product is generated from AVHRR imagery in cloud-free conditions during daytime over oceans.  Due to the relatively large uncertainties associated with surface reflectance over water glint area and land surface as well as limited AVHRR retrieval channels, this dataset only includes retrieval over non-glint water surface (specifically at the anti-solar side of the orbit with viewing angle more than 40 degree away from the specular ray). For more details, see the [Algorithm Description](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Aerosol_Optical_Thickness/AlgorithmDescription_01B-04.pdf).  Image and data processing by NOAA's National Climatic Data Center. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/AOT/V4')                   .filter(ee.Filter.date('2018-02-01', '2018-03-01')); var aerosolOpticalThickness = dataset.select('aot'); var visParams = {   min: 0.0,   max: 0.5,   palette: ['800080', '0000ff', '00ffff', '008000', 'ffff00', 'ff0000'], }; Map.setCenter(-88.6, 26.4, 3); Map.addLayer(     aerosolOpticalThickness, visParams,     'Aerosol Optical Thickness'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_LAI_FAPAR_V4:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_LAI_FAPAR_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_LAI_FAPAR_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_LAI_FAPAR_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_LAI_FAPAR_V4(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Leaf Area Index (LAI) and Fraction of Absorbed Photosynthetically Active Radiation (FAPAR) dataset contains derived values that characterize the canopy and photosynthetic activity of plants. This dataset is derived from the NOAA AVHRR Surface Reflectance product and is gridded at a resolution of 0.05° on a daily basis. The values are computed globally over land surfaces, but not over bare or very sparsely vegetated areas, permanent ice or snow, permanent wetland, urban areas, or water bodies.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www1.ncdc.noaa.gov/pub/data/sds/cdr/CDRs/AVHRR%20Surface%20Reflectance/TechNote.pdf). 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/LAI_FAPAR/V4')                   .filter(ee.Filter.date('2018-02-01', '2018-03-01')); var leafAreaIndex = dataset.select('LAI'); var leafAreaIndexVis = {   min: 0.0,   max: 4000.0,   palette: ['3b0200', '977705', 'ca9f06', 'ffca09', '006a03', '003b02'], }; Map.setCenter(20, 24.5, 2); Map.addLayer(leafAreaIndex, leafAreaIndexVis, 'Leaf Area Index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_LAI_FAPAR_V5:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_LAI_FAPAR_V5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_LAI_FAPAR_V5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_LAI_FAPAR_V5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_LAI_FAPAR_V5(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Leaf Area Index (LAI) and Fraction of Absorbed Photosynthetically Active Radiation (FAPAR) dataset contains derived values that characterize the canopy and photosynthetic activity of plants. This dataset is derived from the NOAA AVHRR Surface Reflectance product and is gridded at a resolution of 0.05° on a daily basis. The values are computed globally over land surfaces, but not over bare or very sparsely vegetated areas, permanent ice or snow, permanent wetland, urban areas, or water bodies.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Leaf_Area_Index_and_FAPAR/AVHRR/AlgorithmDescriptionAVHRR_01B-20c.pdf).  Provider's note: the orbital drift of N-19 (the last NOAA satellite carrying the AVHRR sensor) began to severely degrade the retrieved product quality. Therefore, VIIRS is now the primary sensor being used for these products from 2014-present. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/LAI_FAPAR/V5')                   .filter(ee.Filter.date('2018-02-01', '2018-03-01')); var leafAreaIndex = dataset.select('LAI'); var leafAreaIndexVis = {   min: 0.0,   max: 4000.0,   palette: ['3b0200', '977705', 'ca9f06', 'ffca09', '006a03', '003b02'], }; Map.setCenter(20, 24.5, 2); Map.addLayer(leafAreaIndex, leafAreaIndexVis, 'Leaf Area Index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_NDVI_V4:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_NDVI_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_NDVI_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_NDVI_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_NDVI_V4(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Normalized Difference Vegetation Index (NDVI) contains gridded daily NDVI derived from the NOAA AVHRR Surface Reflectance product. It provides a measurement of surface vegetation coverage activity, gridded at a resolution of 0.05° and computed globally over land surfaces.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www1.ncdc.noaa.gov/pub/data/sds/cdr/CDRs/AVHRR%20Surface%20Reflectance/TechNote.pdf). 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/NDVI/V4')                   .filter(ee.Filter.date('2018-05-01', '2018-06-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: -1000.0,   max: 5000.0,   palette: [     'ffffff', 'ce7e45', 'fcd163', 'c6ca02', '22cc04', '99b718', '207401',     '012e01'   ], }; Map.setCenter(7.71, 17.93, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_NDVI_V5:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_NDVI_V5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_NDVI_V5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_NDVI_V5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_NDVI_V5(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Normalized Difference Vegetation Index (NDVI) contains gridded daily NDVI derived from the NOAA AVHRR Surface Reflectance product. It provides a measurement of surface vegetation coverage activity, gridded at a resolution of 0.05° and computed globally over land surfaces.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Normalized_Difference_Vegetation_Index/AVHRR/AlgorithmDescriptionAVHRR_01B-20b.pdf).  Provider's note: the orbital drift of N-19 (the last NOAA satellite carrying the AVHRR sensor) began to severely degrade the retrieved product quality. Therefore, VIIRS is now the primary sensor being used for these products from 2014-present. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/NDVI/V5')                   .filter(ee.Filter.date('2018-05-01', '2018-06-01')); var ndvi = dataset.select('NDVI'); var ndviVis = {   min: -1000.0,   max: 5000.0,   palette: [     'ffffff', 'ce7e45', 'fcd163', 'c6ca02', '22cc04', '99b718', '207401',     '012e01'   ], }; Map.setCenter(7.71, 17.93, 2); Map.addLayer(ndvi, ndviVis, 'NDVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_SR_V4:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_SR_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_SR_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_SR_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_SR_V4(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Surface Reflectance contains gridded daily surface reflectance and brightness temperatures derived from the Advanced Very High Resolution Radiometer (AVHRR) sensors onboard seven NOAA polar orbiting satellites. The data are gridded at a resolution of 0.05° and computed globally over land surfaces.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www1.ncdc.noaa.gov/pub/data/sds/cdr/CDRs/AVHRR%20Surface%20Reflectance/TechNote.pdf). 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/SR/V4')                   .filter(ee.Filter.date('2018-05-01', '2018-06-01')); var surfaceReflectance = dataset.select('SREFL_CH1'); var surfaceReflectanceVis = {   min: -1000.0,   max: 9000.0,   palette: ['003b02', '006a03', '008d05', '01be07', '01ff09', 'ffffff'], }; Map.setCenter(52.48, 71.72, 0); Map.addLayer(surfaceReflectance, surfaceReflectanceVis, 'Surface Reflectance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_AVHRR_SR_V5:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_AVHRR_SR_V5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_AVHRR_SR_V5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_AVHRR_SR_V5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_AVHRR_SR_V5(example: str = ''):
        """
        The NOAA Climate Data Record (CDR) of AVHRR Surface Reflectance contains gridded daily surface reflectance and brightness temperatures derived from the Advanced Very High Resolution Radiometer (AVHRR) sensors onboard seven NOAA polar orbiting satellites. The data are gridded at a resolution of 0.05° and computed globally over land surfaces.  Known issues with this dataset include:  - TIMEOFDAY variable contains values that are too large by 1 day  - Latitude values are not correctly associated with the center of   the grid cell, error is < 0.002 degrees  - Longitude values are not correctly associated with the center of   the grid cell, error is < 0.02 degrees  See [technical note from the data provider](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Surface_Reflectance/AVHRR/AlgorithmDescriptionAVHRR_01B-20a.pdf).  Provider's note: the orbital drift of N-19 (the last NOAA satellite carrying the AVHRR sensor) began to severely degrade the retrieved product quality. Therefore, VIIRS is now the primary sensor being used for these products from 2014-present. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/AVHRR/SR/V5')                   .filter(ee.Filter.date('2018-05-01', '2018-06-01')); var surfaceReflectance = dataset.select('SREFL_CH1'); var surfaceReflectanceVis = {   min: -1000.0,   max: 9000.0,   palette: ['003b02', '006a03', '008d05', '01be07', '01ff09', 'ffffff'], }; Map.setCenter(52.48, 71.72, 1); Map.addLayer(surfaceReflectance, surfaceReflectanceVis, 'Surface Reflectance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_GRIDSAT_B1_V2:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_GRIDSAT_B1_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_GRIDSAT-B1_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_GRIDSAT-B1_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_GRIDSAT_B1_V2(example: str = ''):
        """
        This dataset provides a high quality Climate Data Record (CDR) of global infrared measurements from geostationary satellites.  The geostationary satellite data (GridSat-B1) provides data from 3 channels: the CDR-quality infrared window (IRWIN) channel (near 11&micro;m), the visible channel (near 0.6&micro;m) and the infrared water vapor (IRWVP) channel (near 6.7&micro;m). The GridSat-B1 data is projected onto a global 0.07 degree latitude equal-angle grid with date coverage spanning from 1980-present. This data is sourced from the 3-hourly International Satellite Cloud Climatology Project (ISCCP) B1 data. The satellites included in this dataset with their longitudinal coverage over time can be seen [here](https://www.ncdc.noaa.gov/gridsat/images/isccp_coverage_VZA60_nolegend.png). In regions of overlap the CDR methodology merges satellites by selecting the nadir-most observations for each grid point.  Notes:  - Mappings from satid to satellite name are contained in the image's   properties as satid_number: \"satellite_name\", e.g. satid_0: GOES-13,   satid_1: GOES-15, and satid_2: GOES-16.  - IRWIN data has been corrected for view zenith angle, but this correction   is not perfect. It also treats all satellites the same way, whereas the   view zenith angle dependence will vary by satellite. Some VZA residual   will be apparent.  - IRWVP data has no view zenith angle correction and is not CDR quality.  - VSCHN data has no view zenith angle corrections and is not CDR quality.  - Removing the View Zenigth Angle correction for the IRWIN channels can be   done with the following:   Original_temperature_observed = irwin_cdr - irwin_vza_adj 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/GRIDSAT-B1/V2')                   .filter(ee.Filter.date('2017-05-01', '2017-05-14')); var brightnessTemp = dataset.select(['irwin_cdr', 'vschn', 'irwvp']); var brightnessTempVis = {   min: 500.0,   max: 10000.0, }; Map.setCenter(7.71, 17.93, 2); Map.addLayer(brightnessTemp, brightnessTempVis, 'Brightness Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_HEAT_FLUXES_V2:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_HEAT_FLUXES_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_HEAT_FLUXES_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_HEAT_FLUXES_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_HEAT_FLUXES_V2(example: str = ''):
        """
        The Ocean Heat Fluxes dataset is part of the NOAA Ocean Surface Bundle (OSB) and provides a high quality Climate Data Record (CDR) of the air/ocean heat fluxes over ice-free oceans.  This dataset is calculated from the OSB CDR parameters of near-surface atmospheric and sea surface temperature using a neural-network emulator of the TOGA-COARE Bulk Air-Sea Flux Algorithm. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/HEAT_FLUXES/V2')                   .filter(ee.Filter.date('2017-05-01', '2017-05-14')); var heatFluxVis = {   min: -50.0,   max: 500.0,   bands: [     'surface_upward_sensible_heat_flux',     'surface_upward_sensible_heat_flux',     'surface_upward_latent_heat_flux',   ] }; Map.setCenter(28.61, -18.98, 2); Map.addLayer(dataset, heatFluxVis, 'Heat Flux'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_OISST_V2:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_OISST_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_OISST_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_OISST_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_OISST_V2(example: str = ''):
        """
        The NOAA 1/4 degree daily Optimum Interpolation Sea Surface Temperature (OISST) provides complete ocean temperature fields constructed by combining bias-adjusted observations from different platforms (satellite, ships, buoys) on a regular global grid, with gaps filled in by interpolation. Satellite data from the Advanced Very High Resolution Radiometer (AVHRR) provides the main input which permits the high temporal-spatial coverage beginning in late 1981 to the present.  The OISST dataset has a single day's data processed twice. First a near real-time preliminary version is released with a lag of 1 day, and a final version with a lag of 14 days. The final version uses extra days for smoothing, and zonal bias correction in addition to replacing the preliminary version. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/OISST/V2')                   .filter(ee.Filter.date('2017-05-01', '2017-05-14')); var seaSurfaceTemperature = dataset.select('sst'); var visParams = {   min: -180.0,   max: 3000.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(20.3, -20.39, 2); Map.addLayer(seaSurfaceTemperature, visParams, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_OISST_V2_1:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_OISST_V2_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_OISST_V2_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_OISST_V2_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_OISST_V2_1(example: str = ''):
        """
        The NOAA 1/4 degree daily Optimum Interpolation Sea Surface Temperature (OISST) provides complete ocean temperature fields constructed by combining bias-adjusted observations from different platforms (satellite, ships, buoys) on a regular global grid, with gaps filled in by interpolation. Satellite data from the Advanced Very High Resolution Radiometer (AVHRR) provides the main input which permits the high temporal-spatial coverage beginning in late 1981 to the present.  The OISST dataset has a single day's data processed twice. First a near real-time preliminary version is released with a lag of 1 day, and a final version with a lag of 14 days. The final version uses extra days for smoothing, and zonal bias correction in addition to replacing the preliminary version. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/OISST/V2_1')                   .filter(ee.Filter.date('2017-05-01', '2017-05-14')); var seaSurfaceTemperature = dataset.select('sst'); var visParams = {   min: -180.0,   max: 3000.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(20.3, -20.39, 2); Map.addLayer(seaSurfaceTemperature, visParams, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_PATMOSX_V53:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_PATMOSX_V53'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_PATMOSX_V53.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_PATMOSX_V53.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_PATMOSX_V53(example: str = ''):
        """
        This dataset provides high quality Climate Data Record (CDR) of multiple cloud properties along with Advanced Very High Resolution Radiometer (AVHRR) Pathfinder Atmospheres Extended (PATMOS-x) brightness temperatures and reflectances. These data have been fitted to a 0.1 x 0.1 equal angle-grid with both ascending and descending assets generated daily from two to ten NOAA and MetOp satellite passes per day.  This dataset includes 48 bands, 11 of which are deemed CDR quality (marked with "CDR variable" in the band list). The cloud products are derived using the ABI (Advanced Baseline Imager) Cloud Height Algorithm (ACHA), and the Daytime Cloud Optical Properties (DCOMP) algorithm. For more detail on the processing see the [Climate Algorithm Theoretical Basis Document (C-ATBD)]( https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/AVHRR-HIRS_Reflectance_PATMOS-x/AlgorithmDescription%20_01B-1c.pdf). 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/PATMOSX/V53')                   .filter(ee.Filter.date('2017-05-01', '2017-05-14')); var cloudEmissivityAndHeight = dataset.select(     ['cld_emiss_acha', 'cld_height_acha', 'cld_height_uncer_acha']); Map.setCenter(71.72, 52.48, 1); Map.addLayer(cloudEmissivityAndHeight, {}, 'Cloud Emissivity and Height'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_SST_PATHFINDER_V53:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_SST_PATHFINDER_V53'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_SST_PATHFINDER_V53.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_SST_PATHFINDER_V53.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_SST_PATHFINDER_V53(example: str = ''):
        """
        The AVHRR Pathfinder Version 5.3 Sea Surface Temperature dataset (PFV53) is a collection of global, twice-daily 4km sea surface temperature data produced in a partnership by the NOAA National Oceanographic Data Center and the University of Miami's Rosenstiel School of Marine and Atmospheric Science. PFV53 was computed from data from the AVHRR instruments on board NOAA's polar orbiting satellite series using an entirely modernized system based on SeaDAS. PFV53 data are nearly 100% compliant with the GHRSST Data Specification Version 2.0 for L3C products and only deviate from that standard in that 'sses_bias', 'sses_standard_deviation', and 'sst_dtime' variables are empty and hence not included into EE assets. PFV53 data were collected through the operational periods of the NOAA-7 through NOAA-19 Polar Operational Environmental Satellites (POES), and are available from 1981 to 2014. Additional information is available at the [NOAA Pathfinder site](https://www.nodc.noaa.gov/satellitedata/pathfinder4km53/).  Additional band details can be found in the [Tech Specs](https://www.ncei.noaa.gov/pub/data/sds/cdr/CDRs/Sea_Surface_Temperature_Pathfinder/AlgorithmDescription_01B-08.pdf) page.  These data were provided by GHRSST and the US NOAA National Centers for Environmental Information (NCEI). This project was supported in part by a grant from the NOAA Climate Data Record (CDR) Program for satellites. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/SST_PATHFINDER/V53')                   .filter(ee.Filter.date('2014-05-01', '2014-05-14')); var seaSurfaceTemperature = dataset.select('sea_surface_temperature'); var visParams = {   min: 0.0,   max: 2500.0,   palette: [     '030d81', '0519ff', '05e8ff', '11ff01', 'fbff01', 'ff9901', 'ff0000',     'ad0000'   ], }; Map.setCenter(-121.99, -2.11, 2); Map.addLayer(seaSurfaceTemperature, visParams, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CDR_SST_WHOI_V2:
    def __init__(self,):
        self.sensor = 'NOAA_CDR_SST_WHOI_V2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CDR_SST_WHOI_V2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CDR_SST_WHOI_V2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CDR_SST_WHOI_V2(example: str = ''):
        """
        The Sea Surface Temperature - WHOI dataset is part of the NOAA Ocean Surface Bundle (OSB) and provides a high quality Climate Data Record (CDR) of sea surface temperature over ice-free oceans.  The SST values are found through modeling the diurnal variability in combination with AVHRR observations of sea surface temperature. 
        :param example: var dataset = ee.ImageCollection('NOAA/CDR/SST_WHOI/V2')                   .filter(ee.Filter.date('2018-03-01', '2018-03-14')); var seaSurfaceTemperature = dataset.select('sea_surface_temperature'); var visParams = {   min: 0.0,   max: 30.0,   palette: [     '040274', '040281', '0502a3', '0502b8', '0502ce', '0502e6',     '0602ff', '235cb1', '307ef3', '269db1', '30c8e2', '32d3ef',     '3be285', '3ff38f', '86e26f', '3ae237', 'b5e22e', 'd6e21f',     'fff705', 'ffd611', 'ffb613', 'ff8b13', 'ff6e08', 'ff500d',     'ff0000', 'de0101', 'c21301', 'a71001', '911003'   ], }; Map.setCenter(-4.92, -21.09, 2); Map.addLayer(seaSurfaceTemperature, visParams, 'Sea Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CFSR:
    def __init__(self,):
        self.sensor = 'NOAA_CFSR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CFSR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CFSR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CFSR(example: str = ''):
        """
        The National Centers for Environmental Prediction (NCEP) Climate Forecast System Reanalysis (CFSR) was designed and executed as a global, high-resolution, coupled atmosphere-ocean-land surface-sea ice system to provide the best estimate of the state of these coupled domains over the 32-year period of record from January 1979 to March 2011. It has been extended as an operational real-time product. The data in Earth Engine are only present starting from December 13, 2018.  Forecasts are initialized four times per day (0000, 0600, 1200, and 1800 UTC). We ingest only a subset of bands from files matching `cdas1.t??z.pgrbh**03|00**.grib2`, i.e. files of only 0-hour and 3-hour forecasts as the others are omitted. The forecast length is indicated by the 'forecast_hour' metadata field.  Some images contain only a subset of bands. Using this dataset with both "00" and "03" forecast types will require you to cast the bands across the collection. 
        :param example: var dataset = ee.ImageCollection('NOAA/CFSR')                   .filter(ee.Filter.date('2019-04-01', '2019-04-07')); var temperatureSurface = dataset.select('Temperature_surface'); var visParams = {   min: 192,   max: 339,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'] };  var soilType = dataset.select('Soil_type_surface'); var soilTypeVisParams = {   min: 1,   max: 9,   palette: [     'red', 'orange', 'blue', 'yellow', 'violet',     'magenta', 'cadetblue', 'pink', 'aquamarine',] } Map.addLayer(     soilType, soilTypeVisParams, 'Soil type at the surface', true, 0.6); Map.addLayer(     temperatureSurface, visParams, 'Temperature at surface (K)', true, 0.6);  Map.setCenter(-88.6, 26.4, 2); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_CFSV2_FOR6H:
    def __init__(self,):
        self.sensor = 'NOAA_CFSV2_FOR6H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_CFSV2_FOR6H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_CFSV2_FOR6H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_CFSV2_FOR6H(example: str = ''):
        """
        The National Centers for Environmental Prediction (NCEP) Climate Forecast System (CFS) is a fully coupled model representing the interaction between the Earth's atmosphere, oceans, land, and sea ice. CFS was developed at the Environmental Modeling Center (EMC) at NCEP. The operational CFS was upgraded to version 2 (CFSv2) on March 30, 2011.  Forecasts are initialized four times per day (0000, 0600, 1200, and 1800 UTC). This is the same model that was used to create the NCEP Climate Forecast System Reanalysis (CFSR), and the purpose of the CFSv2 dataset is to extend CFSR. We ingest only a subset of bands from files matching cdas1.t??z.sfluxgrbf**06**.grib2.  For more information about CFS, please see the [CFS NOAA site](https://cfs.ncep.noaa.gov/). 
        :param example: var dataset = ee.ImageCollection('NOAA/CFSV2/FOR6H')                   .filter(ee.Filter.date('2018-03-01', '2018-03-14')); var temperatureAboveGround = dataset.select('Temperature_height_above_ground'); var visParams = {   min: 220.0,   max: 310.0,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(temperatureAboveGround, visParams, 'Temperature Above Ground'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_DMSP_OLS_CALIBRATED_LIGHTS_V4:
    def __init__(self,):
        self.sensor = 'NOAA_DMSP_OLS_CALIBRATED_LIGHTS_V4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_DMSP-OLS_CALIBRATED_LIGHTS_V4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_DMSP-OLS_CALIBRATED_LIGHTS_V4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_DMSP_OLS_CALIBRATED_LIGHTS_V4(example: str = ''):
        """
        The Defense Meteorological Program (DMSP) Operational Line-Scan System (OLS) has a unique capability to detect visible and near-infrared (VNIR) emission sources at night.  This collection contains global nighttime lights images with no sensor saturation. The sensor is typically operated at a high-gain setting to enable the detection of moonlit clouds. However, with six bit quantization and limited dynamic range, the recorded data are saturated in the bright cores of urban centers. A limited set of observations at low lunar illumination were obtained where the gain of the detector was set significantly lower than its typical operational setting (sometimes by a factor of 100). Sparse data acquired at low-gain settings were combined with the operational data acquired at high-gain settings to produce the set of global nighttime lights images with no sensor saturation. Data from different satellites were merged and blended into the final product in order to gain maximum coverage. For more information, see this [readme](https://eogdata.mines.edu/dmsp/radcal_readme.txt) file from the provider.  Image and data processing by NOAA's National Geophysical Data Center. DMSP data collected by US Air Force Weather Agency. 
        :param example: var dataset = ee.ImageCollection('NOAA/DMSP-OLS/CALIBRATED_LIGHTS_V4')                   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var nighttimeLights = dataset.select('avg_vis'); var nighttimeLightsVis = {   min: 3.0,   max: 60.0, }; Map.setCenter(7.82, 49.1, 4); Map.addLayer(nighttimeLights, nighttimeLightsVis, 'Nighttime Lights'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_DMSP_OLS_NIGHTTIME_LIGHTS:
    def __init__(self,):
        self.sensor = 'NOAA_DMSP_OLS_NIGHTTIME_LIGHTS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_DMSP-OLS_NIGHTTIME_LIGHTS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_DMSP-OLS_NIGHTTIME_LIGHTS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_DMSP_OLS_NIGHTTIME_LIGHTS(example: str = ''):
        """
        The Defense Meteorological Program (DMSP) Operational Line-Scan System (OLS) has a unique capability to detect visible and near-infrared (VNIR) emission sources at night.  Version 4 of the DMSP-OLS Nighttime Lights Time Series consists of cloud-free composites made using all the available archived DMSP-OLS smooth resolution data for calendar years. In cases where two satellites were collecting data, two composites were produced.  Image and data processing by NOAA's National Geophysical Data Center. DMSP data collected by US Air Force Weather Agency. 
        :param example: var dataset = ee.ImageCollection('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS')                   .filter(ee.Filter.date('2010-01-01', '2010-12-31')); var nighttimeLights = dataset.select('avg_vis'); var nighttimeLightsVis = {   min: 3.0,   max: 60.0, }; Map.setCenter(7.82, 49.1, 4); Map.addLayer(nighttimeLights, nighttimeLightsVis, 'Nighttime Lights'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GFS0P25:
    def __init__(self,):
        self.sensor = 'NOAA_GFS0P25'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GFS0P25.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GFS0P25.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GFS0P25(example: str = ''):
        """
        The Global Forecast System (GFS) is a weather forecast model produced by the National Centers for Environmental Prediction (NCEP). The GFS dataset consists of selected model outputs (described below) as gridded forecast variables. The 384-hour forecasts, with 1-hour (up to 120 hours) and 3-hour (after 120 hours) forecast intervals, are made at 6-hour temporal resolution (i.e. updated four times daily). Use the 'creation_time' and 'forecast_time' properties to select data of interest.  The GFS is a coupled model, composed of an atmosphere model, an ocean model, a land/soil model, and a sea ice model which work together to provide an accurate picture of weather conditions. Note that this model may change; see [history of recent modifications to the global forecast/analysis system](https://www.emc.ncep.noaa.gov/gmb/STATS/html/model_changes.html) and the [documentation](https://www.emc.ncep.noaa.gov/emc/pages/numerical_forecast_systems/gfs.php) for more information. There may be significant hour-to-hour and day-to-day fluctuations that require noise-reduction techniques to be applied to bands before analysis.  Note that the available forecast hours and intervals have also changed:  * From 2015/04/01-2017/07/09: 36-hour forecasts, excluding hour 0, at 3-hour intervals. * From 2017/07/09-2021/06/11: 384-hour forecasts, at 1-hour intervals from hours 0-120, at 3-hour intervals from hours 120-240, and 12-hour intervals from hours 240-384. * From 2021/06/12: 384-hour forecasts, at 1-hour intervals from hours 0-120 and 3-hour intervals from hours 120-384. 
        :param example: var dataset = ee.ImageCollection('NOAA/GFS0P25')                   .filter(ee.Filter.date('2018-03-01', '2018-03-02')); var temperatureAboveGround = dataset.select('temperature_2m_above_ground'); var visParams = {   min: -40.0,   max: 35.0,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(71.72, 52.48, 3.0); Map.addLayer(temperatureAboveGround, visParams, 'Temperature Above Ground'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_16_FDCC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_16_FDCC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_16_FDCC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_16_FDCC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_16_FDCC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-16 conterminous fire product for a single time slice.  var image = ee.Image('NOAA/GOES/16/FDCC/2019297103632900000');  var area = image.select('Area'); var temp = image.select('Temp'); var dqf = image.select('DQF');  var xmin = -145; var ymin = 15; var xmax = -55; var ymax = 54; var geometry = ee.Geometry.Rectangle({   coords: [xmin, ymin, xmax, ymax], geodesic: false}); Map.centerObject(geometry, 3);  var DQFVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud                        // Bad surface type, sunglint, LZA threshold exceeded,     'darkslateblue',   // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ]}; Map.addLayer(dqf, DQFVis, 'DQF');  // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var area = area.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('area')).add(1).pow(1.4)); }); Map.addLayer(area, {color: 'orange'}, 'area');  // Buffer fires based on temperature to make them stand out. var temp = temp.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('temp')).add(2).pow(1.27)); }); Map.setCenter(-75, 43.0, 3); Map.addLayer(temp, {color: 'red'}, 'temp'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_16_FDCF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_16_FDCF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_16_FDCF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_16_FDCF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_16_FDCF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncdc.noaa.gov/data-access/satellite-data/goes-r-series-satellites#FDC)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-16 full disk fire product for a single time slice.  var image = ee.Image('NOAA/GOES/16/FDCF/2019167024053900000'); var fireAreaImage = image.select('Area'); var temperatureImage = image.select('Temp'); var dataQualityFlagsImage = image.select('DQF');  var xMin = -142;  // On station as GOES-E var xMax = xMin + 135; Map.setCenter((xMin + xMax) / 2, 15, 3); var geometry = ee.Geometry.Rectangle([xMin, -65, xMax, 65], null, true);  var dataQualityFlagsVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud     'darkslateblue',   // Bad surface type, sunglint, LZA threshold exceeded,                        // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ] }; Map.addLayer(     dataQualityFlagsImage, dataQualityFlagsVis, 'Data Quality Flags (DQF)');  var fireAreaVectors = fireAreaImage.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }); // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var fireAreaFeatureCollection = fireAreaVectors.map(function(feature) {   return feature.buffer(feature.getNumber('area').add(1).pow(1.76)); }); Map.addLayer(fireAreaFeatureCollection, {color: 'orange'}, 'Fire area (orange)');  var temperatureVector = temperatureImage.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }); // Buffer fires based on temperature to make them stand out. var temperature = temperatureVector.map(function(feature) {   return feature.buffer(feature.getNumber('temp').add(2).pow(1.3)); }); Map.addLayer(temperature, {color: 'red'}, 'Temperature (red)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_16_MCMIPC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_16_MCMIPC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_16_MCMIPC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_16_MCMIPC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_16_MCMIPC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/16/MCMIPC/'; var imageName = '2020211203115800000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.setCenter(-75, 37, 5); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_16_MCMIPF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_16_MCMIPF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_16_MCMIPF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_16_MCMIPF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_16_MCMIPF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/16/MCMIPF/'; var imageName = '2020210184019900000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_16_MCMIPM:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_16_MCMIPM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_16_MCMIPM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_16_MCMIPM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_16_MCMIPM(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  The locations of domains 1 and 2 change over time.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Demonstrates displaying GOES-16 Mesoscale images.  // Band names. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN';  /**  * Properly scales an MCMIPM image.  *  * @param {ee.Image} image An unaltered MCMIPM image.  * @return {ee.Image}  */ var applyScaleAndOffset = function(image) {   var names = image.select('CMI_C..').bandNames();    // Scale the radiance bands using the image's metadata.   var scales = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_scale'));   });   var offsets = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_offset'));   });   var scaled = image.select('CMI_C..')                    .multiply(ee.Image.constant(scales))                    .add(ee.Image.constant(offsets));    return image.addBands({srcImg: scaled, overwrite: true}); };  /**  * Computes and adds a green radiance band to a MCMIPM image.  *  * The image must already have been properly scaled via applyScaleAndOffset.  *  * For more information on computing the green band, see:  *   https://doi.org/10.1029/2018EA000379  *  * @param {ee.Image} image An image to add a green radiance band to. It  *     must be the result of the applyScaleAndOffset function.  * @return {ee.Image}  */ var addGreenBand = function(image) {   function toBandExpression(bandName) { return 'b(\'' + bandName + '\')'; }    var B_BLUE = toBandExpression(BLUE);   var B_RED = toBandExpression(RED);   var B_VEGGIE = toBandExpression(VEGGIE);    // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var GREEN_EXPR = GREEN + ' = 0.45 * ' + B_RED + ' + 0.10 * ' + B_VEGGIE +       ' + 0.45 * ' + B_BLUE;    var green = image.expression(GREEN_EXPR).select(GREEN);   return image.addBands(green); };   var COLLECTION = 'NOAA/GOES/16/MCMIPM';  // Select a subset of the collection, correct the values, and add a green band. var START = ee.Date('2020-09-02T20:40:00'); var END = START.advance(10, 'minutes'); var collection = ee.ImageCollection(COLLECTION)   .filterDate(START, END)   .map(applyScaleAndOffset)   .map(addGreenBand);  // Separates the two domains. var domain1_col = collection.filter('domain == 1'); var domain2_col = collection.filter('domain == 2');  // Note that there are 20 assets, 10 in each domain. var size = ee.String('sizes: collection = ').cat(collection.size()); var size1 = ee.String('domain1 = ').cat(domain1_col.size()); var size2 = ee.String('domain2 = ').cat(domain2_col.size()); print(size.cat('  →  ').cat(size1).cat(' and ').cat(size2));  // Visualization parameters. var goesRgbViz = { bands: [RED, GREEN, BLUE], min: 0.0, max: 0.38, gamma: 1.3 };  // Displays a sample image from domain 1 and 2. Map.addLayer(domain1_col.first(), goesRgbViz, 'Domain 1'); Map.addLayer(domain2_col.first(), goesRgbViz, 'Domain 2');  Map.setCenter(-86, 39, 5); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_17_FDCC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_17_FDCC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_17_FDCC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_17_FDCC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_17_FDCC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncei.noaa.gov/sites/default/files/2021-08/GOES-17_ABI_L2_FireHotSpot_Beta_ReadMe.pdf)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  Formerly known as "GOES West."  Satellite is in storage.  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-17 conterminous fire product for a single time slice.  var image = ee.Image('NOAA/GOES/17/FDCC/2019297090619600000');  var area = image.select('Area'); var temp = image.select('Temp'); var dqf = image.select('DQF');  Map.centerObject(image, 3); var geometry = image.geometry();  var DQFVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud                        // Bad surface type, sunglint, LZA threshold exceeded,     'darkslateblue',   // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ]}; Map.addLayer(dqf, DQFVis, 'DQF');  // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var area = area.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('area')).add(1).pow(1.4)); }); Map.addLayer(area, {color: 'orange'}, 'area');  // Buffer fires based on temperature to make them stand out. var temp = temp.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('temp')).add(2).pow(1.2)); }); Map.setCenter(-137, 43.0, 5); Map.addLayer(temp, {color: 'red'}, 'temp'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_17_FDCF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_17_FDCF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_17_FDCF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_17_FDCF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_17_FDCF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C01520)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  Formerly known as "GOES West."  Satellite is in storage.  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-17 full disk fire product for a single time slice.  var image = ee.Image('NOAA/GOES/17/FDCF/2019275191034100000'); var area = image.select('Area'); var temp = image.select('Temp'); var dqf = image.select('DQF');  var xmin = -205;  // On station as GOES-W var xmax = xmin + 135; Map.setCenter((xmin+xmax)/2, 15, 3); var geometry = ee.Geometry.Rectangle([xmin, -65, xmax, 65], null, true);  var DQFVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud                        // Bad surface type, sunglint, LZA threshold exceeded,     'darkslateblue',   // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ]}; Map.addLayer(dqf, DQFVis, 'DQF');  // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var area = area.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('area')).add(1).pow(1.5)); }); Map.addLayer(area, {color: 'orange'}, 'area');  // Buffer fires based on temperature to make them stand out. var temp = temp.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('temp')).add(2).pow(1.2)); }); Map.addLayer(temp, {color: 'red'}, 'temp'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_17_MCMIPC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_17_MCMIPC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_17_MCMIPC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_17_MCMIPC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_17_MCMIPC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  Formerly known as "GOES West."  Satellite is in storage.  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/17/MCMIPC/'; var imageName = '2020211190617600000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.setCenter(-120, 43, 5); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_17_MCMIPF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_17_MCMIPF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_17_MCMIPF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_17_MCMIPF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_17_MCMIPF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  Formerly known as "GOES West."  Satellite is in storage.  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/17/MCMIPF/'; var imageName = '2020211200032100000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_17_MCMIPM:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_17_MCMIPM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_17_MCMIPM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_17_MCMIPM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_17_MCMIPM(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  The locations of domains 1 and 2 change over time.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  Formerly known as "GOES West."  Satellite is in storage.  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Demonstrates displaying GOES-17 Mesoscale images.  // Band names. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN';  /**  * Properly scales an MCMIPM image.  *  * @param {ee.Image} image An unaltered MCMIPM image.  * @return {ee.Image}  */ var applyScaleAndOffset = function(image) {   var names = image.select('CMI_C..').bandNames();    // Scale the radiance bands using the image's metadata.   var scales = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_scale'));   });   var offsets = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_offset'));   });   var scaled = image.select('CMI_C..')                    .multiply(ee.Image.constant(scales))                    .add(ee.Image.constant(offsets));    return image.addBands({srcImg: scaled, overwrite: true}); };  /**  * Computes and adds a green radiance band to a MCMIPM image.  *  * The image must already have been properly scaled via applyScaleAndOffset.  *  * For more information on computing the green band, see:  *   https://doi.org/10.1029/2018EA000379  *  * @param {ee.Image} image An image to add a green radiance band to. It  *     must be the result of the applyScaleAndOffset function.  * @return {ee.Image}  */ var addGreenBand = function(image) {   function toBandExpression(bandName) { return 'b(\'' + bandName + '\')'; }    var B_BLUE = toBandExpression(BLUE);   var B_RED = toBandExpression(RED);   var B_VEGGIE = toBandExpression(VEGGIE);    // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var GREEN_EXPR = GREEN + ' = 0.45 * ' + B_RED + ' + 0.10 * ' + B_VEGGIE +       ' + 0.45 * ' + B_BLUE;    var green = image.expression(GREEN_EXPR).select(GREEN);   return image.addBands(green); };   var COLLECTION = 'NOAA/GOES/17/MCMIPM';  // Select a subset of the collection, correct the values, and add a green band. var START = ee.Date('2020-09-09T21:03:00'); var END = START.advance(10, 'minutes'); var collection = ee.ImageCollection(COLLECTION)   .filterDate(START, END)   .map(applyScaleAndOffset)   .map(addGreenBand);  // Separates the two domains. var domain1_col = collection.filter('domain == 1'); var domain2_col = collection.filter('domain == 2');  // Note that there are 20 assets, 10 in each domain. var size = ee.String('sizes: collection = ').cat(collection.size()); var size1 = ee.String('domain1 = ').cat(domain1_col.size()); var size2 = ee.String('domain2 = ').cat(domain2_col.size()); print(size.cat('  →  ').cat(size1).cat(' and ').cat(size2));  // Visualization parameters. var goesRgbViz = { bands: [RED, GREEN, BLUE], min: 0.0, max: 0.38, gamma: 1.3 };  // Displays a sample image from domain 1 and 2. Map.addLayer(domain1_col.first(), goesRgbViz, 'Domain 1'); Map.addLayer(domain2_col.first(), goesRgbViz, 'Domain 2');  Map.setCenter(-133, 50, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_18_FDCC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_18_FDCC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_18_FDCC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_18_FDCC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_18_FDCC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncdc.noaa.gov/data-access/satellite-data/goes-r-series-satellites#FDC)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-18 conterminous fire product for a single time slice.  // TODO(schwehr): Find an asset with some fires. var image = ee.Image('NOAA/GOES/18/FDCC/2022341230117000000');  var area = image.select('Area'); var temp = image.select('Temp'); var dqf = image.select('DQF');  Map.centerObject(image, 3); var geometry = image.geometry();  var DQFVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud                        // Bad surface type, sunglint, LZA threshold exceeded,     'darkslateblue',   // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ]}; Map.addLayer(dqf, DQFVis, 'DQF');  // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var area = area.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('area')).add(1).pow(1.4)); }); Map.addLayer(area, {color: 'orange'}, 'area');  // Buffer fires based on temperature to make them stand out. var temp = temp.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('temp')).add(2).pow(1.2)); }); Map.setCenter(-137, 43.0, 5); Map.addLayer(temp, {color: 'red'}, 'temp'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_18_FDCF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_18_FDCF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_18_FDCF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_18_FDCF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_18_FDCF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Fire (HSC) product contains four images: one in the form of a fire mask and the other three with pixel values identifying fire temperature, fire area, and fire radiative power.  The ABI L2+ FHS metadata mask assigns a flag to every earth-navigated pixel that indicates its disposition with respect to the FHS algorithm. Operational users who have the lowest tolerance for false alarms should focus on the "processed" and "saturated" categories (mask codes 10, 11, 30, and 31), but within these categories there can still be false alarms.  [README](https://www.ncdc.noaa.gov/data-access/satellite-data/goes-r-series-satellites#FDC)  NOAA provides the following scripts for suggested categories, color maps, and visualizations:   - [GOES-16-17_FireDetection.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireDetection.js)  - [GOES-16-17_FireReclassification.js](https://github.com/google/earthengine-community/blob/master/datasets/scripts/GOES-16-17_FireReclassification.js)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // NOAA GOES-18 full disk fire product for a single time slice.  // TODO(schwehr): Find an asset with some fires. var image = ee.Image('NOAA/GOES/18/FDCF/2022341230020300000'); var area = image.select('Area'); var temp = image.select('Temp'); var dqf = image.select('DQF');  var xmin = -205;  // On station as GOES-W var xmax = xmin + 135; Map.setCenter((xmin+xmax)/2, 15, 3); var geometry = ee.Geometry.Rectangle([xmin, -65, xmax, 65], null, true);  var DQFVis = {   min: 0,   max: 5,   palette: [     'blanchedalmond',  // Good quality fire pixel     'olive',           // Good quality fire free land     'teal',            // Opaque cloud                        // Bad surface type, sunglint, LZA threshold exceeded,     'darkslateblue',   // off Earth, or missing input data     'lemonchiffon',    // Bad input data     'burlywood'        // Algorithm failure   ]}; Map.addLayer(dqf, DQFVis, 'DQF');  // Fires are small enough that they are difficult to see at the scale of // an entire GOES image.  Buffer fires based on area to make them stand out. var area = area.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'area',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('area')).add(1).pow(1.5)); }); Map.addLayer(area, {color: 'orange'}, 'area');  // Buffer fires based on temperature to make them stand out. var temp = temp.reduceToVectors({   geometry: geometry,   scale: 2000,   geometryType: 'centroid',   labelProperty: 'temp',   maxPixels: 1e10, }).map(function(feature){   return feature.buffer(ee.Number(feature.get('temp')).add(2).pow(1.2)); }); Map.addLayer(temp, {color: 'red'}, 'temp'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_18_MCMIPC:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_18_MCMIPC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_18_MCMIPC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_18_MCMIPC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_18_MCMIPC(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/18/MCMIPC/'; var imageName = '2022215195617000000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.setCenter(-120, 43, 5); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_18_MCMIPF:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_18_MCMIPF'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_18_MCMIPF.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_18_MCMIPF.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_18_MCMIPF(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Band aliases. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN'; // 16 pairs of CMI and DQF followed by Bah 2018 synthetic green. // Band numbers in the EE asset, 0-based. var NUM_BANDS = 33; // Skipping the interleaved DQF bands. var BLUE_BAND_INDEX = (1 - 1) * 2; var RED_BAND_INDEX = (2 - 1) * 2; var VEGGIE_BAND_INDEX = (3 - 1) * 2; var GREEN_BAND_INDEX = NUM_BANDS - 1;  // Visualization range for GOES RGB. var GOES_MIN = 0.0; var GOES_MAX = 0.7;  // Alternatively 1.0 or 1.3. var GAMMA = 1.3;  var goesRgbViz = {   bands: [RED, GREEN, BLUE],   min: GOES_MIN,   max: GOES_MAX,   gamma: GAMMA };  var applyScaleAndOffset = function(image) {   image = ee.Image(image);   var bands = new Array(NUM_BANDS);   for (var i = 1; i < 17; i++) {     var bandName = 'CMI_C' + (100 + i + '').slice(-2);     var offset = ee.Number(image.get(bandName + '_offset'));     var scale =  ee.Number(image.get(bandName + '_scale'));     bands[(i-1) * 2] = image.select(bandName).multiply(scale).add(offset);      var dqfName = 'DQF_C' + (100 + i + '').slice(-2);     bands[(i-1) * 2 + 1] = image.select(dqfName);   }    // Bah, Gunshor, Schmit, Generation of GOES-16 True Color Imagery without a   // Green Band, 2018. https://doi.org/10.1029/2018EA000379   // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var green1 = bands[RED_BAND_INDEX].multiply(0.45);   var green2 = bands[VEGGIE_BAND_INDEX].multiply(0.10);   var green3 = bands[BLUE_BAND_INDEX].multiply(0.45);   var green = green1.add(green2).add(green3);   bands[GREEN_BAND_INDEX] = green.rename(GREEN);    return ee.Image(ee.Image(bands).copyProperties(image, image.propertyNames())); };  var collection = 'NOAA/GOES/18/MCMIPF/'; var imageName = '2022215195020500000'; var assetId = collection + imageName; var image = applyScaleAndOffset(assetId); Map.addLayer(image, goesRgbViz); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_GOES_18_MCMIPM:
    def __init__(self,):
        self.sensor = 'NOAA_GOES_18_MCMIPM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_GOES_18_MCMIPM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_GOES_18_MCMIPM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_GOES_18_MCMIPM(example: str = ''):
        """
        [GOES](https://www.goes.noaa.gov) satellites are geostationary weather satellites run by NOAA.  The Cloud and Moisture Imagery products are all at 2km resolution. Bands 1-6 are reflective. The dimensionless "reflectance factor" quantity is normalized by the solar zenith angle. These bands support the characterization of clouds, vegetation, snow/ice, and aerosols. Bands 7-16 are emissive. The brightness temperature at the Top-Of-Atmosphere (TOA) is measured in Kelvin. These bands support the characterization of the surface, clouds, water vapor, ozone, volcanic ash, and dust based on emissive properties.  The locations of domains 1 and 2 change over time.  [README](https://www.ncei.noaa.gov/products/satellite/goes-r-series)  NOAA's Office of Satellite and Product Operations has a [General Satellite Messages](https://www.ospo.noaa.gov/Operations/messages.html) channel with status updates. 
        :param example: // Demonstrates displaying GOES-18 Mesoscale images.  // Band names. var BLUE = 'CMI_C01'; var RED = 'CMI_C02'; var VEGGIE = 'CMI_C03'; var GREEN = 'GREEN';  /**  * Properly scales an MCMIPM image.  *  * @param {ee.Image} image An unaltered MCMIPM image.  * @return {ee.Image}  */ var applyScaleAndOffset = function(image) {   var names = image.select('CMI_C..').bandNames();    // Scale the radiance bands using the image's metadata.   var scales = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_scale'));   });   var offsets = names.map(function(name) {     return image.getNumber(ee.String(name).cat('_offset'));   });   var scaled = image.select('CMI_C..')                    .multiply(ee.Image.constant(scales))                    .add(ee.Image.constant(offsets));    return image.addBands({srcImg: scaled, overwrite: true}); };  /**  * Computes and adds a green radiance band to a MCMIPM image.  *  * The image must already have been properly scaled via applyScaleAndOffset.  *  * For more information on computing the green band, see:  *   https://doi.org/10.1029/2018EA000379  *  * @param {ee.Image} image An image to add a green radiance band to. It  *     must be the result of the applyScaleAndOffset function.  * @return {ee.Image}  */ var addGreenBand = function(image) {   function toBandExpression(bandName) { return 'b(\'' + bandName + '\')'; }    var B_BLUE = toBandExpression(BLUE);   var B_RED = toBandExpression(RED);   var B_VEGGIE = toBandExpression(VEGGIE);    // Green = 0.45 * Red + 0.10 * NIR + 0.45 * Blue   var GREEN_EXPR = GREEN + ' = 0.45 * ' + B_RED + ' + 0.10 * ' + B_VEGGIE +       ' + 0.45 * ' + B_BLUE;    var green = image.expression(GREEN_EXPR).select(GREEN);   return image.addBands(green); };   var COLLECTION = 'NOAA/GOES/18/MCMIPM';  // Select a subset of the collection, correct the values, and add a green band. var START = ee.Date('2022-08-03T19:59:00'); var END = START.advance(10, 'minutes'); var collection = ee.ImageCollection(COLLECTION)   .filterDate(START, END)   .map(applyScaleAndOffset)   .map(addGreenBand);  // Separates the two domains. var domain1_col = collection.filter('domain == 1'); var domain2_col = collection.filter('domain == 2');  // Note that there are 20 assets, 10 in each domain. var size = ee.String('sizes: collection = ').cat(collection.size()); var size1 = ee.String('domain1 = ').cat(domain1_col.size()); var size2 = ee.String('domain2 = ').cat(domain2_col.size()); print(size.cat('  →  ').cat(size1).cat(' and ').cat(size2));  // Visualization parameters. var goesRgbViz = { bands: [RED, GREEN, BLUE], min: 0.0, max: 0.38, gamma: 1.3 };  // Displays a sample image from domain 1 and 2. Map.addLayer(domain1_col.first(), goesRgbViz, 'Domain 1'); Map.addLayer(domain2_col.first(), goesRgbViz, 'Domain 2');  Map.setCenter(-133, 50, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_NCEP_DOE_RE2_total_cloud_coverage:
    def __init__(self,):
        self.sensor = 'NOAA_NCEP_DOE_RE2_total_cloud_coverage'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_NCEP_DOE_RE2_total_cloud_coverage.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_NCEP_DOE_RE2_total_cloud_coverage.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_NCEP_DOE_RE2_total_cloud_coverage(example: str = ''):
        """
        NCEP-DOE Reanalysis 2 project is using a state-of-the-art analysis/forecast system to perform data assimilation using past data from 1979 through the previous year. 
        :param example: // Import the dataset, filter the first five months of 2020. var dataset = ee.ImageCollection('NOAA/NCEP_DOE_RE2/total_cloud_coverage')                   .filter(ee.Filter.date('2020-01-01', '2020-06-01'));  // Select the total cloud cover band. var totalCloudCoverage = dataset.select('tcdc');  // Reduce the image collection to per-pixel mean. var totalCloudCoverageMean = totalCloudCoverage.mean();  // Define visualization parameters. var vis = {   min: 0,   max: 80,  // dataset max is 100   palette: ['black', 'white'], };  // Display the dataset. Map.setCenter(0, 20, 2); Map.addLayer(totalCloudCoverageMean, vis, 'Total Cloud Coverage Data', false);  // Display a visualization image with opacity defined by cloud cover. var visImg = totalCloudCoverageMean.visualize(vis)   .updateMask(totalCloudCoverageMean.divide(100)); Map.addLayer(visImg, null, 'Total Cloud Coverage Vis.', true); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_NGDC_ETOPO1:
    def __init__(self,):
        self.sensor = 'NOAA_NGDC_ETOPO1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_NGDC_ETOPO1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_NGDC_ETOPO1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_NGDC_ETOPO1(example: str = ''):
        """
        ETOPO1 is a 1 arc-minute global relief model of Earth''s surface that integrates land topography and ocean bathymetry. It was built from numerous global and regional data sets. It contains two elevation bands: ice_surface and bedrock. 
        :param example: var dataset = ee.Image('NOAA/NGDC/ETOPO1'); var elevation = dataset.select('bedrock'); var elevationVis = {   min: -7000.0,   max: 3000.0,   palette: ['011de2', 'afafaf', '3603ff', 'fff477', 'b42109'], }; Map.setCenter(-37.62, 25.8, 2); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_NHC_HURDAT2_atlantic:
    def __init__(self,):
        self.sensor = 'NOAA_NHC_HURDAT2_atlantic'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_NHC_HURDAT2_atlantic.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_NHC_HURDAT2_atlantic.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_NHC_HURDAT2_atlantic(example: str = ''):
        """
        Hurricane best track database (HURDAT2).  Atlantic basin 1851-2018.
        :param example: // Show hurricane tracks and points for 2017. var hurricanes = ee.FeatureCollection('NOAA/NHC/HURDAT2/atlantic');  var year = '2017'; var points = hurricanes.filter(ee.Filter.date(ee.Date(year).getRange('year')));  // Find all of the hurricane ids. var GetId = function(point) {   return ee.Feature(point).get('id'); }; var storm_ids = points.toList(1000).map(GetId).distinct();  // Create a line for each hurricane. var lines = ee.FeatureCollection(storm_ids.map(function(storm_id){   var pts = points.filter(ee.Filter.eq('id', ee.String(storm_id)));   pts = pts.sort('system:time_start');   var line = ee.Geometry.LineString(pts.geometry().coordinates());   var feature = ee.Feature(line);   return feature.set('id', storm_id); }));  Map.addLayer(lines, {color: 'red'}, 'tracks'); Map.addLayer(points, {color: 'black'}, 'points');  Map.setCenter(-53, 36, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_NHC_HURDAT2_pacific:
    def __init__(self,):
        self.sensor = 'NOAA_NHC_HURDAT2_pacific'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_NHC_HURDAT2_pacific.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_NHC_HURDAT2_pacific.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_NHC_HURDAT2_pacific(example: str = ''):
        """
        Hurricane best track database (HURDAT2).  Pacific basin 1949-2018.
        :param example: // Show hurricane tracks and points for 1993. var hurricanes = ee.FeatureCollection('NOAA/NHC/HURDAT2/pacific');  var year = '1993'; var points = hurricanes.filter(ee.Filter.date(ee.Date(year).getRange('year')));  // Find all of the hurricane ids. var GetId = function(point) {   return ee.Feature(point).get('id'); }; var storm_ids = points.toList(1000).map(GetId).distinct();  // Create a line for each hurricane. var lines = ee.FeatureCollection(storm_ids.map(function(storm_id){   var pts = points.filter(ee.Filter.eq('id', ee.String(storm_id)));   pts = pts.sort('system:time_start');   var line = ee.Geometry.LineString(pts.geometry().coordinates());   var feature = ee.Feature(line);   return feature.set('id', storm_id); }));  Map.addLayer(lines, {color: 'red'}, 'tracks'); Map.addLayer(points, {color: 'black'}, 'points');  Map.setCenter(210, 30, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_NWS_RTMA:
    def __init__(self,):
        self.sensor = 'NOAA_NWS_RTMA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_NWS_RTMA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_NWS_RTMA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_NWS_RTMA(example: str = ''):
        """
        The Real-Time Mesoscale Analysis (RTMA) is a high-spatial and temporal resolution analysis for near-surface weather conditions.  This dataset includes hourly analyses at 2.5 km for CONUS. 
        :param example: var dataset = ee.ImageCollection('NOAA/NWS/RTMA')                   .filter(ee.Filter.date('2018-03-01', '2018-03-02')); var windSpeed = dataset.select('WIND'); var windSpeedVis = {   min: 0.0,   max: 12.0,   palette: ['001137', '01abab', 'e7eb05', '620500'], }; Map.setCenter(-95.62, 39.91, 4); Map.addLayer(windSpeed, windSpeedVis, 'Wind Speed'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_PERSIANN_CDR:
    def __init__(self,):
        self.sensor = 'NOAA_PERSIANN_CDR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_PERSIANN-CDR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_PERSIANN-CDR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_PERSIANN_CDR(example: str = ''):
        """
        PERSIANN-CDR is a daily quasi-global precipitation product that spans the period from 1983-01-01 to present.  The data is produced quarterly, with a typical lag of three months. The product is developed by the Center for Hydrometeorology and Remote Sensing at the University of California, Irvine (UC-IRVINE/CHRS) using Gridded Satellite (GridSat-B1) IR data that are derived from merging ISCCP B1 IR data, along with GPCP version 2.2. 
        :param example: var dataset = ee.ImageCollection('NOAA/PERSIANN-CDR')                   .filter(ee.Filter.date('2017-05-01', '2017-05-02')); var precipitation = dataset.select('precipitation'); var precipitationVis = {   min: 0.0,   max: 50.0,   palette: ['3907ff', '03fff3', '28ff25', 'fbff09', 'ff1105'], }; Map.setCenter(113.03, 3.34, 3); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP09GA:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP09GA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP09GA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP09GA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP09GA(example: str = ''):
        """
        The Visible Infrared Imaging Radiometer Suite (VIIRS) daily surface reflectance (VNP09GA) product provides an estimate of land surface reflectance from the Suomi National Polar-Orbiting Partnership (S-NPP) VIIRS sensor. Data are provided for three imagery bands (I1, I2, I3) at nominal 500 meter resolution (~463 meter) and nine moderate-resolution bands (M1, M2, M3, M4, M5, M7, M8, M10, M11) at nominal 1 kilometer (~926 meter) resolution. The 500 meter and 1 kilometer datasets are derived through resampling the native 375 meter and 750 meter VIIRS resolutions, respectively, in the L2 input product. These bands are corrected for atmospheric conditions to provide an estimate of the surface spectral reflectance as it would be measured at ground level.  The data is temporally aggregated over each of the 16 possible passes per day. When multiple observations are present for each day, only the first of the highest-quality observations is included.  For additional information, visit the VIIRS [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) and see the [User Guide](https://lpdaac.usgs.gov/documents/124/VNP09_User_Guide_V1.6.pdf).  Documentation:  * [User's Guide] (https://lpdaac.usgs.gov/documents/124/VNP09_User_Guide_V1.6.pdf)  * [Algorithm Theoretical Basis Document (ATBD)] (https://lpdaac.usgs.gov/documents/122/VNP09_ATBD.pdf) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP09GA')                   .filter(ee.Filter.date('2017-05-01', '2017-05-31')); var rgb = dataset.select(['M5', 'M4', 'M3']); var rgbVis = {   min: 0.0,   max: 3000.0, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(rgb, rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP09H1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP09H1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP09H1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP09H1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP09H1(example: str = ''):
        """
        The 8-day Visible Infrared Imaging Radiometer Suite (VIIRS) Surface Reflectance (VNP09H1) Version 1 composite product provides an estimate of land surface reflectance from the Suomi National Polar-orbiting Partnership (Suomi NPP) VIIRS sensor for three imagery bands (I1, I2, I3) at nominal 500m resolution (~463m). The 500m dataset is derived through resampling the native 375m VIIRS resolution in the L2 input product. The data are corrected for atmospheric conditions such as the effects of molecular gases, including ozone and water vapor, and for the effects of atmospheric aerosols. Each pixel represents the best possible Level 2G observation during an 8-day period, which is selected on the basis of high observation coverage, low sensor angle, the absence of clouds or cloud shadow, and aerosol loading. The three reflectance bands, this product includes a state quality assurance (QA) layer and a reflectance band quality layer.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/123/VNP09_User_Guide_V1.1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/122/VNP09_ATBD.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp09h1v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP09H1')                   .filter(ee.Filter.date('2017-05-01', '2017-06-30')); var rgb = dataset.select(['SurfReflect_I1', 'SurfReflect_I2', 'SurfReflect_I3']); var rgbVis = {   min: 0.0,   max: 1.0, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(rgb, rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP13A1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP13A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP13A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP13A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP13A1(example: str = ''):
        """
        The Suomi National Polar-Orbiting Partnership (S-NPP) NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Vegetation Indices (VNP13A1) data product provides vegetation indices by a process of selecting the best available pixel over a 16-day acquisition period at 500 meter resolution. The VNP13 data products are designed after the Moderate Resolution Imaging Spectroradiometer (MODIS) Terra and Aqua Vegetation Indices product suite to promote the continuity of the Earth Observation System (EOS) mission.  The VNP13 algorithm process produces three vegetation indices: (1) Normalized Difference Vegetation Index (NDVI), (2) the Enhanced Vegetation Index (EVI), and (3) Enhanced Vegetation Index-2 (EVI2). (1) NDVI is one of the longest continual remotely sensed time series observations, using both the red and near-infrared (NIR) bands. (2) EVI is a slightly different vegetation index that is more sensitive to canopy cover, while NDVI is more sensitive to chlorophyll. (3) EVI2 is a reformation of the standard 3-band EVI, using the red band and NIR band. This reformation addresses arising issues when comparing VIIRS EVI to other EVI models that do not include a blue band. EVI2 will eventually become the standard EVI.  Along with the three Vegetation Indices layers, this product also includes layers for near-infrared (NIR) reflectance; three shortwave infrared (SWIR) reflectance-red, blue, and green reflectance; composite day of year; pixel reliability; view and sun angles, and a quality layer.  For additional information, visit the VIIRS [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) and see the [User Guide](https://lpdaac.usgs.gov/documents/1372/VNP13_User_Guide_ATBD_V2.1.2.pdf).  Documentation:  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/filespec/VIIRS/1/VNP13A1) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP13A1'); var mean_evi_january_2018 = dataset     .filterDate('2018-01-01', '2018-01-31')     .select('EVI')     .mean(); var evi_vis = {   min: 0,   max: 10000,   palette: ['000000', '004400', '008800', '00bb00', '00ff00'], }; Map.setCenter(95.571, 27.808, 8); Map.addLayer(mean_evi_january_2018, evi_vis, 'Mean EVI January 2018'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP14A1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP14A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP14A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP14A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP14A1(example: str = ''):
        """
        The daily Suomi National Polar-Orbiting Partnership NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Thermal Anomalies/Fire (VNP14A1) Version 1 data product provides daily information about active fires and other thermal anomalies. The VNP14A1 data product is a global, 1km gridded composite of fire pixels detected from VIIRS 750m bands over a daily (24-hour) period. The VNP14 data products are designed after the Moderate Resolution Imaging Spectroradiometer (MODIS) Thermal Anomalies/Fire product suite.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/427/VNP14_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/427/VNP14_User_Guide_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp14a1v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP14A1').first();  var band_vis = {   min: [1],   max: [10000],   palette: ['000000', '004400', '008800', '00bb00', '00ff00'],   bands: ['MaxFRP'], };  Map.setCenter(-1.94, 10.35, 10); Map.addLayer(dataset, band_vis, 'Maximum Fire Radiative Power'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP15A2H:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP15A2H'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP15A2H.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP15A2H.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP15A2H(example: str = ''):
        """
        The Visible Infrared Imaging Radiometer Suite (VIIRS) Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation (FPAR) Version 1 data product provides information about the vegetative canopy layer at 500 meter resolution (VNP15A2H). The VIIRS sensor is located onboard the NOAA/NASA joint Suomi National Polar-Orbiting Partnership (Suomi NPP) satellite. LAI is an index that quantifies the one-sided leaf area of a canopy, while FPAR is the fraction of incoming solar energy absorbed through photosynthesis at 400 to 700 nanometers. This product is intentionally designed after the Terra and Aqua Moderate Resolution Imaging Spectroradiometer (MODIS) LAI/FPAR operational algorithm to promote the continuity of the Earth Observation System (EOS) mission.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/126/VNP15_User_Guide.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/125/VNP15_ATBD.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp15a2hv001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP15A2H')                   .filter(ee.Filter.date('2022-11-01', '2022-12-01'));  var visualization = {   bands: ['Lai'],   min: [0],   max: [4],   palette: [     'a50026',     'd73027',     'f46d43',     'fdae61',     'fee08b',     'ffffbf',     'd9ef8b',     'a6d96a',     '66bd63',     '1a9850',     '006837',   ] }; Map.setCenter(41.2, 38.84, 3); Map.addLayer(dataset, visualization, 'Leaf Area Index (LAI)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP21A1D:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP21A1D'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP21A1D.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP21A1D.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP21A1D(example: str = ''):
        """
        The NASA Suomi National Polar-Orbiting Partnership (Suomi NPP) Visible Infrared Imaging Radiometer Suite (VIIRS) Land Surface Temperature and Emissivity (LST&E) Day Version 1 product (VNP21A1D) is compiled daily from daytime Level 2 Gridded (L2G) intermediate products.  The L2G process maps the daily VNP21 swath granules onto a sinusoidal MODIS grid and stores all observations overlapping a gridded cell for a given day. The VNP21A1 algorithm sorts through all these observations for each cell and estimates the final LST value as an average from all cloud-free observations that have good LST accuracies. Only observations having observation coverage more than a certain threshold (15%) are considered for this averaging.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/429/VNP21_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1332/VNP21_ATBD_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp21a1dv001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP21A1D')                   .filter(ee.Filter.date('2022-11-01', '2022-12-01'));  var visualization = {   bands: ['LST_1KM'],   min: [150],   max: [300],   palette: [     'a50026',     'd73027',     'f46d43',     'fdae61',     'fee08b',     'ffffbf',     'd9ef8b',     'a6d96a',     '66bd63',     '1a9850',     '006837',   ] }; Map.setCenter(41.2, 38.84, 3); Map.addLayer(dataset, visualization, 'LST');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP21A1N:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP21A1N'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP21A1N.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP21A1N.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP21A1N(example: str = ''):
        """
        The NASA Suomi National Polar-Orbiting Partnership (Suomi NPP) Visible Infrared Imaging Radiometer Suite (VIIRS) Land Surface Temperature and Emissivity (LST&E) Night Version 1 product (VNP21A1N) is compiled daily from nighttime Level 2 Gridded (L2G) intermediate products.  The L2G process maps the daily VNP21 swath granules onto a sinusoidal MODIS grid and stores all observations overlapping a gridded cell for a given night. The VNP21A1 algorithm sorts through all these observations for each cell and estimates the final LST value as an average from all cloud-free observations that have good LST accuracies. Only observations having observation coverage more than a certain threshold (15%) are considered for this averaging.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/429/VNP21_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/1332/VNP21_ATBD_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp21a1nv001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP21A1N')                   .filter(ee.Filter.date('2022-11-01', '2022-12-01'));  var visualization = {   bands: ['LST_1KM'],   min: 200,   max: 300,   palette: [     'a50026',     'd73027',     'f46d43',     'fdae61',     'fee08b',     'ffffbf',     'd9ef8b',     'a6d96a',     '66bd63',     '1a9850',     '006837',   ] }; Map.setCenter(41.2, 38.84, 3); Map.addLayer(dataset, visualization, 'LST');
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP22Q2:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP22Q2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP22Q2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP22Q2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP22Q2(example: str = ''):
        """
        The Suomi National Polar-Orbiting Partnership (Suomi NPP) NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Land Cover Dynamics data product provides global land surface phenology (GLSP) metrics at yearly intervals. The VNP22Q2 data product is derived from time series of the two-band Enhanced Vegetation Index (EVI2) calculated from VIIRS Nadir Bidirectional Reflectance Distribution Function (BRDF)-Adjusted Reflectance (NBAR). Vegetation phenology metrics at 500 meter spatial resolution are identified for up to two detected growing cycles per year.  The product contains six phenological transition dates: onset of greenness increase, onset of greenness maximum, onset of greenness decrease, onset of greenness minimum, dates of mid-greenup, and senescence phases. The product also includes the growing season length. The greenness-related metrics consist of EVI2 onset of greenness increase, EVI2 onset of greenness maximum, EVI2 growing season, rate of greenness increase, and rate of greenness decrease. The confidence of phenology detection is provided as greenness agreement growing season, proportion of good quality (PGQ) growing season, PGQ onset greenness increase, PGQ onset greenness maximum, PGQ onset greenness decrease, and PGQ onset greenness minimum. The final layer is quality control specifying the overall quality of the product.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/637/VNP22_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/637/VNP22_User_Guide_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp22q2v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP22Q2')                   .filter(ee.Filter.date('2017-01-01', '2017-12-31')); var rgb = dataset.select([   'EVI2_Growing_Season_Area_1',   'PGQ_Growing_Season_1',   'Greenness_Agreement_Growing_Season_1']); var rgbVis = {   min: [0, 0, 0],   max: [75, 150, 200], }; Map.setCenter(17.93, 7.71, 4); Map.addLayer(rgb, rgbVis, 'False color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP43IA1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP43IA1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP43IA1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP43IA1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP43IA1(example: str = ''):
        """
        The Suomi National Polar-Orbiting Partnership (Suomi NPP) NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Bidirectional Reflectance Distribution Function (BRDF) and Albedo Model Parameters (VNP43IA1) Version 1 product provides kernel weights (parameters) at 500 resolution. The VNP43IA1 product is produced daily using 16 days of VIIRS data, temporally weighted to the ninth day, which is reflected in the file name. The VNP43IA1 product provides three spectrally dependent kernel weights, also known as model parameters: isotropic (fiso), volumetric (fvol), and geometric (fgeo), which can be used to model anisotropic effects of the Earth's surface. All VNP43 data products are designed to promote the continuity of NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) BRDF/Albedo data product suite.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/viirs_user_guide/vnp43ia1_and_vnp43ma1_brdf_albedo_model_parameters_product)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/194/VNP43_ATBD_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp43ia1v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP43IA1')                 .filter(ee.Filter.date('2017-03-10', '2017-03-11'));  var visualization = {   bands: ['BRDF_Albedo_Parameters_fiso_I1'],   min: 0,   max: 1,   palette: [     '000080','0000d9','4000ff','8000ff','0080ff','00ffff',     '00ff80','80ff00','daff00','ffff00','fff500','FFda00',     'ffb000','ffa400','ff4f00','ff2500','ff0a00','ff00ff',   ] };  Map.setCenter(89, 58, 3);  Map.addLayer(dataset, visualization, 'Isotropic parameter for band I1'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP43IA2:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP43IA2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP43IA2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP43IA2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP43IA2(example: str = ''):
        """
        The Suomi National Polar-Orbiting Partnership (Suomi NPP) NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Bidirectional Reflectance Distribution Function (BRDF) and Albedo Quality (VNP43IA2) Version 1 product provides BRDF and Albedo quality at 500m resolution. The VNP43IA2 product is produced daily using 16 days of VIIRS data and is weighted temporally to the ninth day, which is reflected in the file name. The VNP43IA2 product provides information regarding band quality and days of valid observation within a 16-day period for the VIIRS imagery bands. The VNP43 data products are designed to promote the continuity of NASA&apos;s Moderate Resolution Imaging Spectroradiometer (MODIS) BRDF/Albedo data product suite.  Documentation:  * [User's Guide](https://www.umb.edu/spectralmass/viirs_user_guide/vnp43ia2_and_vnp43ma2_brdf_albedo_quality_product)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/194/VNP43_ATBD_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp43ia2v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP43IA2')                 .filter(ee.Filter.date('2021-06-01', '2021-06-03'));  var visualization = {   bands: ['BRDF_Albedo_ValidObs_I1'],   min: 35550,   max: 45535,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(89, 58, 6);  Map.addLayer(dataset, visualization, 'Days of valid observation for band I1'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP46A1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP46A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP46A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP46A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP46A1(example: str = ''):
        """
        The Suomi National Polar-orbiting Partnership (SNPP) Visible Infrared Imaging Radiometer Suite (VIIRS) supports a Day-Night Band (DNB) sensor that provides global daily measurements of nocturnal visible and near-infrared (NIR) light that are suitable for Earth system science and applications. The VIIRS DNB's ultra-sensitivity in lowlight conditions enables us to generate a new set of science-quality nighttime products that manifest substantial improvements in sensor resolution and calibration when compared to the previous era of Defense Meteorological Satellite Program/Operational Linescan System's (DMSP/OLS) nighttime lights image products.  VNP46A1 is a daily, top-of-atmosphere, at-sensor nighttime radiance product called VIIRS/NPP Daily Gridded Day Night Band 15 arc-second Linear Lat Lon Grid Night. The product contains 26 Science Data Sets (SDS) that include sensor radiance, zenith and azimuth angles (at-sensor, solar, and lunar), cloud-mask flags, time, shortwave IR radiance, brightness temperatures, VIIRS quality flags, moon phase angle, and moon illumination fraction. It also provides Quality Flag (QF) information specific to the cloud-mask, VIIRS moderate-resolution bands M10, M11, M12, M13, M15, M16, and DNB.  Documentation:  * [User's Guide](https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/VIIRS_Black_Marble_UG_v1.1_July_2020.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/Product%20Generation%20Algorithms/VIIRS_Black_Marble_ATBD_v1.1_July_2020.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/missions-and-measurements/products/VNP46A1/) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A1').filter(   ee.Filter.date('2013-01-01', '2013-07-01'));  // At-sensor Day/night Band radiance (DNB). var dnb = dataset.select('DNB_At_Sensor_Radiance_500m'); var dnbVis = {   min: 0,   max: 50,   palette: ['black', 'purple', 'cyan', 'green', 'yellow', 'red', 'white'], };  Map.setCenter(-79.4, 43.1, 8);  Map.addLayer(dnb, dnbVis, 'Day-Night Band (DNB) at sensor radiance 500m'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP46A2:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP46A2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP46A2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP46A2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP46A2(example: str = ''):
        """
        The Suomi National Polar-orbiting Partnership (SNPP) Visible Infrared Imaging Radiometer Suite (VIIRS) supports a Day-Night Band (DNB) sensor that provides global daily measurements of nocturnal visible and near-infrared (NIR) light that are suitable for Earth system science and applications. The VIIRS DNB's ultra-sensitivity in lowlight conditions enables us to generate a new set of science-quality nighttime products that manifest substantial improvements in sensor resolution and calibration when compared to the previous era of Defense Meteorological Satellite Program/Operational Linescan System's (DMSP/OLS) nighttime lights image products.  VNP46A2 dataset is a daily moonlight- and atmosphere-corrected Nighttime Lights (NTL) product using the Bidirectional Reflectance Distribution Function (BRDF).  Documentation:  * [User's Guide](https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/VIIRS_Black_Marble_UG_v1.1_July_2020.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://ladsweb.modaps.eosdis.nasa.gov/api/v2/content/archives/Document%20Archive/Science%20Data%20Product%20Documentation/Product%20Generation%20Algorithms/VIIRS_Black_Marble_ATBD_v1.1_July_2020.pdf)  * [General Documentation](https://ladsweb.modaps.eosdis.nasa.gov/missions-and-measurements/products/VNP46A2/) 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A2').filter(   ee.Filter.date('2013-01-01', '2013-07-01'));  // Bidirectional Reflectance Distribution Function (BRDF) var brdf = dataset.select('DNB_BRDF_Corrected_NTL'); var brdfVis = {   min: 0,   max: 100,   palette: ['black', 'purple', 'cyan', 'green', 'yellow', 'red', 'white'], };  Map.setCenter(-79.4, 43.1, 8); // Day/Night Band (DNB) // NightTime Light (NTL) Map.addLayer(brdf, brdfVis, 'DNB_BRDF_Corrected_NTL'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_001_VNP64A1:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_001_VNP64A1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_001_VNP64A1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_001_VNP64A1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_001_VNP64A1(example: str = ''):
        """
        The daily Suomi National Polar-Orbiting Partnership (Suomi NPP) NASA Visible Infrared Imaging Radiometer Suite (VIIRS) Burned Area (VNP64A1) Version 1 data product is a monthly, global gridded 500m product containing per-pixel burned area and quality information. The VNP64 burned area mapping approach employs 750m VIIRS imagery coupled with 750m VIIRS active fire observations.  VIIRS bands that are both sensitive and insensitive to biomass burning are used to detect changes caused by fire and to differentiate them from other types of change.  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/1330/VNP64A1_User_Guide_V1.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://lpdaac.usgs.gov/documents/572/VNP64A1_ATBD_V1.pdf)  * [General Documentation](https://lpdaac.usgs.gov/products/vnp64a1v001/)  * [Land Product Quality Assessment website](https://landweb.modaps.eosdis.nasa.gov/browse?sensor=VIIRS&sat=SNPP) 
        :param example: var image = ee.Image('NOAA/VIIRS/001/VNP64A1/2018_12_01'); var visualization = {   bands: ['Last_Day'],   min: 250.0,   max: 320.0,   palette: [     '000080', '0000d9', '4000ff', '8000ff', '0080ff', '00ffff',     '00ff80', '80ff00', 'daff00', 'ffff00', 'fff500', 'ffda00',     'ffb000', 'ffa400', 'ff4f00', 'ff2500', 'ff0a00', 'ff00ff',   ] };  Map.setCenter(-119.13, 38.32, 8); Map.addLayer(image, visualization, 'Last day'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_DNB_ANNUAL_V21:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_DNB_ANNUAL_V21'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_DNB_ANNUAL_V21.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_DNB_ANNUAL_V21.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_DNB_ANNUAL_V21(example: str = ''):
        """
        Annual global VIIRS nighttime lights dataset is a time series produced from monthly cloud-free average radiance grids spanning 2013 to 2021. Data for 2022 are available in the [NOAA/VIIRS/DNB/ANNUAL_V22](NOAA_VIIRS_DNB_ANNUAL_V22) dataset.  An initial filtering step removed sunlit, moonlit and cloudy pixels, leading to rough composites that contains lights, fires, aurora and background. The rough annual composites are made on monthly increments and then combined to form rough annual composites.  The subsequent steps uses the twelve-month median radiance to discard high and low radiance outliers, filtering out most fires and isolating the background. Background areas are zeroed out using the data range (DR) calculated from 3x3 grid cells. The DR threshold for background is indexed to cloud-cover levels, with higher DR thresholds in areas having low numbers of cloud-free coverages.  Note: 2012 data are not yet included because of differences in processing. (A) 201204-201212, and (B) 201204-201303. Only set (B) has masked median and average bands which doesn't follow the pattern there in other year datasets. 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/DNB/ANNUAL_V21')                   .filter(ee.Filter.date('2020-01-01', '2021-01-01'));  var nighttime = dataset.select('maximum'); var nighttimeVis = {min: 0.0, max: 60.0}; Map.setCenter(-77.1056, 38.8904, 8); Map.addLayer(nighttime, nighttimeVis, 'Nighttime'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_DNB_ANNUAL_V22:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_DNB_ANNUAL_V22'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_DNB_ANNUAL_V22.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_DNB_ANNUAL_V22.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_DNB_ANNUAL_V22(example: str = ''):
        """
        Annual global VIIRS nighttime lights dataset is a time series produced from monthly cloud-free average radiance grids for 2022. Data for earlier years are available in the [NOAA/VIIRS/DNB/ANNUAL_V21](NOAA_VIIRS_DNB_ANNUAL_V21) dataset.  An initial filtering step removed sunlit, moonlit and cloudy pixels, leading to rough composites that contains lights, fires, aurora and background. The rough annual composites are made on monthly increments and then combined to form rough annual composites.  The subsequent steps uses the twelve-month median radiance to discard high and low radiance outliers, filtering out most fires and isolating the background. Background areas are zeroed out using the data range (DR) calculated from 3x3 grid cells. The DR threshold for background is indexed to cloud-cover levels, with higher DR thresholds in areas having low numbers of cloud-free coverages. 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/DNB/ANNUAL_V22')                   .filter(ee.Filter.date('2022-01-01', '2023-01-01'));  var nighttime = dataset.select('maximum'); var nighttimeVis = {min: 0.0, max: 60.0}; Map.setCenter(-77.1056, 38.8904, 8); Map.addLayer(nighttime, nighttimeVis, 'Nighttime'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG(example: str = ''):
        """
        Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB).  As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed.  Cloud cover is determined using the VIIRS Cloud Mask product (VCM). In addition, data near the edges of the swath are not included in the composites (aggregation zones 29-32). Version 1 has NOT been filtered to screen out lights from aurora, fires, boats, and other temporal lights. This separation is under development and will be included in a later version of this time series. Also in development is a method to separate lights from background (non-light) values.  Prior to averaging, the DNB data is filtered to exclude data impacted by stray light, lightning, lunar illumination, and cloud-cover. 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG')                   .filter(ee.Filter.date('2017-05-01', '2017-05-31')); var nighttime = dataset.select('avg_rad'); var nighttimeVis = {min: 0.0, max: 60.0}; Map.setCenter(-77.1056, 38.8904, 8); Map.addLayer(nighttime, nighttimeVis, 'Nighttime'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG:
    def __init__(self,):
        self.sensor = 'NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NOAA_VIIRS_DNB_MONTHLY_V1_VCMSLCFG(example: str = ''):
        """
        Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB).  As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed.  Cloud cover is determined using the VIIRS Cloud Mask product (VCM). In addition, data near the edges of the swath are not included in the composites (aggregation zones 29-32). Version 1 has NOT been filtered to screen out lights from aurora, fires, boats, and other temporal lights. This separation is under development and will be included in a later version of this time series. Also in development is a method to separate lights from background (non-light) values.  This product is an alternative configuration of the VIIRS DNB using a procedure to correct for stray light. The correction procedure extends visible areas closer to the poles and improves dynamic range. It should be noted some artifacts are introduced due to the procedure used in twilight regions; see [reference paper](https://spie.org/Publications/Proceedings/Paper/10.1117/12.2023107) for more details. This product excludes data impacted by cloud cover. 
        :param example: var dataset = ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG')                   .filter(ee.Filter.date('2017-05-01', '2017-05-31')); var nighttime = dataset.select('avg_rad'); var nighttimeVis = {min: 0.0, max: 60.0}; Map.setCenter(-77.1056, 38.8904, 8); Map.addLayer(nighttime, nighttimeVis, 'Nighttime'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class NRCan_CDEM:
    def __init__(self,):
        self.sensor = 'NRCan_CDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/NRCan_CDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/NRCan_CDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_NRCan_CDEM(example: str = ''):
        """
        The Canadian Digital Elevation Model (CDEM) is part of Natural Resources Canada's (NRCan) altimetry system and stems from the existing Canadian Digital Elevation Data (CDED). In these data, elevations can be either ground or reflective surface elevations.  The CDEM is comprised of multiple DEMs with varying resolutions. These vary according to latitude and have a base resolution of 0.75 arc-seconds. For more information see the [Product Specifications](https://ftp.geogratis.gc.ca/pub/nrcan_rncan/elevation/cdem_mnec/doc/CDEM_product_specs.pdf)  Contains information licensed under the [Open Government Licence - Canada](https://open.canada.ca/en/open-government-licence-canada). 
        :param example: var dataset = ee.ImageCollection('NRCan/CDEM'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -50.0,   max: 1500.0,   palette: ['0905ff', 'ffefc4', 'ffffff'], }; Map.setCenter(-139.3643, 63.3213, 9); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_DISALEXI_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_DISALEXI_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_DISALEXI_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_DISALEXI_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_DISALEXI_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Atmosphere-Land Exchange Inverse / Disaggregation of the Atmosphere-Land Exchange Inverse (ALEXI/DisALEXI)  DisALEXI was recently ported to Google Earth Engine as part of the OpenET framework and the baseline ALEXI/DisALEXI model structure is described by Anderson et al. (2012, 2018). The ALEXI evapotranspiration (ET) model specifically uses time differential land surface temperature (LST) measurements from geostationary or moderate resolution polar orbiting platforms to generate regional ET maps. DisALEXI then disaggregates the regional ALEXI ET to finer scales using Landsat data (30 m; biweekly) to resolve individual farm fields and other landscape features. [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/DISALEXI/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET DisALEXI Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_EEMETRIC_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_EEMETRIC_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_EEMETRIC_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_EEMETRIC_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_EEMETRIC_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Google Earth Engine implementation of the Mapping Evapotranspiration at high Resolution with Internalized Calibration model (eeMETRIC)  eeMETRIC applies the advanced METRIC algorithms and process of Allen et al. (2007; 2015) and Allen et al. (2013b), where a singular relationship between the near surface air temperature difference (dT) and delapsed land surface temperature (TsDEM) is used to estimate sensible heat flux (H) and is applied to each Landsat scene. Automated selection of the hot and cold pixels for an image generally follows a statistical isolation procedure described by Allen et al. (2013a) and ReVelle, Kilic and Allen (2019a,b). The calibration of H in eeMETRIC utilizes alfalfa reference ET calculated from the NLDAS gridded weather dataset using a fixed 15% reduction in computed reference ET to account for known biases in the gridded data set. The fixed reduction does not impact the calibration accuracy of eeMETRIC and mostly reduces impacts of boundary layer buoyancy correction.  The identification of candidates for pools of hot and cold pixels has evolved in the eeMETRIC implementation of METRIC. The new automated calibration process incorporates the combination of methodologies and approaches that stem from two development branches of EEFlux (Allen et al., 2015). The first branch focused on improving the automated pixel selection process using standard lapse rates for land surface temperature (LST) without any further spatial delapsing (ReVelle et al., 2019b). The second branch incorporated a secondary spatial delapsing of LST as well as changes to the pixel selection process (ReVelle et al., 2019a). The final, combined approach is described by Kilic et al. (2021).  eeMETRIC employs the aerodynamic-related functions in complex terrain (mountains) developed by Allen et al. (2013b) to improve estimates for aerodynamic roughness, wind speed and boundary layer stability as related to estimated terrain roughness, position on a slope and wind direction. These functions tend to increase estimates for H (and reduce ET) on windward slopes and may reduce H (and increase ET) on leeward slopes. Other METRIC functions employed in eeMETRIC that have been added since the descriptions provided in Allen et al. (2007 and 2011) include reduction in soil heat flux (G) in the presence of organic mulch on the ground surface, use of an excess aerodynamic resistance for shrublands, use of the Perrier function for trees identified as forest (Allen et al., 2018; Santos et al., 2012) and aerodynamic estimation of evaporation from open water rather than using energy balance (Jensen and Allen 2016; Allen et al., 2018). In 2022, the Perrier function was applied to tree (orchard) crops and a 3-source partitioning of bulk surface temperature into canopy temperature, shaded soil temperature and sunlit soil temperature was applied to both orchards and vineyards. These latter applications were made where orchards and vineyards are identified by CDL or, in California, by a state-sponsored land use system. These functions and other enhancements to the original METRIC model are described in the most current METRIC users manual (Allen et al., 2018). eeMETRIC uses the atmospherically corrected surface reflectance and LST from Landsat Collection 2 Level 2, with fallback to Collection 2 Level 1 when needed for near real-time estimates.  [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/EEMETRIC/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET eeMETRIC Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_ENSEMBLE_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_ENSEMBLE_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_ENSEMBLE_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_ENSEMBLE_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_ENSEMBLE_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        The OpenET dataset includes satellite-based data on the total amount of water that is transferred from the land surface to the atmosphere through the process of evapotranspiration (ET). OpenET provides ET data from multiple satellite-driven models, and also calculates a single "ensemble value" from the model ensemble. The models currently included in the OpenET model ensemble are ALEXI/DisALEXI, eeMETRIC, geeSEBAL, PT-JPL, SIMS, and SSEBop. The OpenET ensemble ET value is calculated as the mean of the ensemble after filtering and removing outliers using the median absolute deviation approach. All models currently use Landsat satellite data to produce ET data at a pixel size of 30 meters by 30 meters (0.22 acres per pixel). The monthly ET dataset provides data on total ET by month as an equivalent depth of water in millimeters.  [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/ENSEMBLE/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et_ensemble_mad').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET Ensemble Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_GEESEBAL_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_GEESEBAL_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_GEESEBAL_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_GEESEBAL_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_GEESEBAL_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Implementation of geeSEBAL was recently completed within the OpenET framework and an overview of the current geeSEBAL version can be found in Laipelt et al. (2021), which is based on the original algorithms developed by Bastiaanssen et al. (1998). The OpenET geeSEBAL implementation uses land surface temperature (LST) data from Landsat Collection 2, in addition to NLDAS and gridMET datasets as instantaneous and daily meteorological inputs, respectively. The automated statistical algorithm to select the hot and cold endmembers is based on a simplified version of the Calibration using Inverse Modeling at Extreme Conditions (CIMEC) algorithm proposed by Allen et al. (2013), where quantiles of LST and the normalized difference vegetation index (NDVI) values are used to select endmember candidates in the Landsat domain area. The cold and wet endmember candidates are selected in well vegetated areas, while the hot and dry endmember candidates are selected in the least vegetated cropland areas. Based on the selected endmembers, geeSEBAL assumes that in the cold and wet endmember all available energy is converted to latent heat (with high rates of transpiration), while in the hot and dry endmember all available energy is converted to sensible heat. Finally, estimates of daily evapotranspiration are upscaled from instantaneous estimates based on the evaporative fraction, assuming it is constant during the daytime without significant changes in soil moisture and advection. Based on the results from the OpenET Accuracy Assessment and Intercomparison study, the OpenET geeSEBAL algorithm was modified as follows: (i) the simplified version of CIMEC was improved by using additional filters to select the endmembers, including the use of the USDA Cropland Data Layer (CDL) and filters for NDVI, LST and albedo; (ii) corrections to LST for endmembers based on antecedent precipitation; (iii) definition of NLDAS wind speed thresholds to reduce model instability during the atmospheric correction; and, (iv) improvements to estimate daily net radiation, using FAO-56 as reference (Allen et al., 1998). Overall, geeSEBAL performance is dependent on topographic, climate, and meteorological conditions, with higher sensitivity and uncertainty related to hot and cold endmember selections for the CIMEC automated calibration, and lower sensitivity and uncertainty related to meteorological inputs (Laipelt et al., 2021 and Kayser et al., 2022). To reduce uncertainties related to complex terrain, improvements were added to correct LST and global (incident) radiation on the surface (including the environmental lapse rate, elevation slope and aspect) to represent the effects of topographic features on the model’s endmember selection algorithm and ET estimates.  [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/GEESEBAL/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET geeSEBAL Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_PTJPL_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_PTJPL_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_PTJPL_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_PTJPL_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_PTJPL_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Priestley-Taylor Jet Propulsion Laboratory (PT-JPL)  The core formulation of the PT-JPL model within the OpenET framework has not changed from the original formulation detailed in Fisher et al. (2008). However, enhancements and updates to model inputs and time integration for PT-JPL were made to take advantage of contemporary gridded weather datasets, provide consistency with other models, improve open water evaporation estimates, and account for advection over crop and wetland areas in semiarid and arid environments. These changes include the use of Landsat surface reflectance and thermal radiation for calculating net radiation, photosynthetically active radiation, plant canopy and moisture variables, and use of NLDAS, Spatial CIMIS, and gridMET weather data for estimating insolation and ASCE reference ET. Similar to the implementation of other OpenET models, estimation of daily and monthly time integrated ET is based on the fraction of ASCE reference ET. Open water evaporation is estimated following a surface energy balance approach of Abdelrady et al. (2016) that is specific for water bodies by accounting for water heat flux as opposed to soil heat flux.  [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/PTJPL/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET PT-JPL Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_SIMS_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_SIMS_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_SIMS_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_SIMS_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_SIMS_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Satellite Irrigation Management Support  The NASA Satellite Irrigation Management Support (SIMS) model was originally developed to support satellite mapping of crop coefficients and evapotranspiration (ET) from irrigated lands and to increase access to this data to support use in irrigation scheduling and regional assessment of agricultural water needs (Melton et al., 2012). SIMS uses a reflectance based approach and incorporates the density coefficient described by Allen and Pereira (2009) and Pereira et al. (2020) to compute basal crop coefficients for each 30 x 30 m pixel. The primary change from the most recent SIMS publication (Pereira et al., 2020) for implementation in OpenET is the integration of a gridded soil water balance model to account for soil evaporation following precipitation events. Results of the OpenET Phase I intercomparison and accuracy assessment (Melton et al., 2022) showed that SIMS generally performed well for cropland sites during the growing season, but had a persistent low bias during the winter months or other time periods with frequent precipitation. This result was anticipated, since the reflectance-based approach used by SIMS is not sensitive to soil evaporation. To correct for this underestimation, a soil water balance model based on FAO-56 (Allen et al., 1998) was implemented on Google Earth Engine and driven with gridded precipitation data from gridMET to estimate soil evaporation coefficients. These coefficients were then combined with the basal crop coefficients calculated by SIMS to calculate total crop evapotranspiration using the dual crop coefficient approach. In addition, a modest positive bias was observed in the SIMS data for periods with low or sparse vegetative cover. To correct for this bias, updates were made to the equations that calculate the minimum basal crop coefficient to allow lower minimum basal crop coefficient values to be achieved. Full documentation of the SIMS model, current algorithms, and details and equations used in the soil water balance model are included in the SIMS user manual.  The SIMS model calculates ET under well-watered conditions for the current crop growth stage and condition as measured by the satellite data, and SIMS is generally expected to have a positive bias for deficit irrigated crops and croplands with short-term or intermittent crop water stress. At present, SIMS is only implemented for croplands, and non-agricultural lands are masked out in this data collection. Future research will extend the vegetation density-crop coefficient approach used within SIMS to other land cover types. [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/SIMS/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET SIMS Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenET_SSEBOP_CONUS_GRIDMET_MONTHLY_v2_0:
    def __init__(self,):
        self.sensor = 'OpenET_SSEBOP_CONUS_GRIDMET_MONTHLY_v2_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenET_SSEBOP_CONUS_GRIDMET_MONTHLY_v2_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenET_SSEBOP_CONUS_GRIDMET_MONTHLY_v2_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenET_SSEBOP_CONUS_GRIDMET_MONTHLY_v2_0(example: str = ''):
        """
        Operational Simplified Surface Energy Balance (SSEBop)  The Operational Simplified Surface Energy Balance (SSEBop) model by Senay et al. (2013, 2017) is a thermal-based simplified surface energy model for estimating actual ET based on the principles of satellite psychrometry (Senay 2018). The OpenET SSEBop implementation uses land surface temperature (Ts) from Landsat (Collection 2 Level-2 Science Products) with key model parameters (cold/wet-bulb reference, Tc, and surface psychrometric constant, 1/dT) derived from a combination of observed surface temperature, normalized difference vegetation index (NDVI), climatological average (1980-2017) daily maximum air temperature (Ta, 1-km) from Daymet, and net radiation data from ERA-5. This model implementation uses the Google Earth Engine processing framework for connecting key SSEBop ET functions and algorithms together when generating both intermediate and aggregated ET results. A detailed study and evaluation of the SSEBop model across CONUS (Senay et al., 2022) informs both cloud implementation and assessment for water balance applications at broad scales. Notable model (v0.2.6) enhancements and performance against previous versions include additional compatibility with Landsat 9 (launched Sep 2021), global model extensibility, and improved parameterization of SSEBop using FANO (Forcing and Normalizing Operation) to better estimate ET in all landscapes and all seasons regardless of vegetation cover density, thereby improving model accuracy by avoiding extrapolation of Tc to non-calibration regions.  [Additional information](https://openetdata.org/methodologies/) 
        :param example: var dataset = ee.ImageCollection('OpenET/SSEBOP/CONUS/GRIDMET/MONTHLY/v2_0')   .filterDate('2020-01-01', '2021-01-01');  // Compute the annual evapotranspiration (ET) as the sum of the monthly ET // images for the year. var et = dataset.select('et').sum();  var visualization = {   min: 0,   max: 1400,   palette: [     '9e6212', 'ac7d1d', 'ba9829', 'c8b434', 'd6cf40', 'bed44b', '9fcb51',     '80c256', '61b95c', '42b062', '45b677', '49bc8d', '4dc2a2', '51c8b8',     '55cece', '4db4ba', '459aa7', '3d8094', '356681', '2d4c6e',   ] };  Map.setCenter(-100, 38, 5);  Map.addLayer(et, visualization, 'OpenET SSEBop Annual ET'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_CLM_CLM_LST_MOD11A2_DAYNIGHT_M_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_CLM_CLM_LST_MOD11A2_DAYNIGHT_M_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAYNIGHT_M_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAYNIGHT_M_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_CLM_CLM_LST_MOD11A2_DAYNIGHT_M_v01(example: str = ''):
        """
        Long-term MODIS LST day-time and night-time differences at 1 km based on the 2000-2017 time series  Derived using the [data.table package and quantile function in R](https://gitlab.com/openlandmap/global-layers/tree/master/input_layers/MOD11A2). For more info about the MODIS LST product see [this page](https://lpdaac.usgs.gov/products/mod11a2v006/). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/CLM/CLM_LST_MOD11A2-DAYNIGHT_M/v01');  var visualization = {   bands: ['jan'],   min: -40.5137,   max: 1336.09,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Long-term Land Surface Temperature monthly day-night difference');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_M_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_M_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAY_M_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAY_M_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_M_v01(example: str = ''):
        """
        Land Surface Temperature daytime monthly mean value 2000-2017.  Derived using the [data.table package and quantile function in R](https://gitlab.com/openlandmap/global-layers/tree/master/input_layers/MOD11A2). For more info about the MODIS LST product see [this page](https://lpdaac.usgs.gov/products/mod11a2v006/). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/CLM/CLM_LST_MOD11A2-DAY_M/v01');  var visualization = {   bands: ['jan'],   min: 11989.0,   max: 16700.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Long-term Land Surface Temperature daytime monthly mean');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_SD_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_SD_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAY_SD_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_CLM_CLM_LST_MOD11A2-DAY_SD_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_CLM_CLM_LST_MOD11A2_DAY_SD_v01(example: str = ''):
        """
        Long-term MODIS LST day-time and night-time temperatures standard deviation at 1 km based on the 2000-2017 time series.  Derived using the [data.table package and quantile function in R](https://gitlab.com/openlandmap/global-layers/tree/master/input_layers/MOD11A2). For more info about the MODIS LST product see [this page](https://lpdaac.usgs.gov/products/mod11a2v006/). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/CLM/CLM_LST_MOD11A2-DAY_SD/v01');  var visualization = {   bands: ['jan'],   min: 25.0,   max: 390.0,   palette: [     '2828ff','2828ff','6666ff','8989ff','a1a1ff','b2b2ff',     'c0c0ff','cbcbff','d5d5ff','dedeff','e6e6ff','ededff',     'f5f5ff','ffffff','fcfcff','fffbfb','fff4f4','ffeded',     'ffe5e5','ffdddd','ffd4d4','ffcbcb','ffbfbf','ffb2b2',     'ffa1a1','ff8a8a','ff6767','ff2929',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Long-term Land Surface Temperature daytime monthly sd');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_CLM_CLM_PRECIPITATION_SM2RAIN_M_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_CLM_CLM_PRECIPITATION_SM2RAIN_M_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_CLM_CLM_PRECIPITATION_SM2RAIN_M_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_CLM_CLM_PRECIPITATION_SM2RAIN_M_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_CLM_CLM_PRECIPITATION_SM2RAIN_M_v01(example: str = ''):
        """
        Monthly precipitation in mm at 1 km resolution based on [SM2RAIN-ASCAT 2007-2018](https://doi.org/10.5281/zenodo.2615278), IMERG, CHELSA Climate, and WorldClim.  [Downscaled to 1 km resolution using gdalwarp](https://gitlab.com/openlandmap/global-layers/tree/master/input_layers/clim1km) (cubic splines) and an average between [WorldClim](https://www.worldclim.com/version2), [CHELSA Climate](https://chelsa-climate.org/), and [IMERG monthly product](https://gpm.nasa.gov/data/imerg) (see, e.g, "3B-MO-L.GIS.IMERG.20180601.V05B.tif"). 3x higher weight is given to the SM2RAIN-ASCAT data since it assumed to be more accurate. Processing steps are available [here](https://gitlab.com/openlandmap/global-layers/tree/master/input_layers/clim1km). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/CLM/CLM_PRECIPITATION_SM2RAIN_M/v01');  var visualization = {   bands: ['jan'],   min: 0.0,   max: 380.0,   palette: ['ecffbd', 'ffff00', '3af6ff', '467aff', '313eff', '0008ff'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Precipitation monthly in mm');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_PNV_PNV_BIOME_TYPE_BIOME00K_C_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_PNV_PNV_BIOME_TYPE_BIOME00K_C_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_PNV_PNV_BIOME-TYPE_BIOME00K_C_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_PNV_PNV_BIOME-TYPE_BIOME00K_C_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_PNV_PNV_BIOME_TYPE_BIOME00K_C_v01(example: str = ''):
        """
        Potential Natural Vegetation biomes global predictions of classes (based on predictions using the BIOMES 6000 dataset's 'current biomes' category.)  Potential Natural Vegetation (PNV) is the vegetation cover in equilibrium with climate that would exist at a given location non-impacted by human activities. PNV is useful for raising public awareness about land degradation and for estimating land potential. This dataset contains results of predictions of - (1) global distribution of biomes based on the BIOME 6000 data set (8057 modern pollen-based site reconstructions), - (2) distribution of forest tree species in Europe based on detailed occurrence records (1,546,435 ground observations), and - (3) global monthly Fraction of Absorbed Photosynthetically Active Radiation (FAPAR) values (30,301 randomly-sampled points).  To report an issue or artifact in data, please use [this link](https://github.com/envirometrix/PNVmaps/issues).  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/PNV/PNV_BIOME-TYPE_BIOME00K_C/v01');  var visualization = {   bands: ['biome_type'],   min: 1.0,   max: 32.0,   palette: [     '1c5510','659208','ae7d20','000065','bbcb35','009a18',     'caffca','55eb49','65b2ff','0020ca','8ea228','ff9adf',     'baff35','ffba9a','ffba35','f7ffca','e7e718','798649',     '65ff9a','d29e96',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Potential distribution of biomes');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_PNV_PNV_FAPAR_PROBA_V_D_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_PNV_PNV_FAPAR_PROBA_V_D_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_PNV_PNV_FAPAR_PROBA-V_D_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_PNV_PNV_FAPAR_PROBA-V_D_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_PNV_PNV_FAPAR_PROBA_V_D_v01(example: str = ''):
        """
        Potential Natural Vegetation FAPAR predicted monthly median (based on PROB-V FAPAR 2014-2017). [Description](https://gitlab.com/openlandmap/global-layers/#potential-natural-vegetation).  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/PNV/PNV_FAPAR_PROBA-V_D/v01');  var visualization = {   bands: ['jan'],   min: 0.0,   max: 220.0,   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Potential FAPAR monthly');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_BULKDENS_FINEEARTH_USDA_4A1H_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_BULKDENS_FINEEARTH_USDA_4A1H_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_BULKDENS-FINEEARTH_USDA-4A1H_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_BULKDENS-FINEEARTH_USDA-4A1H_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_BULKDENS_FINEEARTH_USDA_4A1H_M_v02(example: str = ''):
        """
        Soil bulk density (fine earth) 10 x kg / m<sup>3</sup> at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution.  Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/LandGISmaps/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_BULKDENS-FINEEARTH_USDA-4A1H_M/v02');  var visualization = {   bands: ['b0'],   min: 5.0,   max: 185.0,   palette: ['5e3c99', 'b2abd2', 'f7e0b2', 'fdb863', 'e63b01'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Soil bulk density in x 10 kg / m3');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_CLAY_WFRACTION_USDA_3A1A1A_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_CLAY_WFRACTION_USDA_3A1A1A_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_CLAY-WFRACTION_USDA-3A1A1A_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_CLAY-WFRACTION_USDA-3A1A1A_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_CLAY_WFRACTION_USDA_3A1A1A_M_v02(example: str = ''):
        """
        Clay content in % (kg / kg) at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution  Based on machine learning predictions from global compilation of soil profiles and samples. Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02');  var visualization = {   bands: ['b0'],   min: 2,   max: 100,   palette: [     'ffff00', 'f8f806', 'f1f10c', 'ebeb13', 'e4e419', 'dddd20',     'd7d726', 'd0d02d', 'caca33', 'c3c33a', 'bcbc41', 'b6b647',     'b0b04e', 'a9a954', 'a3a35a', '9c9c61', '959568', '8f8f6e',     '898975', '82827b', '7b7b82', '757589', '6e6e8f', '686895',     '61619c', '5a5aa3', '5454a9', '4d4db0', '4747b6', '4141bc',     '3a3ac3', '3333ca', '2d2dd0', '2626d7', '2020dd', '1919e4',     '1212eb', '0c0cf1', '0606f8', '0000ff',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Clay content in % (kg / kg)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_HAPLUDALFS_P_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_HAPLUDALFS_P_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_GRTGROUP_USDA-SOILTAX-HAPLUDALFS_P_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_GRTGROUP_USDA-SOILTAX-HAPLUDALFS_P_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_HAPLUDALFS_P_v01(example: str = ''):
        """
        Predicted USDA soil great groups at 250 m (probabilities).  Distribution of the USDA soil great groups based on machine learning predictions from global compilation of soil profiles. To learn more about soil great groups please refer to the [Illustrated Guide to Soil Taxonomy - NRCS - USDA](https://www.nrcs.usda.gov/wps/PA_NRCSConsumption/download/?cid=stelprdb1247203.pdf).  * Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil) * Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_GRTGROUP_USDA-SOILTAX-HAPLUDALFS_P/v01');  var visualization = {   bands: ['grtgroup'],   min: 0.0,   max: 35.0,   palette: ['ffffb2', 'fecc5c', 'fd8d3c', 'f03b20', 'bd0026'] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Hapludalfs');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_C_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_C_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_GRTGROUP_USDA-SOILTAX_C_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_GRTGROUP_USDA-SOILTAX_C_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_GRTGROUP_USDA_SOILTAX_C_v01(example: str = ''):
        """
        Predicted USDA soil great group probabilities at 250m.  Distribution of the USDA soil great groups based on machine learning predictions from global compilation of soil profiles. To learn more about soil great groups please refer to the [Illustrated Guide to Soil Taxonomy - NRCS - USDA](https://www.nrcs.usda.gov/wps/PA_NRCSConsumption/download/?cid=stelprdb1247203.pdf).  * Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil) * Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_GRTGROUP_USDA-SOILTAX_C/v01');  var visualization = {   bands: ['grtgroup'],   min: 0,   max: 433,   palette: [     'ffffff', 'adff2d', 'adff22', 'a5ff2f', '87ff37', 'baf019',     '87ff19', '96f03d', 'a3f52f', 'aff319', '91ff37', '9cf319',     '9bff37', '91ff19', '71ff37', '86ff19', 'a9d42d', 'aff519',     '9bff19', '9af024', 'a5fd2f', '88ff37', 'afed19', '71ff19',     'aff026', '8cf537', 'b7ff19', '7177c0', '9a85ec', 'f5f5e1',     '52cf5a', 'e42777', '4ef76d', 'ff00fb', 'eb05eb', 'fa04fa',     'fc04f5', 'f50df0', 'f118f1', 'fa0cfa', 'fc05e1', 'f100d5',     'eb09e6', 'fa22fa', 'ffdab9', 'f5d2bb', 'e8c9b8', 'ffddc4',     'e7cbc0', 'ffd2c3', 'f5d6bb', 'd5d3b9', 'e8d4b8', 'e7cdc0',     'f3eac8', 'a0c4ba', 'ffd2b9', 'f5dabb', 'f5d5b9', 'e8ebb8',     'ffddc2', 'e7ffc0', 'f3e6c8', 'ffdab9', 'f5cdb9', 'a91d30',     '796578', 'd8ff6e', '177548', '43efd6', '8496a9', '296819',     '73ffd4', '6fffc8', '75fbc9', '86f5d1', '82ffd2', '88eec8',     '80ffd4', '6bffc9', '88eec8', '7fffc8', '81ffd2', '86f0d4',     '67ffc8', '88eec8', '7ffbcb', '87ffd2', '8af5ce', '6bfad2',     '78f0d4', '88eec8', '7ffbd4', '73f5cd', '88c8d2', '91f0cd',     '73cdd2', '88eec8', 'fb849b', 'dd4479', '61388b', 'a52a30',     '722328', 'd81419', 'a42828', '82f5cd', 'a54c2e', 'c11919',     'b91419', '21b199', '702028', 'b41919', 'b22328', 'a2c7eb',     '36ba79', '806797', 'cb5b5f', 'cd5c5c', 'd94335', 'd35740',     'e05a5d', 'cf5b5c', 'ca5964', 'ca5d5f', 'cd5e5a', 'ca5969',     'd95a35', 'd36240', 'e05c43', 'd64755', 'cf595c', 'ff5f5f',     'cd6058', 'd95f35', 'd35140', 'd65a55', 'e05c59', 'cf525e',     'c65978', 'f5615f', '826f9a', 'cff41a', '4a6f31', 'a96989',     'e16438', '24f640', '88c1f9', 'f5d25c', 'd74322', '7f939e',     '41a545', '8f8340', '09fe03', '0aff00', '0ff30f', '02f00a',     '0fc903', '17f000', '0cff00', '0ac814', '0cfe00', '0aff0a',     '03ff05', '1cf31c', '24f000', '00ff0c', '14c814', '00fe4c',     '14ff96', '44d205', '05f305', '62f00a', '0fcd03', '00d20f',     '1add11', '09ff0c', '03ff05', '05e700', '02f00a', '0fea03',     '00f000', '0ccb0c', '14dd14', '6a685d', 'fae6b9', '769a34',     '6ff2df', 'ca7fc6', 'd8228f', 'c01bf0', 'd2bad3', 'd8c3cb',     'd4c6d4', 'd5bed5', 'ddb9dd', 'd8d2d8', 'd4c9d4', 'd2bad5',     'd5bad5', 'd5b2d5', 'd8c8d2', 'd4cbd4', '552638', '2571eb',     'ffa514', 'f3a502', 'fb7b00', 'f0b405', 'f7a80f', 'fb9113',     'ffa519', 'f3a702', 'fbba07', 'f7970f', 'f3a702', 'fb5a00',     'f0c005', 'f7810f', 'ff9c00', 'f3b002', 'f0b005', 'f7980f',     '4d7cfc', 'ffff00', 'fafa05', 'ebeb22', 'ffff14', 'f1f10a',     'fafa05', 'ebeb1e', 'f5eb0c', 'eef506', 'f1f129', 'fafa05',     'ebeb0c', 'f5d202', 'ffd700', 'f1f12b', 'a91fac', '2da468',     '9a8b71', '76b989', '713959',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'USDA soil taxonomy great groups'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_ORGANIC_CARBON_USDA_6A1C_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_ORGANIC_CARBON_USDA_6A1C_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_ORGANIC-CARBON_USDA-6A1C_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_ORGANIC-CARBON_USDA-6A1C_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_ORGANIC_CARBON_USDA_6A1C_M_v02(example: str = ''):
        """
        Soil organic carbon content in x 5 g / kg at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution  Predicted from a global compilation of soil points. Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_ORGANIC-CARBON_USDA-6A1C_M/v02');  var visualization = {   bands: ['b0'],   min: 0.0,   max: 120.0,   palette: [     'ffffa0','f7fcb9','d9f0a3','addd8e','78c679','41ab5d',     '238443','005b29','004b29','012b13','00120b',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Soil organic carbon content in x 5 g / kg');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_PH_H2O_USDA_4C1A2A_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_PH_H2O_USDA_4C1A2A_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_PH-H2O_USDA-4C1A2A_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_PH-H2O_USDA-4C1A2A_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_PH_H2O_USDA_4C1A2A_M_v02(example: str = ''):
        """
        Soil pH in H2O at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution  Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02');  var visualization = {   bands: ['b0'],   min: 42,   max: 110,   palette: [     'ff0000', 'ff1c00', 'ff3900', 'ff5500', 'ff7100', 'ff8e00',     'ffaa00', 'ffc600', 'ffe200', 'ffff00', 'e3ff00', 'c7ff00',     'aaff00', '8eff00', '72ff00', '55ff00', '39ff00', '1dff00',     '01ff00', '00ff1c', '00ff38', '00ff54', '00ff71', '00ff8d',     '00ffa9', '00ffc6', '00ffe2', '00fffe', '00e3ff', '00c7ff',     '00abff', '008fff', '0072ff', '0056ff', '003aff', '001dff',     '0001ff', '1b00ff', '3800ff', '5400ff',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Soil pH x 10 in H2O'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_SAND_WFRACTION_USDA_3A1A1A_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_SAND_WFRACTION_USDA_3A1A1A_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_SAND-WFRACTION_USDA-3A1A1A_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_SAND-WFRACTION_USDA-3A1A1A_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_SAND_WFRACTION_USDA_3A1A1A_M_v02(example: str = ''):
        """
        Sand content in % (kg / kg) at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution  Based on machine learning predictions from global compilation of soil profiles and samples. Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_SAND-WFRACTION_USDA-3A1A1A_M/v02');  var visualization = {   bands: ['b0'],   min: 1.0,   max: 100.0,   palette: [     'ffff00', 'f8f806', 'f1f10c', 'ebeb13', 'e4e419', 'dddd20',     'd7d726', 'd0d02d', 'caca33', 'c3c33a', 'bcbc41', 'b6b647',     'b0b04e', 'a9a954', 'a3a35a', '9c9c61', '959568', '8f8f6e',     '898975', '82827b', '7b7b82', '757589', '6e6e8f', '686895',     '61619c', '5a5aa3', '5454a9', '4d4db0', '4747b6', '4141bc',     '3a3ac3', '3333ca', '2d2dd0', '2626d7', '2020dd', '1919e4',     '1212eb', '0c0cf1', '0606f8', '0000ff',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Sand content in % (kg / kg)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_TEXTURE_CLASS_USDA_TT_M_v02:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_TEXTURE_CLASS_USDA_TT_M_v02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_TEXTURE-CLASS_USDA-TT_M_v02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_TEXTURE-CLASS_USDA-TT_M_v02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_TEXTURE_CLASS_USDA_TT_M_v02(example: str = ''):
        """
        Soil texture classes (USDA system) for 6 soil depths (0, 10, 30, 60, 100 and 200 cm) at 250 m  Derived from predicted soil texture fractions using the soiltexture package in R. Processing steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_TEXTURE-CLASS_USDA-TT_M/v02');  var visualization = {   bands: ['b0'],   min: 1.0,   max: 12.0,   palette: [     'd5c36b','b96947','9d3706','ae868f','f86714','46d143',     '368f20','3e5a14','ffd557','fff72e','ff5a9d','ff005b',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Soil texture class (USDA system)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OpenLandMap_SOL_SOL_WATERCONTENT_33KPA_USDA_4B1C_M_v01:
    def __init__(self,):
        self.sensor = 'OpenLandMap_SOL_SOL_WATERCONTENT_33KPA_USDA_4B1C_M_v01'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OpenLandMap_SOL_SOL_WATERCONTENT-33KPA_USDA-4B1C_M_v01.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OpenLandMap_SOL_SOL_WATERCONTENT-33KPA_USDA-4B1C_M_v01.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OpenLandMap_SOL_SOL_WATERCONTENT_33KPA_USDA_4B1C_M_v01(example: str = ''):
        """
        Soil water content (volumetric %) for 33kPa and 1500kPa suctions predicted at 6 standard depths (0, 10, 30, 60, 100 and 200 cm) at 250 m resolution  Training points are based on a global compilation of soil profiles:  * [USDA NCSS](https://ncsslabdatamart.sc.egov.usda.gov/) * [AfSPDB](https://www.isric.org/projects/africa-soil-profiles-database-afsp) * [ISRIC WISE](https://data.isric.org/geonetwork/srv/eng/catalog.search#/metadata/a351682c-330a-4995-a5a1-57ad160e621c) * [EGRPR](http://egrpr.esoil.ru/) * [SPADE](https://esdac.jrc.ec.europa.eu/content/soil-profile-analytical-database-2) * [CanNPDB](https://open.canada.ca/data/en/dataset/6457fad6-b6f5-47a3-9bd1-ad14aea4b9e0) * [UNSODA](https://data.nal.usda.gov/dataset/unsoda-20-unsaturated-soil-hydraulic-database-database-and-program-indirect-methods-estimating-unsaturated-hydraulic-properties) * [SWIG](https://doi.pangaea.de/10.1594/PANGAEA.885492) * [HYBRAS](https://www.cprm.gov.br/en/Hydrology/Research-and-Innovation/HYBRAS-4208.html) * [HydroS](https://doi.org/10.4228/ZALF.2003.273)  Data import steps are available [here](https://gitlab.com/openlandmap/compiled-ess-point-data-sets). Spatial prediction steps are described in detail [here](https://gitlab.com/openlandmap/global-layers/tree/master/soil/soil_water). Note: these are actually measured and mapped soil content values; no Pedo-Transfer-Functions have been used (except to fill in the missing NCSS bulk densities). Available water capacity in mm (derived as a difference between field capacity and wilting point multiplied by layer thickness) per layer is available [here](https://doi.org/10.5281/zenodo.2629148). Antarctica is not included.  To access and visualize maps outside of Earth Engine, use [this page](https://opengeohub.org/about-openlandmap).  If you discover a bug, artifact or inconsistency in the LandGIS maps or if you have a question please use the following channels:   *  [Technical issues and questions about the code](https://gitlab.com/openlandmap/global-layers/issues)  *  [General questions and comments](https://disqus.com/home/forums/landgis/) 
        :param example: var dataset = ee.Image('OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01');  var visualization = {   bands: ['b0'],   min: 0.0,   max: 52.9740182135385,   palette: [     'd29642','eec764','b4ee87','32eeeb','0c78ee','2601b7',     '083371',   ] };  Map.centerObject(dataset);  Map.addLayer(dataset, visualization, 'Soil water content at 33kPa (field capacity)');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OREGONSTATE_PRISM_AN81d:
    def __init__(self,):
        self.sensor = 'OREGONSTATE_PRISM_AN81d'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OREGONSTATE_PRISM_AN81d.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OREGONSTATE_PRISM_AN81d.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OREGONSTATE_PRISM_AN81d(example: str = ''):
        """
        The PRISM daily and monthly datasets are gridded climate datasets for the conterminous United States, produced by the PRISM Climate Group at Oregon State University.  Grids are developed using PRISM (Parameter-elevation Regressions on Independent Slopes Model). PRISM interpolation routines simulate how weather and climate vary with elevation, and account for coastal effects, temperature inversions, and terrain barriers that can cause rain shadows. Station data are assimilated from many networks across the country. For more information, see the [Descriptions of PRISM Spatial Climate Datasets](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf).  **Note**  * **Warning**: This dataset should not be   used to calculate century-long climate trends due to non-climatic   variations from to station equipment and location changes, openings   and closings, varying observation times, and the use of relatively   short-term networks. Please see the [dataset documentation   ](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf)   for more details. * The assets have start time of noon UTC, not midnight UTC. * It takes time for observation networks to conduct quality control and   release station data. Therefore,   PRISM datasets are re-modeled several times until six months   have elapsed, when they are considered permanent. A [release   schedule is available](https://www.prism.oregonstate.edu/calendar/). * For use of the 30 arc-second (~800 m) version of this dataset   please contact the provider at prism-questions@nacse.org 
        :param example: var dataset = ee.ImageCollection('OREGONSTATE/PRISM/AN81d')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var precipitation = dataset.select('ppt'); var precipitationVis = {   min: 0.0,   max: 50.0,   palette: ['red', 'yellow', 'green', 'cyan', 'purple'], }; Map.setCenter(-100.55, 40.71, 4); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OREGONSTATE_PRISM_AN81m:
    def __init__(self,):
        self.sensor = 'OREGONSTATE_PRISM_AN81m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OREGONSTATE_PRISM_AN81m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OREGONSTATE_PRISM_AN81m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OREGONSTATE_PRISM_AN81m(example: str = ''):
        """
        The PRISM daily and monthly datasets are gridded climate datasets for the conterminous United States, produced by the PRISM Climate Group at Oregon State University.  Grids are developed using PRISM (Parameter-elevation Regressions on Independent Slopes Model). PRISM interpolation routines simulate how weather and climate vary with elevation, and account for coastal effects, temperature inversions, and terrain barriers that can cause rain shadows. Station data are assimilated from many networks across the country. For more information, see the [Descriptions of PRISM Spatial Climate Datasets](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf).  **Note**  * **Warning**, this dataset should not be   used to calculate century-long climate trends due to non-climatic   variations from to station equipment and location changes, openings   and closings, varying observation times, and the use of relatively   short-term networks. Please see the [dataset   documentation](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf)   for more details. * It takes time for observation networks to conduct quality control   and release station data. Therefore, PRISM datasets are re-modeled   several times until six months have elapsed, when they are   considered permanent. A [release schedule is   available](https://www.prism.oregonstate.edu/calendar/). * For use of the 30 arc-second (~800 m) version of this dataset   please contact the provider at prism-questions@nacse.org. 
        :param example: var dataset = ee.ImageCollection('OREGONSTATE/PRISM/AN81m')                   .filter(ee.Filter.date('2018-07-01', '2018-07-31')); var precipitation = dataset.select('ppt'); var precipitationVis = {   min: 0.0,   max: 300.0,   palette: ['red', 'yellow', 'green', 'cyan', 'purple'], }; Map.setCenter(-100.55, 40.71, 4); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OREGONSTATE_PRISM_Norm81m:
    def __init__(self,):
        self.sensor = 'OREGONSTATE_PRISM_Norm81m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OREGONSTATE_PRISM_Norm81m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OREGONSTATE_PRISM_Norm81m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OREGONSTATE_PRISM_Norm81m(example: str = ''):
        """
        The PRISM daily and monthly datasets are gridded climate datasets for the conterminous United States, produced by the PRISM Climate Group at Oregon State University.  Grids are developed using PRISM (Parameter-elevation Regressions on Independent Slopes Model). PRISM interpolation routines simulate how weather and climate vary with elevation, and account for coastal effects, temperature inversions, and terrain barriers that can cause rain shadows. Station data are assimilated from many networks across the country. For more information, see the [Descriptions of PRISM Spatial Climate Datasets](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf). 
        :param example: var dataset = ee.ImageCollection('OREGONSTATE/PRISM/Norm81m'); var precipitation = dataset.select('ppt'); var precipitationVis = {   min: 0.0,   max: 300.0,   palette: ['red', 'yellow', 'green', 'cyan', 'purple'], }; Map.setCenter(-100.55, 40.71, 0); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OREGONSTATE_PRISM_Norm91m:
    def __init__(self,):
        self.sensor = 'OREGONSTATE_PRISM_Norm91m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OREGONSTATE_PRISM_Norm91m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OREGONSTATE_PRISM_Norm91m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OREGONSTATE_PRISM_Norm91m(example: str = ''):
        """
        The PRISM daily and monthly datasets are gridded climate datasets for the conterminous United States, produced by the PRISM Climate Group at Oregon State University.  Grids are developed using PRISM (Parameter-elevation Regressions on Independent Slopes Model). PRISM interpolation routines simulate how weather and climate vary with elevation, and account for coastal effects, temperature inversions, and terrain barriers that can cause rain shadows. Station data are assimilated from many networks across the country. For more information, see the [Descriptions of PRISM Spatial Climate Datasets](https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf). 
        :param example: var dataset = ee.ImageCollection('OREGONSTATE/PRISM/Norm91m'); var precipitation = dataset.select('ppt'); var precipitationVis = {   min: 0.0,   max: 300.0,   palette: ['red', 'yellow', 'green', 'cyan', 'purple'], }; Map.setCenter(-100.55, 40.71, 0); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class ORTHO_Switzerland_SWISSIMAGE_10cm:
    def __init__(self,):
        self.sensor = 'ORTHO_Switzerland_SWISSIMAGE_10cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/ORTHO_Switzerland_SWISSIMAGE_10cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/ORTHO_Switzerland_SWISSIMAGE_10cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_ORTHO_Switzerland_SWISSIMAGE_10cm(example: str = ''):
        """
        The SWISSIMAGE 10 cm orthophoto mosaic is an assembly of new color digital aerial images over the whole of Switzerland with a ground resolution of 10 cm in the plains and the main alpine valleys and 25 cm in the Alps. It is updated annually.  For more information, please see the [SWISSIMAGE10cm_FR documentation] (https://www.swisstopo.admin.ch/content/swisstopo-internet/fr/geodata/images/ortho/swissimage10/_jcr_content/contentPar/tabs_copy_copy/items/60_1569482292365/tabPar/downloadlist/downloadItems/67_1588752711524.download/Produktinfo_SWISSIMAGE10cm_FR.pdf)  This RGB collection contains digital aerial images with three bands. Standard deviation for the precision in position: +/- 0.15 m for the ground sample distance of 0.1 m. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OSU_GIMP_2000_ICE_OCEAN_MASK:
    def __init__(self,):
        self.sensor = 'OSU_GIMP_2000_ICE_OCEAN_MASK'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OSU_GIMP_2000_ICE_OCEAN_MASK.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OSU_GIMP_2000_ICE_OCEAN_MASK.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OSU_GIMP_2000_ICE_OCEAN_MASK(example: str = ''):
        """
        This dataset provides complete land ice and ocean classification masks at 15 m for the Greenland ice sheet. Ice cover was mapped using a combination of orthorectified panchromatic (band 8) imagery from the Landsat 7 Enhanced Thematic Mapper Plus (ETM+), distributed by the USGS, and RADARSAT-1 Synthetic Amplitude Radar (SAR) amplitude images produced and distributed by I. Joughin at the Applied Physics Laboratory, University of Washington.  The Landsat imagery was acquired for the months of July through September in 1999, 2000 and 2001 (mostly 2000) and the RADARSAT imagery was acquired in fall of 2000. 
        :param example: var dataset = ee.Image('OSU/GIMP/2000_ICE_OCEAN_MASK'); var oceanAndIceMaskVis = {   min: 0.0,   max: 1.0,   bands: ['ice_mask', 'ice_mask', 'ocean_mask'], }; Map.setCenter(-41.0, 74.0, 4); Map.addLayer(dataset, oceanAndIceMaskVis, 'Ocean and Ice Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OSU_GIMP_2000_IMAGERY_MOSAIC:
    def __init__(self,):
        self.sensor = 'OSU_GIMP_2000_IMAGERY_MOSAIC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OSU_GIMP_2000_IMAGERY_MOSAIC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OSU_GIMP_2000_IMAGERY_MOSAIC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OSU_GIMP_2000_IMAGERY_MOSAIC(example: str = ''):
        """
        This dataset provides a complete 15 m resolution image mosaic of the Greenland ice sheet derived from Landsat 7 ETM+ and RADARSAT-1 SAR imagery from the years 1999 to 2002. The methods include a combination of image cloud masking, pan sharpening, image sampling and resizing, and image coregistration. Please see Howat, 2014 for more information regarding processing methods.  **Note**  *  Users of GIMP DEM or GIMP 2000 Image Mosaic images may find it helpful to mask out areas outside of the Greenland coastline using the corresponding 15 m ocean mask image Greenland Ice Mapping Project (GIMP) Land Ice and Ocean Classification Mask, *  The SAR data are distributed at 20 m resolution. Data were up-sampled through bilinear interpolation to 15 m to match the resolution of Landsat band-8.  [General documentation](https://doi.org/10.5067/4RNTRRE4JCYD) 
        :param example: var dataset = ee.Image('OSU/GIMP/2000_IMAGERY_MOSAIC'); var greenlandImage = dataset.select(['B3', 'B2', 'B1']); var visParams = {   min: 0.0,   max: 255.0, }; Map.setCenter(-29.1605, 70.4, 9); Map.addLayer(greenlandImage, visParams, 'Greenland Pansharpened Image'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class OSU_GIMP_DEM:
    def __init__(self,):
        self.sensor = 'OSU_GIMP_DEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OSU_GIMP_DEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OSU_GIMP_DEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OSU_GIMP_DEM(example: str = ''):
        """
        This Digital Elevation Model (DEM) is constructed from a combination of ASTER and SPOT-5 DEM's for the ice sheet periphery and margin (i.e. below the equilbrium line elevation) south of approximately 82.5&deg;N and AVHRR photoclinometry in the ice sheet interior and far north (Scambos and Haran, 2002).  SPOT-5 DEM's were produced and distributed as part of the Spot5 stereoscopic survey of Polar Ice: Reference Images & Topographies (SPIRIT) project (Korona et al., 2009). Ocean surfaces were masked using the GIMP Land Classification mask and replaced with the CNES CLS11 mean sea surface height (Schaeffer et al., 2012).  **Note**  *   All land elevation data is horizontally and vertically registered to average ICESat elevations for the 2003-2009 time period, and therefore the DEM has a nominal date of 2007, although care must be taken when using the DEM in areas of rapid change, such as major outlet glaciers south of 70&deg;0N. *   The DEM has a resolution of 30 m, although the \"true\" resolution of the DEM will vary from 40 m in areas of SPOT-5 coverage (see Korona et al. 2009) to 500 m in areas of photoclinometry. *   The ice-sheet-wide root-mean-squared validation error relative to ICESat is +/-10 m, rangining from close to +/- 1 m over most ice surfaces to +/- 30 m in areas of high relief.  [General documentation](https://doi.org/10.5067/NV34YUIXLP9W) 
        :param example: var dataset = ee.Image('OSU/GIMP/DEM'); var elevation = dataset.select('elevation'); var elevationVis = {   min: 0.0,   max: 2000.0, }; Map.setCenter(-41.0, 76.0, 4); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class OSU_GIMP_ICE_VELOCITY_OPT:
    def __init__(self,):
        self.sensor = 'OSU_GIMP_ICE_VELOCITY_OPT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/OSU_GIMP_ICE_VELOCITY_OPT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/OSU_GIMP_ICE_VELOCITY_OPT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_OSU_GIMP_ICE_VELOCITY_OPT(example: str = ''):
        """
        This dataset, part of the NASA Making Earth System Data Records for Use in Research Environments (MEaSUREs) program, consists of mean monthly velocity maps for selected glacier outlet areas. The maps are generated by tracking visible features between optical image pairs acquired by the Landsat 4 and 5 Thematic Mapper (TM), the Landsat 7 Enhanced Thematic Mapper Plus (ETM+), the Landsat 8 Operational Land Imager (OLI), and the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER).  **Note**  Monthly means are calculated from images, which may have acquisition dates from the preceding or succeeding month. For the naming convention, the month is determined from where the midpoint Julian dates fall. For example, September monthly means may have been generated from images that were acquired in August or in October but the midpoint Julian date between the images falls within September. The exact dates used are included as per-image metadata fields.  [General documentation](https://doi.org/10.5067/VM5DZ20MYF5C) 
        :param example: var dataset = ee.ImageCollection('OSU/GIMP/ICE_VELOCITY_OPT')                   .filter(ee.Filter.date('2016-01-01', '2016-09-15')); var iceVelocityVis = {   min: [-1000],   max: [1000],   palette: ['red', 'black', 'blue'],   bands: ['velocity_x'] }; Map.setCenter(-66.82, 76.151, 7); Map.addLayer(dataset, iceVelocityVis, 'Ice Velocity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_accessibility_to_cities_2015_v1_0:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_accessibility_to_cities_2015_v1_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_accessibility_to_cities_2015_v1_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_accessibility_to_cities_2015_v1_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_accessibility_to_cities_2015_v1_0(example: str = ''):
        """
        This global accessibility map enumerates land-based travel time to the nearest densely-populated area for all areas between 85 degrees north and 60 degrees south for a nominal year 2015.  Densely-populated areas are defined as contiguous areas with 1,500 or more inhabitants per square kilometer or a majority of built-up land cover types coincident with a population center of at least 50,000 inhabitants.  This map was produced through a collaboration between the University of Oxford Malaria Atlas Project (MAP), Google, the European Union Joint Research Centre (JRC), and the University of Twente, Netherlands. The underlying datasets used to produce the map include roads (comprising the first ever global-scale use of Open Street Map and Google roads datasets), railways, rivers, lakes, oceans, topographic conditions (slope and elevation), landcover types, and national borders.  These datasets were each allocated a speed or speeds of travel in terms of time to cross each pixel of that type. The datasets were then combined to produce a &ldquo;friction surface&rdquo;, a map where every pixel is allocated a nominal overall speed of travel based on the types occurring within that pixel. Least-cost-path algorithms (running in Google Earth Engine and, for high-latitude areas, in R) were used in conjunction with this friction surface to calculate the time of travel from all locations to the nearest city (by travel time). Cities were determined using the high-density-cover product created by the Global Human Settlement Project.  Each pixel in the resultant accessibility map thus represents the modeled shortest time from that location to a city.  Source dataset credits are as described in the accompanying paper. 
        :param example: var dataset = ee.Image('Oxford/MAP/accessibility_to_cities_2015_v1_0'); var accessibility = dataset.select('accessibility'); var accessibilityVis = {   min: 0.0,   max: 41556.0,   gamma: 4.0, }; Map.setCenter(18.98, 6.66, 2); Map.addLayer(accessibility, accessibilityVis, 'Accessibility'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_accessibility_to_healthcare_2019:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_accessibility_to_healthcare_2019'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_accessibility_to_healthcare_2019.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_accessibility_to_healthcare_2019.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_accessibility_to_healthcare_2019(example: str = ''):
        """
        This global accessibility map enumerates land-based travel time (in minutes) to the nearest hospital or clinic for all areas between 85 degrees north and 60 degrees south for a nominal year 2019. It also includes "walking-only" travel time, using non-motorized means of transportation only.  Major data collection efforts underway by OpenStreetMap, Google Maps, and academic researchers have been harnessed to compile the most complete collection of healthcare facility locations to date. This map was produced through a collaboration between MAP (University of Oxford), Telethon Kids Institute (Perth, Australia), Google, and the University of Twente, Netherlands.  This project builds on previous work published by Weiss et al 2018 ([doi:10.1038/nature25181](https://doi.org/10.1038/nature25181)). Weiss et al (2018) utilised datasets for roads (comprising the first ever global-scale use of Open Street Map and Google roads datasets), railways, rivers, lakes, oceans, topographic conditions (slope and elevation), landcover types, and national borders. These datasets were each allocated a speed or speeds of travel in terms of time to cross each pixel of that type. The datasets were then combined to produce a "friction surface": a map where every pixel is allocated a nominal overall speed of travel based on the types occurring within that pixel. For the current project, an updated friction surface was created to incorporate recent improvements within OSM roads data.  Least-cost-path algorithms (run in Google Earth Engine and, for high-latitude areas, in R) were used in conjunction with this friction surface to calculate the time of travel from all locations to the nearest (in time) healthcare facility. The healthcare facilities dataset utilized location data from two of the largest global databases: (1) OSM data that was collated and made available for download at [www.healthsites.io](https://www.healthsites.io/); and (2) data extracted from Google Maps. The global datasets were augmented with continental-scale facility locations that were recently published for Africa and Australia. To facilitate comparisons between data sources, only facilities defined as hospitals and clinics were used. Multiple points found within the same pixel were merged to match the resolution of the analysis as defined by the selected gridded representation of the Earth's surface. Each pixel in the resultant accessibility map thus represents the modelled shortest time (in minutes) from that location to a hospital or clinic.  Source dataset credits are as described in the accompanying paper. 
        :param example: var dataset = ee.Image('Oxford/MAP/accessibility_to_healthcare_2019'); var accessibility = dataset.select('accessibility'); var accessibilityVis = {   min: 0.0,   max: 41556.0,   gamma: 4.0, }; Map.setCenter(18.98, 6.66, 2); Map.addLayer(accessibility, accessibilityVis, 'Accessibility'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_EVI_5km_Monthly:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_EVI_5km_Monthly'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_EVI_5km_Monthly.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_EVI_5km_Monthly.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_EVI_5km_Monthly(example: str = ''):
        """
        The underlying dataset for this Enhanced Vegetation Index (EVI) product is MODIS BRDF-corrected imagery (MCD43B4), which was gap-filled using the approach outlined in Weiss et al. (2014) to eliminate missing data caused by factors such as cloud cover. Gap-free outputs were then aggregated temporally and spatially to produce the monthly &asymp;5km product.  This dataset was produced by Harry Gibson and Daniel Weiss of the Malaria Atlas Project (Big Data Institute, University of Oxford, United Kingdom, [https://malariaatlas.org/](https://malariaatlas.org/)). 
        :param example: var dataset = ee.ImageCollection('Oxford/MAP/EVI_5km_Monthly')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var evi = dataset.select('Mean'); var eviVis = {   min: 0.0,   max: 1.0,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(-60.5, -20.0, 2); Map.addLayer(evi, eviVis, 'EVI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_friction_surface_2015_v1_0:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_friction_surface_2015_v1_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_friction_surface_2015_v1_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_friction_surface_2015_v1_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_friction_surface_2015_v1_0(example: str = ''):
        """
        This global friction surface enumerates land-based travel speed for all land pixels between 85 degrees north and 60 degrees south for a nominal year 2015.  This map was produced through a collaboration between the University of Oxford Malaria Atlas Project (MAP), Google, the European Union Joint Research Centre (JRC), and the University of Twente, Netherlands. The underlying datasets used to produce the map include roads (comprising the first ever global-scale use of Open Street Map and Google roads datasets), railways, rivers, lakes, oceans, topographic conditions (slope and elevation), landcover types, and national borders.  These datasets were each allocated a speed or speeds of travel in terms of time to cross each pixel of that type. The datasets were then combined to produce this &ldquo;friction surface&rdquo;, a map where every pixel is allocated a nominal overall speed of travel based on the types occurring within that pixel, with the fastest travel mode intersecting the pixel being used to determine the speed of travel in that pixel (with some exceptions such as national boundaries, which have the effect of imposing a travel time penalty).  This map represents the travel speed from this allocation process, expressed in units of minutes required to travel one meter. It forms the underlying dataset behind the global accessibility map described in the referenced paper.  'Source dataset credits are as described in the accompanying paper. 
        :param example: var dataset = ee.Image('Oxford/MAP/friction_surface_2015_v1_0'); var landBasedTravelSpeed = dataset.select('friction'); var visParams = {   min: 0.0022,   max: 0.04,   palette: [     '313695', '4575b4', '74add1', 'abd9e9', 'e0f3f8', 'ffffbf', 'fee090',     'fdae61', 'f46d43', 'd73027', 'a50026'   ], }; Map.setCenter(43.55, 36.98, 4); Map.addLayer(landBasedTravelSpeed, visParams, 'Land-based travel speed'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_friction_surface_2019:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_friction_surface_2019'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_friction_surface_2019.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_friction_surface_2019.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_friction_surface_2019(example: str = ''):
        """
        This global friction surface enumerates land-based travel speed for all land pixels between 85 degrees north and 60 degrees south for a nominal year 2019.  It also includes "walking-only" travel speed, using non-motorized means of transportation only. This map was produced through a collaboration between MAP (University of Oxford), Telethon Kids Institute (Perth, Australia), Google, and the University of Twente, Netherlands. This project builds on previous work published by Weiss et al 2018 ([doi:10.1038/nature25181](https://doi.org/10.1038/nature25181)). Weiss et al (2018) utilised datasets for roads (comprising the first ever global-scale use of Open Street Map and Google roads datasets), railways, rivers, lakes, oceans, topographic conditions (slope and elevation), landcover types, and national borders. These datasets were each allocated a speed or speeds of travel in terms of time to cross each pixel of that type. The datasets were then combined to produce a "friction surface"; a map where every pixel is allocated a nominal overall speed of travel based on the types occurring within that pixel. For the current project, an updated friction surface was created to incorporate recent improvements within OSM roads data. Differences between this friction surface and the 2015 version (Weiss et al. 2018) are not necessarily indicative of changes in infrastructure (e.g., new roads being built). Such discrepancies are far more likely to be associated with improved data quality, in particular updates made to OSM road coverage. As a result, comparisons between the friction surfaces and resulting travel time maps should be done cautiously and generally not interpreted as representing changes in access over time. This map represents the travel speed from this allocation process, expressed in units of minutes required to travel one meter. It forms the underlying dataset behind the global healthcare accessibility map described in the referenced paper.  Source dataset credits are as described in the accompanying paper. 
        :param example: var dataset = ee.Image('Oxford/MAP/friction_surface_2019'); var landBasedTravelSpeed = dataset.select('friction'); var visParams = {   min: 0.0022,   max: 0.04,   palette: [     '313695', '4575b4', '74add1', 'abd9e9', 'e0f3f8', 'ffffbf', 'fee090',     'fdae61', 'f46d43', 'd73027', 'a50026'   ], }; Map.setCenter(43.55, 36.98, 4); Map.addLayer(landBasedTravelSpeed, visParams, 'Land-based travel speed'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_IGBP_Fractional_Landcover_5km_Annual:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_IGBP_Fractional_Landcover_5km_Annual'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_IGBP_Fractional_Landcover_5km_Annual.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_IGBP_Fractional_Landcover_5km_Annual.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_IGBP_Fractional_Landcover_5km_Annual(example: str = ''):
        """
        The underlying dataset for this landcover product is the IGBP layer found within the MODIS annual landcover product (MCD12Q1). This data was converted from its categorical format, which has a &asymp;500 meter resolution, to a fractional product indicating the integer percentage (0-100) of the output pixel covered by each of the 17 landcover classes (1 per band).  This dataset was produced by Harry Gibson and Daniel Weiss of the Malaria Atlas Project (Big Data Institute, University of Oxford, United Kingdom, [https://malariaatlas.org/](https://malariaatlas.org/)). 
        :param example: var dataset =     ee.ImageCollection('Oxford/MAP/IGBP_Fractional_Landcover_5km_Annual')         .filter(ee.Filter.date('2012-01-01', '2012-12-31')); var landcover = dataset.select('Overall_Class'); var landcoverVis = {   min: 1.0,   max: 19.0,   palette: [     '032f7e', '02740b', '02740b', '8cf502', '8cf502', 'a4da01', 'ffbd05',     'ffbd05', '7a5a02', 'f0ff0f', '869b36', '6091b4', '999999', 'ff4e4e',     'ff4e4e', 'ffffff', 'feffc0', '020202', '020202'   ], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(landcover, landcoverVis, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_LST_Day_5km_Monthly:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_LST_Day_5km_Monthly'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_LST_Day_5km_Monthly.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_LST_Day_5km_Monthly.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_LST_Day_5km_Monthly(example: str = ''):
        """
        The underlying dataset for this daytime product is MODIS land surface temperature data (MOD11A2), which was gap-filled using the approach outlined in Weiss et al. (2014) to eliminate missing data caused by factors such as cloud cover. Gap-free outputs were then aggregated temporally and spatially to produce the monthly &asymp;5km product.  This dataset was produced by Harry Gibson and Daniel Weiss of the Malaria Atlas Project (Big Data Institute, University of Oxford, United Kingdom, [https://malariaatlas.org/](https://malariaatlas.org/)). 
        :param example: var dataset = ee.ImageCollection('Oxford/MAP/LST_Day_5km_Monthly')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var daytimeLandSurfaceTemp = dataset.select('Mean'); var visParams = {   min: -20.0,   max: 50.0,   palette: [     '800080', '0000ab', '0000ff', '008000', '19ff2b', 'a8f7ff', 'ffff00',     'd6d600', 'ffa500', 'ff6b01', 'ff0000'   ], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(     daytimeLandSurfaceTemp, visParams, 'Daytime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_LST_Night_5km_Monthly:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_LST_Night_5km_Monthly'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_LST_Night_5km_Monthly.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_LST_Night_5km_Monthly.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_LST_Night_5km_Monthly(example: str = ''):
        """
        The underlying dataset for this nighttime product is MODIS land surface temperature data (MOD11A2), which was gap-filled using the approach outlined in Weiss et al. (2014) to eliminate missing data caused by factors such as cloud cover. Gap-free outputs were then aggregated temporally and spatially to produce the monthly &asymp;5km product.  This dataset was produced by Harry Gibson and Daniel Weiss of the Malaria Atlas Project (Big Data Institute, University of Oxford, United Kingdom, [https://malariaatlas.org/](https://malariaatlas.org/)). 
        :param example: var dataset = ee.ImageCollection('Oxford/MAP/LST_Night_5km_Monthly')                   .filter(ee.Filter.date('2015-01-01', '2015-12-31')); var nighttimeLandSurfaceTemp = dataset.select('Mean'); var visParams = {   min: -30.0,   max: 30.0,   palette: [     '800080', '0000ab', '0000ff', '008000', '19ff2b', 'a8f7ff', 'ffff00',     'd6d600', 'ffa500', 'ff6b01', 'ff0000'   ], }; Map.setCenter(-88.6, 26.4, 1); Map.addLayer(     nighttimeLandSurfaceTemp, visParams, 'Nighttime Land Surface Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_TCB_5km_Monthly:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_TCB_5km_Monthly'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_TCB_5km_Monthly.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_TCB_5km_Monthly.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_TCB_5km_Monthly(example: str = ''):
        """
        This gap-filled Tasseled Cap Brightness (TCB) dataset was created by applying the tasseled-cap equations defined in Lobser and Cohen (2007) to MODIS BRDF-corrected imagery (MCD43B4). The resulting data were gap-filled using the approach outlined in Weiss et al. (2014) to eliminate missing data caused by factors such as cloud cover, and then the data were aggregated temporally and spatially to produce the monthly &asymp;5km product.  This dataset was produced by Harry Gibson and Daniel Weiss of the [Malaria Atlas Project](https://malariaatlas.org/). 
        :param example: var dataset = ee.ImageCollection('Oxford/MAP/TCB_5km_Monthly')                   .filter(ee.Filter.date('2013-01-01', '2013-12-31')); var tcb = dataset.select('Mean'); var tcbVis = {   min: 0.0,   max: 1.3,   palette: [     '011301', '004c00', '056201', '207401', '3e8601', '66a000', '99b718',     'fcd163', 'ffffff'   ], }; Map.setCenter(-44.65, 22.59, 2); Map.addLayer(tcb, tcbVis, 'TCB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Oxford_MAP_TCW_5km_Monthly:
    def __init__(self,):
        self.sensor = 'Oxford_MAP_TCW_5km_Monthly'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Oxford_MAP_TCW_5km_Monthly.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Oxford_MAP_TCW_5km_Monthly.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Oxford_MAP_TCW_5km_Monthly(example: str = ''):
        """
        This gap-filled Tasseled Cap Wetness (TCW) dataset was created by applying the tasseled-cap equations defined in Lobser and Cohen (2007) to MODIS BRDF-corrected imagery (MCD43B4). The resulting data were gap-filled using the approach outlined in Weiss et al. (2014) to eliminate missing data caused by factors such as cloud cover, and then the data were aggregated temporally and spatially to produce the monthly &asymp;5km product.  This dataset was produced by Harry Gibson and Daniel Weiss of the Malaria Atlas Project (Big Data Institute, University of Oxford, United Kingdom, [https://malariaatlas.org/](https://malariaatlas.org/)). 
        :param example: var dataset = ee.ImageCollection('Oxford/MAP/TCW_5km_Monthly')                   .filter(ee.Filter.date('2013-01-01', '2013-12-31')); var tcw = dataset.select('Mean'); var tcwVis = {   min: -0.6,   max: 0.5,   palette: [     'ffffff', 'fcd163', '99b718', '66a000', '3e8601', '207401', '056201',     '004c00', '011301'   ], }; Map.setCenter(-44.65, 22.59, 2); Map.addLayer(tcw, tcwVis, 'TCW'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_landcover:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_landcover'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_landcover.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_landcover.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_landcover(example: str = ''):
        """
        Digital Earth Australia (DEA) Land Cover translates over 30 years of satellite imagery into evidence of how Australia's land, vegetation and waterbodies have changed over time.  For more information, please see the [DEA Land Cover](https://cmi.ga.gov.au/data-products/dea/607/dea-land-cover-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_ls5t_nbart_gm_cyear_3:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_ls5t_nbart_gm_cyear_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_ls5t_nbart_gm_cyear_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_ls5t_nbart_gm_cyear_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_ls5t_nbart_gm_cyear_3(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Landsat 5 data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  The geomedian part of the product provides an "average" cloud-free image over the given year. The geomedian image is calculated with a multi-dimensional median, using all the spectral measurements from the satellite imagery at the same time in order to maintain the relationships among the measurements.  The median absolute deviation part of the product uses three measures of variance, each of which provides a "second order" high dimensional statistical composite for the given year. The three variance measures show how much an area varies from the "average" in terms of "distance" based on factors such as brightness and spectra:  * Euclidean distance (EMAD) * Cosine (spectral) distance (SMAD) * Bray Curtis dissimilarity (BCMAD)  Together, they provide information on variance in the landscape over the given year and are useful for change detection applications.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation Landsat](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var geomedian_ls5 = ee.ImageCollection('projects/geoscience-aus-cat/assets/ga_ls5t_nbart_gm_cyear_3');  var geometry =      /* color: #98ff00 */     /* displayProperties: [       {         "type": "rectangle"       }     ] */     ee.Geometry.Polygon(       [[[121.15880998755823, -15.010654451073695],         [121.15880998755823, -18.377531570740548],         [125.81701311255823, -18.377531570740548],         [125.81701311255823, -15.010654451073695]]], null, false);            var composite = geomedian_ls5.filterBounds(geometry)                              .filterDate('1995-01-01', '1996-01-01')                              .mosaic();                               var visualization = {   bands: ['red', 'green', 'blue'],   min: 0,   max: 3000 };  Map.centerObject(geometry, 10); Map.addLayer(composite, visualization, '1995 True Color Composite');
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_ls7e_nbart_gm_cyear_3:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_ls7e_nbart_gm_cyear_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_ls7e_nbart_gm_cyear_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_ls7e_nbart_gm_cyear_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_ls7e_nbart_gm_cyear_3(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Landsat 7 data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  The geomedian part of the product provides an "average" cloud-free image over the given year. The geomedian image is calculated with a multi-dimensional median, using all the spectral measurements from the satellite imagery at the same time in order to maintain the relationships among the measurements.  The median absolute deviation part of the product uses three measures of variance, each of which provides a "second order" high dimensional statistical composite for the given year. The three variance measures show how much an area varies from the "average" in terms of "distance" based on factors such as brightness and spectra:  * Euclidean distance (EMAD) * Cosine (spectral) distance (SMAD) * Bray Curtis dissimilarity (BCMAD)  Together, they provide information on variance in the landscape over the given year and are useful for change detection applications.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation Landsat](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var geomedian_ls7 = ee.ImageCollection('projects/geoscience-aus-cat/assets/ga_ls7e_nbart_gm_cyear_3');  var geometry =      /* color: #98ff00 */     /* displayProperties: [       {         "type": "rectangle"       }     ] */     ee.Geometry.Polygon(       [[[121.15880998755823, -15.010654451073695],         [121.15880998755823, -18.377531570740548],         [125.81701311255823, -18.377531570740548],         [125.81701311255823, -15.010654451073695]]], null, false);            var composite = geomedian_ls7.filterBounds(geometry)                              .filterDate('2008-01-01', '2009-01-01')                              .mosaic();                               var visualization = {   bands: ['red', 'green', 'blue'],   min: 0,   max: 3000 };  Map.centerObject(geometry, 10); Map.addLayer(composite, visualization, '2008 True Color Composite');
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_ls8c_nbart_gm_cyear_3:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_ls8c_nbart_gm_cyear_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_ls8c_nbart_gm_cyear_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_ls8c_nbart_gm_cyear_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_ls8c_nbart_gm_cyear_3(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Landsat 8 data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  The geomedian part of the product provides an "average" cloud-free image over the given year. The geomedian image is calculated with a multi-dimensional median, using all the spectral measurements from the satellite imagery at the same time in order to maintain the relationships among the measurements.  The median absolute deviation part of the product uses three measures of variance, each of which provides a "second order" high dimensional statistical composite for the given year. The three variance measures show how much an area varies from the "average" in terms of "distance" based on factors such as brightness and spectra:  * Euclidean distance (EMAD) * Cosine (spectral) distance (SMAD) * Bray Curtis dissimilarity (BCMAD)  Together, they provide information on variance in the landscape over the given year and are useful for change detection applications.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation Landsat](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var geomedian_ls8 = ee.ImageCollection('projects/geoscience-aus-cat/assets/ga_ls8c_nbart_gm_cyear_3');  var geometry =      /* color: #98ff00 */     /* displayProperties: [       {         "type": "rectangle"       }     ] */     ee.Geometry.Polygon(         [[[121.15880998755823, -15.010654451073695],           [121.15880998755823, -18.377531570740548],           [125.81701311255823, -18.377531570740548],           [125.81701311255823, -15.010654451073695]]], null, false);  var composite = geomedian_ls8.filterBounds(geometry)                              .filterDate('2018-01-01', '2019-01-01')                              .mosaic();                               var visualization = {   bands: ['red', 'green', 'blue'],   min: 0,   max: 3000 };  Map.centerObject(geometry, 10); Map.addLayer(composite, visualization, '2018 True Color Composite');  
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_ls_landcover_class_cyear_2:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_ls_landcover_class_cyear_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_ls_landcover_class_cyear_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_ls_landcover_class_cyear_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_ls_landcover_class_cyear_2(example: str = ''):
        """
        Digital Earth Australia (DEA) Land Cover provides annual land cover classifications for Australia using the Food and Agriculture Organisation Land Cover Classification System taxonomy Version 2 (Di Gregorio and Jansen, 1998; 2005).  DEA Land Cover translates over 30 years of satellite imagery into evidence of how Australia's land, vegetation and waterbodies have changed over time.  Land cover is the observed physical cover on the Earth's surface including trees, shrubs, grasses, soils, exposed rocks, water bodies, plantations, crops and built structures. A consistent, Australia-wide land cover product helps understanding of how the different parts of the environment change and inter-relate. Earth observation data recorded over a period of time firstly allows the observation of the state of land cover at a specific time and secondly the way that land cover changes by comparison between times.  For more information, please see the [DEA Landcover Landsat](https://cmi.ga.gov.au/data-products/dea/607/dea-land-cover-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var landcover = ee.ImageCollection('projects/geoscience-aus-cat/assets/ga_ls_landcover_class_cyear_2');  var visualization = {   bands: ['level4_R', 'level4_G', 'level4_B'] };  var lon = 122.41280; var lat = -18.06402;  Map.setCenter(lon, lat, 10);  // Degrees in EPSG:3857. var delta = 0.25;  var areaOfInterest = ee.Geometry.Rectangle(   [lon - delta, lat - delta, lon + delta, lat + delta], null, false);  var image = landcover.filterDate('1995-01-01', '1996-01-01')                      .filterBounds(areaOfInterest);                    Map.addLayer(image, visualization, 'Land Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_ga_ls_wo_fq_cyear_3:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_ga_ls_wo_fq_cyear_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_ga_ls_wo_fq_cyear_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_ga_ls_wo_fq_cyear_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_ga_ls_wo_fq_cyear_3(example: str = ''):
        """
        Digital Earth Australia (DEA) Water Observations uses an algorithm to classify each pixel from Landsat satellite imagery as 'wet', 'dry', or 'invalid'. Water Observations Statistics provides information on how many times each year the Landsat satellites were able to clearly see an area, how many times those observations were wet, and what that means for the percentage of time that water was observed in the landscape.  Combining the classified pixels into summaries covering each year gives the information on where water is usually, and where it is rarely. As no confidence filtering is applied to this product, it is affected by noise where misclassifications have occurred in the input water classifications, and can be difficult to interpret on its own.   For more information, please see the [DEA Water Observations Statistics Landsat](https://cmi.ga.gov.au/data-products/dea/686/dea-water-observations-statistics-landsat)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var water_obs = ee.ImageCollection('projects/geoscience-aus-cat/assets/ga_ls_wo_fq_cyear_3');  var gray = 150; var background = ee.Image.rgb(gray, gray, gray).visualize({ min: 0, max: 255 });  var visualization_frequency = {   bands: ['frequency'],   min: 0.0,   max: 1.0,   palette: ['ffffff', 'ffbbbb', '0000ff'] };  var point = ee.Geometry.Point([113.651455, -26.024137]);  var image = water_obs.filterBounds(point)                      .filterDate('2010-01-01', '2011-01-01')                      .first()                      .visualize(visualization_frequency);                       Map.centerObject(image, 12); var imageWithBackground = ee.ImageCollection([background, image]).mosaic(); Map.addLayer(imageWithBackground, {}, 'Water Frequency ratio'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_geomedians_LS5:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_geomedians_LS5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_geomedians_LS5(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Earth observation data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_geomedians_LS7:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_geomedians_LS7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_geomedians_LS7(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Earth observation data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_geomedians_LS8:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_geomedians_LS8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_geomedians_LS8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_geomedians_LS8(example: str = ''):
        """
        This product provides statistical tools to exploit the time series of Earth observation data available in Digital Earth Australia, providing annual images of general conditions and how much an area changes for a given year.  For more information, please see the [DEA Geometric Median and Median Absolute Deviation](https://cmi.ga.gov.au/data-products/dea/645/dea-geometric-median-and-median-absolute-deviation-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_geoscience_aus_cat_assets_NIDEM:
    def __init__(self,):
        self.sensor = 'projects_geoscience_aus_cat_assets_NIDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_geoscience-aus-cat_assets_NIDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_geoscience-aus-cat_assets_NIDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_geoscience_aus_cat_assets_NIDEM(example: str = ''):
        """
        The National Intertidal Digital Elevation Model (NIDEM; Bishop-Taylor et al. 2018, 2019) is a continental-scale elevation dataset for Australia's exposed intertidal zone. NIDEM provides the first three-dimensional representation of Australia's intertidal sandy beaches and shores, tidal flats and rocky shores and reefs at 25 m spatial resolution, addressing a key gap between the availability of sub-tidal bathymetry and terrestrial elevation data. NIDEM was generated by combining global tidal modelling with a 30-year time series archive of spatially and spectrally calibrated Landsat satellite data managed within the Digital Earth Australia (DEA) platform. NIDEM complements existing intertidal extent products, and provides data to support a new suite of use cases that require a more detailed understanding of the three-dimensional topography of the intertidal zone, such as hydrodynamic modelling, coastal risk management and ecological habitat mapping.  For more information, please see the [DEA Intertidal Elevation](https://cmi.ga.gov.au/data-products/dea/325/dea-intertidal-elevation-landsat#basics)  This product is part of the [Digital Earth Australia Program](https://www.dea.ga.gov.au/) 
        :param example: var nidem = ee.Image('projects/geoscience-aus-cat/assets/NIDEM');  var elevation = nidem.select('nidem'); var elevationVis = {   min: -2.5,   max: 1.5,   palette: [     '440154', '471365', '482475', '463480', '414487', '3b528b', '355f8d',     '2f6c8e', '2a788e', '25848e', '21918c', '1e9c89', '22a884', '2fb47c',     '44bf70', '5ec962', '7ad151', '9bd93c', 'bddf26', 'dfe318', 'fde725'   ], }; Map.setCenter(122.36, -18.10, 11); Map.addLayer(     elevation, elevationVis,     'National Intertidal Digital Elevation Model (NIDEM; m)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_ngis_cat_assets_DEA_NIDEM:
    def __init__(self,):
        self.sensor = 'projects_ngis_cat_assets_DEA_NIDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_ngis-cat_assets_DEA_NIDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_ngis-cat_assets_DEA_NIDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_ngis_cat_assets_DEA_NIDEM(example: str = ''):
        """
        The National Intertidal Digital Elevation Model (NIDEM; Bishop-Taylor et al. 2018, 2019) is a continental-scale elevation dataset for Australia's exposed intertidal zone. NIDEM provides the first three-dimensional representation of Australia's intertidal sandy beaches and shores, tidal flats and rocky shores and reefs at 25 m spatial resolution, addressing a key gap between the availability of sub-tidal bathymetry and terrestrial elevation data. NIDEM was generated by combining global tidal modelling with a 30-year time series archive of spatially and spectrally calibrated Landsat satellite data managed within the Digital Earth Australia (DEA) platform. NIDEM complements existing intertidal extent products, and provides data to support a new suite of use cases that require a more detailed understanding of the three-dimensional topography of the intertidal zone, such as hydrodynamic modelling, coastal risk management and ecological habitat mapping.  For more information, please see the [DEA Intertidal Elevation](https://cmi.ga.gov.au/data-products/dea/325/dea-intertidal-elevation-landsat#basics) 
        :param example: var nidem = ee.Image('projects/ngis-cat/assets/DEA/NIDEM');  var elevation = nidem.select('nidem'); var elevationVis = {   min: -2.5,   max: 1.5,   palette: [     '440154', '471365', '482475', '463480', '414487', '3b528b', '355f8d',     '2f6c8e', '2a788e', '25848e', '21918c', '1e9c89', '22a884', '2fb47c',     '44bf70', '5ec962', '7ad151', '9bd93c', 'bddf26', 'dfe318', 'fde725'   ], }; Map.setCenter(122.36, -18.10, 11); Map.addLayer(     elevation, elevationVis,     'National Intertidal Digital Elevation Model (NIDEM; m)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_planet_nicfi_assets_basemaps_africa:
    def __init__(self,):
        self.sensor = 'projects_planet_nicfi_assets_basemaps_africa'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_planet-nicfi_assets_basemaps_africa.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_planet-nicfi_assets_basemaps_africa.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_planet_nicfi_assets_basemaps_africa(example: str = ''):
        """
        This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use.  To learn how to access the Basemaps, follow the [sign up instructions here](https://developers.planet.com/docs/integrations/gee/nicfi/).  The NICFI Satellite Data Program mosaics (also referred to as Planet-NICFI mosaics) contain both monthly and biannual collections generated every 6 months.  The type of the mosaic is stored in the image metadata field 'cadence'. Use that field along with the start and end date for each mosaic to find the desired imagery.  Full details about the Basemaps are available in [NICFI Satellite Data Program Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf).  For more information about the NICFI (Norway's International Climate and Forest Initiative) Satellite Data Program and the data offered, please visit [the Program's website](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).  In support of NICFI's mission, you can use this data for a number of projects including, but not limited to:  * Advance scientific research about the world's tropical forests and the   critical services they provide. * Implement and improve policies for sustainable forest management and land   use in developing tropical forest countries and jurisdictions. * Increase transparency and accountability in the tropics. * Protect and improve the rights of indigenous peoples and local communities   in tropical forest countries. * Innovate solutions towards reducing pressure on forests from global   commodities and financial markets. 
        :param example: // This collection is not publicly accessible. To sign up for access, // please see https://developers.planet.com/docs/integrations/gee/nicfi var nicfi = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/africa');  // Filter basemaps by date and get the first image from filtered results var basemap= nicfi.filter(ee.Filter.date('2021-03-01','2021-07-01')).first();  Map.centerObject(basemap, 4);  var vis = {'bands':['R','G','B'],'min':64,'max':5454,'gamma':1.8};  Map.addLayer(basemap, vis, '2021-03 mosaic'); Map.addLayer(     basemap.normalizedDifference(['N','R']).rename('NDVI'),     {min:-0.55,max:0.8,palette: [         '8bc4f9', 'c9995c', 'c7d270','8add60','097210'     ]}, 'NDVI', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_planet_nicfi_assets_basemaps_americas:
    def __init__(self,):
        self.sensor = 'projects_planet_nicfi_assets_basemaps_americas'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_planet-nicfi_assets_basemaps_americas.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_planet-nicfi_assets_basemaps_americas.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_planet_nicfi_assets_basemaps_americas(example: str = ''):
        """
        This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use.  To learn how to access the Basemaps, follow the [sign up instructions here](https://developers.planet.com/docs/integrations/gee/nicfi/).  The NICFI Satellite Data Program mosaics (also referred to as Planet-NICFI mosaics) contain both monthly and biannual collections generated every 6 months.  The type of the mosaic is stored in the image metadata field 'cadence'. Use that field along with the start and end date for each mosaic to find the desired imagery.  Full details about the Basemaps are available in [NICFI Satellite Data Program Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf).  For more information about the NICFI (Norway's International Climate and Forest Initiative) Satellite Data Program and the data offered, please visit [the Program's website](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).  In support of NICFI's mission, you can use this data for a number of projects including, but not limited to:  * Advance scientific research about the world's tropical forests and the   critical services they provide. * Implement and improve policies for sustainable forest management and land   use in developing tropical forest countries and jurisdictions. * Increase transparency and accountability in the tropics. * Protect and improve the rights of indigenous peoples and local communities   in tropical forest countries. * Innovate solutions towards reducing pressure on forests from global   commodities and financial markets. 
        :param example: // This collection is not publicly accessible. To sign up for access, // please see https://developers.planet.com/docs/integrations/gee/nicfi var nicfi = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/americas');  // Filter basemaps by date and get the first image from filtered results var basemap= nicfi.filter(ee.Filter.date('2021-03-01','2021-07-01')).first();  Map.centerObject(basemap, 4);  var vis = {'bands':['R','G','B'],'min':64,'max':5454,'gamma':1.8};  Map.addLayer(basemap, vis, '2021-03 mosaic'); Map.addLayer(     basemap.normalizedDifference(['N','R']).rename('NDVI'),     {min:-0.55,max:0.8,palette: [         '8bc4f9', 'c9995c', 'c7d270','8add60','097210'     ]}, 'NDVI', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_planet_nicfi_assets_basemaps_asia:
    def __init__(self,):
        self.sensor = 'projects_planet_nicfi_assets_basemaps_asia'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_planet-nicfi_assets_basemaps_asia.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_planet-nicfi_assets_basemaps_asia.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_planet_nicfi_assets_basemaps_asia(example: str = ''):
        """
        This image collection provides access to high-resolution satellite monitoring of the tropics for the primary purpose of reducing and reversing the loss of tropical forests, contributing to combating climate change, conserving biodiversity, contributing to forest regrowth, restoration and enhancement, and facilitating sustainable development, all of which must be Non-Commercial Use.  To learn how to access the Basemaps, follow the [sign up instructions here](https://developers.planet.com/docs/integrations/gee/nicfi/).  The NICFI Satellite Data Program mosaics (also referred to as Planet-NICFI mosaics) contain both monthly and biannual collections generated every 6 months.  The type of the mosaic is stored in the image metadata field 'cadence'. Use that field along with the start and end date for each mosaic to find the desired imagery.  Full details about the Basemaps are available in [NICFI Satellite Data Program Basemap spec](https://assets.planet.com/docs/NICFI_Basemap_Spec_Addendum.pdf).  For more information about the NICFI (Norway's International Climate and Forest Initiative) Satellite Data Program and the data offered, please visit [the Program's website](https://assets.planet.com/docs/NICFI_General_FAQs.pdf).  In support of NICFI's mission, you can use this data for a number of projects including, but not limited to:  * Advance scientific research about the world's tropical forests and the   critical services they provide. * Implement and improve policies for sustainable forest management and land   use in developing tropical forest countries and jurisdictions. * Increase transparency and accountability in the tropics. * Protect and improve the rights of indigenous peoples and local communities   in tropical forest countries. * Innovate solutions towards reducing pressure on forests from global   commodities and financial markets. 
        :param example: // This collection is not publicly accessible. To sign up for access, // please see https://developers.planet.com/docs/integrations/gee/nicfi var nicfi = ee.ImageCollection('projects/planet-nicfi/assets/basemaps/asia');  // Filter basemaps by date and get the first image from filtered results var basemap= nicfi.filter(ee.Filter.date('2021-03-01','2021-07-01')).first();  Map.setCenter(107, 10, 4);  var vis = {'bands':['R','G','B'],'min':64,'max':5454,'gamma':1.8};  Map.addLayer(basemap, vis, '2021-03 mosaic'); Map.addLayer(     basemap.normalizedDifference(['N','R']).rename('NDVI'),     {min:-0.55,max:0.8,palette: [         '8bc4f9', 'c9995c', 'c7d270','8add60','097210'     ]}, 'NDVI', false);  
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_sat_io_open_datasets_GLOBathy_GLOBathy_bathymetry:
    def __init__(self,):
        self.sensor = 'projects_sat_io_open_datasets_GLOBathy_GLOBathy_bathymetry'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_sat-io_open-datasets_GLOBathy_GLOBathy_bathymetry.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_sat-io_open-datasets_GLOBathy_GLOBathy_bathymetry.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_sat_io_open_datasets_GLOBathy_GLOBathy_bathymetry(example: str = ''):
        """
        The GLObal Bathymetric (GLOBathy) dataset, comprising data on over 1.4 million waterbodies globally, has been meticulously developed to harmonize with the widely recognized HydroLAKES dataset. Utilizing a sophisticated Geographic Information System (GIS)-based framework, GLOBathy constructs detailed bathymetric maps by integrating maximum depth estimates and geometric/geophysical attributes sourced from HydroLAKES. Ensuring data accuracy and reliability, GLOBathy undergoes stringent validation procedures involving 1,503 waterbodies and a diverse range of observed data sources. Consequently, GLOBathy stands as a robust and comprehensive dataset for hydrography and aquatic sciences, offering invaluable resources for researchers and professionals in these fields. 
        :param example: var globathy = ee.Image(   "projects/sat-io/open-datasets/GLOBathy/GLOBathy_bathymetry" );  var palettes = require("users/samapriya/utils:palettes");  // Use these visualization parameters, customized by location. var visParams = { min: 1, max: 700, palette: palettes.extra.blkred };  // Note that the visualization image doesn't require visualization parameters. Map.addLayer(globathy, visParams, "Globathy Bathymetry (m)"); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_sat_io_open_datasets_ORNL_LANDSCAN_GLOBAL:
    def __init__(self,):
        self.sensor = 'projects_sat_io_open_datasets_ORNL_LANDSCAN_GLOBAL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_sat-io_open-datasets_ORNL_LANDSCAN_GLOBAL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_sat-io_open-datasets_ORNL_LANDSCAN_GLOBAL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_sat_io_open_datasets_ORNL_LANDSCAN_GLOBAL(example: str = ''):
        """
        The LandScan dataset, provided by the Oak Ridge National Laboratory (ORNL), offers a comprehensive and high-resolution global population distribution dataset that serves as a valuable resource for a wide range of applications. Leveraging state-of-the-art spatial modeling techniques and advanced geospatial data sources, LandScan provides detailed information on population counts and density at a 30 arc-second resolution, enabling precise and up-to-date insights into human settlement patterns across the globe. With its accuracy and granularity, LandScan supports diverse fields such as urban planning, disaster response, epidemiology, and environmental research, making it an essential tool for decision-makers and researchers seeking to understand and address various societal and environmental challenges on a global scale. 
        :param example: var landscan_global =     ee.ImageCollection('projects/sat-io/open-datasets/ORNL/LANDSCAN_GLOBAL'); var popcount_intervals = '<RasterSymbolizer>' +     ' <ColorMap type="intervals" extended="false" >' +     '<ColorMapEntry color="#CCCCCC" quantity="0" label="No Data"/>' +     '<ColorMapEntry color="#FFFFBE" quantity="5" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#FEFF73" quantity="25" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#FEFF2C" quantity="50" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#FFAA27" quantity="100" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#FF6625" quantity="500" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#FF0023" quantity="2500" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#CC001A" quantity="5000" label="Population Count (Estimate)"/>' +     '<ColorMapEntry color="#730009" quantity="185000" label="Population Count (Estimate)"/>' +     '</ColorMap>' +     '</RasterSymbolizer>';  // Define a dictionary which will be used to make legend and visualize image on // map var dict = {   'names': [     '0', '1-5', '6-25', '26-50', '51-100', '101-500', '501-2500', '2501-5000',     '5001-185000'   ],   'colors': [     '#CCCCCC', '#FFFFBE', '#FEFF73', '#FEFF2C', '#FFAA27', '#FF6625', '#FF0023',     '#CC001A', '#730009'   ] };  // Create a panel to hold the legend widget var legend = ui.Panel({style: {position: 'bottom-left', padding: '8px 15px'}});  // Function to generate the legend function addCategoricalLegend(panel, dict, title) {   // Create and add the legend title.   var legendTitle = ui.Label({     value: title,     style: {       fontWeight: 'bold',       fontSize: '18px',       margin: '0 0 4px 0',       padding: '0'     }   });   panel.add(legendTitle);    var loading = ui.Label('Loading legend...', {margin: '2px 0 4px 0'});   panel.add(loading);    // Creates and styles 1 row of the legend.   var makeRow = function(color, name) {     // Create the label that is actually the colored box.     var colorBox = ui.Label({       style: {         backgroundColor: color,         // Use padding to give the box height and width.         padding: '8px',         margin: '0 0 4px 0'       }     });      // Create the label filled with the description text.     var description = ui.Label({value: name, style: {margin: '0 0 4px 6px'}});      return ui.Panel({       widgets: [colorBox, description],       layout: ui.Panel.Layout.Flow('horizontal')     });   };    // Get the list of palette colors and class names from the image.   var palette = dict['colors'];   var names = dict['names'];   loading.style().set('shown', false);    for (var i = 0; i < names.length; i++) {     panel.add(makeRow(palette[i], names[i]));   }    Map.add(panel); }  addCategoricalLegend(legend, dict, 'Population Count(estimate)');  Map.addLayer(     landscan_global.sort('system:time_start')         .first()         .sldStyle(popcount_intervals),     {}, 'Population Count Estimate 2000'); Map.addLayer(     landscan_global.sort('system:time_start', false)         .first()         .sldStyle(popcount_intervals),     {}, 'Population Count Estimate 2022'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class projects_sat_io_open_datasets_us_drought_monitor:
    def __init__(self,):
        self.sensor = 'projects_sat_io_open_datasets_us_drought_monitor'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/projects_sat-io_open-datasets_us-drought-monitor.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/projects_sat-io_open-datasets_us-drought-monitor.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_projects_sat_io_open_datasets_us_drought_monitor(example: str = ''):
        """
        The U.S. Drought Monitor is a map released every Thursday, showing parts of the U.S. that are in drought. The map uses five classifications: abnormally dry (D0), showing areas that may be going into or are coming out of drought, and four levels of drought: moderate (D1), severe (D2), extreme (D3) and exceptional (D4). The Drought Monitor has been a team effort since its inception in 1999, produced jointly by the National Drought Mitigation Center (NDMC) at the University of Nebraska-Lincoln, the National Oceanic and Atmospheric Administration (NOAA), and the U.S. Department of Agriculture (USDA). The NDMC hosts the web site of the drought monitor and the associated data, and provides the map and data to NOAA, USDA and other agencies. It is freely available at droughtmonitor.unl.edu. 
        :param example: var usdm = ee.ImageCollection(   "projects/sat-io/open-datasets/us-drought-monitor" ); /* Category	Description DO	Abnormally Dry D1	Moderate Drought D2	Severe Drought D3	Extreme Drought D4	Exceptional Drought */  var usdm = ee.Image(usdm.toList(usdm.size()).get(-1));  // Define a dictionary which will be used to make legend and visualize image on map var dict = {   names: [     "DO	Abnormally Dry", //1     "D1 Moderate Drought", //2     "D2 Severe Drought", //3     "D3 Extreme Drought", //4     "D4 Exceptional Drought", //5   ],   colors: ["FFFF00", "FCD37F", "FFAA00", "E60000", "730000"], };  // Create a panel to hold the legend widget var legend = ui.Panel({   style: {     position: "bottom-left",     padding: "8px 15px",   }, });  // Function to generate the legend function addCategoricalLegend(panel, dict, title) {   // Create and add the legend title.   var legendTitle = ui.Label({     value: title,     style: {       fontWeight: "bold",       fontSize: "18px",       margin: "0 0 4px 0",       padding: "0",     },   });   panel.add(legendTitle);    var loading = ui.Label("Loading legend...", { margin: "2px 0 4px 0" });   panel.add(loading);    // Creates and styles 1 row of the legend.   var makeRow = function (color, name) {     // Create the label that is actually the colored box.     var colorBox = ui.Label({       style: {         backgroundColor: color,         // Use padding to give the box height and width.         padding: "8px",         margin: "0 0 4px 0",       },     });      // Create the label filled with the description text.     var description = ui.Label({       value: name,       style: { margin: "0 0 4px 6px" },     });      return ui.Panel({       widgets: [colorBox, description],       layout: ui.Panel.Layout.Flow("horizontal"),     });   };    // Get the list of palette colors and class names from the image.   var palette = dict["colors"];   var names = dict["names"];   loading.style().set("shown", false);    for (var i = 0; i < names.length; i++) {     panel.add(makeRow(palette[i], names[i]));   }    Map.add(panel); }  /*   // Display map and legend /////////////////////////////////////////////////////////////////////////////// */  // Add the legend to the map addCategoricalLegend(legend, dict, "US Drought Monitor");  // Add USDM Image image to the map Map.addLayer(   usdm,   { min: 0, max: 4, palette: dict["colors"] },   usdm.get("system:index").getInfo() ); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class RESOLVE_ECOREGIONS_2017:
    def __init__(self,):
        self.sensor = 'RESOLVE_ECOREGIONS_2017'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/RESOLVE_ECOREGIONS_2017.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/RESOLVE_ECOREGIONS_2017.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_RESOLVE_ECOREGIONS_2017(example: str = ''):
        """
        The RESOLVE Ecoregions dataset, updated in 2017, offers a depiction of the 846 terrestrial ecoregions that represent our living planet.  View the stylized map at [https://ecoregions2017.appspot.com/](https://ecoregions2017.appspot.com/) or in [Earth Engine](https://code.earthengine.google.com/b961ab2adfcb03c920aab63d86c49eb2).  Ecoregions, in the simplest definition, are ecosystems of regional extent. Specifically, ecoregions represent distinct assemblages of biodiversity-all taxa, not just vegetation-whose boundaries include the space required to sustain ecological processes. Ecoregions provide a useful basemap for conservation planning in particular because they draw on natural, rather than political, boundaries, define distinct biogeographic assemblages and ecological habitats within biomes, and assist in representation of Earth's biodiversity.  This dataset is based on recent advances in biogeography - the science concerning the distribution of plants and animals. The original ecoregions dataset has been widely used since its introduction in 2001, underpinning the most recent analyses of the effects of global climate change on nature by ecologists to the distribution of the world's beetles to modern conservation planning.  The 846 terrestrial ecoregions are grouped into 14 biomes and 8 realms. Six of these biomes are forest biomes and remaining eight are non-forest biomes. For the forest biomes, the geographic boundaries of the ecoregions (Dinerstein et al., 2017) and protected areas (UNEP-WCMC 2016) were intersected with the Global Forest Change data (Hansen et al. 2013) for the years 2000 to 2015, to calculate percent of habitat in protected areas and percent of remaining habitat outside protected areas.  Likewise, the boundaries of the non-forest ecoregions and protected areas (UNEP-WCMC 2016) were intersected with Anthropogenic Biomes data (Anthromes v2) for the year 2000 (Ellis et al., 2010) to identify remaining habitats inside and outside the protected areas. Each ecoregion has a unique ID, area (sq. degrees), and NNH (Nature Needs Half) categories 1-4. NNH categories are based on percent of habitat in protected areas and percent of remaining habitat outside protected areas.  1. Half Protected: More than 50% of the total ecoregion area is already    protected. 2. Nature Could Reach Half: Less than 50% of the total ecoregion area is    protected but the amount of remaining unprotected natural habitat could    bring protection to over 50% if new conservation areas are added to the    system. 3. Nature Could Recover: The amount of protected and unprotected natural    habitat remaining is less than 50% but more than 20%. Ecoregions in this    category would require restoration to reach Half Protected. 4. Nature Imperiled: The amount of protected and unprotected natural habitat    remaining is less than or equal to 20%. Achieving half protected is not    possible in the short term and efforts should focus on conserving    remaining, native habitat fragments.  The updated Ecoregions 2017 is the most-up-to-date (as of February 2018) dataset on remaining habitat in each terrestrial ecoregion. It was released to chart progress towards achieving the visionary goal of [Nature Needs Half](https://natureneedshalf.org/), to protect half of all the land on Earth to save a living terrestrial biosphere.  Note - a number of ecoregions are very complex polygons with over a million vertices, such as Rock & Ice. These ecoregions were split when necessary, with attributes like Eco_ID being preserved. If you'd like to see all ecoregions that have been split, please [run this script](https://code.earthengine.google.com/7a437c78fc8cb46ec586bb4e2c10e526). 
        :param example: var ecoRegions = ee.FeatureCollection('RESOLVE/ECOREGIONS/2017');  // patch updated colors var colorUpdates = [ {ECO_ID: 204, COLOR: '#B3493B'}, {ECO_ID: 245, COLOR: '#267400'}, {ECO_ID: 259, COLOR: '#004600'}, {ECO_ID: 286, COLOR: '#82F178'}, {ECO_ID: 316, COLOR: '#E600AA'}, {ECO_ID: 453, COLOR: '#5AA500'}, {ECO_ID: 317, COLOR: '#FDA87F'}, {ECO_ID: 763, COLOR: '#A93800'}, ];  // loop over all other features and create a new style property for styling // later on var ecoRegions = ecoRegions.map(function(f) {   var color = f.get('COLOR');   return f.set({style: {color: color, width: 0}}); });  // make styled features for the regions we need to update colors for, // then strip them from the main asset and merge in the new feature for (var i=0; i < colorUpdates.length; i++) {   colorUpdates[i].layer = ecoRegions       .filterMetadata('ECO_ID','equals',colorUpdates[i].ECO_ID)       .map(function(f) {         return f.set({style: {color: colorUpdates[i].COLOR, width: 0}});       });    ecoRegions = ecoRegions       .filterMetadata('ECO_ID','not_equals',colorUpdates[i].ECO_ID)       .merge(colorUpdates[i].layer); }  // use style property to color shapes var imageRGB = ecoRegions.style({styleProperty: 'style'});  Map.setCenter(16, 49, 4); Map.addLayer(imageRGB, {}, 'RESOLVE/ECOREGIONS/2017'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class RUB_RUBCLIM_LCZ_global_lcz_map_latest:
    def __init__(self,):
        self.sensor = 'RUB_RUBCLIM_LCZ_global_lcz_map_latest'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/RUB_RUBCLIM_LCZ_global_lcz_map_latest.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/RUB_RUBCLIM_LCZ_global_lcz_map_latest.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_RUB_RUBCLIM_LCZ_global_lcz_map_latest(example: str = ''):
        """
        Since their introduction in 2012, Local Climate Zones (LCZs) emerged as a new standard for characterizing urban landscapes, providing a holistic classification approach that takes into account micro-scale land-cover and associated physical properties.  This global map of Local Climate Zones, at 100m pixel size and representative for the nominal year 2018, is derived from multiple earth observation datasets and expert LCZ class labels. LCZ_Filter is the recommended band for most users. The other classification band, LCZ, is only provided as it is used to calculate the LCZ_Probability band.  The LCZ scheme complements other land use / land cover schemes by its focus on urban and rural landscape types, which can be described by any of the 17 classes in the LCZ scheme. Out of the 17 LCZ classes, 10 reflect the 'built' environment, and each LCZ type is associated with generic numerical descriptions of key urban canopy parameters critical to model atmospheric responses to urbanisation.  In addition, since LCZs were originally designed as a new framework for urban heat island studies, they also contain a limited set (7) of 'natural' land-cover classes that can be used as 'control' or 'natural reference' areas.  As these seven natural classes in the LCZ scheme can not capture the heterogeneity of the world's existing natural ecosystems, we advise users - if required - to combine the built LCZ classes with any other land-cover product that provides a wider range of natural land-cover classes.  See also:  * [LCZ Typology](https://doi.org/10.1175/BAMS-D-11-00019.1)  * [Global map of LCZs - paper](https://doi.org/10.5194/essd-14-3835-2022)  * [Global map of LCZs - dataset](https://doi.org/10.5281/zenodo.6364593)  * [LCZ Gaussian filtering](https://doi.org/10.1038/s41597-020-00605-z) 
        :param example: var dataset = ee.ImageCollection('RUB/RUBCLIM/LCZ/global_lcz_map/latest')             .mosaic();  var visualization = {   bands: ['LCZ_Filter'],   min: 1,   max: 17,   palette: [     '8c0000','d10000','ff0000','bf4d00','ff6600',     'ff9955','faee05','bcbcbc','ffccaa','555555',     '006a00','00aa00','648525','b9db79','000000',     'fbf7ae','6a6aff'     ] };  Map.setCenter(7.26, 51.44, 6); Map.addLayer(dataset, visualization, 'LCZ_Filter'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class RUB_RUBCLIM_LCZ_global_lcz_map_v1:
    def __init__(self,):
        self.sensor = 'RUB_RUBCLIM_LCZ_global_lcz_map_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/RUB_RUBCLIM_LCZ_global_lcz_map_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/RUB_RUBCLIM_LCZ_global_lcz_map_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_RUB_RUBCLIM_LCZ_global_lcz_map_v1(example: str = ''):
        """
        Since their introduction in 2012, Local Climate Zones (LCZs) emerged as a new standard for characterizing urban landscapes, providing a holistic classification approach that takes into account micro-scale land-cover and associated physical properties.  This global map of Local Climate Zones, at 100m pixel size and representative for the nominal year 2018, is derived from multiple earth observation datasets and expert LCZ class labels. LCZ_Filter is the recommended band for most users. The other classification band, LCZ, is only provided as it is used to calculate the LCZ_Probability band.  The LCZ scheme complements other land use / land cover schemes by its focus on urban and rural landscape types, which can be described by any of the 17 classes in the LCZ scheme. Out of the 17 LCZ classes, 10 reflect the 'built' environment, and each LCZ type is associated with generic numerical descriptions of key urban canopy parameters critical to model atmospheric responses to urbanisation.  In addition, since LCZs were originally designed as a new framework for urban heat island studies, they also contain a limited set (7) of 'natural' land-cover classes that can be used as 'control' or 'natural reference' areas.  As these seven natural classes in the LCZ scheme can not capture the heterogeneity of the world's existing natural ecosystems, we advise users - if required - to combine the built LCZ classes with any other land-cover product that provides a wider range of natural land-cover classes.  See also:  * [LCZ Typology](https://doi.org/10.1175/BAMS-D-11-00019.1)  * [Global map of LCZs - paper](https://doi.org/10.5194/essd-14-3835-2022)  * [Global map of LCZs - dataset](https://doi.org/10.5281/zenodo.6364593)  * [LCZ Gaussian filtering](https://doi.org/10.1038/s41597-020-00605-z) 
        :param example: var dataset = ee.ImageCollection('RUB/RUBCLIM/LCZ/global_lcz_map/v1')             .mosaic();  var visualization = {   bands: ['LCZ_Filter'],   min: 1,   max: 17,   palette: [     '8c0000','d10000','ff0000','bf4d00','ff6600',     'ff9955','faee05','bcbcbc','ffccaa','555555',     '006a00','00aa00','648525','b9db79','000000',     'fbf7ae','6a6aff'     ] };  Map.setCenter(7.26, 51.44, 6); Map.addLayer(dataset, visualization, 'LCZ_Filter'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class SKYSAT_GEN_A_PUBLIC_ORTHO_MULTISPECTRAL:
    def __init__(self,):
        self.sensor = 'SKYSAT_GEN_A_PUBLIC_ORTHO_MULTISPECTRAL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/SKYSAT_GEN-A_PUBLIC_ORTHO_MULTISPECTRAL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/SKYSAT_GEN-A_PUBLIC_ORTHO_MULTISPECTRAL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_SKYSAT_GEN_A_PUBLIC_ORTHO_MULTISPECTRAL(example: str = ''):
        """
        This data from Planet labs Inc. SkySat satellites was collected for the experimental \"Skybox for Good Beta\" program in 2015, as well as for various crisis response events and a few other projects. The data is available in both a 5-band Multispectral/Pan collection, and a Pansharpened RGB collection.  Each image's asset ID contains the acquisition date and time, for example, image s01_20150304T080608Z was acquired on March 4, 2015 at 08:06 Zulu (UTC). For more information, please see the [Planet Imagery Product Specifications](https://www.planet.com/products/satellite-imagery/files/Planet_Combined_Imagery_Product_Specs_December2017.pdf) and visit the [Planet Imagery and Archive](https://www.planet.com/products/planet-imagery/) site.  This Multispectral/Pan collection contains images with five 16-bit bands shifted up from the original 12-bit data. The B, G, R, and Near-IR bands have a resolution of approximately 2m per pixel, while the Pan band is approximately 0.8m resolution (closer to 1m for off-nadir images). 
        :param example: var dataset = ee.ImageCollection('SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL'); var falseColor = dataset.select(['N', 'G', 'B']); var falseColorVis = {   min: 200.0,   max: 6000.0, }; Map.setCenter(-70.892, 41.6555, 15); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class SKYSAT_GEN_A_PUBLIC_ORTHO_RGB:
    def __init__(self,):
        self.sensor = 'SKYSAT_GEN_A_PUBLIC_ORTHO_RGB'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/SKYSAT_GEN-A_PUBLIC_ORTHO_RGB.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/SKYSAT_GEN-A_PUBLIC_ORTHO_RGB.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_SKYSAT_GEN_A_PUBLIC_ORTHO_RGB(example: str = ''):
        """
        This data from Planet labs Inc. SkySat satellites was collected for the experimental \"Skybox for Good Beta\" program in 2015, as well as for various crisis response events and a few other projects. The data is available in both a 5-band Multispectral/Pan collection, and a Pansharpened RGB collection.  Each image's asset ID contains the acquisition date and time, for example, image s01_20150304T080608Z was acquired on March 4, 2015 at 08:06 Zulu (UTC). For more information, please see the [Planet Imagery Product Specifications](https://assets.planet.com/docs/Planet_Combined_Imagery_Product_Specs_letter_screen.pdf) and visit the [Planet Imagery and Archive](https://www.planet.com/products/planet-imagery/) site.  This RGB collection contains images with three pansharpened, 8-bit bands. The resolution is approximately 0.8m per pixel (closer to 1m for off-nadir images). 
        :param example: var dataset = ee.ImageCollection('SKYSAT/GEN-A/PUBLIC/ORTHO/RGB'); var rgb = dataset.select(['R', 'G', 'B']); var rgbVis = {   min: 11.0,   max: 190.0, }; Map.setCenter(-70.892, 41.6555, 15); Map.addLayer(rgb, rgbVis, 'RGB'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Slovakia_orthos_25cm:
    def __init__(self,):
        self.sensor = 'Slovakia_orthos_25cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Slovakia_orthos_25cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Slovakia_orthos_25cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Slovakia_orthos_25cm(example: str = ''):
        """
        Orthophotomosaic of the Slovak Republic is a set of color orthoimages without overlaps, gaps and visible brightness and color differences along the connecting lines.  For more information, please see the [Slovakia orthophotos documentation](https://www.geoportal.sk/files/zbgis/orto/technicka_sprava_ortofotomozaika_sr_2017-2019.pdf) 
        :param example: var dataset = ee.ImageCollection('Slovakia/orthos/25cm');  Map.setCenter(19.163, 48.751, 15); Map.addLayer(dataset, {}, 'Slovakia orthophotos RGB');
        :return: None
        """
        return None
        

@geeData_registery.add()
class SNU_ESL_BESS_Rad_v1:
    def __init__(self,):
        self.sensor = 'SNU_ESL_BESS_Rad_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/SNU_ESL_BESS_Rad_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/SNU_ESL_BESS_Rad_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_SNU_ESL_BESS_Rad_v1(example: str = ''):
        """
        Breathing Earth System Simulator (BESS) is a simplified process-based model that couples atmosphere and canopy radiative transfers, canopy photosynthesis, transpiration, and energy balance. It couples an atmospheric radiative transfer model and artificial neural network with forcings from MODIS atmospheric products to generate 5-km daily products.  Publications:  * Ryu Youngryel, Chongya Jiang, Hideki Kobayashi, Matteo Detto,   MODIS-derived global land products of shortwave radiation and diffuse and   total photosynthetically active radiation at 5km resolution from 2000.   Remote Sensing of Environment, Volume 204,   2018.   [doi:10.1016/j.rse.2017.09.021](https://doi.org/10.1016/j.rse.2017.09.021) 
        :param example: var dataset = ee.ImageCollection('SNU/ESL/BESS/Rad/v1');  var visParams = {   bands: ['PAR_Daily'],   min: 0,   max: 70,   palette: ['black', 'purple', 'blue', 'yellow', 'orange', 'red'] };  Map.setCenter(2.1, 24.9, 3);  Map.addLayer(     dataset, visParams,     'Surface downwelling photosynthetic radiative flux (W/m^2)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Spain_PNOA_PNOA10:
    def __init__(self,):
        self.sensor = 'Spain_PNOA_PNOA10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Spain_PNOA_PNOA10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Spain_PNOA_PNOA10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Spain_PNOA_PNOA10(example: str = ''):
        """
        Mosaics of orthophotos from flights carried out between 2007 and 2018 by various public administration bodies at 10cm pixel resolution. This data is provided by National Plan for Aerial Orthophotography Spain ([PNOA](https://pnoa.ign.es)).  For more information, please see the [Spain orthophotos documentation](https://pnoa.ign.es/web/portal/pnoa-imagen/proceso-fotogrametrico) 
        :param example: var dataset = ee.ImageCollection('Spain/PNOA/PNOA10'); Map.setCenter(-1.859852, 38.983734, 19); Map.addLayer(dataset, {}, 'Spain RGB (10cm)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Switzerland_SWISSIMAGE_orthos_10cm:
    def __init__(self,):
        self.sensor = 'Switzerland_SWISSIMAGE_orthos_10cm'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Switzerland_SWISSIMAGE_orthos_10cm.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Switzerland_SWISSIMAGE_orthos_10cm.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Switzerland_SWISSIMAGE_orthos_10cm(example: str = ''):
        """
        The SWISSIMAGE 10 cm orthophoto mosaic is an assembly of new color digital aerial images over the whole of Switzerland with a ground resolution of 10 cm in the plains and the main alpine valleys and 25 cm in the Alps. It is updated annually.  For more information, please see the [SWISSIMAGE10cm_FR documentation](https://www.swisstopo.admin.ch/content/swisstopo-internet/fr/geodata/images/ortho/swissimage10/_jcr_content/contentPar/tabs_copy_copy/items/60_1569482292365/tabPar/downloadlist/downloadItems/67_1588752711524.download/SWISSIMAGE10-ProdInfo-FR.pdf)  This RGB collection contains digital aerial images with three bands. Standard deviation for the precision in position: +/- 0.15 m for the ground sample distance of 0.1 m. 
        :param example: var dataset = ee.Image('Switzerland/SWISSIMAGE/orthos/10cm/2017');  Map.setCenter(7.75, 46.02, 18); Map.addLayer(dataset, null, 'Switzerland RGB (10 cm)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TERN_AET_CMRSET_LANDSAT_V2_1:
    def __init__(self,):
        self.sensor = 'TERN_AET_CMRSET_LANDSAT_V2_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TERN_AET_CMRSET_LANDSAT_V2_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TERN_AET_CMRSET_LANDSAT_V2_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TERN_AET_CMRSET_LANDSAT_V2_1(example: str = ''):
        """
        This dataset provides accurate actual evapotranspiration (AET or ETa) for Australia using the CMRSET algorithm. The AET band (named 'ETa') contains the average daily value from the CMRSET model for all cloud-free Landsat observations in that month (indicated with value 3 in the AET Data Source QA bits). After the Landsat 7 ETM+ Scan Line Corrector (SLC) failed on 31 May 2003, Landsat 7 ETM+ data are only used if there are no cloud-free Landsat 5 TM or Landsat 8 OLI data for that month. If there is no cloud-free Landsat available, then pixels are infilled with Landsat-VIIRS blended output (indicated with value 2 in the AET Data Source QA bits). If there is no VIIRS available in a month, then missing monthly AET values are linearly interpolated (indicated with value 1 in the AET Data Source QA bits). This means monthly 30 m AET data covering all Australia, with no gaps due to cloud, are available and ready to use.  Accurate AET information is important for irrigation, food security, and environmental management. Like many other parts of the world, water availability in Australia is limited and AET is the largest consumptive component of the water balance. In Australia 70% of available water is used for crop and pasture irrigation. Better monitoring will support improved water use efficiency in this sector, with any water savings available as environmental flows. Additionally, ground-water dependent ecosystems (GDE) occupy a small area yet are "biodiversity hotspots". Knowing their water needs enables enhanced management of these critical areas. AET can also be used to model the catchment water balance. If used in water balance (mass balance) calculations, then this AET value needs to be multiplied by the number of days in the month.  To let the developers know you are using this dataset, to get information on updates, or if you have any questions please contact: tim.mcvicar@csiro.au, tom.vanniel@csiro.au, jamie.vleeshouwer@csiro.au . 
        :param example: var dataset = ee.ImageCollection('TERN/AET/CMRSET_LANDSAT_V2_1');  var visualization = {   bands: ['ETa'],   min: 1,   max: 7,   palette: ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'] };  Map.setCenter(132, -27, 4);  Map.addLayer(     dataset, visualization, 'Average daily evapotranspiration (mm/day)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TERN_AET_CMRSET_LANDSAT_V2_2:
    def __init__(self,):
        self.sensor = 'TERN_AET_CMRSET_LANDSAT_V2_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TERN_AET_CMRSET_LANDSAT_V2_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TERN_AET_CMRSET_LANDSAT_V2_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TERN_AET_CMRSET_LANDSAT_V2_2(example: str = ''):
        """
        This dataset provides accurate actual evapotranspiration (AET or ETa) for Australia using the CMRSET algorithm. The AET band (named 'ETa') contains the average daily value from the CMRSET model for all cloud-free Landsat observations in that month (indicated with value 3 in the AET Data Source QA bits). After the Landsat 7 ETM+ Scan Line Corrector (SLC) failed on 31 May 2003, Landsat 7 ETM+ data are only used if there are no cloud-free Landsat 5 TM or Landsat 8 OLI data for that month. If there is no cloud-free Landsat data available, pixels are infilled with blended data. The blended data will be blended Landsat-MODIS until Feb 2012, then blended Landsat-VIIRS onwards (indicated with value 2 in the AET Data Source QA bits). If there is no blended data available in a month, then missing monthly AET values are linearly interpolated (indicated with value 1 in the AET Data Source QA bits). This means monthly 30 m AET data covering all Australia, with no gaps due to cloud, are available and ready to use.  Accurate AET information is important for irrigation, food security, and environmental management. Like many other parts of the world, water availability in Australia is limited and AET is the largest consumptive component of the water balance. In Australia 70% of available water is used for crop and pasture irrigation. Better monitoring will support improved water use efficiency in this sector, with any water savings available as environmental flows. Additionally, ground-water dependent ecosystems (GDE) occupy a small area yet are "biodiversity hotspots". Knowing their water needs enables enhanced management of these critical areas. AET can also be used to model the catchment water balance. If used in water balance (mass balance) calculations, then this AET value needs to be multiplied by the number of days in the month.  To let the developers know you are using this dataset, to get information on updates, or if you have any questions please contact: tim.mcvicar@csiro.au, tom.vanniel@csiro.au, jamie.vleeshouwer@csiro.au. 
        :param example: var dataset = ee.ImageCollection('TERN/AET/CMRSET_LANDSAT_V2_2');  var visualization = {   bands: ['ETa'],   min: 0,   max: 7,   palette: ['d7191c', 'fdae61', 'ffffbf', 'abd9e9', '2c7bb6'] };  Map.setCenter(132, -27, 4);  Map.addLayer(     dataset, visualization, 'Average daily evapotranspiration (mm/day)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2010_BG:
    def __init__(self,):
        self.sensor = 'TIGER_2010_BG'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2010_BG.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2010_BG.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2010_BG(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This dataset contains the 2010 census [block groups](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_4), which is a cluster of blocks within the same census tract that have the same first digit of their four-digit census block number. There are just over 300,000 polygon features covering the United States, the District of Columbia, Puerto Rico, and the Island areas.  For full technical details on all TIGER 2010 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2010/TGRSHP10SF1.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2010/BG');  var visParams = {   min: 0,   max: 1e7,   palette: ['d8d9d9', 'aaaaaa', 'b6dfe9', '2ea3f2', '0c71c3'] };  // plotting the water area per polygon dataset = dataset.map(function (f) {   return f.set('AWATER10', ee.Number.parse(f.get('AWATER10'))); });  var image = ee.Image().float().paint(dataset, 'AWATER10');  Map.setCenter(-81.99172, 29.74101, 9); Map.addLayer(ee.Image(1), {min: 0, max: 1}, 'background'); Map.addLayer(image, visParams, 'TIGER/2010/BG'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2010_Blocks:
    def __init__(self,):
        self.sensor = 'TIGER_2010_Blocks'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2010_Blocks.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2010_Blocks.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2010_Blocks(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This dataset contains the 2010 census blocks, roughly equivalent to a city block. There are just over 11 million polygon features covering the United States, the District of Columbia, Puerto Rico, and the [Island areas](https://www.census.gov/data/tables/2010/dec/2010-island-areas.html).  For full technical details on all TIGER 2010 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2010/TGRSHP10SF1.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2010/Blocks'); var visParams = {   min: 0,   max: 700,   palette: ['black', 'brown', 'yellow', 'orange', 'red'] };  // Turn the strings into numbers dataset = dataset.map(function (f) {   return f.set('pop10', ee.Number.parse(f.get('pop10'))); });  var image = ee.Image().float().paint(dataset, 'pop10');  Map.setCenter(-73.99172, 40.74101, 13); Map.addLayer(image, visParams, 'TIGER/2010/Blocks'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2010_Tracts_DP1:
    def __init__(self,):
        self.sensor = 'TIGER_2010_Tracts_DP1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2010_Tracts_DP1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2010_Tracts_DP1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2010_Tracts_DP1(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This table contains the 2010 census Demographic Profile 1 values aggregated by census tract. Tract areas vary tremendously, but in urban areas are roughly equivalent to a neighborhood. There are about 74,000 polygon features covering the United States, the District of Columbia, Puerto Rico, and the [Island areas](https://www.census.gov/data/tables/2010/dec/2010-island-areas.html).  For full technical details on all TIGER 2010 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2010/TGRSHP10SF1.pdf).  Each tract also includes attributes with sums of the DP1 population measurements that intersect the boundary. The columns have the same name as the shortname column in the [DP1 lookup table](https://developers.google.com/earth-engine/tiger_2010_tract_dp1_metadata). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2010/Tracts_DP1'); var visParams = {   min: 0,   max: 4000,   opacity: 0.8, };  // Turn the strings into numbers dataset = dataset.map(function (f) {   return f.set('shape_area', ee.Number.parse(f.get('dp0010001'))); });  Map.setCenter(-103.882, 43.036, 8); var image = ee.Image().float().paint(dataset, 'dp0010001');  Map.addLayer(image, visParams, 'TIGER/2010/Tracts_DP1'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2010_ZCTA5:
    def __init__(self,):
        self.sensor = 'TIGER_2010_ZCTA5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2010_ZCTA5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2010_ZCTA5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2010_ZCTA5(example: str = ''):
        """
        ZIP Code tabulation areas (ZCTAs) are approximate area representations of U.S. Postal Service (USPS) 5-digit ZIP Codes. The Census Bureau defines ZCTAs by allocating each Census block that contains addresses to a single ZIP Code tabulation area, usually to the ZCTA that reflects the most frequently occurring ZIP Code for the addresses within that block. Blocks that do not contain addresses but that are completely surrounded by a single ZIP Code tabulation area (enclaves) are assigned to the surrounding ZCTA; those surrounded by multiple ZCTAs will be added to a single ZCTA based on the longest shared border.  The Census Bureau identifies 5-digit ZIP Code tabulation areas using a 5- character numeric code that represents the most frequently occurring USPS ZIP Code within that ZCTA.  This code may contain leading zeros.  Data users should not use ZCTAs to identify the official USPS ZIP Code for mail delivery. The USPS makes periodic changes to ZIP Codes to support more efficient mail delivery. ZIP Codes that cover primarily nonresidential or post office box addresses may not have a corresponding ZCTA because the delineation process uses primarily residential addresses, resulting in a bias towards ZIP Codes used for city-style mail delivery.  For full technical details on all TIGER 2010 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2010/TGRSHP10SF1.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2010/ZCTA5'); var visParams = {   palette: ['black', 'purple', 'blue', 'green', 'yellow', 'orange', 'red'],   min: 500000,   max: 1000000000, };  var zctaOutlines = ee.Image().float().paint({   featureCollection: dataset,   color: 'black',   width: 1 });  var image = ee.Image().float().paint(dataset, 'ALAND10'); Map.setCenter(-93.8008, 40.7177, 6); Map.addLayer(image, visParams, 'TIGER/2010/ZCTA5'); Map.addLayer(zctaOutlines, {}, 'borders'); Map.addLayer(dataset, {}, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2016_Counties:
    def __init__(self,):
        self.sensor = 'TIGER_2016_Counties'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2016_Counties.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2016_Counties.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2016_Counties(example: str = ''):
        """
        The United States Census Bureau TIGER dataset contains the 2016 boundaries for primary legal divisions of US states.  In most states, these entities are termed "counties". In Louisiana, these divisions are known as "parishes".  Alaska has governmental entities called "boroughs" which fill a similar governmental role to counties, but in some areas those governmental responsibilities are handled directly by the state and sometimes by a city. For Alaska, county equivalent entities thus include  1. organized boroughs, 1. combined city and borough entities (e.g. Juneau), 1. municipalities, and 1. census areas.  The census areas are delineated cooperatively for statistical purposes by the State of Alaska and the Census Bureau.  In four states (Maryland, Missouri, Nevada, and Virginia), there are one or more incorporated places that are independent of any county organization and thus constitute primary divisions of their states. These incorporated places are known as independent cities and are treated as county-equivalent entities for purposes of data presentation.  The District of Columbia and Guam have no primary divisions and each area is considered a county-equivalent entity for purposes of data presentation. The Census Bureau treats the following entities as equivalents of counties for purposes of data presentation: municipios in Puerto Rico, districts and islands in America Samoa, municipalities in the Commonwealth of the Northern Mariana Islands, and islands in the U.S. Virgin Islands.  For full technical details on all TIGER 2016 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2016/TGRSHP2016_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2016/Counties'); var visParams = {   palette: ['purple', 'blue', 'green', 'yellow', 'orange', 'red'],   min: 0,   max: 50,   opacity: 0.8, }; var stateDataset = ee.FeatureCollection('TIGER/2016/States');  // Turn the strings into numbers dataset = dataset.map(function (f) {   return f.set('STATEFP', ee.Number.parse(f.get('STATEFP'))); });  var image = ee.Image().float().paint(dataset, 'STATEFP'); var countyOutlines = ee.Image().float().paint({   featureCollection: dataset,   color: 'black',   width: 1 }); var stateOutlines = ee.Image().float().paint({   featureCollection: stateDataset,   color: 'black',   width: 3 });  Map.setCenter(-99.844, 37.649, 5); Map.addLayer(image, visParams, 'TIGER/2016/Counties'); Map.addLayer(stateOutlines, {}, 'state outlines'); Map.addLayer(countyOutlines, {}, 'county outlines'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2016_Roads:
    def __init__(self,):
        self.sensor = 'TIGER_2016_Roads'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2016_Roads.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2016_Roads.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2016_Roads(example: str = ''):
        """
        This United States Census Bureau TIGER dataset contains all road segments from the 2016 release, containing more than 19 million individual line features covering the United States, the District of Columbia, Puerto Rico, and the [Island Areas](https://www.census.gov/newsroom/releases/archives/2010_census/press-kits/island-areas.html). Each feature represents a road segment geometry (a single navigable linear path connected to at least one intersection).  For full technical details on all TIGER 2016 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2016/TGRSHP2016_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2016/Roads'); var roads = dataset.style({color: '#4285F4', width: 1}); Map.setCenter(-73.99172, 40.74101, 12); Map.addLayer(roads, {}, 'TIGER/2016/Roads'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2016_States:
    def __init__(self,):
        self.sensor = 'TIGER_2016_States'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2016_States.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2016_States.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2016_States(example: str = ''):
        """
        The United States Census Bureau TIGER dataset contains the 2016 boundaries for the primary governmental divisions of the United States. In addition to the fifty states, the Census Bureau treats the District of Columbia, Puerto Rico, and each of the island areas (American Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S. Virgin Islands) as the statistical equivalents of States for the purpose of data presentation. Each feature represents a state or state equivalent.  For full technical details on all TIGER 2016 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2016/TGRSHP2016_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2016/States'); var visParams = {   palette: ['purple', 'blue', 'green', 'yellow', 'orange', 'red'],   min: 500000000,   max: 5e+11,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'ALAND'); Map.setCenter(-99.844, 37.649, 5); Map.addLayer(image, visParams, 'TIGER/2016/States'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2018_Counties:
    def __init__(self,):
        self.sensor = 'TIGER_2018_Counties'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2018_Counties.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2018_Counties.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2018_Counties(example: str = ''):
        """
        The United States Census Bureau TIGER dataset contains the 2018 boundaries for primary legal divisions of US states.  In most states, these entities are termed "counties". In Louisiana, these divisions are known as "parishes".  Alaska has governmental entities called "boroughs" which fill a similar governmental role to counties, but in some areas those governmental responsibilities are handled directly by the state and sometimes by a city. For Alaska, county equivalent entities thus include  1. organized boroughs, 1. combined city and borough entities (e.g. Juneau), 1. municipalities, and 1. census areas.  The census areas are delineated cooperatively for statistical purposes by the State of Alaska and the Census Bureau.  In four states (Maryland, Missouri, Nevada, and Virginia), there are one or more incorporated places that are independent of any county organization and thus constitute primary divisions of their states. These incorporated places are known as independent cities and are treated as county-equivalent entities for purposes of data presentation.  The District of Columbia and Guam have no primary divisions and each area is considered a county-equivalent entity for purposes of data presentation. The Census Bureau treats the following entities as equivalents of counties for purposes of data presentation: municipios in Puerto Rico, districts and islands in America Samoa, municipalities in the Commonwealth of the Northern Mariana Islands, and islands in the U.S. Virgin Islands.  For full technical details on all TIGER 2018 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2018/TGRSHP2018_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2018/Counties'); var visParams = {   palette: ['purple', 'blue', 'green', 'yellow', 'orange', 'red'],   min: 0,   max: 50,   opacity: 0.8, };  // Turn the strings into numbers dataset = dataset.map(function (f) {   return f.set('STATEFP', ee.Number.parse(f.get('STATEFP'))); });  var image = ee.Image().float().paint(dataset, 'STATEFP'); var countyOutlines = ee.Image().float().paint({   featureCollection: dataset,   color: 'black',   width: 1 });  Map.setCenter(-99.844, 37.649, 5); Map.addLayer(image, visParams, 'TIGER/2018/Counties'); Map.addLayer(countyOutlines, {}, 'county outlines'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2018_States:
    def __init__(self,):
        self.sensor = 'TIGER_2018_States'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2018_States.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2018_States.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2018_States(example: str = ''):
        """
        The United States Census Bureau TIGER dataset contains the 2018 boundaries for the primary governmental divisions of the United States. In addition to the fifty states, the Census Bureau treats the District of Columbia, Puerto Rico, and each of the island areas (American Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S. Virgin Islands) as the statistical equivalents of States for the purpose of data presentation. Each feature represents a state or state equivalent.  For full technical details on all TIGER 2018 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2018/TGRSHP2018_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2018/States'); var visParams = {   palette: ['purple', 'blue', 'green', 'yellow', 'orange', 'red'],   min: 500000000.0,   max: 5e+11,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'ALAND'); Map.setCenter(-99.844, 37.649, 5); Map.addLayer(image, visParams, 'TIGER/2018/States'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2020_BG:
    def __init__(self,):
        self.sensor = 'TIGER_2020_BG'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2020_BG.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2020_BG.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2020_BG(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This dataset contains the 2020 census [block groups](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_4), which is a cluster of blocks within the same census tract that have the same first digit of their four-digit census block number. There are just over 240,000 polygon features covering the United States, the District of Columbia, Puerto Rico, and the Island areas.  For full technical details on all TIGER 2020 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2020/TGRSHP2020_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2020/BG');  var visParams = {   min: 0.0,   max: 1e7,   palette: ['d8d9d9', 'aaaaaa', 'b6dfe9', '2ea3f2', '0c71c3'] };  // plotting the water area per polygon dataset = dataset.map(function (f) {   return f.set('AWATER', ee.Number.parse(f.get('AWATER'))); });  var image = ee.Image().float().paint(dataset, 'AWATER');  Map.setCenter(-81.99172, 29.74101, 9); Map.addLayer(ee.Image(1), {min:0, max:1}, 'background'); Map.addLayer(image, visParams, 'TIGER/2020/BG'); Map.addLayer(dataset, null, 'for Inspector', false);
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2020_TABBLOCK20:
    def __init__(self,):
        self.sensor = 'TIGER_2020_TABBLOCK20'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2020_TABBLOCK20.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2020_TABBLOCK20.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2020_TABBLOCK20(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This dataset contains the 2020 census blocks, roughly equivalent to a city block. There are just over eight million polygon features covering the United States, the District of Columbia, Puerto Rico, and the [Island areas](https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/release/2020-island-areas-data-products.html).  For full technical details on all TIGER 2020 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2020/TGRSHP2020_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2020/TABBLOCK20');  var visParams = {   min: 0.0,   max: 1e7,   palette: ['d8d9d9', 'aaaaaa', 'b6dfe9', '2ea3f2', '0c71c3'] };  // plotting the water area per polygon dataset = dataset.map(function (f) {   return f.set('AWATER20', ee.Number.parse(f.get('AWATER20'))); });  var image = ee.Image().float().paint(dataset, 'AWATER20');  Map.setCenter(-73.15, 40.9, 9); Map.addLayer(ee.Image(1), {min:0, max:1}, 'background'); Map.addLayer(image, visParams, 'TIGER/2020/TABBLOCK20'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TIGER_2020_TRACT:
    def __init__(self,):
        self.sensor = 'TIGER_2020_TRACT'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TIGER_2020_TRACT.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TIGER_2020_TRACT.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TIGER_2020_TRACT(example: str = ''):
        """
        The United States Census Bureau regularly releases a geodatabase named TIGER. This dataset contains the 2020 census tracts. Tract areas vary tremendously, but in urban areas are roughly equivalent to a neighborhood. There are just over 85000 polygon features covering the United States, the District of Columbia, Puerto Rico, and the [Island areas](https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/release/2020-island-areas-data-products.html).  For full technical details on all TIGER 2020 products, see the [TIGER technical documentation](https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2020/TGRSHP2020_TechDoc.pdf). 
        :param example: var dataset = ee.FeatureCollection('TIGER/2020/TRACT');  var visParams = {   min: 0.0,   max: 1e7,   palette: ['d8d9d9', 'aaaaaa', 'b6dfe9', '2ea3f2', '0c71c3'] };  // plotting the water area per polygon dataset = dataset.map(function (f) {   return f.set('AWATER', ee.Number.parse(f.get('AWATER'))); });   var image = ee.Image().float().paint(dataset, 'AWATER');  Map.setCenter(-81.99172, 29.74101, 6); Map.addLayer(ee.Image(1), {min:0, max:1}, 'background'); Map.addLayer(image, visParams, 'TIGER/2020/TRACT'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TOMS_MERGED:
    def __init__(self,):
        self.sensor = 'TOMS_MERGED'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TOMS_MERGED.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TOMS_MERGED.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TOMS_MERGED(example: str = ''):
        """
        The Total Ozone Mapping Spectrometer (TOMS) data represent the primary long-term, continuous record of satellite-based observations available for use in monitoring global and regional trends in total ozone over the past 25 years. The data are produced by the Laboratory for Atmospheres at NASA's Goddard Space Flight Center. Version 8 TOMS data products include level 3 gridded data (1.0 x 1.25 deg). The Ozone Monitoring Instrument (OMI), aboard the Aura satellite (July 2004 - current), has a higher resolution (1.0 x 1.0 deg).  These data represent a merged ozone product from TOMS/EarthProbe, TOMS/Nimbus-7, TOMS/Meteor-3, OMI/Aura and USGS-interpolated data for dates with no data.  [Additional TOMS and OMI information](https://ozoneaq.gsfc.nasa.gov/missions/) 
        :param example: var dataset = ee.ImageCollection('TOMS/MERGED')                   .filter(ee.Filter.date('2018-08-01', '2018-08-10')); var columnOzone = dataset.select('ozone'); var columnOzoneVis = {   min: 100,   max: 500,   palette: ['1621a2', 'cyan', 'green', 'yellow', 'orange', 'red'], }; Map.setCenter(6.75, 46.53, 2); Map.addLayer(columnOzone, columnOzoneVis, 'Column Ozone'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TRMM_3B42:
    def __init__(self,):
        self.sensor = 'TRMM_3B42'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TRMM_3B42.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TRMM_3B42.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TRMM_3B42(example: str = ''):
        """
        The Tropical Rainfall Measuring Mission (TRMM) is a joint mission between NASA and the Japan Aerospace Exploration Agency (JAXA) designed to monitor and study tropical rainfall. The 34B2 product contains a gridded, TRMM-adjusted, merged infrared precipitation (mm/hr) and RMS precipitation-error estimate, with a 3-hour temporal resolution and a 0.25 degree spatial resolution.  See the [algorithm description](https://trmm.gsfc.nasa.gov/3b42.html) and the [file specification](https://storm.pps.eosdis.nasa.gov/storm/data/docs/filespec.TRMM.V7.3B42.pdf) for details.  Documentation:  * [PI Documentation](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/3B42_3B43_doc_V7.pdf)  * [File Specification for TRMM Products](https://pps.gsfc.nasa.gov/Documents/filespec.TRMM.V7.pdf)  * [Comparison between TRMM versions 6 and 7](https://pps.gsfc.nasa.gov/Documents/formatChangesV7.pdf)  * [Readme](https://disc2.gesdisc.eosdis.nasa.gov/data/TRMM_L3/TRMM_3B42/doc/README.TRMM_V7.pdf)  * [Details of the TMPA algorithm used in this product](https://pmm.nasa.gov/sites/default/files/imce/3B42_3B43_TMPA_restart.pdf)  * [TRMM Data Gaps](https://web.archive.org/web/20200701000000*/ftp://gpmweb2.pps.eosdis.nasa.gov/tsdis/AB/docs/anomalous.html)  * [Transition from TMPA to IMERG](https://docserver.gesdisc.eosdis.nasa.gov/public/project/GPM/TMPA-to-IMERG_transition.pdf) 
        :param example: var dataset = ee.ImageCollection('TRMM/3B42')                   .filter(ee.Filter.date('2018-04-01', '2018-04-10')); var precipitation =     dataset.select(['precipitation', 'HQprecipitation', 'IRprecipitation']); var precipitationVis = {   min: 0,   max: 12,   gamma: 5, }; Map.setCenter(-79.98, 23.32, 4); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TRMM_3B43V7:
    def __init__(self,):
        self.sensor = 'TRMM_3B43V7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TRMM_3B43V7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TRMM_3B43V7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TRMM_3B43V7(example: str = ''):
        """
        **This collection is no longer being updated. See [IMERG monthly](https://developers.google.com/earth-engine/datasets/catalog/NASA_GPM_L3_IMERG_MONTHLY_V06)**  This dataset algorithmically merges microwave data from multiple satellites, including SSMI, SSMIS, MHS, AMSU-B and AMSR-E, each inter-calibrated to the TRMM Combined Instrument.  Algorithm 3B43 is executed once per calendar month to produce the single, best-estimate precipitation rate and RMS precipitation-error estimate field (3B43) by combining the 3-hourly merged high-quality/IR estimates (3B42) with the monthly accumulated Global Precipitation Climatology Centre (GPCC) rain gauge analysis.  All of the global precipitation datasets have some calibrating data source, which is necessary to control bias differences between contributing satellites.  The multi-satellite data are averaged to the monthly scale and combined with the Global Precipitation Climatology Centre's (GPCC) monthly surface precipitation gauge analysis. In each case the multi-satellite data are adjusted to the large-area mean of the gauge analysis, where available (mostly over land), and then combined with the gauge analysis using a simple inverse estimated-random-error variance weighting.  Regions with poor gauge coverage, like central Africa and the oceans, have a higher weighting on the satellite input.  See the [algorithm description](https://trmm.gsfc.nasa.gov/3b43.html) and the [file specification](https://pps.gsfc.nasa.gov/Documents/filespec.TRMM.V7.pdf) for details. 
        :param example: var dataset = ee.ImageCollection('TRMM/3B43V7')                   .filter(ee.Filter.date('2018-04-01', '2018-05-01')); var precipitation = dataset.select('precipitation'); var precipitationVis = {   min: 0.1,   max: 1.2,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(6.746, 46.529, 3); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Tsinghua_DESS_ChinaTerraceMap_v1:
    def __init__(self,):
        self.sensor = 'Tsinghua_DESS_ChinaTerraceMap_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Tsinghua_DESS_ChinaTerraceMap_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Tsinghua_DESS_ChinaTerraceMap_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Tsinghua_DESS_ChinaTerraceMap_v1(example: str = ''):
        """
        This dataset is a China terrace map at 30 m resolution in 2018. It was developed through supervised pixel-based classification using multisource and multi-temporal data based on the Google Earth Engine platform. The overall accuracy and kappa coefficient achieved 94% and 0.72, respectively. This first 30 m China terrace map can be used for studies on soil erosion, food security, biogeochemical cycle, biodiversity, and ecosystem service assessments. 
        :param example: var image = ee.Image('Tsinghua/DESS/ChinaTerraceMap/v1');  var image = image.updateMask(image); Map.addLayer(image, {min: 0, max: 1, palette: ['a3ff74']}, 'Terraces');  Map.setCenter(106.6, 30.4, 10); Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class Tsinghua_FROM_GLC_GAIA_v10:
    def __init__(self,):
        self.sensor = 'Tsinghua_FROM_GLC_GAIA_v10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/Tsinghua_FROM-GLC_GAIA_v10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/Tsinghua_FROM-GLC_GAIA_v10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_Tsinghua_FROM_GLC_GAIA_v10(example: str = ''):
        """
        This dataset contains annual change information of global impervious surface area from 1985 to 2018 at a 30m resolution. Change from pervious to impervious was determined using a combined approach of supervised classification and temporal consistency checking. Impervious pixels are defined as above 50% impervious. The year of the transition (from pervious to impervious) can be identified from the pixel value, ranging from 34 (year: 1985) to 1 (year: 2018). For example, the impervious surface in 1990 can be revealed as the pixel value greater than 29 (see the lookup table). This dataset is temporally consistent, following the conversion from pervious (e.g., non-urban) to impervious (e.g., urban) monotonically. For more information about the mapping approach and assessment, see [Annual maps of global artificial impervious area (GAIA) between 1985 and 2018 (Gong et al. 2020)](https://doi.org/10.1016/j.rse.2019.111510). 
        :param example: var dataset = ee.Image('Tsinghua/FROM-GLC/GAIA/v10');  var visualization = {   bands: ['change_year_index'],   min: 0,   max: 34,   palette: [     '014352', '1a492c', '071ec4', 'b5ca36', '729eac', '8ea5de',     '818991', '62a3c3', 'ccf4fe', '74f0b9', '32bc55', 'c72144',     '56613b', 'c14683', 'c31c25', '5f6253', '11bf85', 'a61b26',     '99fbc5', '188aaa', 'c2d7f1', 'b7d9d8', '856f96', '109c6b',     '2de3f4', '9a777d', '151796', 'c033d8', '510037', '640c21',     '31a191', '223ab0', 'b692ac', '2de3f4',   ] };  Map.setCenter(-37.62, 25.8, 2);  Map.addLayer(dataset, visualization, 'Change year index'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class TUBerlin_BigEarthNet_v1:
    def __init__(self,):
        self.sensor = 'TUBerlin_BigEarthNet_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/TUBerlin_BigEarthNet_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/TUBerlin_BigEarthNet_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_TUBerlin_BigEarthNet_v1(example: str = ''):
        """
        BigEarthNet is a new large-scale Sentinel-2 benchmark archive, consisting of 590,326 Sentinel-2 image patches.  To construct BigEarthNet, 125 Sentinel-2 tiles were acquired between June 2017 and May 2018 over the 10 countries (Austria, Belgium, Finland, Ireland, Kosovo, Lithuania, Luxembourg, Portugal, Serbia, Switzerland) of Europe. All the tiles were atmospherically corrected by the Sentinel-2 Level 2A product generation and formatting tool (sen2cor).  Then, they were divided into 590,326 non-overlapping image patches. Each image patch was annotated by the multiple land-cover classes (i.e., multi-labels) that were provided from the CORINE Land Cover database of the year 2018 (CLC 2018). 
        :param example: var geometry = ee.Geometry.Polygon(     [[       [16.656886757418057, 48.27086673747943],       [16.656886757418057, 48.21359065567954],       [16.733276070162198, 48.21359065567954],       [16.733276070162198, 48.27086673747943]]]);  var ic = ee.ImageCollection('TUBerlin/BigEarthNet/v1');  var filtered = ic.filterBounds(geometry);  var tiles = filtered.map(function(image) {   var labels = ee.List(image.get('labels'));    var urban = labels.indexOf('Discontinuous urban fabric').gte(0);   var highlight_urban = ee.Image(urban).toInt().multiply(1000);    return image.addBands(       {srcImg: image.select(['B4']).add(highlight_urban), overwrite: true}); });  var image = tiles.mosaic().clip(geometry);  var visParams = {bands: ['B4', 'B3', 'B2'], min: 0, max: 3000};  Map.addLayer(image, visParams); Map.centerObject(image, 13); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UCSB_CHG_CHIRPS_DAILY:
    def __init__(self,):
        self.sensor = 'UCSB_CHG_CHIRPS_DAILY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UCSB-CHG_CHIRPS_DAILY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UCSB-CHG_CHIRPS_DAILY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UCSB_CHG_CHIRPS_DAILY(example: str = ''):
        """
        Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS) is a 30+ year quasi-global rainfall dataset. CHIRPS incorporates 0.05° resolution satellite imagery with in-situ station data to create gridded rainfall time series for trend analysis and seasonal drought monitoring. 
        :param example: var dataset = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')                   .filter(ee.Filter.date('2018-05-01', '2018-05-03')); var precipitation = dataset.select('precipitation'); var precipitationVis = {   min: 1,   max: 17,   palette: ['001137', '0aab1e', 'e7eb05', 'ff4a2d', 'e90000'], }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UCSB_CHG_CHIRPS_PENTAD:
    def __init__(self,):
        self.sensor = 'UCSB_CHG_CHIRPS_PENTAD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UCSB-CHG_CHIRPS_PENTAD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UCSB-CHG_CHIRPS_PENTAD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UCSB_CHG_CHIRPS_PENTAD(example: str = ''):
        """
        Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS) is a 30+ year quasi-global rainfall dataset. CHIRPS incorporates 0.05° resolution satellite imagery with in-situ station data to create gridded rainfall time series for trend analysis and seasonal drought monitoring. 
        :param example: var dataset = ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')                   .filter(ee.Filter.date('2018-05-01', '2018-05-05')); var precipitation = dataset.select('precipitation'); var precipitationVis = {   min: 0,   max: 112,   palette: ['001137', '0aab1e', 'e7eb05', 'ff4a2d', 'e90000'], }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(precipitation, precipitationVis, 'Precipitation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UK_EA_ENGLAND_1M_TERRAIN_2022:
    def __init__(self,):
        self.sensor = 'UK_EA_ENGLAND_1M_TERRAIN_2022'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UK_EA_ENGLAND_1M_TERRAIN_2022.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UK_EA_ENGLAND_1M_TERRAIN_2022.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UK_EA_ENGLAND_1M_TERRAIN_2022(example: str = ''):
        """
        The LIDAR Composite DTM/DSM is a raster terrain model covering ~99% of England at 1m spatial resolution, produced by the UK Environment Agency in 2022. The model contains 3 bands of terrain data: a Digital Terrain Model (DTM), a first return Digital Surface Model (DSM), and a last return DSM.  The DTM is produced from the last or only laser pulse returned to the sensor. Surface objects are removed from the DSM, using bespoke algorithms and manual editing of the data, to produce a terrain model of just the surface. The DTM is derived from a combination of EA Time Stamped archive and National LIDAR Program surveys, which have been merged and re-sampled to give the best possible coverage. Where repeat surveys have been undertaken the newest, best resolution data is used. Where data was resampled a bilinear interpolation was used before being merged. The 2022 LIDAR Composite contains surveys undertaken between 6th June 2000 and 2nd April 2022.  The first return DSM is produced from the first or only laser pulse returned to the sensor and includes heights of objects, such as vehicles, buildings and vegetation, as well as the terrain surface where the first or only return was the ground. The first return DSM is derived from data captured as part of the National LIDAR Program between 11 November 2016 and 5th May 2022. This program divided England into ~300 blocks for survey over continuous winters from 2016 onwards. These surveys are merged together to create the first return LIDAR composite using a feathering technique along the overlaps to remove any small differences in elevation between surveys. Please refer to the data provider's metadata index catalogs which show for any location which survey was used in the production of the LIDAR composite. The first return DSM will not match in coverage or extent of the last return DSM, as the last return DSM composite is produced from both the National LIDAR Program and Timeseries surveys.  The last return DSM is produced from the last or only laser pulse returned to the sensor and includes heights of objects, such as vehicles, buildings and vegetation, as well as the terrain surface. The last return DTM is derived from a combination of EA Time Stamped archive and National LIDAR Program surveys, which have been merged and re-sampled to give the best possible coverage. Where repeat surveys have been undertaken the newest, best resolution data is used. Where data was resampled a bilinear interpolation was used before being merged. The 2022 LIDAR Composite contains surveys undertaken between 6th June 2000 and 2nd April 2022. Please refer to the data provider's metadata index catalogs which show for any location which survey was used in the production of the LIDAR composite.  The data is aligned to the OS National grid and presented in metres, referenced to Ordinance Survey Newlyn and using the OSTN'15 transformation method. All individual LIDAR surveys going into the production of the composites had a vertical accuracy of +/-15cm root-mean-square error. 
        :param example: var img = ee.Image('UK/EA/ENGLAND_1M_TERRAIN/2022').select('dtm'); var visParam = {   palette: ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff'],   max: 630,   min: -5, };  var lon = -2.5; var lat = 54;  Map.addLayer(img, visParam, 'dtm'); Map.setCenter(lon, lat, 5);
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_GLAD_PRIMARY_HUMID_TROPICAL_FORESTS_v1:
    def __init__(self,):
        self.sensor = 'UMD_GLAD_PRIMARY_HUMID_TROPICAL_FORESTS_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_GLAD_PRIMARY_HUMID_TROPICAL_FORESTS_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_GLAD_PRIMARY_HUMID_TROPICAL_FORESTS_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_GLAD_PRIMARY_HUMID_TROPICAL_FORESTS_v1(example: str = ''):
        """
        Primary humid tropical forests provide numerous global ecosystem services, but are under continuing threat of clearing from economic drivers. To facilitate national land use planning and balancing the goals of economic development and maintenance of ecosystem services, a primary humid tropical forest map was created by the UMD GLAD team. The primary forest extent was mapped for the year 2001 at a spatial resolution of 30 meters using globally acquired, free-of-charge, and consistently processed Landsat imagery. 
        :param example: var dataset = ee.ImageCollection(     'UMD/GLAD/PRIMARY_HUMID_TROPICAL_FORESTS/v1').mosaic().selfMask();  var visualization = {   bands: ['Primary_HT_forests'],   min: 1.0,   max: 1.0,   palette: ['008000'] };  Map.setCenter(0.0, 0.0, 2);  Map.addLayer(dataset, visualization, 'Primary HT forests'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2013:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2013'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2013.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2013.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2013(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.0.html) for this Version 1.0, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2013');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2014:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2014'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2014.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2014.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2014(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.1.html) for this Version 1.1 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2014');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2015:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2015'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2015.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2015.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2015(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.2.html) for this Version 1.2 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2015');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2015_v1_3:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2015_v1_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2015_v1_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2015_v1_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2015_v1_3(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.3.html) for this Version 1.3 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2015_v1_3');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2016_v1_4:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2016_v1_4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2016_v1_4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2016_v1_4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2016_v1_4(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.4.html) for this Version 1.4 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2016_v1_4');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2017_v1_5:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2017_v1_5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2017_v1_5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2017_v1_5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2017_v1_5(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.5.html) for this Version 1.5 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2017_v1_5'); var treeCanopyCover = dataset.select('treecover2000'); var treeCanopyCoverVis = {   min: 0.0,   max: 100.0,   palette:       ['3d3d3d', '080a02', '080a02', '080a02', '106e12', '37a930', '03ff17'], }; Map.setCenter(-60.5, -20.0, 2); Map.addLayer(treeCanopyCover, treeCanopyCoverVis, 'Tree Canopy Cover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2018_v1_6:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2018_v1_6'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2018_v1_6.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2018_v1_6.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2018_v1_6(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.6.html) for this Version 1.6 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2018_v1_6');  var visualization = {   bands: ['treecover2000'],   min: 0.0,   max: 100.0,   palette: [     '3d3d3d','080a02','080a02','080a02','106e12','37a930',     '03ff17',   ] };  Map.setCenter(-60.5, -20.0, 2);  Map.addLayer(dataset, visualization, 'Tree Canopy Cover');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2019_v1_7:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2019_v1_7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2019_v1_7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2019_v1_7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2019_v1_7(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.7.html) for this Version 1.7 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2019_v1_7'); var treeCoverVisParam = {   bands: ['treecover2000'],   min: 0,   max: 100,   palette: ['black', 'green'] }; Map.addLayer(dataset, treeCoverVisParam, 'tree cover');  var treeLossVisParam = {   bands: ['lossyear'],   min: 0,   max: 19,   palette: ['yellow', 'red'] }; Map.addLayer(dataset, treeLossVisParam, 'tree loss year'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2020_v1_8:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2020_v1_8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2020_v1_8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2020_v1_8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2020_v1_8(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://storage.googleapis.com/earthenginepartners-hansen/GFC-2020-v1.8/download.html) for this Version 1.8 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.9 (produced with data through 2021), is available as UMD/hansen/global_forest_change_2021_v1_9. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2020_v1_8'); var treeCoverVisParam = {   bands: ['treecover2000'],   min: 0,   max: 100,   palette: ['black', 'green'] }; Map.addLayer(dataset, treeCoverVisParam, 'tree cover');  var treeLossVisParam = {   bands: ['lossyear'],   min: 0,   max: 20,   palette: ['yellow', 'red'] }; Map.addLayer(dataset, treeLossVisParam, 'tree loss year'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2021_v1_9:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2021_v1_9'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2021_v1_9.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2021_v1_9.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2021_v1_9(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands 3, 4, 5, and 7. Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://storage.googleapis.com/earthenginepartners-hansen/GFC-2021-v1.9/download.html) for this Version 1.9 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853.  Note that updated versions of this data are available. The newest version, Version 1.10 (produced with data through 2022), is available as UMD/hansen/global_forest_change_2022_v1_10. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2021_v1_9'); var treeCoverVisParam = {   bands: ['treecover2000'],   min: 0,   max: 100,   palette: ['black', 'green'] }; Map.addLayer(dataset, treeCoverVisParam, 'tree cover');  var treeLossVisParam = {   bands: ['lossyear'],   min: 0,   max: 21,   palette: ['yellow', 'red'] }; Map.addLayer(dataset, treeLossVisParam, 'tree loss year'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMD_hansen_global_forest_change_2022_v1_10:
    def __init__(self,):
        self.sensor = 'UMD_hansen_global_forest_change_2022_v1_10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMD_hansen_global_forest_change_2022_v1_10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMD_hansen_global_forest_change_2022_v1_10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMD_hansen_global_forest_change_2022_v1_10(example: str = ''):
        """
        Results from time-series analysis of Landsat images in characterizing global forest extent and change.  The 'first' and 'last' bands are reference multispectral imagery from the first and last available years for Landsat spectral bands corresponding to red, NIR, SWIR1, and SWIR2.  Reference composite imagery represents median observations from a set of quality-assessed growing-season observations for each of these bands.  Please see the [User Notes](https://storage.googleapis.com/earthenginepartners-hansen/GFC-2022-v1.10/download.html) for this Version 1.10 update, as well as the associated journal article: Hansen, Potapov, Moore, Hancher et al. "High-resolution global maps of 21st-century forest cover change." Science 342.6160 (2013): 850-853. 
        :param example: var dataset = ee.Image('UMD/hansen/global_forest_change_2022_v1_10'); var treeCoverVisParam = {   bands: ['treecover2000'],   min: 0,   max: 100,   palette: ['black', 'green'] }; Map.addLayer(dataset, treeCoverVisParam, 'tree cover');  var treeLossVisParam = {   bands: ['lossyear'],   min: 0,   max: 22,   palette: ['yellow', 'red'] }; Map.addLayer(dataset, treeLossVisParam, 'tree loss year'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_ArcticDEM_V2_2m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_ArcticDEM_V2_2m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_ArcticDEM_V2_2m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_ArcticDEM_V2_2m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_ArcticDEM_V2_2m(example: str = ''):
        """
        ArcticDEM is a digital surface model (DSM) that portrays first-return elevation values that include vegetation, tree canopy, buildings, and other man-made surface features. The 2m asset is a collection of strips rather than a single mosaic due to projection differences between strips.  Strip DEM files correspond to the overlapping area of the input stereopair image swaths as they are collected by DigitalGlobe's constellation of polar-orbiting satellites. Strip DEM dimensions will vary according to the satellite sensor that acquired the images and the off-nadir angle of collection. Most strips are between 16km and 18km in width, and 110km and 120km in length. 
        :param example: var dataset = ee.ImageCollection('UMN/PGC/ArcticDEM/V2/2m'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], }; Map.setCenter(-63.402, 66.368, 7); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_ArcticDEM_V2_5m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_ArcticDEM_V2_5m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_ArcticDEM_V2_5m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_ArcticDEM_V2_5m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_ArcticDEM_V2_5m(example: str = ''):
        """
        ArcticDEM is a digital surface model (DSM) that portrays first-return elevation values that include vegetation, tree canopy, buildings, and other man-made surface features. The 2m asset is a collection of strips rather than a single mosaic due to projection differences between strips.  Mosaicked DEM files are compiled from the best quality strip DEM files which have been blended and feathered to reduce void areas and edge-matching artifacts. Filtered IceSAT altimetry data has been applied to the raster files to improve absolute accuracy. 
        :param example: var dataset = ee.Image('UMN/PGC/ArcticDEM/V2/5m'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], }; Map.setCenter(-63.402, 66.368, 7); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_ArcticDEM_V3_2m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_ArcticDEM_V3_2m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_ArcticDEM_V3_2m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_ArcticDEM_V3_2m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_ArcticDEM_V3_2m(example: str = ''):
        """
        ArcticDEM is a National Geospatial-Intelligence Agency (NGA) and National Science Foundation (NSF) public-private initiative to automatically produce a high-resolution, high-quality digital surface model (DSM) of the Arctic using optical stereo imagery, high-performance computing, and open source photogrammetry software. It includes vegetation, tree canopy, buildings, and other man-made surface features. The 2m asset is a collection of strips rather than a single mosaic due to projection differences between strips.  Strip DEM files correspond to the overlapping area of the input stereopair image swaths as they are collected by DigitalGlobe's constellation of polar-orbiting satellites. Strip DEM dimensions will vary according to the satellite sensor that acquired the images and the off-nadir angle of collection. Most strips are between 16km and 18km in width, and 110km and 120km in length. 
        :param example: var dataset = ee.ImageCollection('UMN/PGC/ArcticDEM/V3/2m'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], }; Map.setCenter(-63.402, 66.368, 7); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_ArcticDEM_V3_2m_mosaic:
    def __init__(self,):
        self.sensor = 'UMN_PGC_ArcticDEM_V3_2m_mosaic'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_ArcticDEM_V3_2m_mosaic.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_ArcticDEM_V3_2m_mosaic.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_ArcticDEM_V3_2m_mosaic(example: str = ''):
        """
        ArcticDEM is a National Geospatial-Intelligence Agency (NGA) and National Science Foundation (NSF) public-private initiative to automatically produce a high-resolution, high-quality digital surface model (DSM) of the Arctic using optical stereo imagery, high-performance computing, and open source photogrammetry software. It includes vegetation, tree canopy, buildings, and other man-made surface features. The 2m asset is a collection of strips rather than a single mosaic due to projection differences between strips.  Mosaicked DEM files are compiled from the best quality strip DEM files which have been blended and feathered to reduce void areas and edge-matching artifacts. Filtered IceSAT altimetry data has been applied to the raster files to improve absolute accuracy. 
        :param example: var dataset = ee.Image('UMN/PGC/ArcticDEM/V3/2m_mosaic'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], }; Map.setCenter(-63.402, 66.368, 7); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_REMA_V1_1_8m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_REMA_V1_1_8m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_REMA_V1_1_8m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_REMA_V1_1_8m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_REMA_V1_1_8m(example: str = ''):
        """
        The Reference Elevation Model of Antarctica (REMA) is a high resolution, time-stamped Digital Surface Model (DSM) of Antarctica at 2-meter and 8-meter spatial resolutions.  Mosaicked DEM files are compiled from multiple strips that have been co-registered, blended, and feathered to reduce edge-matching artifacts. 
        :param example: var mosaic = ee.Image('UMN/PGC/REMA/V1_1/8m');  Map.setCenter(-61, -75, 3);  var elevationVis = {   bands: ['elevation'],   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], };  Map.addLayer(mosaic, elevationVis, 'REMA_DEM_mosaic_8m'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_REMA_V1_2m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_REMA_V1_2m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_REMA_V1_2m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_REMA_V1_2m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_REMA_V1_2m(example: str = ''):
        """
        The Reference Elevation Model of Antarctica (REMA) is a high resolution, time-stamped Digital Surface Model (DSM) of Antarctica at 2-meter and 8-meter spatial resolutions.  Strip DEM files correspond to the overlapping area of the input stereoscopic imagery pair strips as they are collected by DigitalGlobe's constellation of polar-orbiting satellites. Strip DEM dimensions will vary according to the satellite sensor that acquired the images and the off-nadir angle of collection. Most strips are between 13 km and 17 km in width, and 110 km and 120 km in length. 
        :param example: var collection = ee.ImageCollection('UMN/PGC/REMA/V1/2m');  Map.setCenter(-60, -75, 3);  var elevationVis = {   bands: ['elevation'],   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], };  Map.addLayer(collection, elevationVis, 'REMA_DEM_strips_2m'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMN_PGC_REMA_V1_8m:
    def __init__(self,):
        self.sensor = 'UMN_PGC_REMA_V1_8m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMN_PGC_REMA_V1_8m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMN_PGC_REMA_V1_8m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMN_PGC_REMA_V1_8m(example: str = ''):
        """
        The Reference Elevation Model of Antarctica (REMA) is a high resolution, time-stamped Digital Surface Model (DSM) of Antarctica at 2-meter and 8-meter spatial resolutions.  Strip DEM files correspond to the overlapping area of the input stereoscopic imagery pair strips as they are collected by DigitalGlobe's constellation of polar-orbiting satellites. Strip DEM dimensions will vary according to the satellite sensor that acquired the images and the off-nadir angle of collection. Most strips are between 13 km and 17 km in width, and 110 km and 120 km in length. 
        :param example: var collection = ee.ImageCollection('UMN/PGC/REMA/V1/8m');  Map.setCenter(-63.16, -75, 3);  var elevationVis = {   bands: ['elevation'],   min: -50.0,   max: 1000.0,   palette: ['0d13d8', '60e1ff', 'ffffff'], };  Map.addLayer(collection, elevationVis, 'REMA_DEM_strips_8m'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_Climate_IrrMapper_RF_v1_0:
    def __init__(self,):
        self.sensor = 'UMT_Climate_IrrMapper_RF_v1_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_Climate_IrrMapper_RF_v1_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_Climate_IrrMapper_RF_v1_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_Climate_IrrMapper_RF_v1_0(example: str = ''):
        """
        IrrMapper is an annual classification of irrigation status in the 11 Western United States made at Landsat scale (i.e., 30 m) using the Random Forest algorithm, covering years 1986 - present. While the [IrrMapper paper](https://www.mdpi.com/2072-4292/12/14/2328) describes classification of four classes (i.e., irrigated, dryland, uncultivated, wetland), the dataset is converted to a binary classification of irrigated and non-irrigated. 'Irrigated' refers to the detection of any irrigation during the year. The IrrMapper random forest model was trained using an extensive geospatial database of land cover from each of four irrigated- and non-irrigated classes, including over 50,000 human-verified irrigated fields, 38,000 dryland fields, and over 500,000 square kilometers of uncultivated lands. 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_Climate_IrrMapper_RF_v1_1:
    def __init__(self,):
        self.sensor = 'UMT_Climate_IrrMapper_RF_v1_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_Climate_IrrMapper_RF_v1_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_Climate_IrrMapper_RF_v1_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_Climate_IrrMapper_RF_v1_1(example: str = ''):
        """
        IrrMapper is an annual classification of irrigation status in the 11 Western United States made at Landsat scale (i.e., 30 m) using the Random Forest algorithm, covering years 1986 - present.  While the [IrrMapper paper](https://www.mdpi.com/2072-4292/12/14/2328) describes classification of four classes (i.e., irrigated, dryland, uncultivated, wetland), the dataset is converted to a binary classification of irrigated and non-irrigated.  'Irrigated' refers to the detection of any irrigation during the year. The IrrMapper random forest model was trained using an extensive geospatial database of land cover from each of four irrigated- and non-irrigated classes, including over 50,000 human-verified irrigated fields, 38,000 dryland fields, and over 500,000 square kilometers of uncultivated lands.  For version 1.1, the original training data was re-run on Landsat Collection 2 and brought up-to-date. 
        :param example: var dataset = ee.ImageCollection('UMT/Climate/IrrMapper_RF/v1_1'); var irr = dataset.filterDate('2018-01-01', '2018-12-31').mosaic(); var irr = irr.mask(irr.eq(1));  var visualization = {   min: 0.0,   max: 1.0,   palette: ['blue'] }; Map.addLayer(irr, visualization, 'IrrMapper 2018'); Map.setCenter(-112.516, 45.262, 10); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_Climate_IrrMapper_RF_v1_2:
    def __init__(self,):
        self.sensor = 'UMT_Climate_IrrMapper_RF_v1_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_Climate_IrrMapper_RF_v1_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_Climate_IrrMapper_RF_v1_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_Climate_IrrMapper_RF_v1_2(example: str = ''):
        """
        IrrMapper is an annual classification of irrigation status in the 11 Western United States made at Landsat scale (i.e., 30 m) using the Random Forest algorithm, covering years 1986 - present.  While the [IrrMapper paper](https://www.mdpi.com/2072-4292/12/14/2328) describes classification of four classes (i.e., irrigated, dryland, uncultivated, wetland), the dataset is converted to a binary classification of irrigated and non-irrigated.  'Irrigated' refers to the detection of any irrigation during the year. The IrrMapper random forest model was trained using an extensive geospatial database of land cover from each of four irrigated- and non-irrigated classes, including over 50,000 human-verified irrigated fields, 38,000 dryland fields, and over 500,000 square kilometers of uncultivated lands.  For version 1.2, the original training data was greatly expanded, a RF model built for each state, and a more thorough validation and uncertainty analysis undertaken. See the [supplement](https://static-content.springer.com/esm/art%3A10.1038%2Fs43247-023-01152-2/MediaObjects/43247_2023_1152_MOESM3_ESM.docx) to our [paper](https://www.nature.com/articles/s43247-023-01152-2) on the impacts of irrigation on streamflow.  
        :param example: var dataset = ee.ImageCollection('UMT/Climate/IrrMapper_RF/v1_2'); var irr = dataset.filterDate('2023-01-01', '2023-12-31').mosaic();  var visualization = {   min: 0.0,   max: 1.0,   palette: ['blue'] }; Map.addLayer(irr, visualization, 'IrrMapper 2023'); Map.setCenter(-112.516, 45.262, 10); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_NTSG_v2_LANDSAT_GPP:
    def __init__(self,):
        self.sensor = 'UMT_NTSG_v2_LANDSAT_GPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_NTSG_v2_LANDSAT_GPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_NTSG_v2_LANDSAT_GPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_NTSG_v2_LANDSAT_GPP(example: str = ''):
        """
        The Landsat Gross Primary Production (GPP) CONUS dataset estimates GPP using Landsat Surface Reflectance for CONUS. GPP is the amount of carbon captured by plants in an ecosystem and is an essential component in the calculations of Net Primary Production (NPP). GPP is calculated using the MOD17 algorithm (see [MOD17 User Guide](https://www.ntsg.umt.edu/files/modis/MOD17UsersGuide2015_v3.pdf)) with Landsat Surface Reflectance, gridMET, and the National Land Cover Database. 
        :param example: var dataset = ee.ImageCollection('UMT/NTSG/v2/LANDSAT/GPP')                   .filter(ee.Filter.date('2017-05-01', '2017-05-31')); var gpp = dataset.select('GPP'); var gppVis = {   min: 0.0,   max: 1000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(-98.26, 39.32, 5); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_NTSG_v2_LANDSAT_NPP:
    def __init__(self,):
        self.sensor = 'UMT_NTSG_v2_LANDSAT_NPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_NTSG_v2_LANDSAT_NPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_NTSG_v2_LANDSAT_NPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_NTSG_v2_LANDSAT_NPP(example: str = ''):
        """
        The Landsat Net Primary Production (NPP) CONUS dataset estimates NPP using Landsat Surface Reflectance for CONUS. NPP is the amount of carbon captured by plants in an ecosystem, after accounting for losses due to respiration. NPP is calculated using the MOD17 algorithm (see [MOD17 User Guide](https://www.ntsg.umt.edu/files/modis/MOD17UsersGuide2015_v3.pdf)) with Landsat Surface Reflectance, gridMET, and the National Land Cover Database. 
        :param example: var dataset = ee.ImageCollection('UMT/NTSG/v2/LANDSAT/NPP')                   .filter(ee.Filter.date('2016-01-01', '2016-12-31')); var npp = dataset.select('annualNPP'); var nppVis = {   min: 0.0,   max: 20000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(-98.26, 39.32, 5); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_NTSG_v2_MODIS_GPP:
    def __init__(self,):
        self.sensor = 'UMT_NTSG_v2_MODIS_GPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_NTSG_v2_MODIS_GPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_NTSG_v2_MODIS_GPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_NTSG_v2_MODIS_GPP(example: str = ''):
        """
        The MODIS Gross Primary Production (GPP) CONUS dataset estimates GPP using MODIS Surface Reflectance for CONUS. GPP is the amount of carbon captured by plants in an ecosystem and is an essential component in the calculations of Net Primary Production (NPP). GPP is calculated using the MOD17 algorithm (see [MOD17 User Guide](https://www.ntsg.umt.edu/files/modis/MOD17UsersGuide2015_v3.pdf)) with MODIS Surface Reflectance, gridMET, and the National Land Cover Database. 
        :param example: var dataset = ee.ImageCollection('UMT/NTSG/v2/MODIS/GPP')                   .filter(ee.Filter.date('2017-05-01', '2017-05-31')); var gpp = dataset.select('GPP'); var gppVis = {   min: 0.0,   max: 1000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(-98.26, 39.32, 5); Map.addLayer(gpp, gppVis, 'GPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UMT_NTSG_v2_MODIS_NPP:
    def __init__(self,):
        self.sensor = 'UMT_NTSG_v2_MODIS_NPP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UMT_NTSG_v2_MODIS_NPP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UMT_NTSG_v2_MODIS_NPP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UMT_NTSG_v2_MODIS_NPP(example: str = ''):
        """
        The MODIS Net Primary Production (NPP) CONUS dataset estimates NPP using MODIS Surface Reflectance for CONUS. NPP is the amount of carbon captured by plants in an ecosystem, after accounting for losses due to respiration. NPP is calculated using the MOD17 algorithm (see [MOD17 User Guide](https://www.ntsg.umt.edu/files/modis/MOD17UsersGuide2015_v3.pdf)) with MODIS Surface Reflectance, gridMET, and the National Land Cover Database. 
        :param example: var dataset = ee.ImageCollection('UMT/NTSG/v2/MODIS/NPP')                   .filter(ee.Filter.date('2016-01-01', '2016-12-31')); var npp = dataset.select('annualNPP'); var nppVis = {   min: 0.0,   max: 20000.0,   palette: ['bbe029', '0a9501', '074b03'], }; Map.setCenter(-98.26, 39.32, 5); Map.addLayer(npp, nppVis, 'NPP'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UQ_murray_Intertidal_v1_1_data_mask:
    def __init__(self,):
        self.sensor = 'UQ_murray_Intertidal_v1_1_data_mask'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UQ_murray_Intertidal_v1_1_data_mask.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UQ_murray_Intertidal_v1_1_data_mask.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UQ_murray_Intertidal_v1_1_data_mask(example: str = ''):
        """
        The Murray Global Intertidal Change Dataset contains global maps of tidal flat ecosystems produced via a supervised classification of 707,528 Landsat Archive images. Each pixel was classified into tidal flat, permanent water or other with reference to a globally distributed set of training data.  The classification was implemented along the entire global coastline between 60° North and 60° South from 1 January 1984 to 31 December 2016. The image collection consists consists of a time-series of 11 global maps of tidal flats at 30m pixel resolution for set time-periods (1984-1986; 1987-1989; 1990-1992; 1993-1995; 1996-1998; 1999-2001; 2002-2004; 2005-2007; 2008-2010; 2011-2013; 2014-2016)  Flag indicating the spatial limits of the implementation of the tidal flat classifier as defined by altitudinal (+100m) and bathymetric (-100m) limits. 
        :param example: var dataset = ee.Image('UQ/murray/Intertidal/v1_1/data_mask');  var visualization = {   bands: ['datamask'],   min: 0,   max: 1,   palette: ['000000', 'ffffff'] };  Map.setCenter(126.6339, 37.4394, 10);  Map.addLayer(dataset, visualization, 'Data mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UQ_murray_Intertidal_v1_1_global_intertidal:
    def __init__(self,):
        self.sensor = 'UQ_murray_Intertidal_v1_1_global_intertidal'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UQ_murray_Intertidal_v1_1_global_intertidal.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UQ_murray_Intertidal_v1_1_global_intertidal.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UQ_murray_Intertidal_v1_1_global_intertidal(example: str = ''):
        """
        The Murray Global Intertidal Change Dataset contains global maps of tidal flat ecosystems produced via a supervised classification of 707,528 Landsat Archive images. Each pixel was classified into tidal flat, permanent water or other with reference to a globally distributed set of training data.  The classification was implemented along the entire global coastline between 60° North and 60° South from 1 January 1984 to 31 December 2016. The image collection consists consists of a time-series of 11 global maps of tidal flats at 30m pixel resolution for set time-periods (1984-1986; 1987-1989; 1990-1992; 1993-1995; 1996-1998; 1999-2001; 2002-2004; 2005-2007; 2008-2010; 2011-2013; 2014-2016)  This product depicts tidal flat ecosystems around the global coastline.  Pixels classified as tidal flat in the analysis represent several types of tidal flat ecosystems, including unconsolidated fine-grain sediments (tidal mudflats), unconsolidated coarse-grain sediments (tidal sand flats), and consolidated sediments, organic material or rocks (wide tidal rock-platforms), while excluding spectral signatures indicating the presence of vegetation dominated intertidal ecosystems such as mangroves and vegetated marshes. The analysis aimed to identify pixels that are subject to regular tidal inundation, and therefore may also include other intertidal systems where intertidal dynamics are observable. 
        :param example: var dataset = ee.ImageCollection('UQ/murray/Intertidal/v1_1/global_intertidal');  var visualization = {   bands: ['classification'],   min: 0,   max: 1,   palette: ['0000ff'] };  Map.setCenter(126.6339, 37.4394, 10);  Map.addLayer(dataset, visualization, 'Intertidal areas'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UQ_murray_Intertidal_v1_1_qa_pixel_count:
    def __init__(self,):
        self.sensor = 'UQ_murray_Intertidal_v1_1_qa_pixel_count'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UQ_murray_Intertidal_v1_1_qa_pixel_count.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UQ_murray_Intertidal_v1_1_qa_pixel_count.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UQ_murray_Intertidal_v1_1_qa_pixel_count(example: str = ''):
        """
        The Murray Global Intertidal Change Dataset contains global maps of tidal flat ecosystems produced via a supervised classification of 707,528 Landsat Archive images. Each pixel was classified into tidal flat, permanent water or other with reference to a globally distributed set of training data.  The classification was implemented along the entire global coastline between 60° North and 60° South from 1 January 1984 to 31 December 2016. The image collection consists consists of a time-series of 11 global maps of tidal flats at 30m pixel resolution for set time-periods (1984-1986; 1987-1989; 1990-1992; 1993-1995; 1996-1998; 1999-2001; 2002-2004; 2005-2007; 2008-2010; 2011-2013; 2014-2016)  The number of Landsat images used to develop the Landsat covariate layers in each time step of the tidal flat classification. Each image in the image collection refers to a single time step. 
        :param example: var dataset = ee.ImageCollection('UQ/murray/Intertidal/v1_1/qa_pixel_count');  var visualization = {   bands: ['pixel_count'],   min: 0,   max: 300,   palette: ['000000', 'ffffff'] };  Map.setCenter(126.6339, 37.4394, 10);  Map.addLayer(dataset, visualization, 'QA Pixel Count'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USDA_NAIP_DOQQ:
    def __init__(self,):
        self.sensor = 'USDA_NAIP_DOQQ'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USDA_NAIP_DOQQ.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USDA_NAIP_DOQQ.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USDA_NAIP_DOQQ(example: str = ''):
        """
        The National Agriculture Imagery Program (NAIP) acquires aerial imagery during the agricultural growing seasons in the continental U.S.  NAIP projects are contracted each year based upon available funding and the imagery acquisition cycle. Beginning in 2003, NAIP was acquired on a 5-year cycle. 2008 was a transition year, and a three-year cycle began in 2009.  NAIP imagery is acquired at a one-meter ground sample distance (GSD) with a horizontal accuracy that matches within six meters of photo-identifiable ground control points, which are used during image inspection.  Older images were collected using 3 bands (Red, Green, and Blue: RGB), but newer imagery is usually collected with an additional near-infrared band (RGBN). RGB asset ids begin with 'n_', NRG asset ids begin with 'c_', RGBN asset ids begin with 'm_'.  Some older images have GSD of 2 meters. 
        :param example: var dataset = ee.ImageCollection('USDA/NAIP/DOQQ')                   .filter(ee.Filter.date('2017-01-01', '2018-12-31')); var trueColor = dataset.select(['R', 'G', 'B']); var trueColorVis = {   min: 0,   max: 255, }; Map.setCenter(-73.9958, 40.7278, 15); Map.addLayer(trueColor, trueColorVis, 'True Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USDA_NASS_CDL:
    def __init__(self,):
        self.sensor = 'USDA_NASS_CDL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USDA_NASS_CDL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USDA_NASS_CDL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USDA_NASS_CDL(example: str = ''):
        """
        The Cropland Data Layer (CDL) is a crop-specific land cover data layer created annually for the continental United States using moderate resolution satellite imagery and extensive agricultural ground truth. The CDL is created by the USDA, National Agricultural Statistics Service (NASS), Research and Development Division, Geospatial Information Branch, Spatial Analysis Research Section.  For detailed FAQ please visit [CropScape and Cropland Data Layers - FAQs](https://www.nass.usda.gov/Research_and_Science/Cropland/sarsfaqs2.php).  To explore details about the classification accuracies and utility of the data, see [state-level omission and commission errors by crop type and year](https://www.nass.usda.gov/Research_and_Science/Cropland/metadata/meta.php).  The asset date is aligned with the calendar year of harvest. For most crops the planted and harvest year are the same. Some exceptions: winter wheat is unique, as it is planted in the prior year. A hay crop like alfalfa could have been planted years prior.  For winter wheat the data also have a class called "Double Crop Winter Wheat/Soybeans". Some mid-latitude areas of the US have conditions such that a second crop (usually soybeans) can be planted immediately after the harvest of winter wheat and itself still be harvested within the same year. So for mapping winter wheat areas use both classes (use both values 24 and 26).  While the CDL date is aligned with year of harvest, the map itself is more representative of what was planted. In other words, a small percentage of fields on a given year will not be harvested.  Some non-agricultural categories are duplicate due to [two very different epochs in methodology](https://www.google.com/url?sa=D&q=https%3A%2F%2Fwww.nass.usda.gov%2FResearch_and_Science%2FCropland%2F).  The non-ag codes 63-65 and 81-88 are holdovers from the older methodology and will only appear in CDLs from 2007 and earlier. The non-ag codes from 111-195 are from the current methodology which uses the USGS NLCD as non-ag training and will only appear in CDLs 2007 and newer.  2007 was a transition year so there may be both sets of categories in the 2007 national product but will not appear within the same state. 
        :param example: var dataset = ee.ImageCollection('USDA/NASS/CDL')                   .filter(ee.Filter.date('2018-01-01', '2019-12-31'))                   .first(); var cropLandcover = dataset.select('cropland'); Map.setCenter(-100.55, 40.71, 4); Map.addLayer(cropLandcover, {}, 'Crop Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USDOS_LSIB_2013:
    def __init__(self,):
        self.sensor = 'USDOS_LSIB_2013'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USDOS_LSIB_2013.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USDOS_LSIB_2013.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USDOS_LSIB_2013(example: str = ''):
        """
        The United States Office of the Geographer provides the Large Scale International Boundary (LSIB) dataset. It is derived from two other datasets: a LSIB line vector file and the World Vector Shorelines (WVS) from the National Geospatial-Intelligence Agency (NGA). The interior boundaries reflect U.S. government policies on boundaries, boundary disputes, and sovereignty. The exterior boundaries are derived from the WVS; however, the WVS coastline data is outdated and generally shifted from between several hundred meters to over a kilometer. Each feature is the polygonal area enclosed by interior boundaries and exterior coastlines where applicable, and many countries consist of multiple features, one per disjoint region. Each of the 180,741 features is a part of the geometry of one of the 284 countries described in this dataset. 
        :param example: var dataset = ee.FeatureCollection('USDOS/LSIB/2013'); var visParams = {   palette: ['f5ff64', 'b5ffb4', 'beeaff', 'ffc0e8', '8e8dff', 'adadad'],   min: 0,   max: 894, }; var image = ee.Image().int16().paint(dataset, 'iso_num'); Map.setCenter(16.35, 48.83, 4); Map.addLayer(image, visParams, 'USDOS/LSIB/2013', true, 0.8); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USDOS_LSIB_2017:
    def __init__(self,):
        self.sensor = 'USDOS_LSIB_2017'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USDOS_LSIB_2017.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USDOS_LSIB_2017.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USDOS_LSIB_2017(example: str = ''):
        """
        The United States Office of the Geographer provides the Large Scale International Boundary (LSIB) dataset. It is derived from two other datasets: a LSIB line vector file and the World Vector Shorelines (WVS) from the National Geospatial-Intelligence Agency (NGA). The interior boundaries reflect U.S. government policies on boundaries, boundary disputes, and sovereignty. The exterior boundaries are derived from the WVS; however, the WVS coastline data is outdated and generally shifted from between several hundred meters to over a kilometer. Each feature is the polygonal area enclosed by interior boundaries and exterior coastlines where applicable, and many countries consist of multiple features, one per disjoint region. Each of the 180,741 features is a part of the geometry of one of the 284 countries described in this dataset. 
        :param example: var dataset = ee.FeatureCollection('USDOS/LSIB/2017'); var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 3, }; var countries = dataset.style(styleParams); Map.setCenter(16.35, 48.83, 4); Map.addLayer(countries, {}, 'USDOS/LSIB/2017', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USDOS_LSIB_SIMPLE_2017:
    def __init__(self,):
        self.sensor = 'USDOS_LSIB_SIMPLE_2017'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USDOS_LSIB_SIMPLE_2017.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USDOS_LSIB_SIMPLE_2017.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USDOS_LSIB_SIMPLE_2017(example: str = ''):
        """
        The United States Office of the Geographer provides the Large Scale International Boundary (LSIB) dataset. The detailed version (2013) is derived from two other datasets: a LSIB line vector file and the World Vector Shorelines (WVS) from the National Geospatial-Intelligence Agency (NGA). The interior boundaries reflect U.S. government policies on boundaries, boundary disputes, and sovereignty. The exterior boundaries are derived from the WVS; however, the WVS coastline data is outdated and generally shifted from between several hundred meters to over a kilometer. Each feature is the polygonal area enclosed by interior boundaries and exterior coastlines where applicable, and many countries consist of multiple features, one per disjoint region.  Compared with the detailed LSIB, in this simplified dataset some disjointed regions of each country have been reduced to a single feature. Furthermore, it excludes medium and smaller islands. The resulting simplified boundary lines are rarely shifted by more than 100 meters from the detailed LSIB lines. Each of the 312 features is a part of the geometry of one of the 284 countries described in this dataset. 
        :param example: var dataset = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017'); var styleParams = {   fillColor: 'b5ffb4',   color: '00909F',   width: 3, }; var countries = dataset.style(styleParams); Map.setCenter(16.35, 48.83, 4); Map.addLayer(countries, {}, 'USDOS/LSIB_SIMPLE/2017', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_LCMS_v2020_5:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_LCMS_v2020_5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_LCMS_v2020-5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_LCMS_v2020-5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_LCMS_v2020_5(example: str = ''):
        """
        This product is part of the Landscape Change Monitoring System (LCMS) data suite. It shows LCMS-modeled change, land cover, and/or land use classes for each year. This  LCMS version covers the conterminous United States (CONUS) and Southeastern Alaska (SEAK).  LCMS is a remote sensing-based system for mapping and monitoring landscape change across the United States. Its objective is to develop a consistent approach using the latest technology and advancements in change detection to produce a "best available" map of landscape change.  Outputs include three annual products: change, land cover, and land use. Change relates specifically to vegetation cover and includes slow loss, fast loss (which also includes hydrologic changes such as inundation or desiccation), and gain. These values are predicted for each year of the Landsat time series and serve as the foundational products for LCMS. Land cover and land use maps depict life-form level land cover and broad-level land use for each year.  Because no algorithm performs best in all situations, LCMS uses an ensemble of models as predictors, which improves map accuracy across a range of ecosystems and change processes (Healey et al., 2018). The resulting suite of LCMS change, land cover, and land use maps offer a holistic depiction of landscape change across the United States over the past four decades.  Predictor layers for the LCMS model include annual Landsat and Sentinel 2 composites, outputs from the LandTrendr and CCDC change detection algorithms, and terrain information. These components are all accessed and processed using Google Earth Engine (Gorelick et al., 2017).  To produce annual composites, the cFmask (Zhu and Woodcock 2012), cloudScore, and TDOM (Chastain et al., 2019) cloud and cloud shadow masking methods are applied to Landsat Tier 1 and Sentinel 2a and 2b Level-1C top of atmosphere reflectance data. The annual medoid is then computed to summarize each year into a single composite.  The composite time series is temporally segmented using LandTrendr (Kennedy et al., 2010; Kennedy et al., 2018; Cohen et al., 2018).  All cloud and cloud shadow free values are also temporally segmented using the CCDC algorithm (Zhu and Woodcock, 2014).  The raw composite values, LandTrendr fitted values, pair-wise differences, segment duration, change magnitude, and slope, and CCDC September 1 sine and cosine coefficients (first 3 harmonics), fitted values, and pairwise differences, along with elevation, slope, sine of aspect, cosine of aspect, and topographic position indices (Weiss, 2001) from the National Elevation Dataset (NED), are used as independent predictor variables in a Random Forest (Breiman, 2001) model.  Reference data are collected using TimeSync, a web-based tool that helps analysts visualize and interpret the Landsat data record from 1984-present (Cohen et al., 2010).  **Additional Resources**  * [A more detailed code example of using LCMS data.](https://github.com/google/earthengine-community/blob/master/datasets/scripts/LCMS_Visualization.js)  * The [LCMS Data Explorer](https://apps.fs.usda.gov/lcms-viewer) is a web-based application that   provides users the ability to view, analyze, summarize and download LCMS data.  * Please see the [LCMS Methods Brief](https://data.fs.usda.gov/geodata/rastergateway/LCMS/LCMS_v2020-5_Methods.pdf)   for more detailed information regarding methods and accuracy assessment, or the   [LCMS Geodata Clearinghouse](https://data.fs.usda.gov/geodata/rastergateway/LCMS/index.php)   for data downloads, metadata, and support documents.  Contact [sm.fs.lcms@usda.gov](mailto:sm.fs.lcms@usda.gov) with any questions or specific data requests.  * **Breiman, L., 2001.** Machine Learning. *Springer*, 45(3): 261-277 [doi:10.1023/a:1017934522171](https://doi.org/10.1023/a:1017934522171)  * **Chastain, R., Housman, I., Goldstein, J., Finco, M., and Tenneson, K., 2019.** Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM top of atmosphere spectral characteristics over the conterminous United States. In Remote Sensing of Environment. *Science Direct*, 221: 274-285 [doi:10.1016/j.rse.2018.11.012](https://doi.org/10.1016/j.rse.2018.11.012)  * **Cohen, W. B., Yang, Z., and Kennedy, R., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 2. TimeSync - Tools for calibration and validation. In Remote Sensing of Environment. *Science Direct*, 114(12): 2911-2924 [doi:10.1016/j.rse.2010.07.010](https://doi.org/10.1016/j.rse.2010.07.010)  * **Cohen, W. B., Yang, Z., Healey, S. P., Kennedy, R. E., and Gorelick, N., 2018.** A LandTrendr multispectral ensemble for forest disturbance detection. In Remote Sensing of Environment. *Science Direct*, 205: 131-140 [doi:10.1016/j.rse.2017.11.015](https://doi.org/10.1016/j.rse.2017.11.015)  * **Healey, S. P., Cohen, W. B., Yang, Z., Kenneth Brewer, C., Brooks, E. B., Gorelick, N., Hernandez, A. J., Huang, C., Joseph Hughes, M., Kennedy, R. E., Loveland, T. R., Moisen, G. G., Schroeder, T. A., Stehman, S. V., Vogelmann, J. E., Woodcock, C. E., Yang, L., and Zhu, Z., 2018.** Mapping forest change using stacked generalization: An ensemble approach. In Remote Sensing of Environment. *Science Direct*, 204: 717-728 [doi:10.1016/j.rse.2017.09.029](https://doi.org/10.1016/j.rse.2017.09.029)  * **Kennedy, R. E., Yang, Z., and Cohen, W. B., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 1. LandTrendr - Temporal segmentation algorithms. In Remote Sensing of Environment. *Science Direct*, 114(12): 2897-2910 [doi:10.1016/j.rse.2010.07.008](https://doi.org/10.1016/j.rse.2010.07.008)  * **Kennedy, R., Yang, Z., Gorelick, N., Braaten, J., Cavalcante, L., Cohen, W., and Healey, S., 2018.** Implementation of the LandTrendr Algorithm on Google Earth Engine. In Remote Sensing. *MDPI*, 10(5): 691 [doi:10.3390/rs10050691](https://doi.org/10.3390/rs10050691)  * **Weiss, A.D., 2001.** Topographic position and landforms analysis Poster Presentation, ESRI Users Conference, San Diego, CAZhu, Z., and Woodcock, C. E. (2012). Object-based cloud and cloud shadow detection in Landsat imagery. In Remote Sensing of Environment. *Science Direct*, 118: 83-94 [doi:10.1016/j.rse.2011.10.028](https://doi.org/10.1016/j.rse.2011.10.028)  * **Zhu, Z., and Woodcock, C. E., 2014.** Continuous change detection and classification of land cover using all available Landsat data. In Remote Sensing of Environment. *Science Direct*, 144: 152-171 [doi:10.1016/j.rse.2014.01.011](https://doi.org/10.1016/j.rse.2014.01.011) 
        :param example: var dataset = ee.ImageCollection('USFS/GTAC/LCMS/v2020-5');  var lcms = dataset.filterDate('2020', '2021')  // range: [1985, 2020]                .filter('study_area == "CONUS"')  // or "SEAK"                .first();  Map.addLayer(lcms.select('Land_Cover'), {}, 'Land Cover'); Map.addLayer(lcms.select('Land_Use'), {}, 'Land Use'); Map.addLayer(lcms.select('Change'), {}, 'Vegetation Change', false);  Map.setCenter(-98.58, 38.14, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_LCMS_v2020_6:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_LCMS_v2020_6'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_LCMS_v2020-6.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_LCMS_v2020-6.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_LCMS_v2020_6(example: str = ''):
        """
        This product is part of the Landscape Change Monitoring System (LCMS) data suite. It shows LCMS-modeled change, land cover, and/or land use classes for each year. This LCMS version covers Puerto Rico U.S. Virgin Islands (PRUSVI).  LCMS is a remote sensing-based system for mapping and monitoring landscape change across the United States. Its objective is to develop a consistent approach using the latest technology and advancements in change detection to produce a "best available" map of landscape change.  Outputs include three annual products: change, land cover, and land use. Change relates specifically to vegetation cover and includes slow loss, fast loss (which also includes hydrologic changes such as inundation or desiccation), and gain. These values are predicted for each year of the Landsat time series and serve as the foundational products for LCMS. Land cover and land use maps depict life-form level land cover and broad-level land use for each year.  Because no algorithm performs best in all situations, LCMS uses an ensemble of models as predictors, which improves map accuracy across a range of ecosystems and change processes (Healey et al., 2018). The resulting suite of LCMS change, land cover, and land use maps offer a holistic depiction of landscape change across the United States over the past four decades.  Predictor layers for the LCMS model include outputs from the LandTrendr and CCDC change detection algorithms, and terrain information. These components are all accessed and processed using Google Earth Engine (Gorelick et al., 2017).  Landsat Tier 1 and Sentinel 2A, 2B Level-1C top of atmosphere reflectance data are used directly in CCDC and to produce annual composites for LandTrendr. cFmask (Zhu and Woodcock, 2012) (Landsat-only), cloudScore (Chastain et al., 2019) (Landsat-only), and s2cloudless (Sentinel-Hub, 2021) (Sentinel 2-only) are used to mask clouds, while TDOM (Chastain et al., 2019) is used to mask cloud shadows (Landsat and Sentinel 2). For LandTrendr, the annual medoid is then computed to summarize cloud and cloud shadow-free values from each year into a single composite.  The composite time series is temporally segmented using LandTrendr (Kennedy et al., 2010; Kennedy et al., 2018; Cohen et al., 2018).  All cloud and cloud shadow free values are also temporally segmented using the CCDC algorithm (Zhu and Woodcock, 2014).  The raw composite values, LandTrendr fitted values, pair-wise differences, segment duration, change magnitude, and slope, and CCDC September 1 sine and cosine coefficients (first 3 harmonics), fitted values, and pairwise differences, along with elevation, slope, sine of aspect, cosine of aspect, and topographic position indices (Weiss, 2001) from the Digital Elevation Models of Puerto Rico (Taylor et al 2008) and the National Oceanic and Atmospheric Administration Digital Elevation Model for USVI (Love et al. 2014), are used as independent predictor variables in a Random Forest (Breiman, 2001) model.  Reference data are collected using TimeSync, a web-based tool that helps analysts visualize and interpret the Landsat data record from 1984-present (Cohen et al., 2010).  **Additional Resources**  * [A more detailed code example of using LCMS data](https://github.com/google/earthengine-community/blob/master/datasets/scripts/LCMS_Visualization.js).  * The [LCMS Data Explorer](https://apps.fs.usda.gov/lcms-viewer) is a web-based application that   provides users the ability to view, analyze, summarize and download LCMS data.  * Please see the [LCMS Methods Brief](https://data.fs.usda.gov/geodata/rastergateway/LCMS/LCMS_v2020-6_Methods.pdf)   for more detailed information regarding methods and accuracy assessment, or the   [LCMS Geodata Clearinghouse](https://data.fs.usda.gov/geodata/rastergateway/LCMS/index.php)   for data downloads, metadata, and support documents.  Contact [sm.fs.lcms@usda.gov](mailto:sm.fs.lcms@usda.gov) with any questions or specific data requests.  * **Breiman, L., 2001.** Machine Learning. *Springer*, 45(3): 261-277 [doi:10.1023/a:1017934522171](https://doi.org/10.1023/a:1017934522171)  * **Chastain, R., Housman, I., Goldstein, J., Finco, M., and Tenneson, K., 2019.** Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM top of atmosphere spectral characteristics over the conterminous United States. In Remote Sensing of Environment. *Science Direct*, 221: 274-285 [doi:10.1016/j.rse.2018.11.012](https://doi.org/10.1016/j.rse.2018.11.012)  * **Cohen, W. B., Yang, Z., and Kennedy, R., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 2. TimeSync - Tools for calibration and validation. In Remote Sensing of Environment. *Science Direct*, 114(12): 2911-2924 [doi:10.1016/j.rse.2010.07.010](https://doi.org/10.1016/j.rse.2010.07.010)  * **Cohen, W. B., Yang, Z., Healey, S. P., Kennedy, R. E., and Gorelick, N., 2018.** A LandTrendr multispectral ensemble for forest disturbance detection. In Remote Sensing of Environment. *Science Direct*, 205: 131-140 [doi:10.1016/j.rse.2017.11.015](https://doi.org/10.1016/j.rse.2017.11.015)  * **Healey, S. P., Cohen, W. B., Yang, Z., Kenneth Brewer, C., Brooks, E. B., Gorelick, N., Hernandez, A. J., Huang, C., Joseph Hughes, M., Kennedy, R. E., Loveland, T. R., Moisen, G. G., Schroeder, T. A., Stehman, S. V., Vogelmann, J. E., Woodcock, C. E., Yang, L., and Zhu, Z., 2018.** Mapping forest change using stacked generalization: An ensemble approach. In Remote Sensing of Environment. *Science Direct*, 204: 717-728 [doi:10.1016/j.rse.2017.09.029](https://doi.org/10.1016/j.rse.2017.09.029)  * **Kennedy, R. E., Yang, Z., and Cohen, W. B., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 1. LandTrendr - Temporal segmentation algorithms. In Remote Sensing of Environment. *Science Direct*, 114(12): 2897-2910 [doi:10.1016/j.rse.2010.07.008](https://doi.org/10.1016/j.rse.2010.07.008)  * **Kennedy, R., Yang, Z., Gorelick, N., Braaten, J., Cavalcante, L., Cohen, W., and Healey, S., 2018.** Implementation of the LandTrendr Algorithm on Google Earth Engine. In Remote Sensing. *MDPI*, 10(5): 691 [doi:10.3390/rs10050691](https://doi.org/10.3390/rs10050691)  * **Love, M.R., Sutherland, M., Beasley, L., Carignan, K.S., Eakins, B.W. (2014).** Digital Elevation Models of the U.S. Virgin Islands. In NOAA National Geophysical Data Center Internal Publication.  * **Sentinel-Hub (2021).** Sentinel 2 Cloud Detector. [Online]. Available at: [https://github.com/sentinel-hub/sentinel2-cloud-detector](https://github.com/sentinel-hub/sentinel2-cloud-detector) (Accessed: 2021)  * **Taylor, L.A., Eakins, B.W., Carignan, K.S., Warnken, R.R., Sazonova, T., Schoolcraft, D.C. (2008).** Digital Elevation Models of Puerto Rico: Procedures, Data Sources and Analysis. In NOAA Technical Memorandum NESDIS NGDC-13, National Geophysical Data Center, Boulder, CO. (27 pp).  * **Weiss, A.D., 2001.** Topographic position and landforms analysis Poster Presentation, ESRI Users Conference, San Diego, CAZhu, Z., and Woodcock, C. E. (2012). Object-based cloud and cloud shadow detection in Landsat imagery. In Remote Sensing of Environment. *Science Direct*, 118: 83-94 [doi:10.1016/j.rse.2011.10.028](https://doi.org/10.1016/j.rse.2011.10.028)  * **Zhu, Z., and Woodcock, C. E., 2014.** Continuous change detection and classification of land cover using all available Landsat data. In Remote Sensing of Environment. *Science Direct*, 144: 152-171 [doi:10.1016/j.rse.2014.01.011](https://doi.org/10.1016/j.rse.2014.01.011) 
        :param example: var dataset = ee.ImageCollection('USFS/GTAC/LCMS/v2020-6');  var lcms = dataset         .filterDate('2020', '2021')        // range: [1985, 2020]         .filter('study_area == "PRUSVI"')  // Puero Rico only in this version.         .first();  Map.addLayer(lcms.select('Land_Cover'), {}, 'Land Cover'); Map.addLayer(lcms.select('Land_Use'), {}, 'Land Use'); Map.addLayer(lcms.select('Change'), {}, 'Vegetation Change', false);  Map.setCenter(-66.42, 18.13, 9);
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_LCMS_v2021_7:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_LCMS_v2021_7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_LCMS_v2021-7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_LCMS_v2021-7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_LCMS_v2021_7(example: str = ''):
        """
        This product is part of the Landscape Change Monitoring System (LCMS) data suite. It shows LCMS-modeled change, land cover, and/or land use classes for each year. This LCMS version covers the conterminous United States (CONUS)  and Southeastern Alaska (SEAK).  LCMS is a remote sensing-based system for mapping and monitoring landscape change across the United States. Its objective is to develop a consistent approach using the latest technology and advancements in change detection to produce a "best available" map of landscape change.  Outputs include three annual products: change, land cover, and land use. Change relates specifically to vegetation cover and includes slow loss, fast loss (which also includes hydrologic changes such as inundation or desiccation), and gain. These values are predicted for each year of the Landsat time series and serve as the foundational products for LCMS. Land cover and land use maps depict life-form level land cover and broad-level land use for each year.  Because no algorithm performs best in all situations, LCMS uses an ensemble of models as predictors, which improves map accuracy across a range of ecosystems and change processes (Healey et al., 2018). The resulting suite of LCMS change, land cover, and land use maps offer a holistic depiction of landscape change across the United States over the past four decades.  Predictor layers for the LCMS model include outputs from the LandTrendr and CCDC change detection algorithms, and terrain information. These components are all accessed and processed using Google Earth Engine (Gorelick et al., 2017).  Landsat Tier 1 and Sentinel 2A, 2B Level-1C top of atmosphere reflectance data are used directly in CCDC and to produce annual composites for LandTrendr. The cFmask cloud masking algorithm (Foga et al., 2017), which is an implementation of Fmask 2.0 (Zhu and Woodcock, 2012) (Landsat-only), cloudScore (Chastain et al., 2019) (Landsat-only), and s2cloudless (Sentinel-Hub, 2021) (Sentinel 2-only) are used to mask clouds, while TDOM (Chastain et al., 2019) is used to mask cloud shadows (Landsat and Sentinel 2). For LandTrendr, the annual medoid is then computed to summarize cloud and cloud shadow-free values from each year into a single composite.  The composite time series is temporally segmented using LandTrendr (Kennedy et al., 2010; Kennedy et al., 2018; Cohen et al., 2018).  All cloud and cloud shadow free values are also temporally segmented using the CCDC algorithm (Zhu and Woodcock, 2014).  The raw composite values, LandTrendr fitted values, pair-wise differences, segment duration, change magnitude, and slope, and CCDC September 1 sine and cosine coefficients (first 3 harmonics), fitted values, and pairwise differences, along with elevation, slope, sine of aspect, cosine of aspect, and topographic position indices (Weiss, 2001) from the 10 m National Elevation Dataset (NED) (Gesch et al., 2009) was used, and for SEAK, the 30 m NED was used, are used as independent predictor variables in a Random Forest (Breiman, 2001) model.  Reference data are collected using TimeSync, a web-based tool that helps analysts visualize and interpret the Landsat data record from 1984-present (Cohen et al., 2010).  **Additional Resources**  * [A more detailed code example of using LCMS data](https://github.com/google/earthengine-community/blob/master/datasets/scripts/LCMS_Visualization.js).  * The [LCMS Data Explorer](https://apps.fs.usda.gov/lcms-viewer) is a   web-based application that provides users the ability to view, analyze,   summarize and download LCMS data.  * Please see the [LCMS Methods Brief](https://data.fs.usda.gov/geodata/rastergateway/LCMS/LCMS_v2021-7_Methods.pdf)   for more detailed information regarding methods and accuracy assessment, or the   [LCMS Geodata Clearinghouse](https://data.fs.usda.gov/geodata/rastergateway/LCMS/index.php)   for data downloads, metadata, and support documents.  Contact [sm.fs.lcms@usda.gov](mailto:sm.fs.lcms@usda.gov) with any questions or specific data requests.  * **Breiman, L., 2001.** Random Forests. In Machine Learning. *Springer*, 45: 5-32 [doi:10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)  * **Chastain, R., Housman, I., Goldstein, J., Finco, M., and Tenneson, K., 2019.** Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM top of atmosphere spectral characteristics over the conterminous United States. In Remote Sensing of Environment. *Science Direct*, 221: 274-285 [doi:10.1016/j.rse.2018.11.012](https://doi.org/10.1016/j.rse.2018.11.012)  * **Cohen, W. B., Yang, Z., and Kennedy, R., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 2. TimeSync - Tools for calibration and validation. In Remote Sensing of Environment. *Science Direct*, 114(12): 2911-2924 [doi:10.1016/j.rse.2010.07.010](https://doi.org/10.1016/j.rse.2010.07.010)  * **Cohen, W. B., Yang, Z., Healey, S. P., Kennedy, R. E., and Gorelick, N., 2018.** A LandTrendr multispectral ensemble for forest disturbance detection. In Remote Sensing of Environment. *Science Direct*, 205: 131-140 [doi:10.1016/j.rse.2017.11.015](https://doi.org/10.1016/j.rse.2017.11.015)  * **Foga, S., Scaramuzza, P.L., Guo, S., Zhu, Z., Dilley, R.D., Beckmann, T., Schmidt, G.L., Dwyer, J.L., Hughes, M.J., Laue, B., 2017.** Cloud detection algorithm comparison and validation for operational Landsat data products. In Remote Sensing of Environment.  *Science Direct*, 194: 379-390 [doi:10.1016/j.rse.2017.03.026](http://doi.org/10.1016/j.rse.2017.03.026)  * **Gesch, D., Evans, G., Mauck, J., Hutchinson, J., & Carswell, W. J., 2009.** The National Map - Elevation.  *In Fact Sheet*, [doi:10.3133/fs20093053 ](https://doi.org/10.3133/fs20093053)  * **Healey, S. P., Cohen, W. B., Yang, Z., Kenneth Brewer, C., Brooks, E. B., Gorelick, N., Hernandez, A. J., Huang, C., Joseph Hughes, M., Kennedy, R. E., Loveland, T. R., Moisen, G. G., Schroeder, T. A., Stehman, S. V., Vogelmann, J. E., Woodcock, C. E., Yang, L., and Zhu, Z., 2018.** Mapping forest change using stacked generalization: An ensemble approach. In Remote Sensing of Environment. *Science Direct*, 204: 717-728 [doi:10.1016/j.rse.2017.09.029](https://doi.org/10.1016/j.rse.2017.09.029)  * **Kennedy, R. E., Yang, Z., and Cohen, W. B., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 1. LandTrendr - Temporal segmentation algorithms. In Remote Sensing of Environment. *Science Direct*, 114(12): 2897-2910 [doi:10.1016/j.rse.2010.07.008](https://doi.org/10.1016/j.rse.2010.07.008)  * **Kennedy, R., Yang, Z., Gorelick, N., Braaten, J., Cavalcante, L., Cohen, W., and Healey, S., 2018.** Implementation of the LandTrendr Algorithm on Google Earth Engine. In Remote Sensing. *MDPI*, 10(5): 691 [doi:10.3390/rs10050691](https://doi.org/10.3390/rs10050691)  * **Sentinel-Hub, 2021.** Sentinel 2 Cloud Detector. [Online]. Available at: [https://github.com/sentinel-hub/sentinel2-cloud-detector](https://github.com/sentinel-hub/sentinel2-cloud-detector)  * **Weiss, A.D., 2001.** Topographic position and landforms analysis Poster Presentation, ESRI Users Conference, San Diego, CAZhu, Z., and Woodcock, C. E. (2012). Object-based cloud and cloud shadow detection in Landsat imagery. In Remote Sensing of Environment. *Science Direct*, 118: 83-94 [doi:10.1016/j.rse.2011.10.028](https://doi.org/10.1016/j.rse.2011.10.028)  * **Zhu, Z., and Woodcock, C. E., 2014.** Continuous change detection and classification of land cover using all available Landsat data. In Remote Sensing of Environment. *Science Direct*, 144: 152-171 [doi:10.1016/j.rse.2014.01.011](https://doi.org/10.1016/j.rse.2014.01.011) 
        :param example: var dataset = ee.ImageCollection('USFS/GTAC/LCMS/v2021-7');  var lcms = dataset.filterDate('2020', '2021')  // range: [1985, 2021]                .filter('study_area == "CONUS"')  // or "SEAK"                .first();  Map.addLayer(lcms.select('Land_Cover'), {}, 'Land Cover'); Map.addLayer(lcms.select('Land_Use'), {}, 'Land Use'); Map.addLayer(lcms.select('Change'), {}, 'Vegetation Change', false);  Map.setCenter(-98.58, 38.14, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_LCMS_v2022_8:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_LCMS_v2022_8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_LCMS_v2022-8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_LCMS_v2022-8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_LCMS_v2022_8(example: str = ''):
        """
        This product is part of the Landscape Change Monitoring System (LCMS) data suite. It shows LCMS-modeled change, land cover, and/or land use classes for each year that covers the CONUS and OCONUS.  LCMS is a remote sensing-based system for mapping and monitoring landscape change across the United States. Its objective is to develop a consistent approach using the latest technology and advancements in change detection to produce a "best available" map of landscape change.  Outputs include three annual products: change, land cover, and land use. Change relates specifically to vegetation cover and includes slow loss, fast loss (which also includes hydrologic changes such as inundation or desiccation), and gain. These values are predicted for each year of the Landsat time series and serve as the foundational products for LCMS. Land cover and land use maps depict life-form level land cover and broad-level land use for each year.  Because no algorithm performs best in all situations, LCMS uses an ensemble of models as predictors, which improves map accuracy across a range of ecosystems and change processes (Healey et al., 2018). The resulting suite of LCMS change, land cover, and land use maps offer a holistic depiction of landscape change across the United States over the past four decades.  Predictor layers for the LCMS model include outputs from the LandTrendr and CCDC change detection algorithms, and terrain information. These components are all accessed and processed using Google Earth Engine (Gorelick et al., 2017).  For CCDC, United States Geological Survey (USGS) Collection 2 Landsat Tier 1 surface reflectance data were used for the CONUS, and Landsat Tier 1 top of atmosphere reflectance data for SEAK, PRUSVI  and HI. To produce annual composites for LandTrendr, USGS Collection 2 Landsat Tier 1 and Sentinel 2A, 2B Level-1C top of atmosphere reflectance data were used. The cFmask cloud masking algorithm (Foga et al., 2017), which is an implementation of Fmask 2.0 (Zhu and Woodcock, 2012) (Landsat-only), cloudScore (Chastain et al., 2019) (Landsat-only), and s2cloudless (Sentinel-Hub, 2021) (Sentinel 2-only) are used to mask clouds, while TDOM (Chastain et al., 2019) is used to mask cloud shadows (Landsat and Sentinel 2). For LandTrendr, the annual medoid is then computed to summarize cloud and cloud shadow-free values from each year into a single composite.  The composite time series is temporally segmented using LandTrendr (Kennedy et al., 2010; Kennedy et al., 2018; Cohen et al., 2018).  All cloud and cloud shadow free values are also temporally segmented using the CCDC algorithm (Zhu and Woodcock, 2014).  The raw composite values, LandTrendr fitted values, pair-wise differences, segment duration, change magnitude, and slope, and CCDC September 1 sine and cosine coefficients (first 3 harmonics), fitted values, and pairwise differences, along with elevation, slope, sine of aspect, cosine of aspect, and topographic position indices (Weiss, 2001) from the 10 m USGS 3D Elevation Program (3DEP) data (U.S. Geological Survey, 2019), are used as independent predictor variables in a Random Forest (Breiman, 2001) model.  Reference data are collected using TimeSync, a web-based tool that helps analysts visualize and interpret the Landsat data record from 1984-present (Cohen et al., 2010).  **Additional Resources**  * [A more detailed code example of using LCMS data](https://github.com/google/earthengine-community/blob/master/datasets/scripts/LCMS_Visualization.js).  * The [LCMS Data Explorer](https://apps.fs.usda.gov/lcms-viewer) is a web-based application that   provides users the ability to view, analyze, summarize and download LCMS data.  * Please see the [LCMS Methods Brief](https://data.fs.usda.gov/geodata/rastergateway/LCMS/LCMS_v2022-8_Methods.pdf)   for more detailed information regarding methods and accuracy assessment, or the   [LCMS Geodata Clearinghouse](https://data.fs.usda.gov/geodata/rastergateway/LCMS/index.php)   for data downloads, metadata, and support documents.  Contact [sm.fs.lcms@usda.gov](mailto:sm.fs.lcms@usda.gov) with any questions or specific data requests.  * **Breiman, L., 2001.** Random Forests. In Machine Learning. *Springer*, 45: 5-32 [doi:10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)  * **Chastain, R., Housman, I., Goldstein, J., Finco, M., and Tenneson, K., 2019.** Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM top of atmosphere spectral characteristics over the conterminous United States. In Remote Sensing of Environment. *Science Direct*, 221: 274-285 [doi:10.1016/j.rse.2018.11.012](https://doi.org/10.1016/j.rse.2018.11.012)  * **Cohen, W. B., Yang, Z., and Kennedy, R., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 2. TimeSync - Tools for calibration and validation. In Remote Sensing of Environment. *Science Direct*, 114(12): 2911-2924 [doi:10.1016/j.rse.2010.07.010](https://doi.org/10.1016/j.rse.2010.07.010)  * **Cohen, W. B., Yang, Z., Healey, S. P., Kennedy, R. E., and Gorelick, N., 2018.** A LandTrendr multispectral ensemble for forest disturbance detection. In Remote Sensing of Environment. *Science Direct*, 205: 131-140 [doi:10.1016/j.rse.2017.11.015](https://doi.org/10.1016/j.rse.2017.11.015)  * **Foga, S., Scaramuzza, P.L., Guo, S., Zhu, Z., Dilley, R.D., Beckmann, T., Schmidt, G.L., Dwyer, J.L., Hughes, M.J., Laue, B., 2017.** Cloud detection algorithm comparison and validation for operational Landsat data products. In Remote Sensing of Environment.  *Science Direct*, 194: 379-390 [doi:10.1016/j.rse.2017.03.026](http://doi.org/10.1016/j.rse.2017.03.026)  * **U.S. Geological Survey, 2019.** USGS 3D Elevation Program Digital Elevation Model, accessed August 2022 at https://developers.google.com/earth-engine/datasets/catalog/USGS_3DEP_10m  * **Healey, S. P., Cohen, W. B., Yang, Z., Kenneth Brewer, C., Brooks, E. B., Gorelick, N., Hernandez, A. J., Huang, C., Joseph Hughes, M., Kennedy, R. E., Loveland, T. R., Moisen, G. G., Schroeder, T. A., Stehman, S. V., Vogelmann, J. E., Woodcock, C. E., Yang, L., and Zhu, Z., 2018.** Mapping forest change using stacked generalization: An ensemble approach. In Remote Sensing of Environment. *Science Direct*, 204: 717-728 [doi:10.1016/j.rse.2017.09.029](https://doi.org/10.1016/j.rse.2017.09.029)  * **Kennedy, R. E., Yang, Z., and Cohen, W. B., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 1. LandTrendr - Temporal segmentation algorithms. In Remote Sensing of Environment. *Science Direct*, 114(12): 2897-2910 [doi:10.1016/j.rse.2010.07.008](https://doi.org/10.1016/j.rse.2010.07.008)  * **Kennedy, R., Yang, Z., Gorelick, N., Braaten, J., Cavalcante, L., Cohen, W., and Healey, S., 2018.** Implementation of the LandTrendr Algorithm on Google Earth Engine. In Remote Sensing. *MDPI*, 10(5): 691 [doi:10.3390/rs10050691](https://doi.org/10.3390/rs10050691)  * **Sentinel-Hub, 2021.** Sentinel 2 Cloud Detector. [Online]. Available at: [https://github.com/sentinel-hub/sentinel2-cloud-detector](https://github.com/sentinel-hub/sentinel2-cloud-detector)  * **Weiss, A.D., 2001.** Topographic position and landforms analysis Poster Presentation, ESRI Users Conference, San Diego, CAZhu, Z., and Woodcock, C. E. (2012). Object-based cloud and cloud shadow detection in Landsat imagery.  118: 83-94  * **Zhu, Z., and Woodcock, C. E., 2012.**.  Object-based cloud and cloud shadow detection in Landsat imagery. In Remote Sensing of Environment. *Science Direct*, 118: 83-94 [doi:10.1016/j.rse.2011.10.028](https://doi.org/10.1016/j.rse.2011.10.028)  * **Zhu, Z., and Woodcock, C. E., 2014.** Continuous change detection and classification of land cover using all available Landsat data. In Remote Sensing of Environment. *Science Direct*, 144: 152-171 [doi:10.1016/j.rse.2014.01.011](https://doi.org/10.1016/j.rse.2014.01.011) 
        :param example: var dataset = ee.ImageCollection('USFS/GTAC/LCMS/v2022-8');  var lcms = dataset.filterDate('2020', '2021')  // range: [1985, 2022]                .filter('study_area == "CONUS"')  // or "SEAK"                .first();  Map.addLayer(lcms.select('Land_Cover'), {}, 'Land Cover'); Map.addLayer(lcms.select('Land_Use'), {}, 'Land Use'); Map.addLayer(lcms.select('Change'), {}, 'Vegetation Change', false);  Map.setCenter(-98.58, 38.14, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_MTBS_annual_burn_severity_mosaics_v1:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_MTBS_annual_burn_severity_mosaics_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_MTBS_annual_burn_severity_mosaics_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_MTBS_annual_burn_severity_mosaics_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_MTBS_annual_burn_severity_mosaics_v1(example: str = ''):
        """
        The burn severity mosaics consist of thematic raster images of MTBS burn severity classes for all currently completed MTBS fires for the continental United States, Alaska, Hawaii and Puerto Rico. Mosaicked burn severity images are compiled annually for each year by US State and the continental United States. Monitoring Trends in Burn Severity (MTBS) is an interagency program whose goal is to consistently map the burn severity and extent of large fires across all lands of the United States from 1984 to present. This includes all fires 1000 acres or greater in the western United States and 500 acres or greater in the eastern Unites States. The extent of coverage includes the continental U.S., Alaska, Hawaii and Puerto Rico.  The program is conducted by the U.S. Geological Survey Center for Earth Resources Observation and Science (EROS) and the USDA Forest Service Geospatial Technology and Applications Center (GTAC). MTBS was first enacted in 2005, primarily to meet the information needs of the Wildland Fire Leadership Council (WFLC).  The primary objective at that time was to provide data to the WFLC for monitoring the effectiveness of the ten-year National Fire Plan. The scope of the program has grown since inception and provides data to a wide range of users. These include national policy-makers such as WFLC and others who are focused on implementing and monitoring national fire management strategies; field management units such as national forests, parks and other federal and tribal lands that benefit from the availability of GIS-ready maps and data; other federal land cover mapping programs such as LANDFIRE which utilizes burn severity data in their own efforts; and academic and agency research entities interested in fire severity data over significant geographic and temporal extents.  MTBS data are freely available to the public and are generated by leveraging other national programs including the Landsat satellite program, jointly developed and managed by the USGS and NASA. Landsat data are analyzed through a standardized and consistent methodology, generating products at a 30 meter resolution dating back to 1984. One of the greatest strengths of the program is the consistency of the data products which would be impossible without the historic Landsat archive, the largest in the world.  You can visit the [MTBS Project Website](https://www.mtbs.gov) for more information.   You can also visit the [MTBS Data Explorer](https://apps.fs.usda.gov/lcms-viewer/mtbs.html) to learn more and interact with the data. 
        :param example: var dataset = ee.ImageCollection('USFS/GTAC/MTBS/annual_burn_severity_mosaics/v1');  var visualization = {   bands: ['Severity'],   min: 0,   max: 6,   palette:       ['000000', '006400', '7fffd4', 'ffff00', 'ff0000', '7fff00', 'ffffff'] };  Map.setCenter(-95.712891, 37.09024, 5);  Map.addLayer(dataset, visualization, 'Severity'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_MTBS_burned_area_boundaries_v1:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_MTBS_burned_area_boundaries_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_MTBS_burned_area_boundaries_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_MTBS_burned_area_boundaries_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_MTBS_burned_area_boundaries_v1(example: str = ''):
        """
        The [Monitoring Trends in Burn Severity (MTBS)](https://www.mtbs.gov/project-overview) burned area boundaries dataset contains the extent polygons of the burned areas of all currently completed MTBS fires for the continental United States, Alaska, Hawaii, and Puerto Rico.  Below NBR stands for "Normalized Burn Ratio", while dNBR stands for "delta NBR", or "PreFire NBR - PostFire NBR".  Notes on the threshold values:  * dNBR is used when available, but sometimes NBR must be used. * NBR and dNBR, in this situation, have an inverse relationship * Therefore, thresholds are determined based both on the type of incoming   data and the range of the data * The 9999 and -9999 values are fill values representing the cases when   an analyst did not use a threshold (for example, a low severity incident   would not warrant the use of a high severity threshold). * In some cases values of 999 and -999 were entered (instead of 9999   and -9999). Monitoring Trends in Burn Severity (MTBS) is an interagency program whose goal is to consistently map the burn severity and extent of large fires across all lands of the United States from 1984 to present. This includes all fires 1000 acres or greater in the western United States and 500 acres or greater in the eastern Unites States. The extent of coverage includes the continental U.S., Alaska, Hawaii and Puerto Rico.  The program is conducted by the U.S. Geological Survey Center for Earth Resources Observation and Science (EROS) and the USDA Forest Service Geospatial Technology and Applications Center (GTAC). MTBS was first enacted in 2005, primarily to meet the information needs of the Wildland Fire Leadership Council (WFLC).  The primary objective at that time was to provide data to the WFLC for monitoring the effectiveness of the ten-year National Fire Plan. The scope of the program has grown since inception and provides data to a wide range of users. These include national policy-makers such as WFLC and others who are focused on implementing and monitoring national fire management strategies; field management units such as national forests, parks and other federal and tribal lands that benefit from the availability of GIS-ready maps and data; other federal land cover mapping programs such as LANDFIRE which utilizes burn severity data in their own efforts; and academic and agency research entities interested in fire severity data over significant geographic and temporal extents.  MTBS data are freely available to the public and are generated by leveraging other national programs including the Landsat satellite program, jointly developed and managed by the USGS and NASA. Landsat data are analyzed through a standardized and consistent methodology, generating products at a 30 meter resolution dating back to 1984. One of the greatest strengths of the program is the consistency of the data products which would be impossible without the historic Landsat archive, the largest in the world.  You can visit the [MTBS Project Website](https://www.mtbs.gov) for more information.   You can also visit the [MTBS Data Explorer](https://apps.fs.usda.gov/lcms-viewer/mtbs.html) to learn more and interact with the data. 
        :param example: var dataset = ee.FeatureCollection('USFS/GTAC/MTBS/burned_area_boundaries/v1');  var visParams = {   fillColor: 'ff8a50',   color: 'ff5722',   width: 1.0, };  Map.setCenter(-122.2988, 38.8766, 10); Map.addLayer(dataset, visParams, 'USFS/GTAC/MTBS/burned_area_boundaries/v1'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USFS_GTAC_TreeMap_v2016:
    def __init__(self,):
        self.sensor = 'USFS_GTAC_TreeMap_v2016'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USFS_GTAC_TreeMap_v2016.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USFS_GTAC_TreeMap_v2016.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USFS_GTAC_TreeMap_v2016(example: str = ''):
        """
        This product is part of the TreeMap data suite. It provides detailed spatial information on forest characteristics including number of live and dead trees, biomass, and carbon across the entire forested extent of the continental United States in 2016.  TreeMap v2016 contains one image, a 22-band 30 x 30m resolution gridded map of the forests of the continental United States circa 2016, with each band representing an attribute derived from select FIA data (and one band representing the TreeMap ID). Examples of attributes include forest type, canopy cover percent, live tree stocking, live/dead tree biomass, and carbon in live/dead trees.  TreeMap products are the output of a random forest machine learning algorithm that assigns the most similar Forest Inventory Analysis (FIA) plot to each pixel of gridded LANDFIRE input data. The objective is to combine the complimentary strengths of detailed-but-spatially-sparse FIA data with less-detailed-but-spatially-comprehensive LANDFIRE data to produce better estimations of forest characteristics at a variety of scales. TreeMap is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources.  TreeMap is distinct from other imputed forest vegetation products in that it provides an FIA plot identifier to each pixel whereas other datasets provide forest characteristics such as live basal area (e.g., Ohmann and Gregory 2002; Pierce Jr et al. 2009; Wilson, Lister, and Riemann 2012). The FIA plot identifier can be linked to the hundreds of variables and attributes recorded for each tree and plot in the FIA DataMart, FIA's public repository of plot information (Forest Inventory Analysis 2022a).  The 2016 methodology includes disturbance as a response variable, resulting in increased accuracy in mapping disturbed areas. Within-class accuracy was over 90% for forest cover, height, vegetation group, and disturbance code when compared to LANDFIRE maps. At least one pixel within the radius of validation plots matched the class of predicted values in 57.5% of cases for forest cover, 80.0% for height, 80.0% for tree species with highest basal area, and 87.4% for disturbance.  **Additional Resources**  * Please see the [TreeMap 2016 Publication](https://www.fs.usda.gov/research/treesearch/65597)   for more detailed information regarding methods and accuracy assessment.  * The [TreeMap 2016 Data Explorer](https://apps.fs.usda.gov/lcms-viewer/treemap.html)   is a web-based application that provides users the ability to view and   download TreeMap attribute data.  * The [TreeMap Research Data Archive](https://www.fs.usda.gov/rds/archive/Catalog/RDS-2021-0074)   for the full dataset download, metadata, and support documents.  * [TreeMap Raster Data Gateway](https://data.fs.usda.gov/geodata/rastergateway/treemap/)   for TreeMap attribute data downloads, metadata, and support documents.  * [FIA Database Manual version 8](https://www.fia.fs.usda.gov/library/database-documentation/current/ver80/FIADB%20User%20Guide%20P2_8-0.pdf)   for more detailed information on the attributes included in TreeMap 2016.  Contact [sm.fs.treemaphelp@usda.gov](mailto:sm.fs.treemaphelp@usda.gov) with any questions or specific data requests.  * **Forest Inventory Analysis. 2022a.** Forest Inventory Analysis DataMart. Forest Inventory Analysis DataMart FIADB_1.9.0. 2022. [https://apps.fs.usda.gov/fia/datamart/datamart.html](https://apps.fs.usda.gov/fia/datamart/datamart.html).  * **Ohmann, Janet L and Matthew J Gregory. 2002.** Predictive Mapping of Forest Composition and Structure with Direct Gradient Analysis and Nearest- Neighbor Imputation in Coastal Oregon, USA. Can. J. For. Res. 32:725-741. [doi: 10.1139/X02-011](https://doi.org/10.1139/X02-011).  * **Pierce, Kenneth B Jr, Janet L Ohmann, Michael C Wimberly, Matthew J Gregory, and Jeremy S Fried. 2009.** Mapping Wildland Fuels and Forest Structure for Land Management: A Comparison of Nearest Neighbor Imputation and Other Methods. Can. J. For. Res. 39: 1901-1916. [doi:10.1139/X09-102](https://doi.org/10.1139/X09-102).  * **Wilson, B Tyler, Andrew J Lister, and Rachel I Riemann. 2012.** A Nearest-Neighbor Imputation Approach to Mapping Tree Species over Large Areas Using Forest Inventory Plots and Moderate Resolution Raster Data. Forest Ecol. Manag. 271:182-198. [doi: 10.1016/j. foreco.2012.02.002](https://doi.org/10.1016/j.foreco.2012.02.002). 
        :param example: // Load the full dataset var dataset = ee.ImageCollection('USFS/GTAC/TreeMap/v2016');  // Get the 2016 image var tm2016 = dataset.filterDate('2016', '2017').first();  // 'Official' TreeMap 2016 palettes var bamako = ['00404d', '134b42', '265737', '3a652a', '52741c', '71870b', '969206', 'c5ae32', 'e7cd68', 'ffe599']; var bamako_r = JSON.parse(JSON.stringify(bamako)).reverse(); var lajolla = ['ffffcc','fbec9a','f4cc68','eca855','e48751','d2624d','a54742','73382f','422818','1a1a01']; var lajolla_r = JSON.parse(JSON.stringify(lajolla)).reverse(); var imola = ['1a33b3','2446a9','2e599f','396b94','497b85','60927b','7bae74','98cb6d','c4ea67','ffff66']; var imola_r = JSON.parse(JSON.stringify(imola)).reverse();  // Select all 22 attributes var alstk = tm2016.select('ALSTK'); var balive = tm2016.select('BALIVE'); var canopypct = tm2016.select('CANOPYPCT'); var carbon_d = tm2016.select('CARBON_D'); var carbon_dwn = tm2016.select('CARBON_DWN'); var carbon_l = tm2016.select('CARBON_L'); var drybio_d = tm2016.select('DRYBIO_D'); var drybio_l = tm2016.select('DRYBIO_L'); var fldszcd = tm2016.select('FLDSZCD'); var fldtypcd = tm2016.select('FLDTYPCD'); var fortypcd = tm2016.select('FORTYPCD'); var gsstk = tm2016.select('GSSTK'); var qmd_rmrs = tm2016.select('QMD_RMRS'); var sdipct_rmrs = tm2016.select('SDIPCT_RMRS'); var standht = tm2016.select('STANDHT'); var stdszcd = tm2016.select('STDSZCD'); var tpa_dead = tm2016.select('TPA_DEAD'); var tpa_live = tm2016.select('TPA_LIVE'); var value = tm2016.select('Value'); var volbfnet_l = tm2016.select('VOLBFNET_L'); var volcfnet_d = tm2016.select('VOLCFNET_D'); var volcfnet_l = tm2016.select('VOLCFNET_L');  // Add all attributes to the map with the 'official' visualization Map.addLayer(alstk, {'min': 0, 'max': 100, 'palette': bamako_r}, 'ALSTK: All-Live-Tree Stocking (percent)', false); Map.addLayer(balive, {'min': 24, 'max': 217, 'palette': bamako_r}, 'BALIVE: Live Tree Basal Area (ft²)', false); Map.addLayer(canopypct, {'min': 0, 'max': 100, 'palette': bamako_r}, 'CANOPYPCT: Live Canopy Cover (percent)', false); Map.addLayer(carbon_d, {'min': 0, 'max': 9, 'palette': lajolla}, 'CARBON_D: Carbon, Standing Dead (tons/acre)', false); Map.addLayer(carbon_dwn, {'min': 0, 'max': 7, 'palette': lajolla}, 'CARBON_DWN: Carbon, Down Dead (tons/acre)', false); Map.addLayer(carbon_l, {'min': 2, 'max': 59, 'palette': lajolla_r}, 'CARBON_L: Carbon, Live Above Ground (tons/acre)', false); Map.addLayer(drybio_d, {'min': 0, 'max': 10, 'palette': lajolla}, 'DRYBIO_D: Dry Standing Dead Tree Biomass, Above Ground (tons/acre)', false); Map.addLayer(drybio_l, {'min': 4, 'max': 118, 'palette': lajolla_r}, 'DRYBIO_L: Dry Live Tree Biomass, Above Ground (tons/acre)', false); Map.addLayer(fldszcd, {}, 'FLDSZCD: Field Stand-Size Class Code', false); Map.addLayer(fldtypcd, {}, 'FLDTYPCD: Field Forest Type Code'); Map.addLayer(fortypcd, {}, 'FORTYPCD: Algorithm Forest Type Code', false); Map.addLayer(gsstk, {'min': 0, 'max': 100, 'palette': bamako_r}, 'GSSTK: Growing-Stock Stocking (percent)', false); Map.addLayer(qmd_rmrs, {'min': 2, 'max': 25, 'palette': bamako_r}, 'QMD_RMRS: Stand Quadratic Mean Diameter (in)', false); Map.addLayer(sdipct_rmrs, {'min': 6, 'max': 99, 'palette': bamako_r}, 'SDIPCT_RMRS: Stand Density Index (percent of maximum)', false); Map.addLayer(standht, {'min': 23, 'max': 194, 'palette': bamako_r}, 'STANDHT: Height of Dominant Trees (ft)', false); Map.addLayer(stdszcd, {}, 'STDSZCD: Algorithm Stand-Size Class Code', false); Map.addLayer(tpa_dead, {'min': 38, 'max': 126, 'palette': bamako}, 'TPA_DEAD: Dead Trees Per Acre', false); Map.addLayer(tpa_live, {'min': 252, 'max': 1666, 'palette': bamako_r}, 'TPA_LIVE: Live Trees Per Acre', false); Map.addLayer(value.randomVisualizer(), {}, 'Value: TreeMap ID', false); Map.addLayer(volbfnet_l, {'min': 441, 'max': 36522, 'palette': imola_r}, 'VOLBFNET_L: Volume, Live (sawlog-board-ft/acre)', false); Map.addLayer(volcfnet_d, {'min': 5, 'max': 1326, 'palette': imola_r}, 'VOLCFNET_D: Volume, Standing Dead (ft³/acre)', false); Map.addLayer(volcfnet_l, {'min': 137, 'max': 5790, 'palette': imola_r}, 'VOLCFNET_L: Volume, Live (ft³/acre)', false);  // Set basemap Map.setOptions('TERRAIN');  // Center map on CONUS Map.setCenter(-95.712891, 38, 5);
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_3DEP_10m:
    def __init__(self,):
        self.sensor = 'USGS_3DEP_10m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_3DEP_10m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_3DEP_10m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_3DEP_10m(example: str = ''):
        """
        This is the seamless 3DEP DEM dataset for the U.S. with full coverage of the 48 conterminous states, Hawaii, and U.S. territories. Alaska coverage is partially available now and is being expanded to statewide coverage as part of the Alaska Mapping Initiative. Ground spacing is approximately 10 meters north/south, but variable east/west due to convergence of meridians with latitude.  Spatial metadata dataset is ingested as a separate asset [USGS_3DEP_10m_metadata](USGS_3DEP_10m_metadata).  The 1m dataset is ingested as [USGS_3DEP_1m](USGS_3DEP_1m).  Dataset uploaded by [Farmers Business Network](https://fbn.com). 
        :param example: var dataset = ee.Image('USGS/3DEP/10m') var elevation = dataset.select('elevation'); var slope = ee.Terrain.slope(elevation); Map.setCenter(-112.8598, 36.2841, 10); Map.addLayer(elevation, {min: 0, max: 3000,   palette: [     '3ae237', 'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13',     'ff6e08', 'ff500d', 'ff0000', 'de0101', 'c21301', '0602ff', '235cb1',     '307ef3', '269db1', '30c8e2', '32d3ef', '3be285', '3ff38f', '86e26f'   ], }, 'elevation'); Map.addLayer(slope, {min: 0, max: 60}, 'slope'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_3DEP_10m_metadata:
    def __init__(self,):
        self.sensor = 'USGS_3DEP_10m_metadata'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_3DEP_10m_metadata.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_3DEP_10m_metadata.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_3DEP_10m_metadata(example: str = ''):
        """
        This is a table with metadata [for the 3DEP 10m DEM asset](USGS_3DEP_10m).  The Work unit Extent Spatial Metadata (WESM) contains current lidar data availability and basic information about lidar projects, including lidar quality level, data acquisition dates, and links to project-level metadata.  See more details [in this document](https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/atoms/files/3DEP_Spatial_Metadata_Glossary_0.pdf) (taken from [this page](https://www.usgs.gov/media/files/3dep-spatial-metadata-glossary)).  Dataset uploaded by [Farmers Business Network](https://fbn.com). 
        :param example: var fc = ee.FeatureCollection('USGS/3DEP/10m_metadata');  var empty = ee.Image().byte(); var outlines = empty.paint({   featureCollection: fc,   color: 'zmean', }); var palette = ['0000ff', '00ffff', 'ffff00', 'ff0000', 'ffffff']; Map.addLayer(outlines, {palette: palette, max: 2000}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_3DEP_1m:
    def __init__(self,):
        self.sensor = 'USGS_3DEP_1m'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_3DEP_1m.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_3DEP_1m.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_3DEP_1m(example: str = ''):
        """
        This is a tiled collection of images with 1m pixel size from the 3D Elevation Program (3DEP). The 3DEP data holdings serve as the elevation layer of The National Map and provide foundational elevation information for earth science studies and mapping applications in the United States.  The elevations in this DEM represent the topographic bare-earth surface. USGS standard 1m pixel size DEMs are produced exclusively from high resolution light detection and ranging (lidar) source data of images with 1m pixel size or higher resolution. 1m pixel size DEM surfaces are seamless within collection projects but not necessarily seamless across projects. The spatial reference used for tiles of the 1m pixel size DEM within the conterminous United States (CONUS) is Universal Transverse Mercator (UTM) in units of meters and in conformance with the North American Datum of 1983 (NAD83). All bare earth elevation values are in meters and are referenced to the North American Vertical Datum of 1988 (NAVD88). Each tile is distributed in the UTM Zone in which it lies. If a tile crosses two UTM zones, it is delivered in both zones. In this and other cases of image overlaps, elevation values might be slightly different in different images covering the same area.  The 1m pixel size DEM is the highest resolution standard DEM offered in the 3DEP product suite. The 10m 3DEP dataset is available at [USGS_3DEP_10m](USGS_3DEP_10m). 
        :param example: var dataset = ee.ImageCollection('USGS/3DEP/1m'); var visualization = {   min: 0,   max: 3000,   palette: [     '3ae237', 'b5e22e', 'd6e21f', 'fff705', 'ffd611', 'ffb613', 'ff8b13',     'ff6e08', 'ff500d', 'ff0000', 'de0101', 'c21301', '0602ff', '235cb1',     '307ef3', '269db1', '30c8e2', '32d3ef', '3be285', '3ff38f', '86e26f'   ], }; Map.setCenter(-119.0, 34.6, 10); Map.addLayer(dataset, visualization, 'elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_AK_2001:
    def __init__(self,):
        self.sensor = 'USGS_GAP_AK_2001'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_AK_2001.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_AK_2001.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_AK_2001(example: str = ''):
        """
        The GAP/LANDFIRE National Terrestrial Ecosystems data represents a detailed vegetation and land cover classification for the Conterminous U.S., Alaska, Hawaii, and Puerto Rico.GAP/LF 2011 Ecosystems for the Conterminous U.S. is an update of the National Gap Analysis Program Land Cover Data - Version 2.2. Alaska ecosystems have been updated by LANDFIRE to 2012 conditions (LANDFIRE 2012). Hawaii and Puerto Rico data represent the 2001 time-frame (Gon et al. 2006, Gould et al. 2008). The classification scheme used for the Alaska and the lower 48 states is based on NatureServe's Ecological System Classification (Comer et al. 2003), while Puerto Rico and Hawaii's map legend are based on island specific classification systems (Gon et al. 2006, Gould et al. 2008). 
        :param example: var dataset = ee.Image('USGS/GAP/AK/2001');  var visualization = {   bands: ['landcover'],   min: 1.0,   max: 143.0, };  Map.setCenter(-151.97, 63.68, 4);  Map.addLayer(dataset, visualization, 'GAP Alaska'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_CONUS_2011:
    def __init__(self,):
        self.sensor = 'USGS_GAP_CONUS_2011'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_CONUS_2011.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_CONUS_2011.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_CONUS_2011(example: str = ''):
        """
        The GAP/LANDFIRE National Terrestrial Ecosystems data represents a detailed vegetation and land cover classification for the Conterminous U.S., Alaska, Hawaii, and Puerto Rico.GAP/LF 2011 Ecosystems for the Conterminous U.S. is an update of the National Gap Analysis Program Land Cover Data - Version 2.2. Alaska ecosystems have been updated by LANDFIRE to 2012 conditions (LANDFIRE 2012). Hawaii and Puerto Rico data represent the 2001 time-frame (Gon et al. 2006, Gould et al. 2008). The classification scheme used for the Alaska and the lower 48 states is based on NatureServe's Ecological System Classification (Comer et al. 2003), while Puerto Rico and Hawaii's map legend are based on island specific classification systems (Gon et al. 2006, Gould et al. 2008). 
        :param example: var dataset = ee.Image('USGS/GAP/CONUS/2011');  var visualization = {   bands: ['landcover'],   min: 1.0,   max: 584.0, };  Map.setCenter(-98.58, 38.14, 4);  Map.addLayer(dataset, visualization, 'GAP CONUS'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_HI_2001:
    def __init__(self,):
        self.sensor = 'USGS_GAP_HI_2001'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_HI_2001.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_HI_2001.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_HI_2001(example: str = ''):
        """
        The GAP/LANDFIRE National Terrestrial Ecosystems data represents a detailed vegetation and land cover classification for the Conterminous U.S., Alaska, Hawaii, and Puerto Rico.GAP/LF 2011 Ecosystems for the Conterminous U.S. is an update of the National Gap Analysis Program Land Cover Data - Version 2.2. Alaska ecosystems have been updated by LANDFIRE to 2012 conditions (LANDFIRE 2012). Hawaii and Puerto Rico data represent the 2001 time-frame (Gon et al. 2006, Gould et al. 2008). The classification scheme used for the Alaska and the lower 48 states is based on NatureServe's Ecological System Classification (Comer et al. 2003), while Puerto Rico and Hawaii's map legend are based on island specific classification systems (Gon et al. 2006, Gould et al. 2008). 
        :param example: var dataset = ee.Image('USGS/GAP/HI/2001');  var visualization = {   bands: ['landcover'],   min: 1.0,   max: 37.0, };  Map.setCenter(-157.0, 20.1, 7);  Map.addLayer(dataset, visualization, 'GAP Hawaii'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_PAD_US_v20_designation:
    def __init__(self,):
        self.sensor = 'USGS_GAP_PAD_US_v20_designation'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_PAD-US_v20_designation.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_PAD-US_v20_designation.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_PAD_US_v20_designation(example: str = ''):
        """
        PAD-US is America's official national inventory of U.S. terrestrial and marine protected areas that are dedicated to the preservation of biological diversity and to other natural, recreation and cultural uses, managed for these purposes through legal or other effective means.  This database is separated into 4 separate table assets: designation, easement, fee, and proclamation.  The 'Designation' asset includes areas expected to overlap fee-owned lands, including designations such as 'Wilderness Area', leases, agreements, and areas where the protection mechanism (Category) is 'Unknown'.  The PAD-US database strives to be a complete inventory of areas dedicated to the preservation of biological diversity, and other natural (including extraction), recreational or cultural uses, managed for these purposes through legal or other effective means.  PAD-US is an aggregation of \"best available\" spatial data provided by agencies and organizations at a point in time.  This includes both fee ownership of lands as well as management through leases, easements, or other binding agreements.  The data also tracks Congressional designations, Executive designations, and administrative designations identified in management plans (e.g. Bureau of Land Management's 'Area of Environmental Concern').  These factors provide for a robust dataset offering a spatial representation of the complex U.S. protected areas network.  It is important to have in mind a specific analysis question when approaching how to work with the data.  As a full inventory of areas aggregated from authoritative source data, PAD-US includes overlapping designation types and small boundary discrepancies between agency datasets.  Overlapping designations largely occur in the Federal estate of the 'Designation' or 'Combined' feature classes (e.g. 'Wilderness Area' over a 'Wild and Scenic River' and 'National Forest').  It is important to note the presence of overlaps, especially when trying to calculate area statistics; overlapping boundaries count the same area of ground multiple times.  While minor boundary discrepancies remain, most major overlaps have been removed from the 'Fee' asset and this is the best source for overall land area calculations by land manager ('Manager Name') within the PAD-US database (data gaps limit calculations by fee ownership or 'Owner Name').  Statistics summarizing 'Public Access' or Protection Status ('GAP Status Code') by managing agency or organization from an analysis of the PAD-US 1.4 'Combined' feature class are [available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-statistics-and-reports) and will be updated with PAD-US 2.0.  As the PAD-US database is a direct aggregation of source data, the PAD-US development team does not alter spatial linework.  The exception is to \"clip\" lands data along State boundary lines (using the authoritative State boundary file provided by the U.S. Census Bureau) and remove the small segments of boundaries created by this process associated with State or local lands (not Federal or nonprofit lands).  Some boundary discrepancies (or slivers) remain in the dataset.  Data overlaps have been identified and are shared, along with the U.S. Census Bureau State jurisdictional boundary file, with agency data stewards to facilitate edits in source files that will then be incorporated in subsequent PAD-US versions over time. The PAD-US database is built in collaboration with many partners and data stewards. [Information regarding data stewards is available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-stewards). 
        :param example: var dataset = ee.FeatureCollection('USGS/GAP/PAD-US/v20/designation');  // Encode 'GAP_Sts' (protection level) as a number for visualization. dataset = dataset.map(function(feature) {   return feature.set('status', ee.Number.parse(feature.get('GAP_Sts'))); });  // Paint new 'status' value to an image for visualization. var datasetVis = ee.Image().byte().paint(dataset, 'status');  var visualization = {   min: 1,   max: 4,   palette: ['b1a44e', '4eb173', '4e5bb1', 'b14e8c'] };  Map.setCenter(-93.952, 35.400, 8); Map.addLayer(datasetVis, visualization, 'Protection status'); Map.addLayer(dataset, null, 'FeatureCollection', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_PAD_US_v20_easement:
    def __init__(self,):
        self.sensor = 'USGS_GAP_PAD_US_v20_easement'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_PAD-US_v20_easement.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_PAD-US_v20_easement.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_PAD_US_v20_easement(example: str = ''):
        """
        PAD-US is America's official national inventory of U.S. terrestrial and marine protected areas that are dedicated to the preservation of biological diversity and to other natural, recreation and cultural uses, managed for these purposes through legal or other effective means.  This database is separated into 4 separate table assets: designation, easement, fee, and proclamation.  The 'Easement' asset contains non-sensitive data provided directly from the [National Conservation Easement Database (NCED)](https://conservationeasement.us) suitable for distribution in the public domain. The FLWG provides all Federal easements. NCED estimates 5 percent of all easements are withheld from PAD-US as sensitive. The 'Easement' feature class contains some attributes unique to NCED (e.g. Easement Holder Name).  The PAD-US database strives to be a complete inventory of areas dedicated to the preservation of biological diversity, and other natural (including extraction), recreational or cultural uses, managed for these purposes through legal or other effective means.  PAD-US is an aggregation of \"best available\" spatial data provided by agencies and organizations at a point in time.  This includes both fee ownership of lands as well as management through leases, easements, or other binding agreements.  The data also tracks Congressional designations, Executive designations, and administrative designations identified in management plans (e.g. Bureau of Land Management's 'Area of Environmental Concern').  These factors provide for a robust dataset offering a spatial representation of the complex U.S. protected areas network.  It is important to have in mind a specific analysis question when approaching how to work with the data.  As a full inventory of areas aggregated from authoritative source data, PAD-US includes overlapping designation types and small boundary discrepancies between agency datasets.  Overlapping designations largely occur in the Federal estate of the 'Designation' or 'Combined' feature classes (e.g. 'Wilderness Area' over a 'Wild and Scenic River' and 'National Forest').  It is important to note the presence of overlaps, especially when trying to calculate area statistics; overlapping boundaries count the same area of ground multiple times.  While minor boundary discrepancies remain, most major overlaps have been removed from the 'Fee' asset and this is the best source for overall land area calculations by land manager ('Manager Name') within the PAD-US database (data gaps limit calculations by fee ownership or 'Owner Name').  Statistics summarizing 'Public Access' or Protection Status ('GAP Status Code') by managing agency or organization from an analysis of the PAD-US 1.4 'Combined' feature class are [available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-statistics-and-reports) and will be updated with PAD-US 2.0.  As the PAD-US database is a direct aggregation of source data, the PAD-US development team does not alter spatial linework.  The exception is to \"clip\" lands data along State boundary lines (using the authoritative State boundary file provided by the U.S. Census Bureau) and remove the small segments of boundaries created by this process associated with State or local lands (not Federal or nonprofit lands).  Some boundary discrepancies (or slivers) remain in the dataset.  Data overlaps have been identified and are shared, along with the U.S. Census Bureau State jurisdictional boundary file, with agency data stewards to facilitate edits in source files that will then be incorporated in subsequent PAD-US versions over time. The PAD-US database is built in collaboration with many partners and data stewards. [Information regarding data stewards is available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-stewards). 
        :param example: var dataset = ee.FeatureCollection('USGS/GAP/PAD-US/v20/easement');  // Encode 'GAP_Sts' (protection level) as a number for visualization. dataset = dataset.map(function(feature) {   return feature.set('status', ee.Number.parse(feature.get('GAP_Sts'))); });  // Paint new 'status' value to an image for visualization. var datasetVis = ee.Image().byte().paint(dataset, 'status');  var visualization = {   min: 1,   max: 4,   palette: ['b1a44e', '4eb173', '4e5bb1', 'b14e8c'] };  Map.setCenter(-74.127, 43.927, 8); Map.addLayer(datasetVis, visualization, 'Protection status'); Map.addLayer(dataset, null, 'FeatureCollection', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_PAD_US_v20_fee:
    def __init__(self,):
        self.sensor = 'USGS_GAP_PAD_US_v20_fee'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_PAD-US_v20_fee.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_PAD-US_v20_fee.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_PAD_US_v20_fee(example: str = ''):
        """
        PAD-US is America's official national inventory of U.S. terrestrial and marine protected areas that are dedicated to the preservation of biological diversity and to other natural, recreation and cultural uses, managed for these purposes through legal or other effective means.  This database is separated into 4 separate table assets: designation, easement, fee, and proclamation.  The PAD-US 2.0 dataset separates fee ownership from other data types (e.g. management designations, conservation easements). The 'Fee' asset provides a complete, parcel based inventory representing fee-owned protected areas without boundary gaps or overlaps between authoritative datasets provided by agencies. Data gaps associated with ownership, overlaps, and minor discrepancies (slivers) between agency boundaries remain as work continues.  The PAD-US database strives to be a complete inventory of areas dedicated to the preservation of biological diversity, and other natural (including extraction), recreational or cultural uses, managed for these purposes through legal or other effective means.  PAD-US is an aggregation of \"best available\" spatial data provided by agencies and organizations at a point in time.  This includes both fee ownership of lands as well as management through leases, easements, or other binding agreements.  The data also tracks Congressional designations, Executive designations, and administrative designations identified in management plans (e.g. Bureau of Land Management's 'Area of Environmental Concern').  These factors provide for a robust dataset offering a spatial representation of the complex U.S. protected areas network.  It is important to have in mind a specific analysis question when approaching how to work with the data.  As a full inventory of areas aggregated from authoritative source data, PAD-US includes overlapping designation types and small boundary discrepancies between agency datasets.  Overlapping designations largely occur in the Federal estate of the 'Designation' or 'Combined' feature classes (e.g. 'Wilderness Area' over a 'Wild and Scenic River' and 'National Forest').  It is important to note the presence of overlaps, especially when trying to calculate area statistics; overlapping boundaries count the same area of ground multiple times.  While minor boundary discrepancies remain, most major overlaps have been removed from the 'Fee' asset and this is the best source for overall land area calculations by land manager ('Manager Name') within the PAD-US database (data gaps limit calculations by fee ownership or 'Owner Name').  Statistics summarizing 'Public Access' or Protection Status ('GAP Status Code') by managing agency or organization from an analysis of the PAD-US 1.4 'Combined' feature class are [available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-statistics-and-reports) and will be updated with PAD-US 2.0.  As the PAD-US database is a direct aggregation of source data, the PAD-US development team does not alter spatial linework.  The exception is to \"clip\" lands data along State boundary lines (using the authoritative State boundary file provided by the U.S. Census Bureau) and remove the small segments of boundaries created by this process associated with State or local lands (not Federal or nonprofit lands).  Some boundary discrepancies (or slivers) remain in the dataset.  Data overlaps have been identified and are shared, along with the U.S. Census Bureau State jurisdictional boundary file, with agency data stewards to facilitate edits in source files that will then be incorporated in subsequent PAD-US versions over time. The PAD-US database is built in collaboration with many partners and data stewards. [Information regarding data stewards is available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-stewards). 
        :param example: var dataset = ee.FeatureCollection('USGS/GAP/PAD-US/v20/fee');  // Encode 'GAP_Sts' (protection level) as a number for visualization. dataset = dataset.map(function(feature) {   return feature.set('status', ee.Number.parse(feature.get('GAP_Sts'))); });  // Paint new 'status' value to an image for visualization. var datasetVis = ee.Image().byte().paint(dataset, 'status');  var visualization = {   min: 1,   max: 4,   palette: ['b1a44e', '4eb173', '4e5bb1', 'b14e8c'] };  Map.setCenter(-100.612, 43.687, 8); Map.addLayer(datasetVis, visualization, 'Protection status'); Map.addLayer(dataset, null, 'FeatureCollection', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_PAD_US_v20_proclamation:
    def __init__(self,):
        self.sensor = 'USGS_GAP_PAD_US_v20_proclamation'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_PAD-US_v20_proclamation.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_PAD-US_v20_proclamation.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_PAD_US_v20_proclamation(example: str = ''):
        """
        PAD-US is America's official national inventory of U.S. terrestrial and marine protected areas that are dedicated to the preservation of biological diversity and to other natural, recreation and cultural uses, managed for these purposes through legal or other effective means.  This database is separated into 4 separate table assets: designation, easement, fee, and proclamation.  The 'Proclamation' asset includes boundaries that provide additional context for the features in the 'Fee', 'Designation', or 'Easement' assets, suitable for display as an outline because internal ownership is not represented. These include Military Lands, Proclamation Boundaries (National Park Service and Forest Service), or Approved Acquisition Boundaries (U.S. Fish and Wildlife Service).  The PAD-US database strives to be a complete inventory of areas dedicated to the preservation of biological diversity, and other natural (including extraction), recreational or cultural uses, managed for these purposes through legal or other effective means.  PAD-US is an aggregation of \"best available\" spatial data provided by agencies and organizations at a point in time.  This includes both fee ownership of lands as well as management through leases, easements, or other binding agreements.  The data also tracks Congressional designations, Executive designations, and administrative designations identified in management plans (e.g. Bureau of Land Management's 'Area of Environmental Concern').  These factors provide for a robust dataset offering a spatial representation of the complex U.S. protected areas network.  It is important to have in mind a specific analysis question when approaching how to work with the data.  As a full inventory of areas aggregated from authoritative source data, PAD-US includes overlapping designation types and small boundary discrepancies between agency datasets.  Overlapping designations largely occur in the Federal estate of the 'Designation' or 'Combined' feature classes (e.g. 'Wilderness Area' over a 'Wild and Scenic River' and 'National Forest').  It is important to note the presence of overlaps, especially when trying to calculate area statistics; overlapping boundaries count the same area of ground multiple times.  While minor boundary discrepancies remain, most major overlaps have been removed from the 'Fee' asset and this is the best source for overall land area calculations by land manager ('Manager Name') within the PAD-US database (data gaps limit calculations by fee ownership or 'Owner Name').  Statistics summarizing 'Public Access' or Protection Status ('GAP Status Code') by managing agency or organization from an analysis of the PAD-US 1.4 'Combined' feature class are [available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-statistics-and-reports) and will be updated with PAD-US 2.0.  As the PAD-US database is a direct aggregation of source data, the PAD-US development team does not alter spatial linework.  The exception is to \"clip\" lands data along State boundary lines (using the authoritative State boundary file provided by the U.S. Census Bureau) and remove the small segments of boundaries created by this process associated with State or local lands (not Federal or nonprofit lands).  Some boundary discrepancies (or slivers) remain in the dataset.  Data overlaps have been identified and are shared, along with the U.S. Census Bureau State jurisdictional boundary file, with agency data stewards to facilitate edits in source files that will then be incorporated in subsequent PAD-US versions over time. The PAD-US database is built in collaboration with many partners and data stewards. [Information regarding data stewards is available](https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-stewards). 
        :param example: var dataset = ee.FeatureCollection('USGS/GAP/PAD-US/v20/proclamation');  // Encode 'GAP_Sts' (protection level) as a number for visualization. dataset = dataset.map(function(feature) {   return feature.set('status', ee.Number.parse(feature.get('GAP_Sts'))); });  // Paint new 'status' value to an image for visualization. var datasetVis = ee.Image().byte().paint(dataset, 'status');  var visualization = {   min: 1,   max: 4,   palette: ['b1a44e', '4eb173', '4e5bb1', 'b14e8c'] };  Map.setCenter(-92.852, 31.549, 8); Map.addLayer(datasetVis, visualization, 'Protection status'); Map.addLayer(dataset, null, 'FeatureCollection', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GAP_PR_2001:
    def __init__(self,):
        self.sensor = 'USGS_GAP_PR_2001'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GAP_PR_2001.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GAP_PR_2001.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GAP_PR_2001(example: str = ''):
        """
        The GAP/LANDFIRE National Terrestrial Ecosystems data represents a detailed vegetation and land cover classification for the Conterminous U.S., Alaska, Hawaii, and Puerto Rico.GAP/LF 2011 Ecosystems for the Conterminous U.S. is an update of the National Gap Analysis Program Land Cover Data - Version 2.2. Alaska ecosystems have been updated by LANDFIRE to 2012 conditions (LANDFIRE 2012). Hawaii and Puerto Rico data represent the 2001 time-frame (Gon et al. 2006, Gould et al. 2008). The classification scheme used for the Alaska and the lower 48 states is based on NatureServe's Ecological System Classification (Comer et al. 2003), while Puerto Rico and Hawaii's map legend are based on island specific classification systems (Gon et al. 2006, Gould et al. 2008). 
        :param example: var dataset = ee.Image('USGS/GAP/PR/2001');  var visualization = {   bands: ['landcover'],   min: 1.0,   max: 70.0, };  Map.setCenter(-66.51, 18.23, 8);  Map.addLayer(dataset, visualization, 'GAP Purto Rico'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GFSAD1000_V0:
    def __init__(self,):
        self.sensor = 'USGS_GFSAD1000_V0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GFSAD1000_V0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GFSAD1000_V0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GFSAD1000_V0(example: str = ''):
        """
        The GFSAD is a NASA-funded project to provide high-resolution global cropland data and their water use that contributes towards global food security in the twenty-first century. The GFSAD products are derived through multi-sensor remote sensing data (e.g., Landsat, MODIS, AVHRR), secondary data, and field-plot data and aims at documenting cropland dynamics.  At a nominal 1km scale, V0.0 provides the spatial distribution of the five major global cropland types (wheat, rice, corn, barley, and soybeans) which occupy 60% of all global cropland areas. The map is produced by overlaying these crops over the remote sensing derived global irrigated and rainfed cropland area map of the International Water Management Institute. V0.0 an 8-class product that provides information on global: cropland extent, crop dominance, irrigated versus rainfed cropping, and cropping intensity (single, double, triple, and continuous crops). The GFSAD1000 nominal 2010 product was created with data from 2007 to 2012. 
        :param example: var dataset = ee.Image('USGS/GFSAD1000_V0'); var cropDominance = dataset.select('landcover'); var cropDominanceVis = {   min: 0.0,   max: 9.0,   palette: [     'black', 'white', 'green', 'yellow', 'brown', 'orange', '02be11', '015e08',     '02a50f', 'purple'   ], }; Map.setCenter(-17.22, 13.72, 2); Map.addLayer(cropDominance, cropDominanceVis, 'Crop Dominance'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GFSAD1000_V1:
    def __init__(self,):
        self.sensor = 'USGS_GFSAD1000_V1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GFSAD1000_V1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GFSAD1000_V1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GFSAD1000_V1(example: str = ''):
        """
        The GFSAD is a NASA-funded project to provide high-resolution global cropland data and their water use that contributes towards global food security in the twenty-first century. The GFSAD products are derived through multi-sensor remote sensing data (e.g., Landsat, MODIS, AVHRR), secondary data, and field-plot data and aims at documenting cropland dynamics.  At a nominal 1km scale, V0.1 provides the spatial distribution of a disaggregated five-class global cropland extent map derived from four major studies: Thenkabail et al. (2009a, 2011), Pittman et al. (2010), Yu et al. (2013), and Friedl et al. (2010). V1.0 is a 5-class product that provides information on global cropland extent and irrigated versus rainfed cropping. There is no crop type or crop type dominance information. Cropping intensity (single, double, triple, and continuous crops) can be obtained for every pixel using time-series remote sensing data. The GFSAD1000 nominal 2010 product was created with data from 2007 to 2012. 
        :param example: var dataset = ee.Image('USGS/GFSAD1000_V1'); var cropMask = dataset.select('landcover'); var cropMaskVis = {   min: 0.0,   max: 5.0,   palette: ['black', 'orange', 'brown', '02a50f', 'green', 'yellow'], }; Map.setCenter(-17.22, 13.72, 2); Map.addLayer(cropMask, cropMaskVis, 'Crop Mask'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GMTED2010:
    def __init__(self,):
        self.sensor = 'USGS_GMTED2010'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GMTED2010.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GMTED2010.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GMTED2010(example: str = ''):
        """
        The Global Multi-resolution Terrain Elevation Data 2010 (GMTED2010) dataset contains elevation data for the globe collected from various sources. The version of the dataset available here is Breakline Emphasis, 7.5 arc-seconds resolution. Breakline emphasis maintains the critical topographic features (streams or ridges) within the landscape by maintaining any minimum elevation or maximum elevation value on a breakline that passes within the specified analysis window. More details are available in the dataset [report](https://pubs.usgs.gov/of/2011/1073/pdf/of2011-1073.pdf).  The primary source dataset for GMTED2010 is NGA''s SRTM Digital Terrain Elevation Data (DTED&reg;, [https://www2.jpl.nasa.gov/srtm/](https://www2.jpl.nasa.gov/srtm/)) (void-filled) 1-arc-second data. For the geographic areas outside the SRTM coverage area and to fill in remaining holes in the SRTM data, the following sources were used: non-SRTM DTED&reg;, Canadian Digital Elevation Data (CDED) at two resolutions, Satellite Pour l''Observation de la Terre (SPOT 5) Reference3D, National Elevation Dataset (NED) for the continental United States and Alaska, GEODATA 9 second digital elevation model (DEM) for Australia, an Antarctica satellite radar and laser altimeter DEM, and a Greenland satellite radar altimeter DEM.  This dataset replaces the GTOPO30 Elevation Model. 
        :param example: var dataset = ee.Image('USGS/GMTED2010'); var elevation = dataset.select('be75'); var elevationVis = {   min: -100.0,   max: 6500.0,   gamma: 3.5, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GMTED2010_FULL:
    def __init__(self,):
        self.sensor = 'USGS_GMTED2010_FULL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GMTED2010_FULL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GMTED2010_FULL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GMTED2010_FULL(example: str = ''):
        """
        The Global Multi-resolution Terrain Elevation Data 2010 (GMTED2010) dataset contains elevation data for the globe collected from various sources at 7.5 arc-seconds resolution. More details are available in the dataset [report](https://pubs.usgs.gov/of/2011/1073/pdf/of2011-1073.pdf).  The primary source dataset for GMTED2010 is NGA''s SRTM Digital Terrain Elevation Data (DTED&reg;, [https://www2.jpl.nasa.gov/srtm/](https://www2.jpl.nasa.gov/srtm/)) (void-filled) 1-arc-second data. For the geographic areas outside the SRTM coverage area and to fill in remaining holes in the SRTM data, the following sources were used: non-SRTM DTED&reg;, Canadian Digital Elevation Data (CDED) at two resolutions, Satellite Pour l''Observation de la Terre (SPOT 5) Reference3D, National Elevation Dataset (NED) for the continental United States and Alaska, GEODATA 9 second digital elevation model (DEM) for Australia, an Antarctica satellite radar and laser altimeter DEM, and a Greenland satellite radar altimeter DEM.  This dataset replaces the GTOPO30 Elevation Model. 
        :param example: var dataset = ee.Image('USGS/GMTED2010_FULL'); var elevation = dataset.select('min'); var elevationVis = {   min: -100.0,   max: 6500.0,   gamma: 3.5, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(elevation, elevationVis, 'Minimum Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_GTOPO30:
    def __init__(self,):
        self.sensor = 'USGS_GTOPO30'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_GTOPO30.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_GTOPO30.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_GTOPO30(example: str = ''):
        """
        GTOPO30 is a global digital elevation model (DEM) with a horizontal grid spacing of 30 arc seconds (approximately 1 kilometer). The DEM was derived from several raster and vector sources of topographic information.  Completed in late 1996, GTOPO30 was developed over a three-year period through a collaborative effort led by the U.S. Geological Survey''s Center for Earth Resources Observation and Science (EROS). The following organizations  participated by contributing funding or source data:  the National Aeronautics  and Space Administration (NASA), the United Nations Environment Programme/Global Resource Information Database (UNEP/GRID), the U.S. Agency for International Development (USAID), the Instituto Nacional de Estadistica Geografica e Informatica (INEGI) of Mexico, the Geographical Survey Institute  (GSI) of Japan, Manaaki Whenua Landcare Research of New Zealand, and the  Scientific Committee on Antarctic Research (SCAR). 
        :param example: var dataset = ee.Image('USGS/GTOPO30'); var elevation = dataset.select('elevation'); var elevationVis = {   min: -10.0,   max: 8000.0,   gamma: 1.6, }; Map.setCenter(11.69, 43.9, 4); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_LIMA_MOSAIC:
    def __init__(self,):
        self.sensor = 'USGS_LIMA_MOSAIC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_LIMA_MOSAIC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_LIMA_MOSAIC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_LIMA_MOSAIC(example: str = ''):
        """
        The Landsat Image Mosaic of Antarctica (LIMA) is a seamless and virtually cloudless mosaic created from processed Landsat 7 ETM+ scenes.  This LIMA dataset is the 16-bit Intermediate LIMA. The mosaic consists of pan-sharpened normalized surface reflectance scenes (Landsat ETM+ bands 1, 2, 3, and 4). The mosaic was constructed by ordering cloud free images on top and trimming image boundaries when tile discontinuities occurred.  Users can find the mosaic tile footprints available at: [USGS/LIMA/MOSAIC_TILE_FOOTPRINTS](https://code.earthengine.google.com/?asset=USGS/LIMA/MOSAIC_TILE_FOOTPRINTS) 
        :param example: var dataset = ee.Image('USGS/LIMA/MOSAIC'); var antarctica = dataset.select(['B3', 'B2', 'B1']); var antarcticaVis = {   min: 0.0,   max: 10000.0, }; Map.setCenter(164.619, -77.99, 7); Map.addLayer(antarctica, antarcticaVis, 'Antartica Imagery (RGB)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_LIMA_SR:
    def __init__(self,):
        self.sensor = 'USGS_LIMA_SR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_LIMA_SR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_LIMA_SR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_LIMA_SR(example: str = ''):
        """
        The Landsat Image Mosaic of Antarctica (LIMA) is a seamless and virtually cloudless mosaic created from processed Landsat 7 ETM+ scenes.  Processed Landsat Scenes (16 bit) are Level 1Gt NLAPS scenes converted to 16 bit, processed with sun-angle correction, and converted to reflectance values ([Bindschadler 2008](https://lima.usgs.gov/LIMA_paper.pdf)).  Each Landsat scene is processed with elevation data and sun-angle correction to ensure surface features were accurately represented. The sun's angle in Antarctica gives the appearance of a setting sun. Because of the low sun angle, as Landsat passes over Antarctica, the outer edges of the continent appear brighter than areas closer to the South Pole, so scenes have bright and dark areas. Inconsistent sun angles and shadows where corrected for these scenes. Without this process, mosaicking would produce a patchwork of scenes since each scene would have a brighter and a darker side.  Users can find individual image metadata available as a table at: [USGS/LIMA/SR_METADATA](USGS_LIMA_SR_METADATA) 
        :param example: var dataset = ee.ImageCollection('USGS/LIMA/SR'); var antarctica = dataset.select(['B3', 'B2', 'B1']); var antarcticaVis = {   min: 0.0,   max: 10000.0, }; Map.setCenter(164.619, -77.99, 7); Map.addLayer(antarctica, antarcticaVis, 'Antartica Imagery (RGB)'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_LIMA_SR_METADATA:
    def __init__(self,):
        self.sensor = 'USGS_LIMA_SR_METADATA'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_LIMA_SR_METADATA.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_LIMA_SR_METADATA.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_LIMA_SR_METADATA(example: str = ''):
        """
        The Landsat Image Mosaic of Antarctica (LIMA) is a seamless and virtually cloudless mosaic created from processed Landsat 7 ETM+ scenes.  Processed Landsat Scenes (16 bit) are Level 1Gt NLAPS scenes converted to 16 bit, processed with sun-angle correction, and converted to reflectance values ([Bindschadler 2008](https://lima.usgs.gov/LIMA_paper.pdf)).  Each Landsat scene is processed with elevation data and sun-angle correction to ensure surface features were accurately represented. The sun's angle in Antarctica gives the appearance of a setting sun. Because of the low sun angle, as Landsat passes over Antarctica, the outer edges of the continent appear brighter than areas closer to the South Pole, so scenes have bright and dark areas. Inconsistent sun angles and shadows where corrected for these scenes. Without this process, mosaicking would produce a patchwork of scenes since each scene would have a brighter and a darker side.  This is a table which contains metadata for the Image Collection [USGS/LIMA/SR](USGS_LIMA_SR)  
        :param example: var dataset = ee.FeatureCollection('USGS/LIMA/SR_METADATA');  // Calculate the age of each feature by subtracting // the acquisition date from "today". var feature_ages = dataset.map(   function(feature) {     var today = ee.Date.fromYMD(2024, 1, 12);     var acq_date = ee.Date.parse(       'yyyy-MM-dd', feature.get('ACQ_DATE'));     var diff = today.difference(acq_date, 'day');     return feature.set({'ACQ_AGE': diff});   } );  // Reduce by calculating the smallest ACQ_AGE, // which gives the most recent acquisition date for // that area. var reduced_ages = feature_ages.reduceToImage({   properties: ['ACQ_AGE'],   reducer: ee.Reducer.min() });  var reduced_ages_vis = {   min: 6000,   max: 9000,   palette: ['00ff00', 'ff0000'], };  var lon = -43.6; var lat = -74.2; var gray = 150; var background = ee.Image.rgb(gray, gray, gray).visualize({min: 0, max: 255});  Map.setCenter(lon, lat, 2); Map.addLayer(   reduced_ages,   reduced_ages_vis,   'Acquisition Age');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NED:
    def __init__(self,):
        self.sensor = 'USGS_NED'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NED.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NED.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NED(example: str = ''):
        """
        The National Elevation Dataset (NED) used to be* the primary elevation data product of the USGS. The NED is a seamless dataset with the best available raster elevation data of the conterminous United States, parts of Alaska, Hawaii, and some territorial islands. The NED is derived from diverse source data that are processed to a common coordinate system and unit of vertical measure. NED data are distributed in conformance with the North American Datum of 1983 (NAD 83). All elevation values are in meters and, over the conterminous United States, are referenced to the North American Vertical Datum of 1988 (NAVD 88). The vertical reference will vary in other areas.  *For over 15 years, the NED was the primary elevation data product of the USGS' National Map. However, it has been renamed and now considered just one component of elevation in The National Map after the 3D Elevation Program became operational. 
        :param example: var dataset = ee.Image('USGS/NED'); var elevation = dataset.select('elevation'); var elevationVis = {   min: 0.0,   max: 4000.0,   gamma: 1.6, }; Map.setCenter(-100.55, 40.71, 5); Map.addLayer(elevation, elevationVis, 'Elevation'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD:
    def __init__(self,):
        self.sensor = 'USGS_NLCD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD(example: str = ''):
        """
        This dataset is superseded by newer datasets:  * 2016 landcover and imperviousness data in   [USGS/NLCD_RELEASES/2019_REL/NLCD](USGS_NLCD_RELEASES_2019_REL_NLCD). * 2019 landcover and imperviousness data in   [USGS/NLCD_RELEASES/2019_REL/NLCD](USGS_NLCD_RELEASES_2019_REL_NLCD). * 2019 rangeland data in   [USGS/NLCD_RELEASES/2019_REL/RCMAP/V4/COVER](USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER).  NLCD (the National Land Cover Database) is a 30-m Landsat-based land cover database spanning 8 epochs (1992, 2001, 2004, 2006, 2008, 2011, 2013 and 2016). 1992 data are primarily based on unsupervised classification of Landsat data, while the rest of the images rely on the imperviousness data layer for the urban classes and on a decision-tree classification for the rest. The 1992 image is not directly comparable to any later editions of NLCD.  This dataset has one image for the continental US for each of the eight epochs, plus separate images for Alaska, Hawaii, and Puerto Rico in 2001 and 2011. (They could not be merged in due to having a different projection from the continental US images.)  Note that the impervious layers and tree cover layers for Alaska 2011 only have data for parts of Alaska.  For the impervious layer, only the parts of Kenai Peninsula Borough and Anchorage Municipality are available. Tree cover is only available on a strip along the coast from the southern tip of the Alaskan Panhandle up through the Kenai Peninsula, plus Kodiak Island.  NLCD 2016 Shrub Component products characterize the percentage of each 30-meter pixel in the Western United States covered by shrub, herbaceous, bare ground, litter, sagebrush, big sagebrush and annual herbaceous, along with estimating shrub height and sagebrush height. These products have been produced by USGS in collaboration with the Bureau of Land Management.  NLCD products are created by the Multi-Resolution Land Characteristics (MRLC) Consortium, a partnership of federal agencies led by the U.S. Geological Survey. 
        :param example: // Import the NLCD collection. var dataset = ee.ImageCollection('USGS/NLCD');  // The collection contains images for multiple years and regions in the USA. print('Products:', dataset.aggregate_array('system:index'));  // Filter the collection to the 2016 product. var nlcd2016 = dataset.filter(ee.Filter.eq('system:index', 'NLCD2016')).first();  // Each product has multiple bands for describing aspects of land cover. print('Bands:', nlcd2016.bandNames());  // Select the land cover band. var landcover = nlcd2016.select('landcover');  // Display land cover on the map. Map.setCenter(-95, 38, 5); Map.addLayer(landcover, null, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2016_REL:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2016_REL'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2016_REL.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2016_REL.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2016_REL(example: str = ''):
        """
        This dataset is partially superseded by newer datasets:  * Landcover and imperviousness data in   [USGS/NLCD_RELEASES/2019_REL/NLCD](USGS_NLCD_RELEASES_2019_REL_NLCD). * Rangeland data in   [USGS/NLCD_RELEASES/2019_REL/RCMAP/V4/COVER](USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER).  NLCD (the National Land Cover Database) is a 30-m Landsat-based land cover database spanning 8 epochs (1992, 2001, 2004, 2006, 2008, 2011, 2013 and 2016). 1992 data are primarily based on unsupervised classification of Landsat data, while the rest of the images rely on the imperviousness data layer for the urban classes and on a decision-tree classification for the rest. The 1992 image is not directly comparable to any later editions of NLCD.  This dataset has one image for the continental US for each of the eight epochs, plus separate images for Alaska, Hawaii, and Puerto Rico in 2001, 2011, and 2016. (They could not be merged in due to having a different projection from the continental US images.)  Note that the impervious layers and tree cover layers for Alaska 2011 only have data for parts of Alaska.  For the impervious layer, only the parts of Kenai Peninsula Borough and Anchorage Municipality are available. Tree cover is only available on a strip along the coast from the southern tip of the Alaskan Panhandle up through the Kenai Peninsula, plus Kodiak Island.  NLCD 2016 Rangeland Component products characterize the percentage of each 30-meter pixel in the Western United States covered by shrub, herbaceous, bare ground, litter, sagebrush, big sagebrush and annual herbaceous, along with estimating shrub height and sagebrush height. These products have been produced by USGS in collaboration with the Bureau of Land Management.  NLCD products are created by the Multi-Resolution Land Characteristics (MRLC) Consortium, a partnership of federal agencies led by the U.S. Geological Survey. 
        :param example: // Import the NLCD collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2016_REL');  // The collection contains images for multiple years and regions in the USA. print('Products:', dataset.aggregate_array('system:index'));  // Filter the collection to the 2016 product. var nlcd2016 = dataset.filter(ee.Filter.eq('system:index', '2016')).first();  // Each product has multiple bands for describing aspects of land cover. print('Bands:', nlcd2016.bandNames());  // Select the land cover band. var landcover = nlcd2016.select('landcover');  // Display land cover on the map. Map.setCenter(-95, 38, 5); Map.addLayer(landcover, null, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2019_REL_NLCD:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2019_REL_NLCD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2019_REL_NLCD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2019_REL_NLCD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2019_REL_NLCD(example: str = ''):
        """
        NLCD (the National Land Cover Database) is a 30-m Landsat-based land cover database spanning 8 epochs (2001, 2004, 2006, 2008, 2011, 2013, 2016, and 2019). A ninth epoch for 2021 is also available [here](USGS_NLCD_RELEASES_2021_REL_NLCD). The images rely on the imperviousness data layer for the urban classes and on a decision-tree classification for the rest.  This dataset has one image for the continental US for each epoch. Alaska, Hawaii, and Puerto Rico data can be found in the previous [2016 NLCD release](USGS_NLCD_RELEASES_2016_REL).  NLCD products are created by the Multi-Resolution Land Characteristics (MRLC) Consortium, a partnership of federal agencies led by the U.S. Geological Survey. 
        :param example: // Import the NLCD collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2019_REL/NLCD');  // The collection contains images for multiple years and regions in the USA. print('Products:', dataset.aggregate_array('system:index'));  // Filter the collection to the 2016 product. var nlcd2016 = dataset.filter(ee.Filter.eq('system:index', '2016')).first();  // Each product has multiple bands for describing aspects of land cover. print('Bands:', nlcd2016.bandNames());  // Select the land cover band. var landcover = nlcd2016.select('landcover');  // Display land cover on the map. Map.setCenter(-95, 38, 5); Map.addLayer(landcover, null, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2019_REL_RCMAP_V4_COVER(example: str = ''):
        """
        Rangeland ecosystems in the western United States have a dynamic response to climate change, fire, and other anthropogenic disturbances. The Rangeland Condition, Monitoring, Assessment, and Projection (RCMAP) product aims to capture this response by quantifying the percent cover of rangeland components, associated error, and trends across the western U.S. using Landsat imagery from 1985-2020.  RCMAP quantifies the percent cover of components across the western U.S. rangelands (after Rigge et al. 2020) using Landsat imagery from 1985-2020. The RCMAP timeseries consists of eight fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush and shrub, and the temporal trends of each. The four primary components (bare ground, shrub, litter, and herbaceous) are designed to sum to 100% in each pixel when added to tree canopy cover. The secondary components annual herbaceous and perennial herbaceous are subsets of the primary component herbaceous, while non-sagebrush shrub and sagebrush are subsets of shrub. Secondary components cannot have cover greater than their respective primary component. One year, 2012, was excluded from the timeseries due to a lack of quality imagery.  MRLC developed an automated method to identify change in spectral conditions between each year in the Landsat archive and the circa 2016 base map. Regression tree models were trained from the unchanged portions of each year in the time series. Post-processing models corrected post-burn trajectories and eliminated noise and illogical change in the predictions. The current generation of RCMAP has been improved with more training data, regional-scale Landsat composites, and more robust change detection. MRLC assessed the temporal patterns in each component with a linear model and structural change method which determines break points in the timeseries using an 8-year temporal moving window. The linear and structural change methods generally agreed on gross patterns of change, but the latter found breaks more often with most pixels having at least one break point. Data provide spatiotemporal information on the occurrence of breaks, but even more critically, attribute those change events to specific component(s). The spatially, temporally, and thematically (i.e., multi-component) detailed specific information on rangeland condition can contribute to understanding major patterns of change at local, regional, and continental levels.  See also:  * Rigge, M., C. Homer, L. Cleeves, D. K. Meyer, B. Bunde, H. Shi, G. Xian,   S. Schell, and M. Bobo. 2020. Quantifying western U.S. rangelands as   fractional components with multi-resolution remote sensing and in situ   data. Remote Sensing 12.   [doi:10.3390/rs12030412](https://doi.org/10.3390/rs12030412)  * Rigge, M., C. Homer, H. Shi, D. Meyer, B.   Bunde, B. Granneman, K. Postma, P. Danielson, A. Case, and G. Xian. 2021.   Rangeland Fractional Components Across the Western United States   from 1985 to 2018. Remote Sensing 13:813.   [doi:10.3390/rs13040813](https://doi.org/10.3390/rs13040813) 
        :param example: // Import the NLCD RCMAP collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2019_REL/RCMAP/V4/COVER');  // Filter the collection to the 2016 product. var rcmap2016 = dataset.filter(ee.Filter.eq('system:index', '2016')).first();  // Each product has multiple bands for different rangeland categories. print('Bands:', rcmap2016.bandNames());  // Select the rangeland_annual_herbaceous band. var landcover = rcmap2016.select('rangeland_annual_herbaceous');  var vis = {   'palette': [       '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687', 'e0d281', 'ddd077', 'd6cc6d',       'd3c667', 'd0c55e', 'cfc555', 'c6bd4f', 'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17',       'aaaa0a', 'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700', '82aa00', '7aaa00',       '77aa00', '70aa00', '6caa00', '67aa00', '5fa700', '57a700', '52a700', '4fa700', '4aa700', '42a700',       '3ca700', '37a700', '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200', '2d9100',       '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200', '297d00', '297a00', '297900', '277700',       '247400', '247000', '29700f', '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',       '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f', '2f62ac', '2c5fb7', '245ec4',       '1e5ed0', '115cdd', '005ae0', '0057dd', '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8',       '0142b0', '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a', '012d85', '012c82', '01297a',   ] };  // Display land cover on the map. Map.setCenter(-114, 38, 6); Map.addLayer(landcover, vis, 'Rangeland Annual Herbaceous %'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_COVER:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_COVER'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_COVER.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_COVER.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_COVER(example: str = ''):
        """
        The RCMAP (Rangeland Condition Monitoring Assessment and Projection) dataset quantifies the percent cover of rangeland components across the western U.S. using Landsat imagery from 1985 to 2021. The RCMAP product suite consists of nine fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, and tree, in addition to the temporal trends of each component. Several enhancements were made to the RCMAP process relative to prior generations. First, they have trained time-series predictions directly from 331 high-resolution sites collected from 2013 to 2018 from Assessment, Inventory, and Monitoring (AIM) instead of using the 2016 "base" map as an intermediary. This removes one level of model error and allows the direct association of high-resolution derived training data to the corresponding year of Landsat imagery. They have incorporated all available (as of 10/1/22) Bureau of Land Management (BLM), Assessment, Inventory, and Monitoring (AIM), and Landscape Monitoring Framework (LMF) observations. LANDFIRE public reference database training observations spanning from 1985 to 2015 have been added. Neural network models with Keras tuner optimization have replaced Cubist models as the classifier. They have added a tree canopy cover component.  The study area has expanded to include all of California, Oregon, and Washington; in prior generations, landscapes to the west of the Cascades were excluded. Additional spectral indices have been added as predictor variables, tasseled cap wetness, brightness, and greenness. Geographic location and elevation above sea level have been added as predictor variables. CCDC-Synthetic Landsat images were obtained for 6 monthly periods for each region and were added as predictors. These data augment the phenologic detail of the 2 seasonal Landsat composites.  Post-processing has been improved with updated fire recovery equations stratified by ecosystem resistance and resilience (R and R) classes (Maestas and Campbell, 2016) to stratify recovery rates. Ecosystem R and R maps are only available for the sagebrush biome.  They intersected classes with 1985 to 2020 average water year precipitation to identify precipitation thresholds corresponding to R and R classes. Outside of the sagebrush biome, precipitation was used to produce R and R equivalent (low, medium, high). Due to the fast recovery following fire in California chaparral (e.g., Keeley and Keeley, 1981, Storey et al., 2016), they used EPA level 3 ecoregions to define a 4th R and R zone. Recovery rates are based on (Arkle et al., (in press)) who evaluated the recovery of plant functional groups in 1,278 post-fire rehab plots by time since disturbance stratified by ecosystem resistance and resilience. They have expanded this analysis by evaluated postfire-recovery in all AIM and LMF data across the West to establish maximum sage, shrub, and tree cover by time-since fire. Recovery limits in California follow (Keeley and Keeley, 1981 and Storey et al., 2016). Second, post-processing has been enhanced through a revised noise detection model. For each pixel, they fit a third order polynomial model for each component cover time-series. Observations with a z-score more than 2 standard deviations from the mean are removed, and a new third order polynomial model (i.e., cleaned fit) is fit to observations within this threshold. Finally, looking again at all observations, those observations with a z-score more than 2 standard deviations from the mean of the cleaned fit are replaced with the mean of the prior and subsequent year component cover values.  The mapping area included eight regions which were subsequently mosaicked for all nine components.  These data can be used to answer critical questions regarding the influence of climate change and the suitability of management practices. Component products can be downloaded from the [Multi-Resolution Land Characteristics Consortium](https://www.mrlc.gov/data).  See also:  * Rigge, M., C. Homer, L. Cleeves, D. K. Meyer, B. Bunde, H. Shi, G. Xian,   S. Schell, and M. Bobo. 2020. Quantifying western U.S. rangelands as   fractional components with multi-resolution remote sensing and in situ   data. Remote Sensing 12.   [doi:10.3390/rs12030412](https://doi.org/10.3390/rs12030412)  * Rigge, M., C. Homer, H. Shi, D. Meyer, B.   Bunde, B. Granneman, K. Postma, P. Danielson, A. Case, and G. Xian. 2021.   Rangeland Fractional Components Across the Western United States   from 1985 to 2018. Remote Sensing 13:813.   [doi:10.3390/rs13040813](https://doi.org/10.3390/rs13040813) 
        :param example: // Import the NLCD RCMAP collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2019_REL/RCMAP/V5/COVER');  // Filter the collection to the 2019 product. var nlcd2019 = dataset.filter(ee.Filter.eq('system:index', '2019')).first();  // Each product has multiple bands for different rangeland categories. print('Bands:', nlcd2019.bandNames());  // Select the rangeland_annual_herbaceous band. var percentCover = nlcd2019.select('rangeland_annual_herbaceous');  var vis = {   // Map 0..100.   'palette': [     '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',     'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',     'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',     'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',     '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',     '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',     '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',     '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',     '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',     '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',     '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',     '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',     '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',     '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',     '012d85', '012c82', '01297a'   ] };  // Display the image on the map. Map.setCenter(-114, 38, 6); Map.addLayer(percentCover, vis, 'Rangeland Annual Herbaceous %'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS(example: str = ''):
        """
        The RCMAP product suite includes nine fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, and tree. It also includes rule-based error maps and the temporal trends of each component. Data characterize the percentage of each 30-meter pixel in the Western United States covered by each component for each year from 1985-2021, providing change information for 36 years.  The temporal patterns in each RCMAP component are assessed with two approaches: 1) linear trends and 2) a breaks and stable states method with an 8-year temporal moving window based on structural change at the pixel level. Linear trend products include slope and p-value calculated from least squares linear regression. The slope represents the average percent cover change per year over the time series and the p-value reflects the confidence of change in each pixel. The structural change method partitions the time series into segments of similar slope values, with statistically significant break-points indicating perturbations to the prior trajectory. The break point trends analysis suite relies on structural break methods, resulting in the identification of the number and timing of breaks in the following statistics are produced: 1) for each component, each year, the presence/absence of breaks, 2) the slope, p-value, and standard error of the segment occurring in each year, 3) the overall model R2 (quality of model fit to the temporal profile), and 4) an index, Total Change Intensity. This index reflects the total amount of change occurring across components in that pixel. The linear and structural change methods generally agreed on patterns of change, but the latter found breaks more often, with at least one break point in most pixels. The structural change model provides more robust statistics on the significant minority of pixels with non-monotonic trends, while detrending some interannual signal potentially superfluous from a long-term perspective. 
        :param example: // Import the NLCD RCMAP TRENDS image. var dataset = ee.Image('USGS/NLCD_RELEASES/2019_REL/RCMAP/V5/TRENDS'); var trends = dataset.select('annual_herbaceous_break_point'); var vis = {   min: [0],   max: [5],   'palette': [     '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',     'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',     'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',     'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',     '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',     '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',     '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',     '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',     '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',     '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',     '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',     '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',     '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',     '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',     '012d85', '012c82', '01297a'   ] }; // Display the image on the map. Map.setCenter(-114, 38, 6); Map.addLayer(trends, vis, 'annual herbaceous breakpoint in integer');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS_YEAR:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS_YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS_YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS_YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2019_REL_RCMAP_V5_TRENDS_YEAR(example: str = ''):
        """
        This collection includes RCMAP yearly products from 1985 through 2021. The RCMAP product suite includes nine fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, and tree. It also includes rule-based error maps and the temporal trends of each component. Data characterize the percentage of each 30-meter pixel in the Western United States covered by each component for each year from 1985-2021, providing change information for 36 years.  The temporal patterns in each RCMAP component are assessed with two approaches: 1) linear trends and 2) a breaks and stable states method with an 8-year temporal moving window based on structural change at the pixel level. Linear trend products include slope and p-value calculated from least squares linear regression. The slope represents the average percent cover change per year over the time series and the p-value reflects the confidence of change in each pixel. The structural change method partitions the time series into segments of similar slope values, with statistically significant break-points indicating perturbations to the prior trajectory. The break point trends analysis suite relies on structural break methods, resulting in the identification of the number and timing of breaks in the following statistics are produced: 1) for each component, each year, the presence/absence of breaks, 2) the slope, p-value, and standard error of the segment occurring in each year, 3) the overall model R2 (quality of model fit to the temporal profile), and 4) an index, Total Change Intensity. This index reflects the total amount of change occurring across components in that pixel. The linear and structural change methods generally agreed on patterns of change, but the latter found breaks more often, with at least one break point in most pixels. The structural change model provides more robust statistics on the significant minority of pixels with non-monotonic trends, while detrending some interannual signal potentially superfluous from a long-term perspective. 
        :param example: // Import the NLCD RCMAP TRENDS YEAR collection. var image = ee.ImageCollection(   'USGS/NLCD_RELEASES/2019_REL/RCMAP/V5/TRENDS_YEAR' ).select('annual_herbaceous_segment_pvalue');  var vis = {   min: [0],   max: [100],   palette: [   '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',   'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',   'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',   'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',   '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',   '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',   '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',   '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',   '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',   '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',   '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',   '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',   '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',   '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',   '012d85', '012c82', '01297a'   ] };  // Display the image on the map. Map.setCenter(-114, 38, 6); Map.addLayer(image, vis, 'Annual herbaceous segment pvalue'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2020_REL_NALCMS:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2020_REL_NALCMS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2020_REL_NALCMS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2020_REL_NALCMS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2020_REL_NALCMS(example: str = ''):
        """
        The 2020 North American Land Cover 30-meter dataset was produced as part of the North American Land Change Monitoring System (NALCMS), a trilateral effort between Natural Resources Canada, the United States Geological Survey, and three Mexican organizations including the National Institute of Statistics and Geography (Instituto Nacional de Estad&iacute;stica y Geograf&iacute;a), National Commission for the Knowledge and Use of the Biodiversity (Comisi&oacute;n Nacional Para el Conocimiento y Uso de la Biodiversidad), and the National Forestry Commission of Mexico (Comisi&oacute;n Nacional Forestal).  The collaboration is facilitated by the Commission for Environmental Cooperation, an international organization created by the Canada, Mexico, and United States governments under the North American Agreement on Environmental Cooperation to promote environmental collaboration between the three countries.  The general objective of NALCMS is to devise, through collective effort, a harmonized multi-scale land cover monitoring approach which ensures high accuracy and consistency in monitoring land cover changes at the North American scale and which meets each country's specific requirements.  This 30-meter dataset of North American Land Cover reflects land cover information for 2020 from Mexico and Canada, 2019 over the conterminous United States and 2021 over Alaska.  Each country developed its own classification method to identify Land Cover classes and then provided an input layer to produce a continental Land Cover map across North America. Canada, Mexico, and the United States developed their own 30-meter land cover products; see specific sections on data generation below.  The main inputs for image classification were 30-meter Landsat 8 Collection 2 Level 1 data in the three countries (Canada, the United States and Mexico). Image selection processes and reduction to specific spectral bands varied among the countries due to study-site-specific requirements.  While Canada selected most images from the year 2020 with a few from 2019 and 2021, the Conterminous United States employed mainly images from 2019, while Alaska land cover maps are mainly based on the use of images from 2021. The land cover map for Mexico was based on land cover change detection between 2015 and 2020 Mexico Landsat 8 mosaics.  In order to generate a seamless and consistent land cover map of North America, national maps were generated for Canada by the CCRS; for Mexico by CONABIO, INEGI, and CONAFOR; and for the United States by the USGS. Each country chose their own approaches, ancillary data, and land cover mapping methodologies to create national datasets. This North America dataset was produced by combining the national land cover datasets.  The integration of the three national products merged four Land Cover map sections, Alaska, Canada, the conterminous United States and Mexico.  See also:  * Natural Resources Canada has North American Land Cover information   available online at   [https://open.canada.ca/data/en/dataset/ee1580ab-a23d-4f86-a09b-79763677eb47](   https://open.canada.ca/data/en/dataset/ee1580ab-a23d-4f86-a09b-79763677eb47)  * The National Commission for the Knowledge and Use of Biodiversity has   North American Land Cover information available online at   [https://www.biodiversidad.gob.mx/monitoreo/cobertura-suelo](     https://www.biodiversidad.gob.mx/monitoreo/cobertura-suelo)  * The U.S. Geological Survey has North American Land Cover information   available online at [www.mrlc.gov](https://www.mrlc.gov) 
        :param example: // Import the NALCMS image. var image = ee.Image('USGS/NLCD_RELEASES/2020_REL/NALCMS');  Map.addLayer(   image,   {     palette: [       '033e00',  // 1  Temperate or sub-polar needleleaf forest       '939b71',  // 2  Sub-polar taiga needleleaf forest       '196d12',  // 3  Tropical or sub-tropical broadleaf evergreen forest       '1fab01',  // 4  Tropical or sub-tropical broadleaf deciduous forest       '5b725c',  // 5  Temperate or sub-polar broadleaf deciduous forest       '6b7d2c',  // 6  Mixed forest       'b29d29',  // 7  Tropical or sub-tropical shrubland       'b48833',  // 8  Temperate or sub-polar shrubland       'e9da5d',  // 9  Tropical or sub-tropical grassland       'e0cd88',  // 10  Temperate or sub-polar grassland       'a07451',  // 11  Sub-polar or polar shrubland-lichen-moss       'bad292',  // 12  Sub-polar or polar grassland-lichen-moss       '3f8970',  // 13  Sub-polar or polar barren-lichen-moss       '6ca289',  // 14  Wetland       'e6ad6a',  // 15  Cropland       'a9abae',  // 16  Barren land       'db2126',  // 17  Urban and built-up       '4c73a1',  // 18  Water       'fff7fe',  // 19  Snow and ice     ],    min: 1,    max: 19,   },   'NALCMS Land Cover');  Map.setCenter(-114, 38, 6); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2021_REL_NLCD:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2021_REL_NLCD'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2021_REL_NLCD.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2021_REL_NLCD.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2021_REL_NLCD(example: str = ''):
        """
        The U.S. Geological Survey (USGS), in partnership with several federal agencies, has now developed and released seven National Land Cover Database (NLCD) products: NLCD 1992, 2001, 2006, 2011, 2016, 2019, and 2021. Beginning with the 2016 release, land cover products were created for two-to-three-year intervals between 2001 and the most recent year. These products provide spatially explicit and reliable information on the Nation’s land cover and land cover change. NLCD continues to provide innovative, consistent, and robust methodologies for production of a multi-temporal land cover and land cover change database.  The NLCD 2021 release is update based, so the Land Cover and Impervious Surface products released in [2019](USGS_NLCD_RELEASES_2019_REL_NLCD) are unchanged and used directly with NLCD 2021 for change analysis though the NLCD timespan. Science products and the change index are updated and will need to be reacquired to contain the additional 2021 change. These new products use a streamlined compositing process for assembling and preprocessing Landsat imagery and geospatial ancillary datasets; a temporally, spectrally, and spatially integrated land cover change analysis strategy; a theme-based post-classification protocol for generating land cover and change products; a continuous fields biophysical parameters modeling method; and a scripted operational system. The overall accuracy of the 2019 Level I land cover was 91%. Results from this study confirm the robustness of this comprehensive and highly automated procedure for NLCD 2021 operational mapping (see [doi:10.1080/15481603](https://doi.org/10.1080/15481603.2023.2181143) for the latest accuracy assessment publication). Questions about the NLCD 2021 land cover product can be directed to the NLCD 2021 land cover mapping team at USGS EROS, Sioux Falls, SD (605) 594-6151 or mrlc@usgs.gov. See included spatial metadata for more details.  Please see National Land Cover Database (NLCD) [2019 NLCD release](https://doi.org/10.5066/P9KZCM54) for the 2019 release of NLCD which is used with the 2021 release for comparisons through the years. Also refer to the larger NLCD Community page for all things NLCD related National Land Cover Database (NLCD) [NLCD Community Page](https://www.sciencebase.gov/catalog/item/6345b637d34e342aee0863aa). 
        :param example: // Import the NLCD collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/NLCD');  // The collection contains images for the 2021 year release and the full suite // of products. print('Products:', dataset.aggregate_array('system:index'));  // Filter the collection to the 2021 product. var nlcd2021 = dataset.filter(ee.Filter.eq('system:index', '2021')).first();  // Each product has multiple bands for describing aspects of land cover. print('Bands:', nlcd2021.bandNames());  // Select the land cover band. var landcover = nlcd2021.select('landcover');  // Display land cover on the map. Map.setCenter(-95, 38, 5); Map.addLayer(landcover, null, 'Landcover'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2021_REL_TCC_v2021_4:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2021_REL_TCC_v2021_4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2021_REL_TCC_v2021-4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2021_REL_TCC_v2021-4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2021_REL_TCC_v2021_4(example: str = ''):
        """
        This product is part of the Tree Canopy Cover (TCC) data suite. It includes modeled TCC, standard error (SE), and  National Land Cover Database's (NLCD) TCC data for each year. TCC data produced by the the United States Department  of Agriculture, Forest Service (USFS) are included in the Multi-Resolution Land Characteristics (MRLC) consortium  that is part of the National Land Cover Database (NLCD) project managed by the United States (US) Geological Survey (USGS).  The Science TCC product and NLCD TCC are remote sensing-based map output produced by the USFS. The objecive of TCC Science  and NLCD TCC are to develop a consistent approach using the latest technology and advancements in TCC mapping to produce a  "best available" map of TCC across the Conterminous United States (CONUS) and southeast Alaska, Hawaii and  Puerto Rico-US Virgin Islands (OCONUS).  Model outputs include Science TCC, Science SE and NLCD TCC. Science TCC and SE include data from 2008 through 2021.  NLCD TCC include data from 2011 through 2021, with data fully masked in 2008, 2009 and 2010.   *Science TCC is the raw direct model outputs.  *Science SE is the model standard deviation of the predicted values from all regression trees.   *The NLCD TCC product undergoes further post processing applied to the annual Science TCC images,  which includes several masking (water and non-tree agriculture), filtering, and minimum-mapping unit (MMU) routines,  as well as processes that reduce interannual noise and return longer duration trends.    Each image includes a data mask band that has three values representing areas of no data (0), mapped tree canopy cover(1),  and non-processing area (2). The non-processing areas are pixels in the study area with no cloud or cloud shadow-free data. No data and non-processing area pixels are masked in TCC and SE images.  Due to CONUS size and wide variety of ecotones, CONUS modeling was broken up into 54 480x480 km tiles. For each tile,  a unique random forest model was built using 2011 fitted LandTrendr, 2011 CDL, and terrain data. All reference data  that were part of the 70% available for model calibration that intersected tiles within a 5x5 window around the center  tile were used to train the random forest model. That model was then applied to the center tile. For OCONUS, one model  was applied to each study area, and no tiles were used.   Predictor layers for the TCC model include outputs from the LandTrendr and terrain information. These components are all accessed and processed using Google Earth Engine (Gorelick et al., 2017).  To produce annual composites for LandTrendr, USGS Collection 2 Landsat Tier 1 and Sentinel 2A,  2B Level-1C top of atmosphere reflectance data were used. The cFmask cloud masking algorithm  (Foga et al., 2017), which is an implementation of Fmask 2.0 (Zhu and Woodcock, 2012)  (Landsat-only), cloudScore (Chastain et al., 2019) (Landsat-only), and s2cloudless (Sentinel-Hub, 2021) (Sentinel 2-only) are used to mask clouds, while TDOM (Chastain et al., 2019) is used to mask cloud shadows (Landsat and Sentinel 2). For LandTrendr, the annual medoid is then computed to summarize cloud and cloud shadow-free values from each year into a single composite.  The composite time series is temporally segmented using LandTrendr (Kennedy et al., 2010; Kennedy et al., 2018; Cohen et al., 2018).  The raw composite values, LandTrendr fitted values, pair-wise differences, segment duration, change magnitude, and slope, along with elevation, slope, sine of  aspect, and cosine of aspect from the 10 m USGS 3D. Elevation Program (3DEP) data  (U.S. Geological Survey, 2019), are used as independent predictor variables in a Random  Forest (Breiman, 2001) model.  Reference data are collected from USFS Forest Inventory and Analysis (FIA) photo-interpreted  TCC data, and used to make wall-to wall TCC predictions on a pixel-wise basis.   **Additional Resources**  Please see the [TCC Methods Brief](https://data.fs.usda.gov/geodata/rastergateway/treecanopycover/docs/TCC_v2021-4_Methods.pdf) for more detailed information regarding methods and accuracy assessment, or the [TCC Geodata Clearinghouse](https://data.fs.usda.gov/geodata/rastergateway/treecanopycover/) for data downloads, metadata, and support documents.  Contact [sm.fs.tcc@usda.gov](mail to:sm.fs.tcc@usda.gov) with any questions or specific data requests.  * **Breiman, L., 2001.** Random Forests. In Machine Learning. *Springer*, 45: 5-32 [doi:10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)  * **Chastain, R., Housman, I., Goldstein, J., Finco, M., and Tenneson, K., 2019.** Empirical cross sensor comparison of Sentinel-2A and 2B MSI, Landsat-8 OLI, and Landsat-7 ETM top of atmosphere spectral characteristics over the conterminous United States. In Remote Sensing of Environment. *Science Direct*, 221: 274-285 [doi:10.1016/j.rse.2018.11.012](https://doi.org/10.1016/j.rse.2018.11.012)  * **Cohen, W. B., Yang, Z., Healey, S. P., Kennedy, R. E., and Gorelick, N., 2018.** A LandTrendr multispectral ensemble for forest disturbance detection. In Remote Sensing of Environment. *Science Direct*, 205: 131-140 [doi:10.1016/j.rse.2017.11.015](https://doi.org/10.1016/j.rse.2017.11.015)  * **Foga, S., Scaramuzza, P.L., Guo, S., Zhu, Z., Dilley, R.D., Beckmann, T., Schmidt, G.L., Dwyer, J.L., Hughes, M.J., Laue, B., 2017.** Cloud detection algorithm comparison and validation for operational Landsat data products. In Remote Sensing of Environment.  *Science Direct*, 194: 379-390 [doi:10.1016/j.rse.2017.03.026](http://doi.org/10.1016/j.rse.2017.03.026)  * **U.S. Geological Survey, 2019.** USGS 3D Elevation Program Digital Elevation  Model, accessed August 2022 at https://developers.google.com/earth-engine/datasets/catalog/USGS_3DEP_10m  * **Kennedy, R. E., Yang, Z., and Cohen, W. B., 2010.** Detecting trends in forest disturbance and recovery using yearly Landsat time series: 1. LandTrendr - Temporal segmentation algorithms. In Remote Sensing of Environment. *Science Direct*, 114(12): 2897-2910 [doi:10.1016/j.rse.2010.07.008](https://doi.org/10.1016/j.rse.2010.07.008)  * **Kennedy, R., Yang, Z., Gorelick, N., Braaten, J., Cavalcante, L., Cohen, W., and Healey, S., 2018.** Implementation of the LandTrendr Algorithm on Google Earth Engine. In Remote Sensing. *MDPI*, 10(5): 691 [doi:10.3390/rs10050691](https://doi.org/10.3390/rs10050691)  * **Sentinel-Hub, 2021.** Sentinel 2 Cloud Detector. [Online]. Available at: [https://github.com/sentinel-hub/sentinel2-cloud-detector](https://github.com/sentinel-hub/sentinel2-cloud-detector)  * **Zhu, Z., and Woodcock, C. E., 2012.**.  Object-based cloud and cloud shadow detection in Landsat imagery. In Remote Sensing of Environment. *Science Direct*,  118: 83-94 [doi:10.1016/j.rse.2011.10.028](https://doi.org/10.1016/j.rse.2011.10.028) 
        :param example: // Import the tree canopy cover collection var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/TCC/v2021-4');  //Filter collection to 2021 and CONUS study area  var tcc = dataset.filter(ee.Filter.calendarRange(2021, 2021,'year'))  // range: [2008, 2021]                .filter('study_area == "CONUS"')  // or "AK", "PRUSVI", "HAWAII"                 .first();  // TCC palette var tcc_palette = [     'CDA066',     'D7C29E',     'C2D096',     'B7D692',     'ADDD8E',     '78C679',     '5CB86B',     '41AB5D',     '39A156',     '329750',     '238443',     '11763D',     '006837',     '004529'   ]  // SE palette  var se_palette = [     '000000',     'FFFFFF',     ]                 // Display images on map  Map.addLayer(tcc.select('data_mask'), {min:0,max:2}, 'Data Mask',false); Map.addLayer(tcc.select('Science_Percent_Tree_Canopy_Cover'), {min:0,max:60,palette:tcc_palette}, 'Science Percent Tree Canopy Cover'); Map.addLayer(tcc.select('Science_Percent_Tree_Canopy_Cover_Standard_Error'), {min:0,max:4000,palette:se_palette}, 'Science Percent Tree Canopy Cover Standard Error'); Map.addLayer(tcc.select('NLCD_Percent_Tree_Canopy_Cover'), {min:0,max:60,palette:tcc_palette}, 'NLCD Percent Tree Canopy Cover');  Map.setCenter(-98.58, 38.14, 4); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_COVER:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_COVER'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_COVER.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_COVER.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_COVER(example: str = ''):
        """
        'The RCMAP (Rangeland Condition Monitoring Assessment and Projection) dataset quantifies the percent cover of rangeland components across western North America using Landsat imagery from 1985-2023. The RCMAP product suite consists of ten fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, tree, and shrub height in addition to the temporal trends of each component. Several enhancements were made to the RCMAP process relative to prior generations. First, high-resolution training was revised using an improved neural-net classifier and modelling approach. These data serve as foundation to the RCMAP approach. The training database was further improved by incorporating additional datasets. Next, the Landsat compositing approach was improved to better capture the range of conditions from across each year and through time. These composites are based on Collection 2 Landsat data with improved geolocation accuracy and dynamic range. Finally, the Canadian portion of the sagebrush biome was included, which expanded the study area by 29,199 km2.  Processing efficiency has been increased using open-source software and USGS High-Performance Computing (HPC) resources. The mapping area included eight regions which were subsequently mosaicked. These data can be used to answer critical questions regarding the influence of climate change and the suitability of management practices. Component products can be downloaded at [Multi-Resolution Land Characteristics Consortium](https://www.mrlc.gov/data).  See also:  * Rigge, M., H. Shi, C. Homer, P. Danielson, and B. Granneman. 2019.   Long-term trajectories of fractional component change in the Northern   Great Basin, USA. Ecosphere 10(6):e02762.   [doi:10.1002/ecs2.2762](https://doi.org/10.1002/ecs2.2762)  * Rigge, M., C. Homer, L. Cleeves, D. K. Meyer, B. Bunde, H. Shi, G. Xian,   S. Schell, and M. Bobo. 2020. Quantifying western U.S. rangelands as   fractional components with multi-resolution remote sensing and in situ   data. Remote Sensing 12.   [doi:10.3390/rs12030412](https://doi.org/10.3390/rs12030412)  * Rigge, M., C. Homer, H. Shi, D. Meyer, B.   Bunde, B. Granneman, K. Postma, P. Danielson, A. Case, and G. Xian. 2021.   Rangeland Fractional Components Across the Western United States   from 1985 to 2018. Remote Sensing 13:813.   [doi:10.3390/rs13040813](https://doi.org/10.3390/rs13040813).', 
        :param example: // Import the NLCD RCMAP collection. var dataset = ee.ImageCollection('USGS/NLCD_RELEASES/2023_REL/RCMAP/V6/COVER');  // Filter the collection to the 2021 product. var nlcd2021 = dataset.filter(ee.Filter.eq('system:index', '2021')).first();  // Each product has multiple bands for different rangeland categories. print('Bands:', nlcd2021.bandNames());  // Select the rangeland_annual_herbaceous band. var percentCover = nlcd2021.select('rangeland_annual_herbaceous');  var vis = {   // Map 0..100.   'palette': [     '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',     'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',     'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',     'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',     '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',     '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',     '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',     '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',     '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',     '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',     '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',     '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',     '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',     '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',     '012d85', '012c82', '01297a'   ] };  // Display the image on the map. Map.setCenter(-114, 38, 6); Map.addLayer(percentCover, vis, 'Rangeland Annual Herbaceous %'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS(example: str = ''):
        """
        The RCMAP (Rangeland Condition Monitoring Assessment and Projection) dataset quantifies the percent cover of rangeland components across western North America using Landsat imagery from 1985-2023. The RCMAP product suite consists of ten fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, tree, and shrub height in addition to the temporal trends of each component. Several enhancements were made to the RCMAP process relative to prior generations. First, high-resolution training was revised using an improved neural-net classifier and modelling approach. These data serve as foundation to the RCMAP approach. The training database was further improved by incorporating additional datasets. Next, the Landsat compositing approach was improved to better capture the range of conditions from across each year and through time. These composites are based on Collection 2 Landsat data with improved geolocation accuracy and dynamic range. Finally, the Canadian portion of the sagebrush biome was included, which expanded the study area by 29,199 km2.  Processing efficiency has been increased using open-source software and USGS High-Performance Computing (HPC) resources. The mapping area included eight regions which were subsequently mosaicked. These data can be used to answer critical questions regarding the influence of climate change and the suitability of management practices. Component products can be downloaded at [Multi-Resolution Land Characteristics Consortium](https://www.mrlc.gov/data).  The temporal patterns were assessed in each RCMAP component with two approaches, 1) linear trends and 2) a breaks and stable states method with an 8-year temporal moving window based on structural change at the pixel level. Linear trend products include slope and p-value calculated from least squares linear regression. The slope represents the average percent cover change per year over the times-series and the p-value reflects the confidence of change in each pixel. The structural change method partitions the time-series into segments of similar slope values, with statistically significant breakpoints indicating perturbations to the prior trajectory. The break point trends analysis suite relies on structural break methods, resulting in the identification of the number and timing of breaks in the time-series, and the significance of each segment. The following statistics were produced: 1) for each component, each year, the presence/absence of breaks, 2) the slope, p-value, and standard error of the segment occurring in each year, 3) the overall model R2 (quality of model fit to the temporal profile), and 4) an index, Total Change Intensity. This index reflects the total amount of change occurring across components in that pixel. The linear and structural change methods generally agreed on patterns of change, but the latter found breaks more often, with at least one break point in most pixels. The structural change model provides more robust statistics on the significant minority of pixels with non-monotonic trends, while detrending some interannual signal potentially superfluous from a long-term perspective. 
        :param example: // Import the NLCD RCMAP TRENDS image. var dataset = ee.Image('USGS/NLCD_RELEASES/2023_REL/RCMAP/V6/TRENDS'); var trends = dataset.select('annual_herbaceous_break_point'); var vis = {   min: [0],   max: [5],   'palette': [     '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',     'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',     'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',     'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',     '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',     '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',     '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',     '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',     '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',     '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',     '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',     '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',     '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',     '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',     '012d85', '012c82', '01297a'   ] }; // Display the image on the map. Map.setCenter(-114, 38, 6); Map.addLayer(trends, vis, 'annual herbaceous breakpoint in integer');
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS_YEAR:
    def __init__(self,):
        self.sensor = 'USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS_YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS_YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS_YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_NLCD_RELEASES_2023_REL_RCMAP_V6_TRENDS_YEAR(example: str = ''):
        """
        This collection includes RCMAP yearly products from 1985 through 2023. The RCMAP (Rangeland Condition Monitoring Assessment and Projection) dataset quantifies the percent cover of rangeland components across western North America using Landsat imagery from 1985-2023. The RCMAP product suite consists of ten fractional components: annual herbaceous, bare ground, herbaceous, litter, non-sagebrush shrub, perennial herbaceous, sagebrush, shrub, tree, and shrub height in addition to the temporal trends of each component. Several enhancements were made to the RCMAP process relative to prior generations. First, high-resolution training was revised using an improved neural-net classifier and modelling approach. These data serve as foundation to the RCMAP approach. The training database was further improved by incorporating additional datasets. Next, the Landsat compositing approach was improved to better capture the range of conditions from across each year and through time. These composites are based on Collection 2 Landsat data with improved geolocation accuracy and dynamic range. Finally, the Canadian portion of the sagebrush biome was included, which expanded the study area by 29,199 km2.  Processing efficiency has been increased using open-source software and USGS High-Performance Computing (HPC) resources. The mapping area included eight regions which were subsequently mosaicked. These data can be used to answer critical questions regarding the influence of climate change and the suitability of management practices. Component products can be downloaded at [Multi-Resolution Land Characteristics Consortium](https://www.mrlc.gov/data).  The temporal patterns were assessed in each RCMAP component with two approaches, 1) linear trends and 2) a breaks and stable states method with an 8-year temporal moving window based on structural change at the pixel level. Linear trend products include slope and p-value calculated from least squares linear regression. The slope represents the average percent cover change per year over the times-series and the p-value reflects the confidence of change in each pixel. The structural change method partitions the time-series into segments of similar slope values, with statistically significant breakpoints indicating perturbations to the prior trajectory. The break point trends analysis suite relies on structural break methods, resulting in the identification of the number and timing of breaks in the time-series, and the significance of each segment. The following statistics were produced: 1) for each component, each year, the presence/absence of breaks, 2) the slope, p-value, and standard error of the segment occurring in each year, 3) the overall model R2 (quality of model fit to the temporal profile), and 4) an index, Total Change Intensity. This index reflects the total amount of change occurring across components in that pixel. The linear and structural change methods generally agreed on patterns of change, but the latter found breaks more often, with at least one break point in most pixels. The structural change model provides more robust statistics on the significant minority of pixels with non-monotonic trends, while detrending some interannual signal potentially superfluous from a long-term perspective. 
        :param example: // Import the NLCD RCMAP TRENDS YEAR collection. var image = ee.ImageCollection(     'USGS/NLCD_RELEASES/2023_REL/RCMAP/V6/TRENDS_YEAR'   ).select('annual_herbaceous_segment_pvalue');      var vis = {     min: [0],     max: [100],     palette: [     '000000', 'f9e8b7', 'f7e3ac', 'f0dfa3', 'eedf9c', 'eada91', 'e8d687',     'e0d281', 'ddd077', 'd6cc6d', 'd3c667', 'd0c55e', 'cfc555', 'c6bd4f',     'c4ba46', 'bdb83a', 'bbb534', 'b7b02c', 'b0ad1f', 'adac17', 'aaaa0a',     'a3a700', '9fa700', '9aa700', '92a700', '8fa700', '87a700', '85a700',     '82aa00', '7aaa00', '77aa00', '70aa00', '6caa00', '67aa00', '5fa700',     '57a700', '52a700', '4fa700', '4aa700', '42a700', '3ca700', '37a700',     '37a300', '36a000', '369f00', '349d00', '339900', '339900', '2f9200',     '2d9100', '2d8f00', '2c8a00', '2c8800', '2c8500', '2c8400', '2b8200',     '297d00', '297a00', '297900', '277700', '247400', '247000', '29700f',     '2c6d1c', '2d6d24', '336d2d', '366c39', '376c44', '396a4a', '396a55',     '3a6a5f', '3a696a', '396774', '3a6782', '39668a', '376292', '34629f',     '2f62ac', '2c5fb7', '245ec4', '1e5ed0', '115cdd', '005ae0', '0057dd',     '0152d6', '0151d0', '014fcc', '014ac4', '0147bd', '0144b8', '0142b0',     '0141ac', '013da7', '013aa0', '01399d', '013693', '013491', '012f8a',     '012d85', '012c82', '01297a'     ]   };      // Display the image on the map.   Map.setCenter(-114, 38, 6);   Map.addLayer(image, vis, 'Annual herbaceous segment pvalue');   
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_SRTMGL1_003:
    def __init__(self,):
        self.sensor = 'USGS_SRTMGL1_003'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_SRTMGL1_003.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_SRTMGL1_003.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_SRTMGL1_003(example: str = ''):
        """
        The Shuttle Radar Topography Mission (SRTM, see [Farr et al. 2007](https://onlinelibrary.wiley.com/doi/10.1029/2005RG000183/full)) digital elevation data is an international research effort that obtained digital elevation models on a near-global scale. This SRTM V3 product (SRTM Plus) is provided by NASA JPL at a resolution of 1 arc-second (approximately 30m).  This dataset has undergone a void-filling process using open-source data (ASTER GDEM2, GMTED2010, and NED), as opposed to other versions that contain voids or have been void-filled with commercial sources. For more information on the different versions see the [SRTM Quick Guide](https://lpdaac.usgs.gov/documents/13/SRTM_Quick_Guide.pdf).  Documentation:  * [User's Guide](https://lpdaac.usgs.gov/documents/179/SRTM_User_Guide_V3.pdf)  * [General Documentation](https://lpdaac.usgs.gov/documents/13/SRTM_Quick_Guide.pdf)  * [Algorithm Theoretical Basis Document (ATBD)](https://doi.org/10.1029/2005RG000183) 
        :param example: var dataset = ee.Image('USGS/SRTMGL1_003'); var elevation = dataset.select('elevation'); var slope = ee.Terrain.slope(elevation); Map.setCenter(-112.8598, 36.2841, 10); Map.addLayer(slope, {min: 0, max: 60}, 'slope'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC02:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC02'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC02.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC02.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC02(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC02');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC04:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC04'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC04.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC04.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC04(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC04');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC06:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC06'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC06.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC06.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC06(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC06');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC08:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC08'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC08.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC08.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC08(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC08');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC10:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC10(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC10');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class USGS_WBD_2017_HUC12:
    def __init__(self,):
        self.sensor = 'USGS_WBD_2017_HUC12'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/USGS_WBD_2017_HUC12.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/USGS_WBD_2017_HUC12.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_USGS_WBD_2017_HUC12(example: str = ''):
        """
        The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection of hydrologic unit (HU) data consistent with the national criteria for delineation and resolution. It defines the areal extent of surface water drainage to a point except in coastal or lake front areas where there could be multiple outlets as stated by the [Federal Standards and Procedures for the National Watershed Boundary Dataset](https://pubs.usgs.gov/tm/11/a3). Watershed boundaries are determined solely upon science-based hydrologic principles, not favoring any administrative boundaries or special projects, nor particular program or agency. The intent of defining HUs for the WBD is to establish a baseline drainage boundary framework, accounting for all land and surface areas.  The HUs are delineated at 1:24,000-scale in the conterminous United States, 1:25,000-scale in Hawaii and the Caribbean, and 1:63,360-scale in Alaska, meeting the National Map Accuracy Standards (NMAS). WBDs are represented as polygons that define the boundary of the HUs. The HUs are given a Hydrologic Unit Code (HUC) that ranges from 2 digits to 12 digits. These codes describe where the unit is in the country and the level of the unit. The number of digits in a HUC is related to 6 levels of detail for the WBD: the lower level polygons cover larger areas than higher level ones. The higher the level, the more digits to the HUC, since previous levels are nested in it.  The WBD polygons attributes include HUCs, size (in the form of acres and square kilometers), name, downstream HUC, type of watershed, non-contributing areas, and flow modifications. WBD line attributes contain the highest level of hydrologic unit for each boundary, line source information and flow modifications.  | Name         | Level | Digit | HU Code | |--------------|-------|-------|---------| | Region       | 1     | 2     | 2       | | Subregion    | 2     | 4     | 4       | | Basin        | 3     | 6     | 6       | | Subbasin     | 4     | 8     | 8       | | Watershed    | 5     | 10    | 10      | | Subwatershed | 6     | 12    | 12      |  *Calculated by the data provider. 
        :param example: var dataset = ee.FeatureCollection('USGS/WBD/2017/HUC12');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-105.861, 39.529, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class UTOKYO_WTLAB_KBDI_v1:
    def __init__(self,):
        self.sensor = 'UTOKYO_WTLAB_KBDI_v1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/UTOKYO_WTLAB_KBDI_v1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/UTOKYO_WTLAB_KBDI_v1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_UTOKYO_WTLAB_KBDI_v1(example: str = ''):
        """
        Keetch-Byram Drought Index (KBDI) is a continuous reference scale for estimating the dryness of the soil and duff layers. The index increases for each day without rain (the amount of increase depends on the daily high temperature) and decreases when it rains. This system is based primarily on recent rainfall patterns. It is a measure of meteorological drought; it reflects water gain or loss within the soil.  The scale ranges from 0 (no moisture deficit) to 800 (extreme drought). The range of the index is determined by assuming that there is 20 cm of moisture in a saturated soil that is readily available to the vegetation (Keetch and Byram, 1968). KBDI is world widely used for drought monitoring for national weather forecast, wildfire prevention and usefully especially in regions with rain-fed crops. 
        :param example: var collection = ee.ImageCollection('UTOKYO/WTLAB/KBDI/v1')   .select('KBDI')   .filterDate('2019-01-01', '2019-01-10'); var bandViz = {   min: 0,   max: 800,   palette: [     '001a4d', '003cb3', '80aaff', '336600', 'cccc00', 'cc9900', 'cc6600',     '660033'   ] }; Map.addLayer(collection.mean(), bandViz, 'Keetch-Byram Drought Index'); Map.setCenter(120, 3, 3); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class VITO_PROBAV_C1_S1_TOC_100M:
    def __init__(self,):
        self.sensor = 'VITO_PROBAV_C1_S1_TOC_100M'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/VITO_PROBAV_C1_S1_TOC_100M.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/VITO_PROBAV_C1_S1_TOC_100M.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_VITO_PROBAV_C1_S1_TOC_100M(example: str = ''):
        """
        Proba-V is a satellite mission tasked to map land cover and vegetation growth. It was designed to provide continuity for the VGT optical instrument from the SPOT-4 and SPOT-5 missions.  The sensor collects data in three VNIR (visible and near-infrared) bands and one SWIR (short-wave infrared) spectral band with a 2250km field of view. Global images are produced every 2 days at 300m resolution, and a 100m image from nadir observations every 5 days. These images are later composited to produce this daily synthesis dataset. The description of the compositing and atmospheric correction procedures can be found in the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf).  The reflectances provided in this dataset are presented as Digital Count Numbers (DN) and must be converted according to the guidelines in Section 4.6.1 of the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf). 
        :param example: var dataset = ee.ImageCollection('VITO/PROBAV/C1/S1_TOC_100M')                   .filter(ee.Filter.date('2018-03-01', '2018-04-01')); var falseColor = dataset.select(['RED', 'NIR', 'BLUE']); var falseColorVis = {   min: 20.0,   max: 2000.0, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class VITO_PROBAV_C1_S1_TOC_333M:
    def __init__(self,):
        self.sensor = 'VITO_PROBAV_C1_S1_TOC_333M'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/VITO_PROBAV_C1_S1_TOC_333M.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/VITO_PROBAV_C1_S1_TOC_333M.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_VITO_PROBAV_C1_S1_TOC_333M(example: str = ''):
        """
        Proba-V is a satellite mission tasked to map land cover and vegetation growth. It was designed to provide continuity for the VGT optical instrument from the SPOT-4 and SPOT-5 missions.  The sensor collects data in three VNIR (visible and near-infrared) bands and one SWIR (short-wave infrared) spectral band with a 2250km field of view. Global images are produced every 2 days at 300m resolution, and a 100m image from nadir observations every 5 days. These images are later composited to produce this daily synthesis dataset. The description of the compositing and atmospheric correction procedures can be found in the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf).  The reflectances provided in this dataset are presented as Digital Count Numbers (DN) and must be converted according to the guidelines in Section 4.6.1 of the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf). 
        :param example: var dataset = ee.ImageCollection('VITO/PROBAV/C1/S1_TOC_333M')                   .filter(ee.Filter.date('2018-03-01', '2018-04-01')); var falseColor = dataset.select(['RED', 'NIR', 'BLUE']); var falseColorVis = {   min: 20.0,   max: 2000.0, }; Map.setCenter(17.93, 7.71, 2); Map.addLayer(falseColor, falseColorVis, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class VITO_PROBAV_S1_TOC_100M:
    def __init__(self,):
        self.sensor = 'VITO_PROBAV_S1_TOC_100M'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/VITO_PROBAV_S1_TOC_100M.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/VITO_PROBAV_S1_TOC_100M.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_VITO_PROBAV_S1_TOC_100M(example: str = ''):
        """
        Proba-V is a satellite mission tasked to map land cover and vegetation growth. It was designed to provide continuity for the VGT optical instrument from the SPOT-4 and SPOT-5 missions.  The sensor collects data in three VNIR (visible and near-infrared) bands and one SWIR (short-wave infrared) spectral band with a 2250km field of view. Global images are produced every 2 days at 300m resolution, and a 100m image from nadir observations every 5 days. These images are later composited to produce this daily synthesis dataset. The description of the compositing and atmospheric correction procedures can be found in the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf).  The reflectances provided in this dataset are presented as Digital Count Numbers (DN) and must be converted according to the guidelines in Section 4.6.1 of the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf). 
        :param example: var dataset = ee.ImageCollection('VITO/PROBAV/S1_TOC_100M');  var visualization = {   bands: ['RED', 'NIR', 'BLUE'],   min: 20.0,   max: 2000.0, };  Map.setCenter(17.93, 7.71, 2);  Map.addLayer(dataset, visualization, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class VITO_PROBAV_S1_TOC_333M:
    def __init__(self,):
        self.sensor = 'VITO_PROBAV_S1_TOC_333M'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/VITO_PROBAV_S1_TOC_333M.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/VITO_PROBAV_S1_TOC_333M.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_VITO_PROBAV_S1_TOC_333M(example: str = ''):
        """
        Proba-V is a satellite mission tasked to map land cover and vegetation growth. It was designed to provide continuity for the VGT optical instrument from the SPOT-4 and SPOT-5 missions.  The sensor collects data in three VNIR (visible and near-infrared) bands and one SWIR (short-wave infrared) spectral band with a 2250km field of view. Global images are produced every 2 days at 300m resolution, and a 100m image from nadir observations every 5 days. These images are later composited to produce this daily synthesis dataset. The description of the compositing and atmospheric correction procedures can be found in the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf).  The reflectances provided in this dataset are presented as Digital Count Numbers (DN) and must be converted according to the guidelines in Section 4.6.1 of the [user manual](https://publications.vito.be/2017-1333-probav-products-user-manual.pdf). 
        :param example: var dataset = ee.ImageCollection('VITO/PROBAV/S1_TOC_333M');  var visualization = {   bands: ['RED', 'NIR', 'BLUE'],   min: 20.0,   max: 2000.0, };  Map.setCenter(17.93, 7.71, 2);  Map.addLayer(dataset, visualization, 'False Color'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WCMC_biomass_carbon_density_v1_0:
    def __init__(self,):
        self.sensor = 'WCMC_biomass_carbon_density_v1_0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WCMC_biomass_carbon_density_v1_0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WCMC_biomass_carbon_density_v1_0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WCMC_biomass_carbon_density_v1_0(example: str = ''):
        """
        This dataset represents above- and below-ground terrestrial carbon storage (tonnes (t) of C per hectare (ha)) for circa 2010. The dataset was constructed by combining the most reliable publicly available datasets and overlaying them with the ESA CCI landcover map for the year 2010 (ESA, 2017), assigning to each grid cell the corresponding above-ground biomass value from the biomass map that was most appropriate for the grid cell's landcover type. Input carbon datasets were identified through a literature review of existing datasets on biomass carbon in terrestrial ecosystems published in peer-reviewed literature. To determine which datasets to combine to produce the global carbon density map, identified datasets were evaluated based on resolution, accuracy, biomass definition and reference date (see Table 1 in paper cited for further information on datasets selected). After aggregating each selected dataset to a nominal scale of 300 m resolution, forest categories in the CCI ESA 2010 landcover dataset were used to extract above-ground biomass from Santoro et al. 2018 for forest areas. Woodland and savanna biomass were then incorporated for Africa from Bouvet et al. 2018., and from Santoro et al. 2018 for areas outside of Africa and outside of forest. Biomass from croplands, sparse vegetation and grassland landcover classes from CCI ESA, in addition to shrubland areas outside Africa missing from Santoro et al. 2018, were extracted from were extracted from Xia et al. 2014. and Spawn et al. 2017 averaged by ecological zone for each landcover type. Below-ground biomass were added using root-to-shoot ratios from the 2006 IPCC guidelines for National Greenhouse Gas Inventories (IPCC, 2006). No below-ground values were assigned to croplands as ratios were unavailable. Above-and-below-ground biomass were then summed together and multiplied by 0.5 to convert to carbon, generating a single above-and-below-ground biomass carbon layer. This dataset has not been validated.  References:  * Bouvet, A. et al. 2018. An above-ground biomass map of African savannahs and woodlands at 25 m resolution derived from ALOS PALSAR. Remote Sensing of the Environment 206, 156-173. * ESA (2017) [Land Cover CCI Product User Guide Version 2. Tech. Rep.](https://maps.elie.ucl.ac.be/CCI/viewer/download/ESACCI-LC-Ph2-PUGv2_2.0.pdf). * IPCC (2006) 2006 IPCC guidelines for national greenhouse gas inventories (eds HS Eggleston, L Buendia, K Miwa, T Ngara, K Tanabe.) Kanagawa, Japan: IGES. * Santoro, M. et al. (2018). A detailed portrait of the forest aboveground biomass pool for the year 2010 obtained from multiple remote sensing observations. Geophysical Research Abstracts 20, EGU2018-EG18932. * Spawn SA et al. (2017) New global biomass map for the year 2010. New Orleans, LA: American Geophysical Union. * Xia, J. et al. (2014) Spatio-temporal patterns and climate variables controlling of biomass carbon stock of global grassland ecosystems from 1982 to 2006. Remote Sensing 6, 1783-1802.  Provider's note: The UN Environment Programme World Conservation Monitoring Centre (UNEP-WCMC) carbon biomass dataset represents conditions between 1982 and 2010 depending on land cover type. The relative patterns of carbon stocks are well represented with this dataset. The [NASA/ORNL carbon biomass dataset](https://daac.ornl.gov/VEGETATION/guides/Global_Maps_C_Density_2010.html) represents biomass conditions for 2010, with uncertainty estimates at the pixel-level. Additional biomass of non-dominant land cover types are represented within each pixel. For more detailed information, please refer to the papers describing each dataset: WCMC [(Soto-Navarro et al. 2020)](https://royalsocietypublishing.org/doi/full/10.1098/rstb.2019.0128) and [NASA/ORNL](NASA_ORNL_biomass_carbon_density_v1) [(Spawn et al. 2020)](https://www.nature.com/articles/s41597-020-0444-4). 
        :param example: var image = ee.Image('WCMC/biomass_carbon_density/v1_0/2010');  Map.addLayer(ee.Image(1), {min: 0, max: 1}, 'base_map'); Map.addLayer(     image, {       min: 1,       max: 180,       palette: ['d9f0a3', 'addd8e', '78c679', '41ab5d', '238443', '005a32']     },     'carbon_tonnes_per_ha'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WCMC_WDPA_current_points:
    def __init__(self,):
        self.sensor = 'WCMC_WDPA_current_points'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WCMC_WDPA_current_points.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WCMC_WDPA_current_points.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WCMC_WDPA_current_points(example: str = ''):
        """
        The World Database on Protected Areas (WDPA) is the most up-to-date and complete source of information on protected areas, updated monthly with submissions from governments, non-governmental organizations, landowners, and communities. It is managed by the United Nations Environment Programme's World Conservation Monitoring Centre (UNEP-WCMC) with support from IUCN and its World Commission on Protected Areas (WCPA).  **WDPA User Manual.** For details including methodologies,standards, data providers, metadata field definitions and descriptions, refer to the [WDPA User Manual](https://pp-import-production.s3.amazonaws.com/WDPA_Manual_1_5.pdf).  The WDPA has two feature classes with associated spatial and tabular data on more than 200k protected areas. About 91% contain polygon boundaries, with the remaining only as points, representing the center of the protected area as much as possible.  **Asset Naming Conventions.** WCMC updates the WDPA on a monthly basis. The most recent version is always available as WCMC/WDPA/current/polygons and WCMC/WDPA/current/points. Historical versions, starting with July 2017, are available in the format WCMC/WDPA/YYYYMM/polygons and WCMC/WDPA/YYYYMM/points.  Please see the [WDPA User Manual](https://pp-import-production.s3.amazonaws.com/WDPA_Manual_1_5.pdf) for additional details on the field list. 
        :param example: var dataset = ee.FeatureCollection('WCMC/WDPA/current/points');  dataset = dataset.style({   color: '4285F4',   pointSize: 3, });  Map.setCenter(110.57, 0.88, 4);  Map.addLayer(dataset, {}, 'Protected Area Points'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WCMC_WDPA_current_polygons:
    def __init__(self,):
        self.sensor = 'WCMC_WDPA_current_polygons'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WCMC_WDPA_current_polygons.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WCMC_WDPA_current_polygons.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WCMC_WDPA_current_polygons(example: str = ''):
        """
        The World Database on Protected Areas (WDPA) is the most up-to-date and complete source of information on protected areas, updated monthly with submissions from governments, non-governmental organizations, landowners, and communities. It is managed by the United Nations Environment Programme's World Conservation Monitoring Centre (UNEP-WCMC) with support from IUCN and its World Commission on Protected Areas (WCPA).  **WDPA User Manual.** For details including methodologies,standards, data providers, metadata field definitions and descriptions, refer to the [WDPA User Manual](https://pp-import-production.s3.amazonaws.com/WDPA_Manual_1_5.pdf).  The WDPA has two feature classes with associated spatial and tabular data on more than 200k protected areas. About 91% contain polygon boundaries, with the remaining only as points, representing the center of the protected area as much as possible.  **Asset Naming Conventions.** WCMC updates the WDPA on a monthly basis. The most recent version is always available as WCMC/WDPA/current/polygons and WCMC/WDPA/current/points. Historical versions, starting with July 2017, are available in the format WCMC/WDPA/YYYYMM/polygons and WCMC/WDPA/YYYYMM/points.  Please see the [WDPA User Manual](https://pp-import-production.s3.amazonaws.com/WDPA_Manual_1_5.pdf) for additional details on the field list. 
        :param example: var dataset = ee.FeatureCollection('WCMC/WDPA/current/polygons'); var visParams = {   palette: ['2ed033', '5aff05', '67b9ff', '5844ff', '0a7618', '2c05ff'],   min: 0.0,   max: 1550000.0,   opacity: 0.8, }; var image = ee.Image().float().paint(dataset, 'REP_AREA'); Map.setCenter(41.104, -17.724, 6); Map.addLayer(image, visParams, 'WCMC/WDPA/current/polygons'); Map.addLayer(dataset, null, 'for Inspector', false); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WHBU_NBAR_1YEAR:
    def __init__(self,):
        self.sensor = 'WHBU_NBAR_1YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WHBU_NBAR_1YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WHBU_NBAR_1YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WHBU_NBAR_1YEAR(example: str = ''):
        """
        The mosaics are created by using the MODIS 8-Day 500 meter BRDF-Albedo Quality product.  Data Quality flags are used to select the best observations from the MODIS 8-day 500 meter Nadir BRDF-Adjusted Reflectance imagery product.  This specific mosaic picks observations from the three highest quality categories over a 1-year period of MODIS data.  The MODIS NBAR annual mosaics have been used by government agencies and NGOs in tropical countries as input to generate aboveground biomass/carbon maps. The Woods Hole Research Center has been using the dataset for country capacity building and technical training workshops in tropical countries. 
        :param example: var dataset = ee.ImageCollection('WHBU/NBAR_1YEAR');  Map.addLayer(dataset.mean(), {min:0, max:7000}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WHBU_NBAR_2YEAR:
    def __init__(self,):
        self.sensor = 'WHBU_NBAR_2YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WHBU_NBAR_2YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WHBU_NBAR_2YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WHBU_NBAR_2YEAR(example: str = ''):
        """
        The mosaics are created by using the MODIS 8-Day 500 meter BRDF-Albedo Quality product.  Data Quality flags are used to select the best observations from the MODIS 8-day 500 meter Nadir BRDF-Adjusted Reflectance imagery product.  This specific mosaic picks observations from the three highest quality categories over a 2-year period of MODIS data.  The MODIS NBAR annual mosaics have been used by government agencies and NGOs in tropical countries as input to generate aboveground biomass/carbon maps. The Woods Hole Research Center has been using the dataset for country capacity building and technical training workshops in tropical countries. 
        :param example: var dataset = ee.ImageCollection('WHBU/NBAR_2YEAR');  Map.addLayer(dataset.mean(), {min:0, max:7000}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WHBU_NBAR_3YEAR:
    def __init__(self,):
        self.sensor = 'WHBU_NBAR_3YEAR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WHBU_NBAR_3YEAR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WHBU_NBAR_3YEAR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WHBU_NBAR_3YEAR(example: str = ''):
        """
        The mosaics are created by using the MODIS 8-Day 500 meter BRDF-Albedo Quality product.  Data Quality flags are used to select the best observations from the MODIS 8-day 500 meter Nadir BRDF-Adjusted Reflectance imagery product.  This specific mosaic picks observations from the three highest quality categories over a 3-year period of MODIS data.  The MODIS NBAR annual mosaics have been used by government agencies and NGOs in tropical countries as input to generate aboveground biomass/carbon maps. The Woods Hole Research Center has been using the dataset for country capacity building and technical training workshops in tropical countries. 
        :param example: var dataset = ee.ImageCollection('WHBU/NBAR_3YEAR');  Map.addLayer(dataset.mean(), {min:0, max:7000}); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WHRC_biomass_tropical:
    def __init__(self,):
        self.sensor = 'WHRC_biomass_tropical'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WHRC_biomass_tropical.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WHRC_biomass_tropical.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WHRC_biomass_tropical(example: str = ''):
        """
        A national-level map of above-ground live woody biomass density for tropical countries at 500m. This dataset was assembled from a combination of co-located field measurements, LiDAR observations, and imagery recorded from the Moderate Resolution Imaging Spectroradiometer (MODIS). 
        :param example: var dataset = ee.Image('WHRC/biomass/tropical'); // Show results only over land. var landMask = ee.Image('NOAA/NGDC/ETOPO1').select('bedrock').gt(0); var liveWoodyBiomass = dataset.updateMask(landMask);  var visParams = {   min: 0,   max: 350,   palette: [     'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',     '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',     '012e01', '011d01', '011301'   ], }; Map.addLayer(     liveWoodyBiomass, visParams, 'Aboveground Live Woody Biomass (Mg/ha)');  Map.setCenter(-69.4, 0.3, 3); Map.setOptions('SATELLITE'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WM_geoLab_geoBoundaries_500_ADM0:
    def __init__(self,):
        self.sensor = 'WM_geoLab_geoBoundaries_500_ADM0'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WM_geoLab_geoBoundaries_500_ADM0.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WM_geoLab_geoBoundaries_500_ADM0.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WM_geoLab_geoBoundaries_500_ADM0(example: str = ''):
        """
        The geoBoundaries Global Database of Political Administrative Boundaries Database is an online, open license resource of boundaries (i.e., state, county) for every country in the world. Currently 199 total entities are tracked, including all 195 UN member states, Greenland, Taiwan, Niue, and Kosovo. They provide three different type of datasets, the one currently ingested is Comprehensive Global Administrative Zones.  Comprehensive Global Administrative Zones (CGAZ) is a set of global composites for administrative boundaries. Disputed areas are removed and replaced with polygons following US Department of State definitions. It has three boundary levels ADM0, ADM1 and ADM2, clipped to international boundaries (US Department of State), with gaps filled between borders. ADM0 is part of CGAZ and it has country-level boundaries.  (see [Dataset description of WM global administation boundaries](   https://www.geoboundaries.org/index.html). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WM_geoLab_geoBoundaries_500_ADM1:
    def __init__(self,):
        self.sensor = 'WM_geoLab_geoBoundaries_500_ADM1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WM_geoLab_geoBoundaries_500_ADM1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WM_geoLab_geoBoundaries_500_ADM1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WM_geoLab_geoBoundaries_500_ADM1(example: str = ''):
        """
        The geoBoundaries Global Database of Political Administrative Boundaries Database is an online, open license resource of boundaries (i.e., state, county) for every country in the world. Currently 199 total entities are tracked, including all 195 UN member states, Greenland, Taiwan, Niue, and Kosovo. They provide three different type of datasets, the one currently ingested is Comprehensive Global Administrative Zones.  Comprehensive Global Administrative Zones (CGAZ) is a set of global composites for administrative boundaries. Disputed areas are removed and replaced with polygons following US Department of State definitions. It has three boundary levels ADM0, ADM1 and ADM2, clipped to international boundaries (US Department of State), with gaps filled between borders. ADM1 is part of CGAZ and it has district-level boundaries.  (see [Dataset description of WM global administation boundaries](   https://www.geoboundaries.org/index.html). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WM_geoLab_geoBoundaries_500_ADM2:
    def __init__(self,):
        self.sensor = 'WM_geoLab_geoBoundaries_500_ADM2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WM_geoLab_geoBoundaries_500_ADM2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WM_geoLab_geoBoundaries_500_ADM2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WM_geoLab_geoBoundaries_500_ADM2(example: str = ''):
        """
        The geoBoundaries Global Database of Political Administrative Boundaries Database is an online, open license resource of boundaries (i.e., state, county) for every country in the world. Currently 199 total entities are tracked, including all 195 UN member states, Greenland, Taiwan, Niue, and Kosovo. They provide three different type of datasets, the one currently ingested is Comprehensive Global Administrative Zones.  Comprehensive Global Administrative Zones (CGAZ) is a set of global composites for administrative boundaries. Disputed areas are removed and replaced with polygons following US Department of State definitions. It has three boundary levels ADM0, ADM1 and ADM2, clipped to international boundaries (US Department of State), with gaps filled between borders. ADM2 is part of CGAZ and it has municipality-level boundaries.  (see [Dataset description of WM global administation boundaries](   https://www.geoboundaries.org/index.html). 
        :param example: 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WORLDCLIM_V1_BIO:
    def __init__(self,):
        self.sensor = 'WORLDCLIM_V1_BIO'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WORLDCLIM_V1_BIO.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WORLDCLIM_V1_BIO.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WORLDCLIM_V1_BIO(example: str = ''):
        """
        WorldClim V1 Bioclim provides bioclimatic variables that are derived from the monthly temperature and rainfall in order to generate more biologically meaningful values.  The bioclimatic variables represent annual trends (e.g., mean annual temperature, annual precipitation), seasonality (e.g., annual range in temperature and precipitation), and extreme or limiting environmental factors (e.g., temperature of the coldest and warmest month, and precipitation of the wet and dry quarters).  The bands scheme follows that of ANUCLIM, except that for temperature seasonality the standard deviation was used because a coefficient of variation does not make sense with temperatures between -1 and 1.  WorldClim version 1 was developed by Robert J. Hijmans, Susan Cameron, and Juan Parra, at the Museum of Vertebrate Zoology, University of California, Berkeley, in collaboration with Peter Jones and Andrew Jarvis (CIAT), and with Karen Richardson (Rainforest CRC). 
        :param example: var dataset = ee.Image('WORLDCLIM/V1/BIO'); var annualMeanTemperature = dataset.select('bio01').multiply(0.1); var visParams = {   min: -23,   max: 30,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(71.7, 52.4, 3); Map.addLayer(annualMeanTemperature, visParams, 'Annual Mean Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WORLDCLIM_V1_MONTHLY:
    def __init__(self,):
        self.sensor = 'WORLDCLIM_V1_MONTHLY'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WORLDCLIM_V1_MONTHLY.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WORLDCLIM_V1_MONTHLY.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WORLDCLIM_V1_MONTHLY(example: str = ''):
        """
        WorldClim version 1 has average monthly global climate data for minimum, mean, and maximum temperature and for precipitation.  WorldClim version 1 was developed by Robert J. Hijmans, Susan Cameron, and Juan Parra, at the Museum of Vertebrate Zoology, University of California, Berkeley, in collaboration with Peter Jones and Andrew Jarvis (CIAT), and with Karen Richardson (Rainforest CRC). 
        :param example: var dataset = ee.ImageCollection('WORLDCLIM/V1/MONTHLY'); var meanTemperature = dataset.select('tavg').first().multiply(0.1); var meanTemperatureVis = {   min: -40,   max: 30,   palette: ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'], }; Map.setCenter(71.7, 52.4, 3); Map.addLayer(meanTemperature, meanTemperatureVis, 'Mean Temperature'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WorldPop_GP_100m_pop:
    def __init__(self,):
        self.sensor = 'WorldPop_GP_100m_pop'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WorldPop_GP_100m_pop.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WorldPop_GP_100m_pop.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WorldPop_GP_100m_pop(example: str = ''):
        """
        Global high-resolution, contemporary data on human population distributions are a prerequisite for the accurate measurement of the impacts of population growth, for monitoring changes, and for planning interventions. The WorldPop project aims to meet these needs through the provision of detailed and open access population distribution datasets built using transparent and peer-reviewed approaches.  Full details on the methods and datasets used in constructing the data, along with open access publications, are provided on the [WorldPop website](https://www.worldpop.org/). In brief, recent census-based population counts matched to their associated administrative units are disaggregated to ~100x100m grid cells through machine learning approaches that exploit the relationships between population densities and a range of geospatial covariate layers. The mapping approach is Random Forest-based dasymetric redistribution.  This dataset depict estimated number of people residing in each grid cell in 2010, 2015, and other years.  For 2020, the breakdown of population by age and sex is available in the [WorldPop/GP/100m/pop_age_sex](WorldPop_GP_100m_pop_age_sex) and [WorldPop/GP/100m/pop_age_sex_cons_unadj](WorldPop_GP_100m_pop_age_sex_cons_unadj) collections.  Further WorldPop gridded datasets on population age structures, poverty, urban growth, and population dynamics are freely available on the WorldPop website. WorldPop represents a collaboration between researchers at the University of Southampton, Universite Libre de Bruxelles, and University of Louisville. The project is principally funded by the Bill and Melinda Gates Foundation. 
        :param example: var dataset = ee.ImageCollection('WorldPop/GP/100m/pop');  var visualization = {   bands: ['population'],   min: 0.0,   max: 50.0,   palette: ['24126c', '1fff4f', 'd4ff50'] };  Map.setCenter(113.643, 34.769, 7);  Map.addLayer(dataset, visualization, 'Population');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WorldPop_GP_100m_pop_age_sex:
    def __init__(self,):
        self.sensor = 'WorldPop_GP_100m_pop_age_sex'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WorldPop_GP_100m_pop_age_sex.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WorldPop_GP_100m_pop_age_sex.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WorldPop_GP_100m_pop_age_sex(example: str = ''):
        """
        Global high-resolution, contemporary data on human population distributions are a prerequisite for the accurate measurement of the impacts of population growth, for monitoring changes, and for planning interventions. The WorldPop project aims to meet these needs through the provision of detailed and open access population distribution datasets built using transparent and peer-reviewed approaches.  Full details on the methods and datasets used in constructing the data, along with open access publications, are provided on the [WorldPop website](https://www.worldpop.org/). In brief, recent census-based population counts matched to their associated administrative units are disaggregated to ~100x100m grid cells through machine learning approaches that exploit the relationships between population densities and a range of geospatial covariate layers. The mapping approach is Random Forest-based dasymetric redistribution.  This dataset contains breakdown of estimated population by age and gender groups. Currently only 2020 data are present.  [See explanation of constrained vs unconstrained datasets](https://www.worldpop.org/methods/top_down_constrained_vs_unconstrained).  Further WorldPop gridded datasets on population age structures, poverty, urban growth, and population dynamics are freely available on the WorldPop website. WorldPop represents a collaboration between researchers at the University of Southampton, Universite Libre de Bruxelles, and University of Louisville. The project is principally funded by the Bill and Melinda Gates Foundation. 
        :param example: var dataset = ee.ImageCollection('WorldPop/GP/100m/pop_age_sex');  var visualization = {   bands: ['population'],   min: 0.0,   max: 50.0,   palette: ['24126c', '1fff4f', 'd4ff50'] };  Map.setCenter(113.643, 34.769, 7);  Map.addLayer(dataset, visualization, 'Population');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WorldPop_GP_100m_pop_age_sex_cons_unadj:
    def __init__(self,):
        self.sensor = 'WorldPop_GP_100m_pop_age_sex_cons_unadj'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WorldPop_GP_100m_pop_age_sex_cons_unadj.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WorldPop_GP_100m_pop_age_sex_cons_unadj.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WorldPop_GP_100m_pop_age_sex_cons_unadj(example: str = ''):
        """
        Global high-resolution, contemporary data on human population distributions are a prerequisite for the accurate measurement of the impacts of population growth, for monitoring changes, and for planning interventions. The WorldPop project aims to meet these needs through the provision of detailed and open access population distribution datasets built using transparent and peer-reviewed approaches.  Full details on the methods and datasets used in constructing the data, along with open access publications, are provided on the [WorldPop website](https://www.worldpop.org/). In brief, recent census-based population counts matched to their associated administrative units are disaggregated to ~100x100m grid cells through machine learning approaches that exploit the relationships between population densities and a range of geospatial covariate layers. The mapping approach is Random Forest-based dasymetric redistribution.  This dataset contains top-down constrained breakdown of estimated population by age and gender groups. Currently only 2020 data are present.  Top-down constrained age/sex structure estimate datasets for individual countries for 2020 at 100m spatial resolution with country totals adjusted to match the corresponding official United Nations population estimates that have been prepared by the Population Division of the Department of Economic and Social Affairs of the United Nations Secretariat ([2019 Revision of World Population Prospects](https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/EXCEL_FILES/1_Population/WPP2019_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.xlsx)).  [See explanation of constrained vs unconstrained datasets](https://www.worldpop.org/methods/top_down_constrained_vs_unconstrained).  Further WorldPop gridded datasets on population age structures, poverty, urban growth, and population dynamics are freely available on the WorldPop website. WorldPop represents a collaboration between researchers at the University of Southampton, Universite Libre de Bruxelles, and University of Louisville. The project is principally funded by the Bill and Melinda Gates Foundation. 
        :param example: var dataset = ee.ImageCollection('WorldPop/GP/100m/pop_age_sex_cons_unadj');  var visualization = {   bands: ['population'],   min: 0.0,   max: 50.0,   palette: ['24126c', '1fff4f', 'd4ff50'] };  Map.setCenter(113.643, 34.769, 7);  Map.addLayer(dataset, visualization, 'Population'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WorldPop_POP:
    def __init__(self,):
        self.sensor = 'WorldPop_POP'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WorldPop_POP.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WorldPop_POP.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WorldPop_POP(example: str = ''):
        """
        High-resolution, contemporary data on human population distributions are a prerequisite for the accurate measurement of the impacts of population growth, for monitoring changes, and for planning interventions. The WorldPop project aims to meet these needs through the provision of detailed and open access population distribution datasets built using transparent and peer-reviewed approaches.  Full details on the methods and datasets used in constructing the data, along with open access publications, are provided on the [WorldPop website](https://www.worldpop.org/). In brief, recent census-based population counts matched to their associated administrative units are disaggregated to &asymp;100x100m grid cells through machine learning approaches that exploit the relationships between population densities and a range of geospatial covariate layers. The datasets depict estimated number of people residing in each grid cell in 2010, 2015, and other years.  Further WorldPop gridded datasets on population age structures, poverty, urban growth, and population dynamics are freely available on the WorldPop website. WorldPop represents a collaboration between researchers at the University of Southampton, Universite Libre de Bruxelles, and University of Louisville. The project is principally funded by the Bill and Melinda Gates Foundation. 
        :param example: var dataset = ee.ImageCollection('WorldPop/POP'); var population = dataset.select('population'); var populationVis = {   min: 0.0,   max: 50.0,   palette: ['24126c', '1fff4f', 'd4ff50'], }; Map.setCenter(113.643, 34.769, 7); Map.addLayer(population, populationVis, 'Population'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GFW_FORMA_alerts:
    def __init__(self,):
        self.sensor = 'WRI_GFW_FORMA_alerts'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GFW_FORMA_alerts.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GFW_FORMA_alerts.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GFW_FORMA_alerts(example: str = ''):
        """
        **NOTE from WRI**: WRI decided to stop updating FORMA alerts. The goal was to simplify the [Global Forest Watch](https://www.globalforestwatch.org) user experience and reduce redundancy. We found that [Terra-i](http://www.terra-i.org/terra-i.html) and [GLAD](https://glad-forest-alert.appspot.com/) were more frequently used. Moreover, using GLAD as a standard, found that Terra-i outperformed FORMA globally.  FORMA alerts are detected using a combination of two MODIS products: NDVI (Normalized Difference Vegetation Index) and FIRMS (Fires Information for Resource Management System). NDVI updates are processed every 16 days, while fire updates are processed daily. Models are developed individually for each ecogroup to relate the two inputs to the area of clearing, using the Hansen annual tree cover loss data to train the model. The minimum threshold to qualify as an alert is 25% of the pixel cleared, though thresholds vary by ecogroup to minimize false positives. Here is an [example script](https://code.earthengine.google.com/f29b1e4360f3fc36847bd789ceeb20f6) for a quick introduction to the FORMA datasets.  The percentage of clearing takes a value of 0, no clearing detected, or in the range [ecogroup_bound:100), where ecogroup_bound is given by WRI/GFW/FORMA/thresholds . The time periods over which data is collected varies by N-days, where N is the number of days between the alert_date and the last MODIS NDVI update. 
        :param example: var dataset = ee.Image('WRI/GFW/FORMA/alerts'); var formaAlerts = dataset.select('alert_delta'); var formaAlertsVis = {   min: 25,   max: 75,   palette: ['d65898', 'da68a2'], }; Map.setCenter(6.746, 46.529, 6); Map.addLayer(formaAlerts, formaAlertsVis, 'FORMA Alerts'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GFW_FORMA_raw_output_firms:
    def __init__(self,):
        self.sensor = 'WRI_GFW_FORMA_raw_output_firms'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GFW_FORMA_raw_output_firms.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GFW_FORMA_raw_output_firms.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GFW_FORMA_raw_output_firms(example: str = ''):
        """
        **NOTE from WRI**: WRI decided to stop updating FORMA alerts. The goal was to simplify the [Global Forest Watch](https://www.globalforestwatch.org) user experience and reduce redundancy. We found that [Terra-i](http://www.terra-i.org/terra-i.html) and [GLAD](https://glad-forest-alert.appspot.com/) were more frequently used. Moreover, using GLAD as a standard, found that Terra-i outperformed FORMA globally.  FORMA alerts are detected using a combination of two MODIS products: NDVI (Normalized Difference Vegetation Index) and FIRMS (Fires Information for Resource Management System). NDVI updates are processed every 16 days, while fire updates are processed daily. Models are developed individually for each ecogroup to relate the two inputs to the area of clearing, using the Hansen annual tree cover loss data to train the model. The minimum threshold to qualify as an alert is 25% of the pixel cleared, though thresholds vary by ecogroup to minimize false positives. Here is an [example script](https://code.earthengine.google.com/f29b1e4360f3fc36847bd789ceeb20f6) for a quick introduction to the FORMA datasets.  The images in this ImageCollection contain the raw FORMA data calculated after new MODIS FIRMS data becomes available, approximately every day.  Each band gives a percentage of clearing (from 0 to 100) for different accumulation periods. "N" is the number of days between the latest FIRMS update and the previous NDVI update. N is given by the 'date_delta' property. 
        :param example: var dataset = ee.ImageCollection('WRI/GFW/FORMA/raw_output_firms')                   .filter(ee.Filter.date('2018-08-01', '2018-08-15')); var percentageOfClearing = dataset.select('nday'); var visParams = {   min: 0.0,   max: 0.01, }; Map.setCenter(26, -8, 3); Map.addLayer(percentageOfClearing, visParams, 'Percentage of clearing'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GFW_FORMA_raw_output_ndvi:
    def __init__(self,):
        self.sensor = 'WRI_GFW_FORMA_raw_output_ndvi'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GFW_FORMA_raw_output_ndvi.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GFW_FORMA_raw_output_ndvi.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GFW_FORMA_raw_output_ndvi(example: str = ''):
        """
        **NOTE from WRI**: WRI decided to stop updating FORMA alerts. The goal was to simplify the [Global Forest Watch](https://www.globalforestwatch.org) user experience and reduce redundancy. We found that [Terra-i](http://www.terra-i.org/terra-i.html) and [GLAD](https://glad-forest-alert.appspot.com/) were more frequently used. Moreover, using GLAD as a standard, found that Terra-i outperformed FORMA globally.  FORMA alerts are detected using a combination of two MODIS products: NDVI (Normalized Difference Vegetation Index) and FIRMS (Fires Information for Resource Management System). NDVI updates are processed every 16 days, while fire updates are processed daily. Models are developed individually for each ecogroup to relate the two inputs to the area of clearing, using the Hansen annual tree cover loss data to train the model. The minimum threshold to qualify as an alert is 25% of the pixel cleared, though thresholds vary by ecogroup to minimize false positives. Here is an [example script](https://code.earthengine.google.com/f29b1e4360f3fc36847bd789ceeb20f6) for a quick introduction to the FORMA datasets.  The images in this ImageCollection contain the raw FORMA data calculated after new MODIS NDVI data becomes available, approximately every 16 days.  The image contains 4 bands. The 'delta', 'near_term_delta', and 'clearing' bands all give a percentage of clearing (from 0 to 100) for different accumulation periods. Accuracy gives a measure of confidence in these predictions (0 = very little confidence, 100 is high confidence). 
        :param example: var dataset = ee.ImageCollection('WRI/GFW/FORMA/raw_output_ndvi')                   .filter(ee.Filter.date('2018-01-01', '2018-01-02')); var percentOfClearing = dataset.select('clearing'); var visParams = {   min: 0,   max: 1, }; Map.setCenter(26, -8, 3); Map.addLayer(     percentOfClearing, visParams, 'Percent of clearing in the last 365 days'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GFW_FORMA_thresholds:
    def __init__(self,):
        self.sensor = 'WRI_GFW_FORMA_thresholds'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GFW_FORMA_thresholds.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GFW_FORMA_thresholds.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GFW_FORMA_thresholds(example: str = ''):
        """
        **NOTE from WRI**: WRI decided to stop updating FORMA alerts. The goal was to simplify the [Global Forest Watch](https://www.globalforestwatch.org) user experience and reduce redundancy. We found that [Terra-i](http://www.terra-i.org/terra-i.html) and [GLAD](https://glad-forest-alert.appspot.com/) were more frequently used. Moreover, using GLAD as a standard, found that Terra-i outperformed FORMA globally.  FORMA alerts are detected using a combination of two MODIS products: NDVI (Normalized Difference Vegetation Index) and FIRMS (Fires Information for Resource Management System). NDVI updates are processed every 16 days, while fire updates are processed daily. Models are developed individually for each ecogroup to relate the two inputs to the area of clearing, using the Hansen annual tree cover loss data to train the model. The minimum threshold to qualify as an alert is 25% of the pixel cleared, though thresholds vary by ecogroup to minimize false positives. Here is an [example script](https://code.earthengine.google.com/f29b1e4360f3fc36847bd789ceeb20f6) for a quick introduction to the FORMA datasets.  This image contains the thresholds at which, when crossed, a FORMA alert is produced. The values are equal to max(25,40%*RegionalMax), where RegionalMax is the historical maximum clearing for a pixel in this ecogroup. 
        :param example: var dataset = ee.Image('WRI/GFW/FORMA/thresholds'); var thresholds = dataset.select('delta_bound'); var visParams = {   min: 0,   max: 50, }; Map.setCenter(26, -8, 3); Map.addLayer(thresholds, visParams, 'Thresholds for FORMA alerts'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GFW_FORMA_vegetation_tstats:
    def __init__(self,):
        self.sensor = 'WRI_GFW_FORMA_vegetation_tstats'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GFW_FORMA_vegetation_tstats.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GFW_FORMA_vegetation_tstats.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GFW_FORMA_vegetation_tstats(example: str = ''):
        """
        **NOTE from WRI**: WRI decided to stop updating FORMA alerts. The goal was to simplify the [Global Forest Watch](https://www.globalforestwatch.org) user experience and reduce redundancy. We found that [Terra-i](http://www.terra-i.org/terra-i.html) and [GLAD](https://glad-forest-alert.appspot.com/) were more frequently used. Moreover, using GLAD as a standard, found that Terra-i outperformed FORMA globally.  FORMA alerts are detected using a combination of two MODIS products: NDVI (Normalized Difference Vegetation Index) and FIRMS (Fires Information for Resource Management System). NDVI updates are processed every 16 days, while fire updates are processed daily. Models are developed individually for each ecogroup to relate the two inputs to the area of clearing, using the Hansen annual tree cover loss data to train the model. The minimum threshold to qualify as an alert is 25% of the pixel cleared, though thresholds vary by ecogroup to minimize false positives. Here is an [example script](https://code.earthengine.google.com/f29b1e4360f3fc36847bd789ceeb20f6) for a quick introduction to the FORMA datasets.  The images in this ImageCollection contain the "reversed rectified t-statistics" used in calculating NTT, the vegetation color index derived from MODIS NDVI that FORMA uses to measure browning. Using a sum reducer on over various date ranges in this ImageCollection produces an "NTT" image.  The images are broken by "ecogroup". 
        :param example: var dataset = ee.ImageCollection('WRI/GFW/FORMA/vegetation_tstats')                   .filter(ee.Filter.date('2018-07-01', '2018-07-15')); var tstat = dataset.select('tstat_r'); var visParams = {   min: 0,   max: 1, }; Map.setCenter(26, -8, 3); Map.addLayer(tstat, visParams, 'Reversed rectified t-statistics'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WRI_GPPD_power_plants:
    def __init__(self,):
        self.sensor = 'WRI_GPPD_power_plants'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WRI_GPPD_power_plants.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WRI_GPPD_power_plants.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WRI_GPPD_power_plants(example: str = ''):
        """
        The Global Power Plant Database is a comprehensive, open source database of power plants around the world. It centralizes power plant data to make it easier to navigate, compare and draw insights. Each power plant is geolocated and entries contain information on plant capacity, generation, ownership, and fuel type. As of June 2018, the database includes around 28,500 power plants from 164 countries. It will be continuously updated as data becomes available.  The methodology for the dataset creation is given in the World Resources Institute publication ["A Global Database of Power Plants"](https://www.wri.org/publication/global-power-plant-database).  Associated code for the creation of the dataset can be found on [GitHub](https://github.com/wri/global-power-plant-database). The bleeding-edge version of the database (which may contain substantial differences from the release in Earth Engine) is available on GitHub as well.  If you use this dataset, the provider (WRI) has requested that you [register your use](https://goo.gl/ivTvkd) and (optionally) sign up to receive update notifications. 
        :param example: // Visualization for WRI/GPPD/power_plants  var table = ee.FeatureCollection('WRI/GPPD/power_plants');  // Get a color from a fuel var fuelColor = ee.Dictionary({   'Coal': '000000',   'Oil': '593704',   'Gas': 'bc80bd',   'Hydro': '0565A6',   'Nuclear': 'e31a1c',   'Solar': 'ff7f00',   'Waste': '6a3d9a',   'Wind': '5ca2d1',   'Geothermal': 'fdbf6f',   'Biomass': '229a00' });  // List of fuels to add to the map var fuels = [     'Coal', 'Oil', 'Gas', 'Hydro', 'Nuclear',     'Solar', 'Waste', 'Wind', 'Geothermal', 'Biomass'];  /**  * Computes size from capacity and color from fuel type.  *  * @param {!ee.Geometry.Point} pt A point  * @return {!ee.Geometry.Point} Input point with added style dictionary.  */ function addStyle(pt) {   var size = ee.Number(pt.get('capacitymw')).sqrt().divide(10).add(2);   var color = fuelColor.get(pt.get('fuel1'));   return pt.set(       'styleProperty', ee.Dictionary({'pointSize': size, 'color': color})); }  // Make a FeatureCollection out of the power plant data table. var pp = ee.FeatureCollection(table).map(addStyle); print(pp.first());  /**  * Adds power plants of a certain fuel type to the map.  *  * @param {string} fuel A fuel type  */ function addLayer(fuel) {   print(fuel);   Map.addLayer(       pp.filter(ee.Filter.eq('fuel1', fuel))           .style({styleProperty: 'styleProperty', neighborhood: 50}),       {}, fuel, true, 0.65); }  // Apply `addLayer` to each record in `fuels`. fuelColor.keys().evaluate(function(fuelsList) {   fuelsList.map(addLayer); }); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level03:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level03'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level03.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level03.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level03(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level03');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 4);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 4e6},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level04:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level04'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level04.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level04.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level04(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level04');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 4e6},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level05:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level05'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level05.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level05.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level05(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level05');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 2.6e6},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level06:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level06'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level06.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level06.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level06(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level06');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 5e5},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level07:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level07'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level07.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level07.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level07(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level07');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 1e5},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level08:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level08'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level08.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level08.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level08(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level08');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 5e4},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level09:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level09'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level09.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level09.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level09(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level09');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 1e4},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level10:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level10(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level10');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 1e4},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level11:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level11'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level11.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level11.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level11(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level11');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-43.50, -24.70, 6);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  // View the continent of South America. var region = ee.Geometry.BBox(-80, -60, -20, 20); Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 1e4},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroATLAS_v1_Basins_level12:
    def __init__(self,):
        self.sensor = 'WWF_HydroATLAS_v1_Basins_level12'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroATLAS_v1_Basins_level12.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroATLAS_v1_Basins_level12.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroATLAS_v1_Basins_level12(example: str = ''):
        """
        BasinATLAS is a component of the [HydroATLAS database](https://www.hydrosheds.org/page/hydroatlas), which is a component of [HydroSHEDS](https://www.hydrosheds.org).  BasinATLAS provides a standardized compendium of hydro-environmental attribute information for all watersheds of the world at high spatial resolution. This dataset includes data for 56 variables, partitioned into 281 attributes and organized in six categories: hydrology; physiography; climate; land cover & use; soils & geology; and anthropogenic influences (see Table 1 in the HydroATLAS documentation linked below).  Watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes. The underlying watershed deleniation uses the NASA SRTM Digital Elevatin Map (DEM) below 60oN latitude and the USGS HYDRO1k DEM above 60oN.  Technical documentation:  [https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf](https://www.hydrosheds.org/images/inpages/HydroATLAS_TechDoc_v10.pdf)  Note that the quality of HydroATLAS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was used (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: // Load the HydroATLAS dataset. var basinATLAS = ee.FeatureCollection('WWF/HydroATLAS/v1/Basins/level12');  // Set visualization to show upstream drainage area. var upstreamDrainageArea = ee.Image().byte().paint({   featureCollection: basinATLAS,   color: 'UP_AREA', });  // Set map extent to show the Nile and surrounding basins. Map.setCenter(-46.25, -23.57, 7);  // Create a viridis colormap. var viridis = [   '481567', '482677', '453781', '404788', '39568c', '33638d', '2d708e',   '287d8e', '238a8d', '1f968b', '20a387', '29af7f', '3cbb75', '55c667',   '73d055', '95d840', 'b8de29', 'dce319', 'fde725'];  var region = ee.Geometry.BBox(-80, -60, -20, 20);  Map.addLayer(upstreamDrainageArea.clip(region), {palette: viridis, max: 1e4},              'Upstream Drainage Area [mm]', true, 0.8); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_03CONDEM:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_03CONDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_03CONDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_03CONDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_03CONDEM(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This hydrologically conditioned elevation dataset is the result of an iterative conditioning and correction process. Note that the conditioning process alters the original DEM and may render it incorrect for applications other than deriving drainage directions. Endorheic basins (inland sinks) are ''seeded'' with a no-data cell at their lowest point in order to terminate the flow. Full details of the underlying digital elevation model are available in the HydroSHEDS website and documentation.  This dataset is at 3 arc-second resolution. The datasets available at 3 arc-seconds are the Void-Filled DEM, Hydrologically Conditioned DEM, and Drainage (Flow) Direction.  There are two areas with incorrect negative values of -100 close to Vancouver, Canada around (50.16, -123.85) and Australia (-14.96, 129.62) 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/03CONDEM'); var elevation = dataset.select('b1'); var elevationVis = {   min: -50.0,   max: 3000.0,   gamma: 2.0, }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_03DIR:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_03DIR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_03DIR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_03DIR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_03DIR(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This drainage direction dataset defines the direction of flow from each cell in the conditioned DEM to its steepest down-slope neighbor. Values of drainage direction vary from 1 to 128. All final outlet cells to the ocean are flagged with a value of 0. All cells that mark the lowest point of an endorheic basin (inland sink) are flagged with a value of -1. The drainage direction values follow the convention adopted by ESRI's flow direction implementation: 1=E, 2=SE, 4=S, 8=SW, 16=W, 32=NW, 64=N, 128=NE. \ \  This dataset is at 3 arc-second resolution. The datasets available at 3 arc-seconds are the Void-Filled DEM, Hydrologically Conditioned DEM, and Drainage (Flow) Direction.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/03DIR'); var drainageDirection = dataset.select('b1'); var drainageDirectionVis = {   min: 1.0,   max: 128.0,   palette: [     '000000', '023858', '006837', '1a9850', '66bd63', 'a6d96a', 'd9ef8b',     'ffffbf', 'fee08b', 'fdae61', 'f46d43', 'd73027'   ], }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(drainageDirection, drainageDirectionVis, 'Drainage Direction');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_03VFDEM:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_03VFDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_03VFDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_03VFDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_03VFDEM(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This void-filled elevation dataset is the first step towards producing the conditioned DEM datasets. Spikes and wells in the SRTM data were detected and voided out. Small voids were filled by interpolation of surrounding elevations. The ocean was set to an elevation of 0 meters, and lakes, islands, and rivers were filled using other techniques. Full details of the underlying digital elevation model are available in the HydroSHEDS website and documentation.  This dataset is at 3 arc-second resolution. The datasets available at 3 arc-seconds are the Void-Filled DEM, Hydrologically Conditioned DEM, and Drainage (Flow) Direction.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/03VFDEM'); var elevation = dataset.select('b1'); var elevationVis = {   min: -50.0,   max: 3000.0,   gamma: 2.0, }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_15ACC:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_15ACC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_15ACC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_15ACC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_15ACC(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This flow accumulation dataset defines the amount of upstream area (in number of cells) draining into each cell. The drainage direction layer is used to define which cells flow into the target cell. The number of accumulated cells is essentially a measure of the upstream catchment area. However, since the cell size of the HydroSHEDS data set depends on latitude, the cell accumulation value cannot directly be translated into drainage areas in square kilometers. Values range from 1 at topographic highs (river sources) to very large numbers (on the order of millions of cells) at the mouths of large rivers.  This dataset is at 15 arc-second resolution. The datasets available  at 15 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/15ACC'); var flowAccumulation = dataset.select('b1'); var flowAccumulationVis = {   min: 0.0,   max: 500.0,   palette: [     '000000', '023858', '006837', '1a9850', '66bd63', 'a6d96a', 'd9ef8b',     'ffffbf', 'fee08b', 'fdae61', 'f46d43', 'd73027'   ], }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(flowAccumulation, flowAccumulationVis, 'Flow Accumulation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_15CONDEM:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_15CONDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_15CONDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_15CONDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_15CONDEM(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This hydrologically conditioned elevation dataset is the result of an iterative conditioning and correction process. Note that the conditioning process alters the original DEM and may render it incorrect for applications other than deriving drainage directions. Endorheic basins (inland sinks) are 'seeded' with a no-data cell at their lowest point in order to terminate the flow. Full details of the underlying digital elevation model are available in the HydroSHEDS website and documentation.  This dataset is at 15 arc-second resolution. The datasets available at 15 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/15CONDEM'); var elevation = dataset.select('b1'); var elevationVis = {   min: -50.0,   max: 3000.0,   gamma: 2.0, }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_15DIR:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_15DIR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_15DIR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_15DIR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_15DIR(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This drainage direction dataset defines the direction of flow from each cell in the conditioned DEM to its steepest down-slope neighbor. Values of drainage direction vary from 1 to 128. All final outlet cells to the ocean are flagged with a value of 0. All cells that mark the lowest point of an endorheic basin (inland sink) are flagged with a value of -1. The drainage direction values follow the convention adopted by ESRI's flow direction implementation: 1=E, 2=SE, 4=S, 8=SW, 16=W, 32=NW, 64=N, 128=NE.  This dataset is at 15 arc-second resolution. The datasets available at 15 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/15DIR'); var drainageDirection = dataset.select('b1'); var drainageDirectionVis = {   min: 1.0,   max: 128.0,   palette: [     '000000', '023858', '006837', '1a9850', '66bd63', 'a6d96a', 'd9ef8b',     'ffffbf', 'fee08b', 'fdae61', 'f46d43', 'd73027'   ], }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(drainageDirection, drainageDirectionVis, 'Drainage Direction');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_30ACC:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_30ACC'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_30ACC.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_30ACC.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_30ACC(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This flow accumulation dataset defines the amount of upstream area (in number of cells) draining into each cell. The drainage direction layer is used to define which cells flow into the target cell. The number of accumulated cells is essentially a measure of the upstream catchment area. However, since the cell size of the HydroSHEDS data set depends on latitude, the cell accumulation value cannot directly be translated into drainage areas in square kilometers. Values range from 1 at topographic highs (river sources) to very large numbers (on the order of millions of cells) at the mouths of large rivers.  This dataset is at 30 arc-second resolution. The datasets available at 30 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/30ACC'); var flowAccumulation = dataset.select('b1'); var flowAccumulationVis = {   min: 0.0,   max: 500.0,   palette: [     '000000', '023858', '006837', '1a9850', '66bd63', 'a6d96a', 'd9ef8b',     'ffffbf', 'fee08b', 'fdae61', 'f46d43', 'd73027'   ], }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(flowAccumulation, flowAccumulationVis, 'Flow Accumulation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_30CONDEM:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_30CONDEM'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_30CONDEM.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_30CONDEM.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_30CONDEM(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This hydrologically conditioned elevation dataset is the result of an iterative conditioning and correction process. Note that the conditioning process alters the original DEM and may render it incorrect for applications other than deriving drainage directions. Endorheic basins (inland sinks) are ''seeded'' with a no-data cell at their lowest point in order to terminate the flow. Full details of the underlying digital elevation model are available in the HydroSHEDS website and documentation.  This dataset is at 30 arc-second resolution. The datasets available at 30 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/30CONDEM'); var elevation = dataset.select('b1'); var elevationVis = {   min: -50.0,   max: 3000.0,   gamma: 2.0, }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(elevation, elevationVis, 'Elevation');
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_30DIR:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_30DIR'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_30DIR.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_30DIR.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_30DIR(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This drainage direction dataset defines the direction of flow from each cell in the conditioned DEM to its steepest down-slope neighbor. Values of drainage direction vary from 1 to 128. All final outlet cells to the ocean are flagged with a value of 0. All cells that mark the lowest point of an endorheic basin (inland sink) are flagged with a value of -1. The drainage direction values follow the convention adopted by ESRI's flow direction implementation: 1=E, 2=SE, 4=S, 8=SW, 16=W, 32=NW, 64=N, 128=NE. \ \  This dataset is at 30 arc-second resolution. The datasets available at 30 arc-seconds are the Hydrologically Conditioned DEM, Drainage (Flow) Direction, and Flow Accumulation.  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.Image('WWF/HydroSHEDS/30DIR'); var drainageDirection = dataset.select('b1'); var drainageDirectionVis = {   min: 1.0,   max: 128.0,   palette: [     '000000', '023858', '006837', '1a9850', '66bd63', 'a6d96a', 'd9ef8b',     'ffffbf', 'fee08b', 'fdae61', 'f46d43', 'd73027'   ], }; Map.setCenter(-121.652, 38.022, 8); Map.addLayer(drainageDirection, drainageDirectionVis, 'Drainage Direction'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_1:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_1'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_1.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_1.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_1(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_1');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_10:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_10'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_10.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_10.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_10(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_10');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_11:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_11'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_11.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_11.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_11(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_11');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_12:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_12'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_12.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_12.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_12(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_12');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_2:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_2'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_2.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_2.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_2(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_2');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_3:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_3'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_3.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_3.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_3(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_3');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_4:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_4(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_4');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_5:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_5'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_5.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_5.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_5(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_5');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_6:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_6'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_6.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_6.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_6(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_6');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_7:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_7'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_7.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_7.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_7(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_7');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_8:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_8'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_8.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_8.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_8(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_8');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_Basins_hybas_9:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_Basins_hybas_9'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_9.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_Basins_hybas_9.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_Basins_hybas_9(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polygons of nested, hierarchical watersheds, based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data. The watersheds range from level 1 (coarse) to level 12 (detailed), using Pfastetter codes.  Technical documentation:  [https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf](https://hydrosheds.org/images/inpages/HydroBASINS_TechDoc_v1c.pdf)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_9');  var visualization = {   color: '808080',   strokeWidth: 1 };  dataset = dataset.draw(visualization);  Map.setCenter(-117.731, 53.033, 7); Map.addLayer(dataset, null, 'Basins'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class WWF_HydroSHEDS_v1_FreeFlowingRivers:
    def __init__(self,):
        self.sensor = 'WWF_HydroSHEDS_v1_FreeFlowingRivers'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/WWF_HydroSHEDS_v1_FreeFlowingRivers.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/WWF_HydroSHEDS_v1_FreeFlowingRivers.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_WWF_HydroSHEDS_v1_FreeFlowingRivers(example: str = ''):
        """
        HydroSHEDS is a mapping product that provides hydrographic information for regional and global-scale applications in a consistent format. It offers a suite of geo-referenced datasets (vector and raster) at various scales, including river networks, watershed boundaries, drainage directions, and flow accumulations. HydroSHEDS is based on elevation data obtained in 2000 by NASA's Shuttle Radar Topography Mission (SRTM).  This dataset provides polylines that represent river networks, derived from and consistent with other HydroSHEDS datasets. These data are based on 15 arc-seconds (approx. 500 m at the equator) resolution raster data.  [Mapping the world's free-flowing rivers: data set and technical documentation]( https://figshare.com/articles/Mapping_the_world_s_free-flowing_rivers_data_set_and_technical_documentation/7688801)  Note that the quality of the HydroSHEDS data is significantly lower for regions above 60 degrees northern latitude as there is no underlying SRTM elevation data available and thus a coarser-resolution DEM was (HYDRO1k provided by USGS).  HydroSHEDS was developed by the World Wildlife Fund (WWF) Conservation Science Program in partnership with the U.S. Geological Survey, the International Centre for Tropical Agriculture, The Nature Conservancy, and the Center for Environmental Systems Research of the University of Kassel, Germany. 
        :param example: var dataset = ee.FeatureCollection('WWF/HydroSHEDS/v1/FreeFlowingRivers');  // Paint 'RIV_ORD' (river order) value to an image for visualization. var datasetVis = ee.Image().byte().paint(dataset, 'RIV_ORD', 2);  var visParams = {   min: 1,   max: 10,   palette: ['08519c', '3182bd', '6baed6', 'bdd7e7', 'eff3ff'] };  Map.setCenter(-122.348, 45.738, 9); Map.addLayer(datasetVis, visParams, 'Free flowing rivers'); Map.addLayer(dataset, null, 'FeatureCollection', false);
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_Summer_UHI_yearly_pixel_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the fifth component. 
        :param example: var dataset = ee.ImageCollection('YALE/YCEO/UHI/Summer_UHI_yearly_pixel/v4');  var visualization = {   bands: ['Daytime'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c', 'fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'Daytime UHI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_UHI_all_averaged_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_UHI_all_averaged_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_UHI_all_averaged_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_UHI_all_averaged_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_UHI_all_averaged_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the first component. 
        :param example: var dataset = ee.Image('YALE/YCEO/UHI/UHI_all_averaged/v4');  var visualization = {   bands: ['all_daytime_UHI'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c', 'fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'All Daytime UHI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_UHI_monthly_averaged_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_UHI_monthly_averaged_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_UHI_monthly_averaged_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_UHI_monthly_averaged_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_UHI_monthly_averaged_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the second component. 
        :param example: var dataset = ee.Image('YALE/YCEO/UHI/UHI_monthly_averaged/v4');  var visualization = {   bands: ['Jan_day_UHI'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c', 'fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'January Daytime UHI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_UHI_yearly_averaged_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_UHI_yearly_averaged_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_UHI_yearly_averaged_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_UHI_yearly_averaged_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_UHI_yearly_averaged_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the third component. 
        :param example: var dataset = ee.ImageCollection('YALE/YCEO/UHI/UHI_yearly_averaged/v4');  var visualization = {   bands: ['Daytime'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c','fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'Daytime UHI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_UHI_yearly_pixel_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_UHI_yearly_pixel_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_UHI_yearly_pixel_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_UHI_yearly_pixel_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_UHI_yearly_pixel_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the fourth component. 
        :param example: var dataset = ee.ImageCollection('YALE/YCEO/UHI/UHI_yearly_pixel/v4');  var visualization = {   bands: ['Daytime'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c', 'fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'Daytime UHI'); 
        :return: None
        """
        return None
        

@geeData_registery.add()
class YALE_YCEO_UHI_Winter_UHI_yearly_pixel_v4:
    def __init__(self,):
        self.sensor = 'YALE_YCEO_UHI_Winter_UHI_yearly_pixel_v4'
        # Fetch the data
        # Check if the request was successful
        if os.path.exists('./datasets/YALE_YCEO_UHI_Winter_UHI_yearly_pixel_v4.json'):
            # Load the JSON content
            col = Collection(json.loads('./datasets/YALE_YCEO_UHI_Winter_UHI_yearly_pixel_v4.json'))
            self.bBox = col.bbox_list()
            self.timeInterval = col.datetime_interval()
        else:
            bBox = [[-180, -90, 180, 90]]
            self.bBox = tuple([BBox.from_list(x) for x in bBox])
            self.timeInterval = iter(tuple([(iso8601.parse_date("2014-10-03T00:00:00Z"), iso8601.parse_date("2024-03-13T18:04:55Z"))]))

    @staticmethod
    def get_YALE_YCEO_UHI_Winter_UHI_yearly_pixel_v4(example: str = ''):
        """
        This dataset contains annual, summertime, and wintertime surface urban heat island (SUHI) intensities for day and night for over 10,000 urban clusters throughout the world. The dataset was created using the MODIS 8-day TERRA and AQUA land surface temperature (LST) products, the Landscan urban extent database, the Global Multi-resolution Terrain Elevation Data 2010, and the European Space Agency (ESA) Climate Change Initiative (CCI) land cover data using the Simplified Urban-Extent Algorithm. The product is available both at the pixel level (at 300 m resolution after downscaling) and as urban cluster means from 2003 to 2018. The monthly composites are only available as urban cluster means.  A summary of older versions, including changes from the dataset created and analyzed in the originally published manuscript can be found on the [Yale Center for Earth Observation website](https://yceo.yale.edu/research/global-surface-uhi-explorer). The dataset can also be explored using the [Global Surface UHI Explorer web application](https://yceo.users.earthengine.app/view/uhimap).  The dataset is split into the following six components:  1. **UHI_all_averaged:** Image containing cluster-mean composite daytime and nighttime SUHI intensity for annual, summer, and winter.  2. **UHI_monthly_averaged:** Image containing cluster-mean monthly composites of daytime and nighttime SUHI intensity.  3. **UHI_yearly_averaged:** Image collection of cluster-mean yearly composites of daytime and nighttime SUHI intensity from 2003. to 2018.  4. **UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) annual daytime and nighttime SUHI intensity from 2003 to 2018.  5. **Summer_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) summertime daytime and nighttime SUHI intensity from 2003 to 2018.  6. **Winter_UHI_yearly_pixel:** Image collection of spatially disaggregated (nominal scale of 300 m) wintertime daytime and nighttime SUHI intensity from 2003 to 2018.  This asset is the sixth component. 
        :param example: var dataset = ee.ImageCollection('YALE/YCEO/UHI/Winter_UHI_yearly_pixel/v4');  var visualization = {   bands: ['Daytime'],   min: -1.5,   max: 7.5,   palette: [     '313695', '74add1', 'fed976', 'feb24c', 'fd8d3c', 'fc4e2a', 'e31a1c',     'b10026'] };  Map.setCenter(-74.7, 40.6, 7);  Map.addLayer(dataset, visualization, 'Daytime UHI'); 
        :return: None
        """
        return None
        
